{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EPL Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# making all pandas columns visable with display command\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, Activation, Flatten, Dense, Dropout, LSTM\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv(\"datasets/epl_data_train_onehot.csv\")\n",
    "test=pd.read_csv(\"datasets/epl_data_test_onehot.csv\")\n",
    "# print(train.head())\n",
    "# print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2660, 29)\n",
      "(2660,)\n"
     ]
    }
   ],
   "source": [
    "X_train = train.drop(columns = ['FTR'])\n",
    "y_train = train['FTR']\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(380, 29)\n",
      "(380,)\n"
     ]
    }
   ],
   "source": [
    "X_test = test.drop(columns = ['FTR'])\n",
    "y_test = test['FTR']\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = X_train.shape[1]\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 41-75-3\n",
    "# We first need to define the sequence of dependencies (the computational graph)\n",
    "# x = Input(shape=(20,32))\n",
    "def fit_model(learning_rate, hidden_layer, dropout, batch_size):\n",
    "    x = Input(shape=(columns,))\n",
    "    # h = Conv2D(32, (7, 7), strides=(2, 2))(x)\n",
    "    # h = Activation('relu')(x)\n",
    "    h = Flatten()(x)\n",
    "    for i in hidden_layer:\n",
    "        h = Dense(i, activation = 'relu')(h)\n",
    "    # for i in range(10):\n",
    "    #     h = Dense(75)(h)\n",
    "    h = Dropout(dropout)(h)\n",
    "    p = Activation('softmax')(h)\n",
    "\n",
    "    # Now that we have defined how to find p from x, we can create a \n",
    "    # model simply by saying what is input and what is output\n",
    "    model = Model(inputs=x, outputs=p)\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(lr=learning_rate), metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    \n",
    "    history = model.fit(X_train, y_train, batch_size=batch_size, epochs=200, validation_split=0.04)\n",
    "    return history,model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 29)]              0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 41)                1230      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 75)                3150      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 75)                0         \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 75)                0         \n",
      "=================================================================\n",
      "Total params: 4,380\n",
      "Trainable params: 4,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 4.8947 - accuracy: 0.0000e+00 - val_loss: 4.8878 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.8232 - accuracy: 0.0000e+00 - val_loss: 4.8218 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.7520 - accuracy: 0.0000e+00 - val_loss: 4.7560 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 4.6817 - accuracy: 0.0000e+00 - val_loss: 4.6900 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/200\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 4.6121 - accuracy: 0.0000e+00 - val_loss: 4.6234 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 4.5423 - accuracy: 0.0000e+00 - val_loss: 4.5561 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 4.4723 - accuracy: 3.9170e-04 - val_loss: 4.4869 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/200\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 4.4008 - accuracy: 0.0027 - val_loss: 4.4139 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/200\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 4.3265 - accuracy: 0.0082 - val_loss: 4.3334 - val_accuracy: 0.0093\n",
      "Epoch 10/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.2446 - accuracy: 0.0208 - val_loss: 4.2452 - val_accuracy: 0.0093\n",
      "Epoch 11/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.1517 - accuracy: 0.0372 - val_loss: 4.1417 - val_accuracy: 0.0187\n",
      "Epoch 12/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.0508 - accuracy: 0.0642 - val_loss: 4.0303 - val_accuracy: 0.0467\n",
      "Epoch 13/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.9465 - accuracy: 0.0960 - val_loss: 3.9179 - val_accuracy: 0.0654\n",
      "Epoch 14/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.8433 - accuracy: 0.1391 - val_loss: 3.8091 - val_accuracy: 0.1121\n",
      "Epoch 15/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.7429 - accuracy: 0.1770 - val_loss: 3.7052 - val_accuracy: 0.1402\n",
      "Epoch 16/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6450 - accuracy: 0.2154 - val_loss: 3.6031 - val_accuracy: 0.1776\n",
      "Epoch 17/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 3.5498 - accuracy: 0.2542 - val_loss: 3.5036 - val_accuracy: 0.2243\n",
      "Epoch 18/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.4567 - accuracy: 0.2946 - val_loss: 3.4066 - val_accuracy: 0.3084\n",
      "Epoch 19/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3651 - accuracy: 0.3380 - val_loss: 3.3109 - val_accuracy: 0.3458\n",
      "Epoch 20/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 3.2747 - accuracy: 0.3858 - val_loss: 3.2177 - val_accuracy: 0.3738\n",
      "Epoch 21/200\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 3.1861 - accuracy: 0.4152 - val_loss: 3.1270 - val_accuracy: 0.4299\n",
      "Epoch 22/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 3.0997 - accuracy: 0.4379 - val_loss: 3.0398 - val_accuracy: 0.4486\n",
      "Epoch 23/200\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 3.0159 - accuracy: 0.4407 - val_loss: 2.9542 - val_accuracy: 0.4766\n",
      "Epoch 24/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 2.9351 - accuracy: 0.4501 - val_loss: 2.8708 - val_accuracy: 0.4673\n",
      "Epoch 25/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.8578 - accuracy: 0.4567 - val_loss: 2.7909 - val_accuracy: 0.4673\n",
      "Epoch 26/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 2.7841 - accuracy: 0.4622 - val_loss: 2.7143 - val_accuracy: 0.4766\n",
      "Epoch 27/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 2.7139 - accuracy: 0.4665 - val_loss: 2.6418 - val_accuracy: 0.4673\n",
      "Epoch 28/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.6471 - accuracy: 0.4712 - val_loss: 2.5729 - val_accuracy: 0.4673\n",
      "Epoch 29/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 2.5832 - accuracy: 0.4732 - val_loss: 2.5076 - val_accuracy: 0.4673\n",
      "Epoch 30/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 2.5224 - accuracy: 0.4759 - val_loss: 2.4455 - val_accuracy: 0.4673\n",
      "Epoch 31/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4645 - accuracy: 0.4779 - val_loss: 2.3864 - val_accuracy: 0.4673\n",
      "Epoch 32/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4094 - accuracy: 0.4763 - val_loss: 2.3300 - val_accuracy: 0.4766\n",
      "Epoch 33/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3566 - accuracy: 0.4767 - val_loss: 2.2761 - val_accuracy: 0.4766\n",
      "Epoch 34/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3060 - accuracy: 0.4783 - val_loss: 2.2247 - val_accuracy: 0.4766\n",
      "Epoch 35/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2576 - accuracy: 0.4767 - val_loss: 2.1759 - val_accuracy: 0.4766\n",
      "Epoch 36/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 2.2112 - accuracy: 0.4794 - val_loss: 2.1294 - val_accuracy: 0.4766\n",
      "Epoch 37/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 2.1665 - accuracy: 0.4810 - val_loss: 2.0853 - val_accuracy: 0.4766\n",
      "Epoch 38/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 2.1238 - accuracy: 0.4826 - val_loss: 2.0429 - val_accuracy: 0.4766\n",
      "Epoch 39/200\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 2.0824 - accuracy: 0.4826 - val_loss: 2.0013 - val_accuracy: 0.4766\n",
      "Epoch 40/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 2.0423 - accuracy: 0.4826 - val_loss: 1.9610 - val_accuracy: 0.4766\n",
      "Epoch 41/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0037 - accuracy: 0.4834 - val_loss: 1.9223 - val_accuracy: 0.4766\n",
      "Epoch 42/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.9665 - accuracy: 0.4849 - val_loss: 1.8853 - val_accuracy: 0.4766\n",
      "Epoch 43/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.9306 - accuracy: 0.4853 - val_loss: 1.8503 - val_accuracy: 0.4766\n",
      "Epoch 44/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.8961 - accuracy: 0.4865 - val_loss: 1.8165 - val_accuracy: 0.4766\n",
      "Epoch 45/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.8628 - accuracy: 0.4865 - val_loss: 1.7840 - val_accuracy: 0.4766\n",
      "Epoch 46/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.8309 - accuracy: 0.4884 - val_loss: 1.7530 - val_accuracy: 0.4766\n",
      "Epoch 47/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.8002 - accuracy: 0.4888 - val_loss: 1.7235 - val_accuracy: 0.4766\n",
      "Epoch 48/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.7708 - accuracy: 0.4881 - val_loss: 1.6949 - val_accuracy: 0.4766\n",
      "Epoch 49/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 1s 4ms/step - loss: 1.7424 - accuracy: 0.4884 - val_loss: 1.6677 - val_accuracy: 0.4766\n",
      "Epoch 50/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.7151 - accuracy: 0.4884 - val_loss: 1.6412 - val_accuracy: 0.4766\n",
      "Epoch 51/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6889 - accuracy: 0.4861 - val_loss: 1.6161 - val_accuracy: 0.4766\n",
      "Epoch 52/200\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 1.6637 - accuracy: 0.4865 - val_loss: 1.5917 - val_accuracy: 0.4766\n",
      "Epoch 53/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6392 - accuracy: 0.4869 - val_loss: 1.5680 - val_accuracy: 0.4766\n",
      "Epoch 54/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6157 - accuracy: 0.4869 - val_loss: 1.5455 - val_accuracy: 0.4766\n",
      "Epoch 55/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 1.5930 - accuracy: 0.4869 - val_loss: 1.5237 - val_accuracy: 0.4766\n",
      "Epoch 56/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5711 - accuracy: 0.4873 - val_loss: 1.5026 - val_accuracy: 0.4766\n",
      "Epoch 57/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5500 - accuracy: 0.4861 - val_loss: 1.4826 - val_accuracy: 0.4766\n",
      "Epoch 58/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 1.5295 - accuracy: 0.4861 - val_loss: 1.4631 - val_accuracy: 0.4766\n",
      "Epoch 59/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 1.5097 - accuracy: 0.4869 - val_loss: 1.4443 - val_accuracy: 0.4766\n",
      "Epoch 60/200\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 1.4908 - accuracy: 0.4861 - val_loss: 1.4264 - val_accuracy: 0.4766\n",
      "Epoch 61/200\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 1.4723 - accuracy: 0.4857 - val_loss: 1.4089 - val_accuracy: 0.4766\n",
      "Epoch 62/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 1.4546 - accuracy: 0.4853 - val_loss: 1.3924 - val_accuracy: 0.4766\n",
      "Epoch 63/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.4375 - accuracy: 0.4845 - val_loss: 1.3763 - val_accuracy: 0.4766\n",
      "Epoch 64/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.4210 - accuracy: 0.4841 - val_loss: 1.3611 - val_accuracy: 0.4860\n",
      "Epoch 65/200\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 1.4051 - accuracy: 0.4841 - val_loss: 1.3462 - val_accuracy: 0.4860\n",
      "Epoch 66/200\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 1.3898 - accuracy: 0.4849 - val_loss: 1.3319 - val_accuracy: 0.4860\n",
      "Epoch 67/200\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 1.3750 - accuracy: 0.4853 - val_loss: 1.3182 - val_accuracy: 0.4860\n",
      "Epoch 68/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.3608 - accuracy: 0.4845 - val_loss: 1.3052 - val_accuracy: 0.4860\n",
      "Epoch 69/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.3472 - accuracy: 0.4837 - val_loss: 1.2927 - val_accuracy: 0.4860\n",
      "Epoch 70/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 1.3339 - accuracy: 0.4834 - val_loss: 1.2807 - val_accuracy: 0.4766\n",
      "Epoch 71/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 1.3213 - accuracy: 0.4837 - val_loss: 1.2690 - val_accuracy: 0.4766\n",
      "Epoch 72/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.3092 - accuracy: 0.4837 - val_loss: 1.2580 - val_accuracy: 0.4766\n",
      "Epoch 73/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.2975 - accuracy: 0.4822 - val_loss: 1.2475 - val_accuracy: 0.4766\n",
      "Epoch 74/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.2863 - accuracy: 0.4814 - val_loss: 1.2373 - val_accuracy: 0.4766\n",
      "Epoch 75/200\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 1.2756 - accuracy: 0.4822 - val_loss: 1.2278 - val_accuracy: 0.4860\n",
      "Epoch 76/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.2654 - accuracy: 0.4818 - val_loss: 1.2185 - val_accuracy: 0.4860\n",
      "Epoch 77/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.2556 - accuracy: 0.4834 - val_loss: 1.2098 - val_accuracy: 0.4860\n",
      "Epoch 78/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.2463 - accuracy: 0.4826 - val_loss: 1.2013 - val_accuracy: 0.4860\n",
      "Epoch 79/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.2374 - accuracy: 0.4830 - val_loss: 1.1933 - val_accuracy: 0.4860\n",
      "Epoch 80/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.2288 - accuracy: 0.4830 - val_loss: 1.1857 - val_accuracy: 0.4860\n",
      "Epoch 81/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.2207 - accuracy: 0.4826 - val_loss: 1.1783 - val_accuracy: 0.4860\n",
      "Epoch 82/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.2130 - accuracy: 0.4834 - val_loss: 1.1714 - val_accuracy: 0.4860\n",
      "Epoch 83/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.2057 - accuracy: 0.4834 - val_loss: 1.1647 - val_accuracy: 0.4860\n",
      "Epoch 84/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 1.1986 - accuracy: 0.4837 - val_loss: 1.1583 - val_accuracy: 0.4860\n",
      "Epoch 85/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.1919 - accuracy: 0.4834 - val_loss: 1.1522 - val_accuracy: 0.4860\n",
      "Epoch 86/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.1856 - accuracy: 0.4857 - val_loss: 1.1462 - val_accuracy: 0.4860\n",
      "Epoch 87/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.1795 - accuracy: 0.4869 - val_loss: 1.1406 - val_accuracy: 0.4953\n",
      "Epoch 88/200\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 1.1737 - accuracy: 0.4869 - val_loss: 1.1353 - val_accuracy: 0.4953\n",
      "Epoch 89/200\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 1.1682 - accuracy: 0.4861 - val_loss: 1.1301 - val_accuracy: 0.4953\n",
      "Epoch 90/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 1.1629 - accuracy: 0.4873 - val_loss: 1.1253 - val_accuracy: 0.4860\n",
      "Epoch 91/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.1579 - accuracy: 0.4857 - val_loss: 1.1205 - val_accuracy: 0.4953\n",
      "Epoch 92/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.1531 - accuracy: 0.4861 - val_loss: 1.1159 - val_accuracy: 0.4860\n",
      "Epoch 93/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.1486 - accuracy: 0.4884 - val_loss: 1.1116 - val_accuracy: 0.4953\n",
      "Epoch 94/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.1442 - accuracy: 0.4888 - val_loss: 1.1075 - val_accuracy: 0.4860\n",
      "Epoch 95/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.1400 - accuracy: 0.4908 - val_loss: 1.1032 - val_accuracy: 0.4860\n",
      "Epoch 96/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.1360 - accuracy: 0.4912 - val_loss: 1.0995 - val_accuracy: 0.4860\n",
      "Epoch 97/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.1322 - accuracy: 0.4904 - val_loss: 1.0958 - val_accuracy: 0.4860\n",
      "Epoch 98/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.1286 - accuracy: 0.4908 - val_loss: 1.0922 - val_accuracy: 0.4860\n",
      "Epoch 99/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.1252 - accuracy: 0.4908 - val_loss: 1.0888 - val_accuracy: 0.4860\n",
      "Epoch 100/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.1218 - accuracy: 0.4892 - val_loss: 1.0855 - val_accuracy: 0.5047\n",
      "Epoch 101/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.1186 - accuracy: 0.4896 - val_loss: 1.0822 - val_accuracy: 0.5047\n",
      "Epoch 102/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.1155 - accuracy: 0.4904 - val_loss: 1.0792 - val_accuracy: 0.5047\n",
      "Epoch 103/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.1125 - accuracy: 0.4908 - val_loss: 1.0761 - val_accuracy: 0.5047\n",
      "Epoch 104/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.1098 - accuracy: 0.4904 - val_loss: 1.0733 - val_accuracy: 0.5047\n",
      "Epoch 105/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.1070 - accuracy: 0.4908 - val_loss: 1.0704 - val_accuracy: 0.5047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.1044 - accuracy: 0.4916 - val_loss: 1.0676 - val_accuracy: 0.5047\n",
      "Epoch 107/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.1018 - accuracy: 0.4928 - val_loss: 1.0651 - val_accuracy: 0.5140\n",
      "Epoch 108/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0994 - accuracy: 0.4924 - val_loss: 1.0624 - val_accuracy: 0.5140\n",
      "Epoch 109/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0971 - accuracy: 0.4935 - val_loss: 1.0599 - val_accuracy: 0.5140\n",
      "Epoch 110/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0948 - accuracy: 0.4935 - val_loss: 1.0574 - val_accuracy: 0.5140\n",
      "Epoch 111/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 1.0926 - accuracy: 0.4943 - val_loss: 1.0552 - val_accuracy: 0.5140\n",
      "Epoch 112/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 1.0905 - accuracy: 0.4928 - val_loss: 1.0526 - val_accuracy: 0.5140\n",
      "Epoch 113/200\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 1.0884 - accuracy: 0.4943 - val_loss: 1.0507 - val_accuracy: 0.5140\n",
      "Epoch 114/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0864 - accuracy: 0.4943 - val_loss: 1.0487 - val_accuracy: 0.5140\n",
      "Epoch 115/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0845 - accuracy: 0.4947 - val_loss: 1.0462 - val_accuracy: 0.5140\n",
      "Epoch 116/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0827 - accuracy: 0.4935 - val_loss: 1.0443 - val_accuracy: 0.5140\n",
      "Epoch 117/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0808 - accuracy: 0.4928 - val_loss: 1.0424 - val_accuracy: 0.5140\n",
      "Epoch 118/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 1.0791 - accuracy: 0.4947 - val_loss: 1.0403 - val_accuracy: 0.5140\n",
      "Epoch 119/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0774 - accuracy: 0.4931 - val_loss: 1.0384 - val_accuracy: 0.5140\n",
      "Epoch 120/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0758 - accuracy: 0.4939 - val_loss: 1.0368 - val_accuracy: 0.5140\n",
      "Epoch 121/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0742 - accuracy: 0.4959 - val_loss: 1.0350 - val_accuracy: 0.5140\n",
      "Epoch 122/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0727 - accuracy: 0.4955 - val_loss: 1.0331 - val_accuracy: 0.5140\n",
      "Epoch 123/200\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 1.0712 - accuracy: 0.4963 - val_loss: 1.0315 - val_accuracy: 0.5140\n",
      "Epoch 124/200\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 1.0697 - accuracy: 0.4943 - val_loss: 1.0298 - val_accuracy: 0.5140\n",
      "Epoch 125/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0683 - accuracy: 0.4963 - val_loss: 1.0281 - val_accuracy: 0.5140\n",
      "Epoch 126/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 1.0670 - accuracy: 0.4955 - val_loss: 1.0265 - val_accuracy: 0.5140\n",
      "Epoch 127/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0657 - accuracy: 0.4971 - val_loss: 1.0251 - val_accuracy: 0.5140\n",
      "Epoch 128/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 1.0644 - accuracy: 0.4975 - val_loss: 1.0235 - val_accuracy: 0.5140\n",
      "Epoch 129/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0631 - accuracy: 0.4967 - val_loss: 1.0223 - val_accuracy: 0.5140\n",
      "Epoch 130/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0619 - accuracy: 0.4967 - val_loss: 1.0207 - val_accuracy: 0.5140\n",
      "Epoch 131/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0607 - accuracy: 0.4982 - val_loss: 1.0195 - val_accuracy: 0.5140\n",
      "Epoch 132/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0596 - accuracy: 0.4963 - val_loss: 1.0180 - val_accuracy: 0.5140\n",
      "Epoch 133/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0585 - accuracy: 0.4986 - val_loss: 1.0169 - val_accuracy: 0.5140\n",
      "Epoch 134/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0574 - accuracy: 0.4963 - val_loss: 1.0157 - val_accuracy: 0.5140\n",
      "Epoch 135/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0563 - accuracy: 0.4963 - val_loss: 1.0146 - val_accuracy: 0.5140\n",
      "Epoch 136/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0553 - accuracy: 0.4975 - val_loss: 1.0132 - val_accuracy: 0.5140\n",
      "Epoch 137/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0542 - accuracy: 0.4975 - val_loss: 1.0122 - val_accuracy: 0.5140\n",
      "Epoch 138/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0534 - accuracy: 0.4959 - val_loss: 1.0109 - val_accuracy: 0.5140\n",
      "Epoch 139/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0523 - accuracy: 0.4967 - val_loss: 1.0098 - val_accuracy: 0.5140\n",
      "Epoch 140/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0514 - accuracy: 0.4986 - val_loss: 1.0088 - val_accuracy: 0.5140\n",
      "Epoch 141/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0505 - accuracy: 0.4967 - val_loss: 1.0077 - val_accuracy: 0.5140\n",
      "Epoch 142/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0496 - accuracy: 0.4963 - val_loss: 1.0066 - val_accuracy: 0.5140\n",
      "Epoch 143/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0487 - accuracy: 0.4975 - val_loss: 1.0055 - val_accuracy: 0.5140\n",
      "Epoch 144/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0478 - accuracy: 0.4975 - val_loss: 1.0045 - val_accuracy: 0.5140\n",
      "Epoch 145/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0470 - accuracy: 0.4978 - val_loss: 1.0036 - val_accuracy: 0.5140\n",
      "Epoch 146/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0462 - accuracy: 0.4975 - val_loss: 1.0025 - val_accuracy: 0.5234\n",
      "Epoch 147/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 1.0453 - accuracy: 0.4982 - val_loss: 1.0015 - val_accuracy: 0.5234\n",
      "Epoch 148/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0446 - accuracy: 0.4967 - val_loss: 1.0007 - val_accuracy: 0.5234\n",
      "Epoch 149/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 1.0438 - accuracy: 0.4975 - val_loss: 0.9995 - val_accuracy: 0.5234\n",
      "Epoch 150/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0430 - accuracy: 0.4975 - val_loss: 0.9988 - val_accuracy: 0.5234\n",
      "Epoch 151/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0423 - accuracy: 0.4975 - val_loss: 0.9980 - val_accuracy: 0.5234\n",
      "Epoch 152/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0415 - accuracy: 0.4978 - val_loss: 0.9970 - val_accuracy: 0.5234\n",
      "Epoch 153/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0408 - accuracy: 0.4971 - val_loss: 0.9961 - val_accuracy: 0.5234\n",
      "Epoch 154/200\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 1.0401 - accuracy: 0.4990 - val_loss: 0.9953 - val_accuracy: 0.5234\n",
      "Epoch 155/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0394 - accuracy: 0.4978 - val_loss: 0.9944 - val_accuracy: 0.5234\n",
      "Epoch 156/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0388 - accuracy: 0.4986 - val_loss: 0.9936 - val_accuracy: 0.5234\n",
      "Epoch 157/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0381 - accuracy: 0.4994 - val_loss: 0.9928 - val_accuracy: 0.5234\n",
      "Epoch 158/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0375 - accuracy: 0.4994 - val_loss: 0.9920 - val_accuracy: 0.5234\n",
      "Epoch 159/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0368 - accuracy: 0.4990 - val_loss: 0.9915 - val_accuracy: 0.5234\n",
      "Epoch 160/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0362 - accuracy: 0.4994 - val_loss: 0.9905 - val_accuracy: 0.5234\n",
      "Epoch 161/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0355 - accuracy: 0.5014 - val_loss: 0.9898 - val_accuracy: 0.5234\n",
      "Epoch 162/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0350 - accuracy: 0.5002 - val_loss: 0.9891 - val_accuracy: 0.5234\n",
      "Epoch 163/200\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 1.0343 - accuracy: 0.5010 - val_loss: 0.9884 - val_accuracy: 0.5234\n",
      "Epoch 164/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0337 - accuracy: 0.5010 - val_loss: 0.9876 - val_accuracy: 0.5234\n",
      "Epoch 165/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0332 - accuracy: 0.5006 - val_loss: 0.9869 - val_accuracy: 0.5234\n",
      "Epoch 166/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0327 - accuracy: 0.5002 - val_loss: 0.9862 - val_accuracy: 0.5234\n",
      "Epoch 167/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0321 - accuracy: 0.5010 - val_loss: 0.9855 - val_accuracy: 0.5234\n",
      "Epoch 168/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0316 - accuracy: 0.5006 - val_loss: 0.9850 - val_accuracy: 0.5234\n",
      "Epoch 169/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0310 - accuracy: 0.5006 - val_loss: 0.9843 - val_accuracy: 0.5234\n",
      "Epoch 170/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0305 - accuracy: 0.5014 - val_loss: 0.9838 - val_accuracy: 0.5234\n",
      "Epoch 171/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0299 - accuracy: 0.5014 - val_loss: 0.9830 - val_accuracy: 0.5234\n",
      "Epoch 172/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0295 - accuracy: 0.5010 - val_loss: 0.9826 - val_accuracy: 0.5234\n",
      "Epoch 173/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0289 - accuracy: 0.5014 - val_loss: 0.9820 - val_accuracy: 0.5234\n",
      "Epoch 174/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0284 - accuracy: 0.5022 - val_loss: 0.9813 - val_accuracy: 0.5234\n",
      "Epoch 175/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0279 - accuracy: 0.5014 - val_loss: 0.9808 - val_accuracy: 0.5234\n",
      "Epoch 176/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0275 - accuracy: 0.5010 - val_loss: 0.9803 - val_accuracy: 0.5234\n",
      "Epoch 177/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0270 - accuracy: 0.5025 - val_loss: 0.9796 - val_accuracy: 0.5234\n",
      "Epoch 178/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0266 - accuracy: 0.5029 - val_loss: 0.9791 - val_accuracy: 0.5234\n",
      "Epoch 179/200\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 1.0261 - accuracy: 0.5025 - val_loss: 0.9783 - val_accuracy: 0.5234\n",
      "Epoch 180/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0256 - accuracy: 0.5025 - val_loss: 0.9779 - val_accuracy: 0.5234\n",
      "Epoch 181/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0252 - accuracy: 0.5025 - val_loss: 0.9774 - val_accuracy: 0.5234\n",
      "Epoch 182/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0248 - accuracy: 0.5022 - val_loss: 0.9767 - val_accuracy: 0.5234\n",
      "Epoch 183/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0243 - accuracy: 0.5018 - val_loss: 0.9763 - val_accuracy: 0.5234\n",
      "Epoch 184/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0238 - accuracy: 0.5018 - val_loss: 0.9758 - val_accuracy: 0.5234\n",
      "Epoch 185/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0234 - accuracy: 0.5033 - val_loss: 0.9751 - val_accuracy: 0.5234\n",
      "Epoch 186/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0230 - accuracy: 0.5025 - val_loss: 0.9747 - val_accuracy: 0.5234\n",
      "Epoch 187/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0227 - accuracy: 0.5033 - val_loss: 0.9742 - val_accuracy: 0.5234\n",
      "Epoch 188/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0222 - accuracy: 0.5025 - val_loss: 0.9737 - val_accuracy: 0.5234\n",
      "Epoch 189/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0219 - accuracy: 0.5033 - val_loss: 0.9732 - val_accuracy: 0.5234\n",
      "Epoch 190/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 1.0214 - accuracy: 0.5025 - val_loss: 0.9728 - val_accuracy: 0.5234\n",
      "Epoch 191/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 1.0210 - accuracy: 0.5045 - val_loss: 0.9723 - val_accuracy: 0.5234\n",
      "Epoch 192/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0207 - accuracy: 0.5045 - val_loss: 0.9717 - val_accuracy: 0.5234\n",
      "Epoch 193/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0203 - accuracy: 0.5033 - val_loss: 0.9712 - val_accuracy: 0.5234\n",
      "Epoch 194/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0199 - accuracy: 0.5045 - val_loss: 0.9708 - val_accuracy: 0.5234\n",
      "Epoch 195/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0195 - accuracy: 0.5045 - val_loss: 0.9701 - val_accuracy: 0.5234\n",
      "Epoch 196/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0191 - accuracy: 0.5049 - val_loss: 0.9698 - val_accuracy: 0.5234\n",
      "Epoch 197/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0188 - accuracy: 0.5049 - val_loss: 0.9692 - val_accuracy: 0.5234\n",
      "Epoch 198/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0185 - accuracy: 0.5053 - val_loss: 0.9688 - val_accuracy: 0.5234\n",
      "Epoch 199/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0181 - accuracy: 0.5065 - val_loss: 0.9684 - val_accuracy: 0.5234\n",
      "Epoch 200/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0177 - accuracy: 0.5045 - val_loss: 0.9678 - val_accuracy: 0.5234\n",
      "0.5233644843101501 {'loss': 1.0177156925201416, 'accuracy': 0.5045045018196106, 'val_loss': 0.9678374528884888, 'val_accuracy': 0.5233644843101501}\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 29)]              0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 41)                1230      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 75)                3150      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 75)                0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 75)                0         \n",
      "=================================================================\n",
      "Total params: 4,380\n",
      "Trainable params: 4,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 4.6610 - accuracy: 0.0000e+00 - val_loss: 4.7716 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.6225 - accuracy: 0.0000e+00 - val_loss: 4.7336 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.5846 - accuracy: 0.0000e+00 - val_loss: 4.6959 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.5471 - accuracy: 3.9170e-04 - val_loss: 4.6583 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.5101 - accuracy: 0.0012 - val_loss: 4.6214 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.4736 - accuracy: 0.0016 - val_loss: 4.5846 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.4374 - accuracy: 0.0024 - val_loss: 4.5487 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.4016 - accuracy: 0.0035 - val_loss: 4.5130 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 2ms/step - loss: 4.3662 - accuracy: 0.0043 - val_loss: 4.4778 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.3311 - accuracy: 0.0051 - val_loss: 4.4434 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.2963 - accuracy: 0.0082 - val_loss: 4.4089 - val_accuracy: 0.0093\n",
      "Epoch 12/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.2619 - accuracy: 0.0125 - val_loss: 4.3749 - val_accuracy: 0.0093\n",
      "Epoch 13/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.2276 - accuracy: 0.0168 - val_loss: 4.3415 - val_accuracy: 0.0093\n",
      "Epoch 14/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.1936 - accuracy: 0.0212 - val_loss: 4.3078 - val_accuracy: 0.0187\n",
      "Epoch 15/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.1596 - accuracy: 0.0262 - val_loss: 4.2746 - val_accuracy: 0.0187\n",
      "Epoch 16/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.1258 - accuracy: 0.0341 - val_loss: 4.2413 - val_accuracy: 0.0187\n",
      "Epoch 17/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.0921 - accuracy: 0.0439 - val_loss: 4.2087 - val_accuracy: 0.0374\n",
      "Epoch 18/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.0585 - accuracy: 0.0584 - val_loss: 4.1756 - val_accuracy: 0.0561\n",
      "Epoch 19/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.0249 - accuracy: 0.0713 - val_loss: 4.1426 - val_accuracy: 0.0748\n",
      "Epoch 20/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.9911 - accuracy: 0.0842 - val_loss: 4.1095 - val_accuracy: 0.0841\n",
      "Epoch 21/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.9570 - accuracy: 0.1007 - val_loss: 4.0766 - val_accuracy: 0.1028\n",
      "Epoch 22/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.9227 - accuracy: 0.1179 - val_loss: 4.0429 - val_accuracy: 0.1028\n",
      "Epoch 23/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.8878 - accuracy: 0.1324 - val_loss: 4.0093 - val_accuracy: 0.1028\n",
      "Epoch 24/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.8522 - accuracy: 0.1508 - val_loss: 3.9755 - val_accuracy: 0.1028\n",
      "Epoch 25/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.8156 - accuracy: 0.1633 - val_loss: 3.9411 - val_accuracy: 0.1121\n",
      "Epoch 26/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.7782 - accuracy: 0.1806 - val_loss: 3.9065 - val_accuracy: 0.1121\n",
      "Epoch 27/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.7399 - accuracy: 0.1962 - val_loss: 3.8694 - val_accuracy: 0.1215\n",
      "Epoch 28/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.7005 - accuracy: 0.2096 - val_loss: 3.8314 - val_accuracy: 0.1308\n",
      "Epoch 29/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.6594 - accuracy: 0.2209 - val_loss: 3.7916 - val_accuracy: 0.1308\n",
      "Epoch 30/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.6165 - accuracy: 0.2350 - val_loss: 3.7503 - val_accuracy: 0.1402\n",
      "Epoch 31/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 3.5715 - accuracy: 0.2476 - val_loss: 3.7062 - val_accuracy: 0.1682\n",
      "Epoch 32/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 3.5247 - accuracy: 0.2523 - val_loss: 3.6590 - val_accuracy: 0.1682\n",
      "Epoch 33/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.4760 - accuracy: 0.2589 - val_loss: 3.6091 - val_accuracy: 0.1682\n",
      "Epoch 34/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 3.4251 - accuracy: 0.2671 - val_loss: 3.5512 - val_accuracy: 0.1682\n",
      "Epoch 35/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.3722 - accuracy: 0.2765 - val_loss: 3.4903 - val_accuracy: 0.1682\n",
      "Epoch 36/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 3.3184 - accuracy: 0.2789 - val_loss: 3.4287 - val_accuracy: 0.1589\n",
      "Epoch 37/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 3.2639 - accuracy: 0.2852 - val_loss: 3.3671 - val_accuracy: 0.1776\n",
      "Epoch 38/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 3.2095 - accuracy: 0.2875 - val_loss: 3.3060 - val_accuracy: 0.1869\n",
      "Epoch 39/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 3.1551 - accuracy: 0.2914 - val_loss: 3.2456 - val_accuracy: 0.1869\n",
      "Epoch 40/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 3.1010 - accuracy: 0.2953 - val_loss: 3.1867 - val_accuracy: 0.1963\n",
      "Epoch 41/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 3.0475 - accuracy: 0.2981 - val_loss: 3.1280 - val_accuracy: 0.2056\n",
      "Epoch 42/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.9947 - accuracy: 0.3004 - val_loss: 3.0708 - val_accuracy: 0.2056\n",
      "Epoch 43/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.9425 - accuracy: 0.3024 - val_loss: 3.0151 - val_accuracy: 0.2056\n",
      "Epoch 44/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.8913 - accuracy: 0.3055 - val_loss: 2.9601 - val_accuracy: 0.2150\n",
      "Epoch 45/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 2.8408 - accuracy: 0.3079 - val_loss: 2.9076 - val_accuracy: 0.2150\n",
      "Epoch 46/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 2.7916 - accuracy: 0.3106 - val_loss: 2.8557 - val_accuracy: 0.2430\n",
      "Epoch 47/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 2.7433 - accuracy: 0.3114 - val_loss: 2.8050 - val_accuracy: 0.2430\n",
      "Epoch 48/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 2.6961 - accuracy: 0.3200 - val_loss: 2.7551 - val_accuracy: 0.2710\n",
      "Epoch 49/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.6500 - accuracy: 0.3255 - val_loss: 2.7061 - val_accuracy: 0.2710\n",
      "Epoch 50/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.6050 - accuracy: 0.3314 - val_loss: 2.6587 - val_accuracy: 0.2710\n",
      "Epoch 51/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5611 - accuracy: 0.3349 - val_loss: 2.6128 - val_accuracy: 0.2710\n",
      "Epoch 52/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5183 - accuracy: 0.3427 - val_loss: 2.5679 - val_accuracy: 0.2617\n",
      "Epoch 53/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.4765 - accuracy: 0.3455 - val_loss: 2.5239 - val_accuracy: 0.2804\n",
      "Epoch 54/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4357 - accuracy: 0.3525 - val_loss: 2.4811 - val_accuracy: 0.2710\n",
      "Epoch 55/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3960 - accuracy: 0.3596 - val_loss: 2.4391 - val_accuracy: 0.2804\n",
      "Epoch 56/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.3573 - accuracy: 0.3639 - val_loss: 2.3984 - val_accuracy: 0.2804\n",
      "Epoch 57/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.3198 - accuracy: 0.3709 - val_loss: 2.3588 - val_accuracy: 0.2804\n",
      "Epoch 58/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.2832 - accuracy: 0.3792 - val_loss: 2.3203 - val_accuracy: 0.3084\n",
      "Epoch 59/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2476 - accuracy: 0.3823 - val_loss: 2.2830 - val_accuracy: 0.3084\n",
      "Epoch 60/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2131 - accuracy: 0.3858 - val_loss: 2.2471 - val_accuracy: 0.3084\n",
      "Epoch 61/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1795 - accuracy: 0.3890 - val_loss: 2.2117 - val_accuracy: 0.3364\n",
      "Epoch 62/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.1469 - accuracy: 0.3929 - val_loss: 2.1777 - val_accuracy: 0.3364\n",
      "Epoch 63/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.1153 - accuracy: 0.3968 - val_loss: 2.1447 - val_accuracy: 0.3458\n",
      "Epoch 64/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0846 - accuracy: 0.3995 - val_loss: 2.1127 - val_accuracy: 0.3458\n",
      "Epoch 65/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0549 - accuracy: 0.4034 - val_loss: 2.0817 - val_accuracy: 0.3551\n",
      "Epoch 66/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.0261 - accuracy: 0.4078 - val_loss: 2.0515 - val_accuracy: 0.3832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.9981 - accuracy: 0.4144 - val_loss: 2.0229 - val_accuracy: 0.3925\n",
      "Epoch 68/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.9710 - accuracy: 0.4179 - val_loss: 1.9946 - val_accuracy: 0.3832\n",
      "Epoch 69/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9447 - accuracy: 0.4203 - val_loss: 1.9673 - val_accuracy: 0.3925\n",
      "Epoch 70/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9191 - accuracy: 0.4269 - val_loss: 1.9409 - val_accuracy: 0.3925\n",
      "Epoch 71/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.8944 - accuracy: 0.4293 - val_loss: 1.9155 - val_accuracy: 0.3925\n",
      "Epoch 72/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.8705 - accuracy: 0.4320 - val_loss: 1.8908 - val_accuracy: 0.3925\n",
      "Epoch 73/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.8473 - accuracy: 0.4367 - val_loss: 1.8669 - val_accuracy: 0.3925\n",
      "Epoch 74/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.8248 - accuracy: 0.4371 - val_loss: 1.8439 - val_accuracy: 0.3925\n",
      "Epoch 75/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.8031 - accuracy: 0.4387 - val_loss: 1.8216 - val_accuracy: 0.3925\n",
      "Epoch 76/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.7821 - accuracy: 0.4399 - val_loss: 1.8000 - val_accuracy: 0.4019\n",
      "Epoch 77/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.7617 - accuracy: 0.4410 - val_loss: 1.7792 - val_accuracy: 0.4019\n",
      "Epoch 78/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.7421 - accuracy: 0.4426 - val_loss: 1.7590 - val_accuracy: 0.4019\n",
      "Epoch 79/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.7230 - accuracy: 0.4450 - val_loss: 1.7396 - val_accuracy: 0.4019\n",
      "Epoch 80/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.7045 - accuracy: 0.4465 - val_loss: 1.7209 - val_accuracy: 0.4019\n",
      "Epoch 81/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.6866 - accuracy: 0.4485 - val_loss: 1.7026 - val_accuracy: 0.4019\n",
      "Epoch 82/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.6693 - accuracy: 0.4477 - val_loss: 1.6849 - val_accuracy: 0.3925\n",
      "Epoch 83/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.6525 - accuracy: 0.4481 - val_loss: 1.6679 - val_accuracy: 0.3925\n",
      "Epoch 84/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.6363 - accuracy: 0.4508 - val_loss: 1.6512 - val_accuracy: 0.3832\n",
      "Epoch 85/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.6206 - accuracy: 0.4512 - val_loss: 1.6352 - val_accuracy: 0.3832\n",
      "Epoch 86/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.6054 - accuracy: 0.4544 - val_loss: 1.6199 - val_accuracy: 0.3832\n",
      "Epoch 87/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.5907 - accuracy: 0.4548 - val_loss: 1.6049 - val_accuracy: 0.3832\n",
      "Epoch 88/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.5765 - accuracy: 0.4567 - val_loss: 1.5902 - val_accuracy: 0.3832\n",
      "Epoch 89/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.5626 - accuracy: 0.4583 - val_loss: 1.5763 - val_accuracy: 0.3738\n",
      "Epoch 90/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.5493 - accuracy: 0.4602 - val_loss: 1.5626 - val_accuracy: 0.3738\n",
      "Epoch 91/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.5363 - accuracy: 0.4591 - val_loss: 1.5493 - val_accuracy: 0.3832\n",
      "Epoch 92/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.5237 - accuracy: 0.4599 - val_loss: 1.5365 - val_accuracy: 0.3925\n",
      "Epoch 93/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.5115 - accuracy: 0.4618 - val_loss: 1.5241 - val_accuracy: 0.4112\n",
      "Epoch 94/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.4997 - accuracy: 0.4602 - val_loss: 1.5120 - val_accuracy: 0.4112\n",
      "Epoch 95/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.4882 - accuracy: 0.4595 - val_loss: 1.5003 - val_accuracy: 0.4112\n",
      "Epoch 96/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.4771 - accuracy: 0.4595 - val_loss: 1.4889 - val_accuracy: 0.4112\n",
      "Epoch 97/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.4663 - accuracy: 0.4591 - val_loss: 1.4777 - val_accuracy: 0.4112\n",
      "Epoch 98/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.4558 - accuracy: 0.4602 - val_loss: 1.4671 - val_accuracy: 0.4112\n",
      "Epoch 99/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.4455 - accuracy: 0.4626 - val_loss: 1.4566 - val_accuracy: 0.4112\n",
      "Epoch 100/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.4356 - accuracy: 0.4622 - val_loss: 1.4464 - val_accuracy: 0.4112\n",
      "Epoch 101/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.4260 - accuracy: 0.4630 - val_loss: 1.4367 - val_accuracy: 0.4112\n",
      "Epoch 102/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.4166 - accuracy: 0.4618 - val_loss: 1.4269 - val_accuracy: 0.4112\n",
      "Epoch 103/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.4075 - accuracy: 0.4634 - val_loss: 1.4178 - val_accuracy: 0.4112\n",
      "Epoch 104/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.3987 - accuracy: 0.4634 - val_loss: 1.4087 - val_accuracy: 0.4112\n",
      "Epoch 105/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.3901 - accuracy: 0.4646 - val_loss: 1.4000 - val_accuracy: 0.4112\n",
      "Epoch 106/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.3818 - accuracy: 0.4642 - val_loss: 1.3913 - val_accuracy: 0.4206\n",
      "Epoch 107/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.3736 - accuracy: 0.4630 - val_loss: 1.3831 - val_accuracy: 0.4206\n",
      "Epoch 108/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.3658 - accuracy: 0.4618 - val_loss: 1.3750 - val_accuracy: 0.4206\n",
      "Epoch 109/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.3581 - accuracy: 0.4618 - val_loss: 1.3672 - val_accuracy: 0.4206\n",
      "Epoch 110/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.3506 - accuracy: 0.4630 - val_loss: 1.3596 - val_accuracy: 0.4299\n",
      "Epoch 111/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.3433 - accuracy: 0.4634 - val_loss: 1.3520 - val_accuracy: 0.4486\n",
      "Epoch 112/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.3363 - accuracy: 0.4634 - val_loss: 1.3447 - val_accuracy: 0.4486\n",
      "Epoch 113/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.3294 - accuracy: 0.4626 - val_loss: 1.3377 - val_accuracy: 0.4486\n",
      "Epoch 114/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.3227 - accuracy: 0.4630 - val_loss: 1.3308 - val_accuracy: 0.4486\n",
      "Epoch 115/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.3162 - accuracy: 0.4634 - val_loss: 1.3240 - val_accuracy: 0.4486\n",
      "Epoch 116/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.3098 - accuracy: 0.4642 - val_loss: 1.3175 - val_accuracy: 0.4579\n",
      "Epoch 117/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.3036 - accuracy: 0.4638 - val_loss: 1.3112 - val_accuracy: 0.4579\n",
      "Epoch 118/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 1.2976 - accuracy: 0.4634 - val_loss: 1.3050 - val_accuracy: 0.4579\n",
      "Epoch 119/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.2918 - accuracy: 0.4630 - val_loss: 1.2988 - val_accuracy: 0.4579\n",
      "Epoch 120/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.2860 - accuracy: 0.4646 - val_loss: 1.2929 - val_accuracy: 0.4579\n",
      "Epoch 121/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.2805 - accuracy: 0.4638 - val_loss: 1.2873 - val_accuracy: 0.4579\n",
      "Epoch 122/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.2750 - accuracy: 0.4638 - val_loss: 1.2816 - val_accuracy: 0.4579\n",
      "Epoch 123/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.2698 - accuracy: 0.4653 - val_loss: 1.2760 - val_accuracy: 0.4579\n",
      "Epoch 124/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 3ms/step - loss: 1.2646 - accuracy: 0.4657 - val_loss: 1.2708 - val_accuracy: 0.4579\n",
      "Epoch 125/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.2596 - accuracy: 0.4665 - val_loss: 1.2655 - val_accuracy: 0.4579\n",
      "Epoch 126/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.2548 - accuracy: 0.4665 - val_loss: 1.2604 - val_accuracy: 0.4579\n",
      "Epoch 127/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.2500 - accuracy: 0.4677 - val_loss: 1.2555 - val_accuracy: 0.4579\n",
      "Epoch 128/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.2453 - accuracy: 0.4681 - val_loss: 1.2506 - val_accuracy: 0.4579\n",
      "Epoch 129/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.2409 - accuracy: 0.4693 - val_loss: 1.2459 - val_accuracy: 0.4579\n",
      "Epoch 130/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.2364 - accuracy: 0.4693 - val_loss: 1.2414 - val_accuracy: 0.4579\n",
      "Epoch 131/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.2321 - accuracy: 0.4693 - val_loss: 1.2369 - val_accuracy: 0.4579\n",
      "Epoch 132/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.2279 - accuracy: 0.4704 - val_loss: 1.2326 - val_accuracy: 0.4579\n",
      "Epoch 133/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.2238 - accuracy: 0.4704 - val_loss: 1.2284 - val_accuracy: 0.4579\n",
      "Epoch 134/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.2199 - accuracy: 0.4704 - val_loss: 1.2241 - val_accuracy: 0.4579\n",
      "Epoch 135/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.2160 - accuracy: 0.4712 - val_loss: 1.2202 - val_accuracy: 0.4579\n",
      "Epoch 136/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.2122 - accuracy: 0.4728 - val_loss: 1.2162 - val_accuracy: 0.4579\n",
      "Epoch 137/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.2085 - accuracy: 0.4720 - val_loss: 1.2121 - val_accuracy: 0.4579\n",
      "Epoch 138/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.2049 - accuracy: 0.4736 - val_loss: 1.2083 - val_accuracy: 0.4579\n",
      "Epoch 139/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.2013 - accuracy: 0.4736 - val_loss: 1.2046 - val_accuracy: 0.4579\n",
      "Epoch 140/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.1979 - accuracy: 0.4743 - val_loss: 1.2010 - val_accuracy: 0.4579\n",
      "Epoch 141/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.1945 - accuracy: 0.4743 - val_loss: 1.1974 - val_accuracy: 0.4579\n",
      "Epoch 142/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.1913 - accuracy: 0.4751 - val_loss: 1.1941 - val_accuracy: 0.4579\n",
      "Epoch 143/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.1881 - accuracy: 0.4747 - val_loss: 1.1908 - val_accuracy: 0.4579\n",
      "Epoch 144/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.1849 - accuracy: 0.4732 - val_loss: 1.1871 - val_accuracy: 0.4579\n",
      "Epoch 145/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.1819 - accuracy: 0.4743 - val_loss: 1.1841 - val_accuracy: 0.4579\n",
      "Epoch 146/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.1789 - accuracy: 0.4743 - val_loss: 1.1809 - val_accuracy: 0.4579\n",
      "Epoch 147/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.1760 - accuracy: 0.4740 - val_loss: 1.1778 - val_accuracy: 0.4579\n",
      "Epoch 148/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.1732 - accuracy: 0.4736 - val_loss: 1.1748 - val_accuracy: 0.4579\n",
      "Epoch 149/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.1704 - accuracy: 0.4751 - val_loss: 1.1721 - val_accuracy: 0.4579\n",
      "Epoch 150/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.1677 - accuracy: 0.4759 - val_loss: 1.1689 - val_accuracy: 0.4579\n",
      "Epoch 151/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.1651 - accuracy: 0.4759 - val_loss: 1.1662 - val_accuracy: 0.4579\n",
      "Epoch 152/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.1624 - accuracy: 0.4763 - val_loss: 1.1633 - val_accuracy: 0.4579\n",
      "Epoch 153/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.1599 - accuracy: 0.4755 - val_loss: 1.1606 - val_accuracy: 0.4579\n",
      "Epoch 154/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.1574 - accuracy: 0.4755 - val_loss: 1.1580 - val_accuracy: 0.4579\n",
      "Epoch 155/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.1550 - accuracy: 0.4763 - val_loss: 1.1553 - val_accuracy: 0.4579\n",
      "Epoch 156/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.1527 - accuracy: 0.4759 - val_loss: 1.1527 - val_accuracy: 0.4579\n",
      "Epoch 157/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.1503 - accuracy: 0.4767 - val_loss: 1.1504 - val_accuracy: 0.4579\n",
      "Epoch 158/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.1481 - accuracy: 0.4767 - val_loss: 1.1476 - val_accuracy: 0.4579\n",
      "Epoch 159/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.1458 - accuracy: 0.4759 - val_loss: 1.1454 - val_accuracy: 0.4579\n",
      "Epoch 160/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.1436 - accuracy: 0.4767 - val_loss: 1.1429 - val_accuracy: 0.4579\n",
      "Epoch 161/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.1415 - accuracy: 0.4771 - val_loss: 1.1406 - val_accuracy: 0.4579\n",
      "Epoch 162/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.1394 - accuracy: 0.4767 - val_loss: 1.1382 - val_accuracy: 0.4579\n",
      "Epoch 163/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.1374 - accuracy: 0.4779 - val_loss: 1.1362 - val_accuracy: 0.4579\n",
      "Epoch 164/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.1354 - accuracy: 0.4787 - val_loss: 1.1339 - val_accuracy: 0.4579\n",
      "Epoch 165/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.1334 - accuracy: 0.4787 - val_loss: 1.1318 - val_accuracy: 0.4579\n",
      "Epoch 166/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.1315 - accuracy: 0.4787 - val_loss: 1.1295 - val_accuracy: 0.4579\n",
      "Epoch 167/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.1296 - accuracy: 0.4798 - val_loss: 1.1276 - val_accuracy: 0.4579\n",
      "Epoch 168/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.1278 - accuracy: 0.4798 - val_loss: 1.1254 - val_accuracy: 0.4579\n",
      "Epoch 169/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.1259 - accuracy: 0.4810 - val_loss: 1.1234 - val_accuracy: 0.4579\n",
      "Epoch 170/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.1242 - accuracy: 0.4806 - val_loss: 1.1214 - val_accuracy: 0.4579\n",
      "Epoch 171/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.1224 - accuracy: 0.4806 - val_loss: 1.1195 - val_accuracy: 0.4579\n",
      "Epoch 172/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.1208 - accuracy: 0.4814 - val_loss: 1.1176 - val_accuracy: 0.4579\n",
      "Epoch 173/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.1190 - accuracy: 0.4818 - val_loss: 1.1155 - val_accuracy: 0.4579\n",
      "Epoch 174/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.1173 - accuracy: 0.4810 - val_loss: 1.1136 - val_accuracy: 0.4579\n",
      "Epoch 175/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.1158 - accuracy: 0.4826 - val_loss: 1.1119 - val_accuracy: 0.4579\n",
      "Epoch 176/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.1141 - accuracy: 0.4826 - val_loss: 1.1101 - val_accuracy: 0.4579\n",
      "Epoch 177/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.1126 - accuracy: 0.4814 - val_loss: 1.1084 - val_accuracy: 0.4579\n",
      "Epoch 178/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.1110 - accuracy: 0.4826 - val_loss: 1.1067 - val_accuracy: 0.4579\n",
      "Epoch 179/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.1095 - accuracy: 0.4826 - val_loss: 1.1049 - val_accuracy: 0.4579\n",
      "Epoch 180/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.1081 - accuracy: 0.4830 - val_loss: 1.1032 - val_accuracy: 0.4579\n",
      "Epoch 181/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 2ms/step - loss: 1.1066 - accuracy: 0.4826 - val_loss: 1.1013 - val_accuracy: 0.4579\n",
      "Epoch 182/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.1051 - accuracy: 0.4834 - val_loss: 1.0997 - val_accuracy: 0.4579\n",
      "Epoch 183/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.1038 - accuracy: 0.4826 - val_loss: 1.0982 - val_accuracy: 0.4579\n",
      "Epoch 184/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.1024 - accuracy: 0.4834 - val_loss: 1.0964 - val_accuracy: 0.4579\n",
      "Epoch 185/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.1011 - accuracy: 0.4837 - val_loss: 1.0950 - val_accuracy: 0.4579\n",
      "Epoch 186/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.0997 - accuracy: 0.4830 - val_loss: 1.0934 - val_accuracy: 0.4673\n",
      "Epoch 187/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.0984 - accuracy: 0.4826 - val_loss: 1.0918 - val_accuracy: 0.4673\n",
      "Epoch 188/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.0971 - accuracy: 0.4826 - val_loss: 1.0904 - val_accuracy: 0.4673\n",
      "Epoch 189/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.0959 - accuracy: 0.4837 - val_loss: 1.0889 - val_accuracy: 0.4673\n",
      "Epoch 190/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.0947 - accuracy: 0.4849 - val_loss: 1.0874 - val_accuracy: 0.4673\n",
      "Epoch 191/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.0934 - accuracy: 0.4849 - val_loss: 1.0859 - val_accuracy: 0.4766\n",
      "Epoch 192/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.0922 - accuracy: 0.4845 - val_loss: 1.0845 - val_accuracy: 0.4766\n",
      "Epoch 193/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.0910 - accuracy: 0.4845 - val_loss: 1.0831 - val_accuracy: 0.4766\n",
      "Epoch 194/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.0898 - accuracy: 0.4841 - val_loss: 1.0817 - val_accuracy: 0.4766\n",
      "Epoch 195/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.0887 - accuracy: 0.4845 - val_loss: 1.0803 - val_accuracy: 0.4766\n",
      "Epoch 196/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.0876 - accuracy: 0.4845 - val_loss: 1.0791 - val_accuracy: 0.4766\n",
      "Epoch 197/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.0865 - accuracy: 0.4865 - val_loss: 1.0778 - val_accuracy: 0.4766\n",
      "Epoch 198/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.0854 - accuracy: 0.4845 - val_loss: 1.0764 - val_accuracy: 0.4953\n",
      "Epoch 199/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.0843 - accuracy: 0.4865 - val_loss: 1.0751 - val_accuracy: 0.4953\n",
      "Epoch 200/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.0832 - accuracy: 0.4869 - val_loss: 1.0740 - val_accuracy: 0.4953\n",
      "0.4953271150588989 {'loss': 1.0832277536392212, 'accuracy': 0.4868781864643097, 'val_loss': 1.0739868879318237, 'val_accuracy': 0.4953271150588989}\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 29)]              0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 41)                1230      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 75)                3150      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 75)                0         \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 75)                0         \n",
      "=================================================================\n",
      "Total params: 4,380\n",
      "Trainable params: 4,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 4.9355 - accuracy: 0.0027 - val_loss: 4.6405 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.8485 - accuracy: 0.0043 - val_loss: 4.5754 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.7594 - accuracy: 0.0110 - val_loss: 4.5116 - val_accuracy: 0.0093\n",
      "Epoch 4/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.6980 - accuracy: 0.0192 - val_loss: 4.4511 - val_accuracy: 0.0187\n",
      "Epoch 5/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.6384 - accuracy: 0.0380 - val_loss: 4.3927 - val_accuracy: 0.0561\n",
      "Epoch 6/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.5573 - accuracy: 0.0521 - val_loss: 4.3356 - val_accuracy: 0.0654\n",
      "Epoch 7/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 4.5012 - accuracy: 0.0662 - val_loss: 4.2804 - val_accuracy: 0.0935\n",
      "Epoch 8/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.4366 - accuracy: 0.0881 - val_loss: 4.2263 - val_accuracy: 0.1121\n",
      "Epoch 9/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.3944 - accuracy: 0.0995 - val_loss: 4.1740 - val_accuracy: 0.1589\n",
      "Epoch 10/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.3452 - accuracy: 0.1195 - val_loss: 4.1239 - val_accuracy: 0.1963\n",
      "Epoch 11/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.2816 - accuracy: 0.1441 - val_loss: 4.0745 - val_accuracy: 0.2150\n",
      "Epoch 12/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.2378 - accuracy: 0.1516 - val_loss: 4.0246 - val_accuracy: 0.2430\n",
      "Epoch 13/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.1867 - accuracy: 0.1653 - val_loss: 3.9761 - val_accuracy: 0.2617\n",
      "Epoch 14/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.1425 - accuracy: 0.1743 - val_loss: 3.9279 - val_accuracy: 0.2804\n",
      "Epoch 15/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.1494 - accuracy: 0.1688 - val_loss: 3.8810 - val_accuracy: 0.2897\n",
      "Epoch 16/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.0475 - accuracy: 0.1908 - val_loss: 3.8304 - val_accuracy: 0.3271\n",
      "Epoch 17/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.0074 - accuracy: 0.1982 - val_loss: 3.7799 - val_accuracy: 0.3271\n",
      "Epoch 18/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.9816 - accuracy: 0.1974 - val_loss: 3.7301 - val_accuracy: 0.3271\n",
      "Epoch 19/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.9508 - accuracy: 0.2033 - val_loss: 3.6806 - val_accuracy: 0.3364\n",
      "Epoch 20/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.9013 - accuracy: 0.2060 - val_loss: 3.6334 - val_accuracy: 0.3364\n",
      "Epoch 21/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.8532 - accuracy: 0.2115 - val_loss: 3.5845 - val_accuracy: 0.3364\n",
      "Epoch 22/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.7938 - accuracy: 0.2225 - val_loss: 3.5339 - val_accuracy: 0.3458\n",
      "Epoch 23/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.7665 - accuracy: 0.2260 - val_loss: 3.4865 - val_accuracy: 0.3458\n",
      "Epoch 24/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.7217 - accuracy: 0.2378 - val_loss: 3.4383 - val_accuracy: 0.3551\n",
      "Epoch 25/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.7127 - accuracy: 0.2436 - val_loss: 3.3939 - val_accuracy: 0.3925\n",
      "Epoch 26/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6295 - accuracy: 0.2640 - val_loss: 3.3481 - val_accuracy: 0.4299\n",
      "Epoch 27/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5588 - accuracy: 0.2879 - val_loss: 3.3036 - val_accuracy: 0.4486\n",
      "Epoch 28/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5708 - accuracy: 0.2918 - val_loss: 3.2616 - val_accuracy: 0.4486\n",
      "Epoch 29/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5277 - accuracy: 0.3063 - val_loss: 3.2211 - val_accuracy: 0.4860\n",
      "Epoch 30/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5029 - accuracy: 0.3177 - val_loss: 3.1829 - val_accuracy: 0.5140\n",
      "Epoch 31/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.4715 - accuracy: 0.3333 - val_loss: 3.1448 - val_accuracy: 0.5140\n",
      "Epoch 32/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.4785 - accuracy: 0.3302 - val_loss: 3.1115 - val_accuracy: 0.5047\n",
      "Epoch 33/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3879 - accuracy: 0.3568 - val_loss: 3.0741 - val_accuracy: 0.5047\n",
      "Epoch 34/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3769 - accuracy: 0.3494 - val_loss: 3.0408 - val_accuracy: 0.5140\n",
      "Epoch 35/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3154 - accuracy: 0.3690 - val_loss: 3.0065 - val_accuracy: 0.5327\n",
      "Epoch 36/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3540 - accuracy: 0.3533 - val_loss: 2.9754 - val_accuracy: 0.5327\n",
      "Epoch 37/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.2883 - accuracy: 0.3686 - val_loss: 2.9454 - val_accuracy: 0.5327\n",
      "Epoch 38/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.2951 - accuracy: 0.3623 - val_loss: 2.9190 - val_accuracy: 0.5327\n",
      "Epoch 39/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.2475 - accuracy: 0.3705 - val_loss: 2.8913 - val_accuracy: 0.5327\n",
      "Epoch 40/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.1919 - accuracy: 0.3827 - val_loss: 2.8645 - val_accuracy: 0.5327\n",
      "Epoch 41/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.2217 - accuracy: 0.3749 - val_loss: 2.8402 - val_accuracy: 0.5327\n",
      "Epoch 42/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.1932 - accuracy: 0.3752 - val_loss: 2.8169 - val_accuracy: 0.5514\n",
      "Epoch 43/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.2045 - accuracy: 0.3729 - val_loss: 2.7945 - val_accuracy: 0.5514\n",
      "Epoch 44/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.2366 - accuracy: 0.3588 - val_loss: 2.7768 - val_accuracy: 0.5514\n",
      "Epoch 45/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 3.1201 - accuracy: 0.3948 - val_loss: 2.7552 - val_accuracy: 0.5514\n",
      "Epoch 46/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.1386 - accuracy: 0.3866 - val_loss: 2.7359 - val_accuracy: 0.5514\n",
      "Epoch 47/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.1105 - accuracy: 0.3890 - val_loss: 2.7163 - val_accuracy: 0.5514\n",
      "Epoch 48/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.1249 - accuracy: 0.3874 - val_loss: 2.7001 - val_accuracy: 0.5421\n",
      "Epoch 49/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.1011 - accuracy: 0.3866 - val_loss: 2.6839 - val_accuracy: 0.5421\n",
      "Epoch 50/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.0816 - accuracy: 0.3929 - val_loss: 2.6671 - val_accuracy: 0.5421\n",
      "Epoch 51/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.0922 - accuracy: 0.3901 - val_loss: 2.6525 - val_accuracy: 0.5421\n",
      "Epoch 52/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.0443 - accuracy: 0.4003 - val_loss: 2.6387 - val_accuracy: 0.5421\n",
      "Epoch 53/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.0792 - accuracy: 0.3913 - val_loss: 2.6259 - val_accuracy: 0.5421\n",
      "Epoch 54/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.0410 - accuracy: 0.3972 - val_loss: 2.6138 - val_accuracy: 0.5421\n",
      "Epoch 55/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.0290 - accuracy: 0.3980 - val_loss: 2.6027 - val_accuracy: 0.5514\n",
      "Epoch 56/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.9880 - accuracy: 0.4046 - val_loss: 2.5924 - val_accuracy: 0.5514\n",
      "Epoch 57/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.0011 - accuracy: 0.3937 - val_loss: 2.5825 - val_accuracy: 0.5514\n",
      "Epoch 58/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.0369 - accuracy: 0.3921 - val_loss: 2.5740 - val_accuracy: 0.5514\n",
      "Epoch 59/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.9493 - accuracy: 0.4199 - val_loss: 2.5639 - val_accuracy: 0.5514\n",
      "Epoch 60/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.0273 - accuracy: 0.3964 - val_loss: 2.5559 - val_accuracy: 0.5514\n",
      "Epoch 61/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.0521 - accuracy: 0.3843 - val_loss: 2.5489 - val_accuracy: 0.5514\n",
      "Epoch 62/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.0152 - accuracy: 0.3995 - val_loss: 2.5411 - val_accuracy: 0.5514\n",
      "Epoch 63/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.9721 - accuracy: 0.4011 - val_loss: 2.5325 - val_accuracy: 0.5514\n",
      "Epoch 64/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.9509 - accuracy: 0.4027 - val_loss: 2.5230 - val_accuracy: 0.5514\n",
      "Epoch 65/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.9459 - accuracy: 0.4136 - val_loss: 2.5131 - val_accuracy: 0.5514\n",
      "Epoch 66/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.9466 - accuracy: 0.4046 - val_loss: 2.5034 - val_accuracy: 0.5514\n",
      "Epoch 67/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.9167 - accuracy: 0.4093 - val_loss: 2.4928 - val_accuracy: 0.5514\n",
      "Epoch 68/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.8677 - accuracy: 0.4179 - val_loss: 2.4809 - val_accuracy: 0.5607\n",
      "Epoch 69/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.8808 - accuracy: 0.4191 - val_loss: 2.4685 - val_accuracy: 0.5607\n",
      "Epoch 70/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.8603 - accuracy: 0.4172 - val_loss: 2.4568 - val_accuracy: 0.5421\n",
      "Epoch 71/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.8574 - accuracy: 0.4246 - val_loss: 2.4439 - val_accuracy: 0.5421\n",
      "Epoch 72/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.8487 - accuracy: 0.4179 - val_loss: 2.4324 - val_accuracy: 0.5421\n",
      "Epoch 73/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.8137 - accuracy: 0.4266 - val_loss: 2.4209 - val_accuracy: 0.5421\n",
      "Epoch 74/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.7983 - accuracy: 0.4215 - val_loss: 2.4084 - val_accuracy: 0.5327\n",
      "Epoch 75/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.8254 - accuracy: 0.4160 - val_loss: 2.3961 - val_accuracy: 0.5327\n",
      "Epoch 76/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 2.8285 - accuracy: 0.4254 - val_loss: 2.3835 - val_accuracy: 0.5327\n",
      "Epoch 77/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.8514 - accuracy: 0.4042 - val_loss: 2.3726 - val_accuracy: 0.5327\n",
      "Epoch 78/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.7689 - accuracy: 0.4136 - val_loss: 2.3583 - val_accuracy: 0.5327\n",
      "Epoch 79/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.6996 - accuracy: 0.4269 - val_loss: 2.3421 - val_accuracy: 0.5421\n",
      "Epoch 80/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.7364 - accuracy: 0.4246 - val_loss: 2.3278 - val_accuracy: 0.5421\n",
      "Epoch 81/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.7336 - accuracy: 0.4109 - val_loss: 2.3137 - val_accuracy: 0.5421\n",
      "Epoch 82/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.7489 - accuracy: 0.4191 - val_loss: 2.2983 - val_accuracy: 0.5421\n",
      "Epoch 83/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.7013 - accuracy: 0.4148 - val_loss: 2.2806 - val_accuracy: 0.5421\n",
      "Epoch 84/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.7146 - accuracy: 0.4136 - val_loss: 2.2638 - val_accuracy: 0.5421\n",
      "Epoch 85/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.6396 - accuracy: 0.4348 - val_loss: 2.2453 - val_accuracy: 0.5421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.6445 - accuracy: 0.4324 - val_loss: 2.2263 - val_accuracy: 0.5421\n",
      "Epoch 87/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.5895 - accuracy: 0.4332 - val_loss: 2.2056 - val_accuracy: 0.5421\n",
      "Epoch 88/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.6326 - accuracy: 0.4168 - val_loss: 2.1864 - val_accuracy: 0.5421\n",
      "Epoch 89/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.6134 - accuracy: 0.4230 - val_loss: 2.1674 - val_accuracy: 0.5421\n",
      "Epoch 90/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.5074 - accuracy: 0.4324 - val_loss: 2.1465 - val_accuracy: 0.5421\n",
      "Epoch 91/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.5550 - accuracy: 0.4332 - val_loss: 2.1278 - val_accuracy: 0.5421\n",
      "Epoch 92/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.5368 - accuracy: 0.4250 - val_loss: 2.1084 - val_accuracy: 0.5327\n",
      "Epoch 93/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.5294 - accuracy: 0.4226 - val_loss: 2.0895 - val_accuracy: 0.5234\n",
      "Epoch 94/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.5024 - accuracy: 0.4348 - val_loss: 2.0694 - val_accuracy: 0.5234\n",
      "Epoch 95/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.5305 - accuracy: 0.4156 - val_loss: 2.0524 - val_accuracy: 0.5234\n",
      "Epoch 96/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.5314 - accuracy: 0.4105 - val_loss: 2.0365 - val_accuracy: 0.5234\n",
      "Epoch 97/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4698 - accuracy: 0.4336 - val_loss: 2.0186 - val_accuracy: 0.5234\n",
      "Epoch 98/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4148 - accuracy: 0.4340 - val_loss: 2.0000 - val_accuracy: 0.5327\n",
      "Epoch 99/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4156 - accuracy: 0.4215 - val_loss: 1.9819 - val_accuracy: 0.5327\n",
      "Epoch 100/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4528 - accuracy: 0.4305 - val_loss: 1.9672 - val_accuracy: 0.5421\n",
      "Epoch 101/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.5252 - accuracy: 0.4101 - val_loss: 1.9549 - val_accuracy: 0.5327\n",
      "Epoch 102/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4545 - accuracy: 0.4336 - val_loss: 1.9402 - val_accuracy: 0.5421\n",
      "Epoch 103/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4461 - accuracy: 0.4277 - val_loss: 1.9266 - val_accuracy: 0.5421\n",
      "Epoch 104/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4089 - accuracy: 0.4195 - val_loss: 1.9126 - val_accuracy: 0.5514\n",
      "Epoch 105/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4171 - accuracy: 0.4144 - val_loss: 1.8988 - val_accuracy: 0.5514\n",
      "Epoch 106/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3851 - accuracy: 0.4305 - val_loss: 1.8843 - val_accuracy: 0.5514\n",
      "Epoch 107/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4312 - accuracy: 0.4273 - val_loss: 1.8744 - val_accuracy: 0.5514\n",
      "Epoch 108/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4338 - accuracy: 0.4144 - val_loss: 1.8652 - val_accuracy: 0.5514\n",
      "Epoch 109/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4566 - accuracy: 0.4168 - val_loss: 1.8563 - val_accuracy: 0.5514\n",
      "Epoch 110/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4254 - accuracy: 0.4097 - val_loss: 1.8473 - val_accuracy: 0.5514\n",
      "Epoch 111/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3883 - accuracy: 0.4254 - val_loss: 1.8382 - val_accuracy: 0.5514\n",
      "Epoch 112/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3856 - accuracy: 0.4250 - val_loss: 1.8285 - val_accuracy: 0.5514\n",
      "Epoch 113/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4074 - accuracy: 0.4219 - val_loss: 1.8203 - val_accuracy: 0.5607\n",
      "Epoch 114/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4061 - accuracy: 0.4093 - val_loss: 1.8124 - val_accuracy: 0.5607\n",
      "Epoch 115/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3826 - accuracy: 0.4281 - val_loss: 1.8052 - val_accuracy: 0.5607\n",
      "Epoch 116/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3580 - accuracy: 0.4234 - val_loss: 1.7971 - val_accuracy: 0.5607\n",
      "Epoch 117/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4295 - accuracy: 0.4160 - val_loss: 1.7911 - val_accuracy: 0.5607\n",
      "Epoch 118/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4170 - accuracy: 0.4136 - val_loss: 1.7863 - val_accuracy: 0.5514\n",
      "Epoch 119/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3757 - accuracy: 0.4399 - val_loss: 1.7795 - val_accuracy: 0.5421\n",
      "Epoch 120/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4506 - accuracy: 0.4191 - val_loss: 1.7768 - val_accuracy: 0.5421\n",
      "Epoch 121/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4048 - accuracy: 0.4172 - val_loss: 1.7721 - val_accuracy: 0.5421\n",
      "Epoch 122/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4383 - accuracy: 0.4148 - val_loss: 1.7686 - val_accuracy: 0.5421\n",
      "Epoch 123/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3702 - accuracy: 0.4191 - val_loss: 1.7634 - val_accuracy: 0.5421\n",
      "Epoch 124/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3346 - accuracy: 0.4246 - val_loss: 1.7576 - val_accuracy: 0.5421\n",
      "Epoch 125/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3934 - accuracy: 0.4128 - val_loss: 1.7538 - val_accuracy: 0.5421\n",
      "Epoch 126/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3642 - accuracy: 0.4215 - val_loss: 1.7496 - val_accuracy: 0.5421\n",
      "Epoch 127/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3593 - accuracy: 0.4172 - val_loss: 1.7447 - val_accuracy: 0.5421\n",
      "Epoch 128/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4163 - accuracy: 0.4152 - val_loss: 1.7416 - val_accuracy: 0.5514\n",
      "Epoch 129/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3900 - accuracy: 0.4273 - val_loss: 1.7381 - val_accuracy: 0.5514\n",
      "Epoch 130/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4858 - accuracy: 0.4011 - val_loss: 1.7382 - val_accuracy: 0.5514\n",
      "Epoch 131/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3468 - accuracy: 0.4297 - val_loss: 1.7349 - val_accuracy: 0.5514\n",
      "Epoch 132/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3955 - accuracy: 0.4183 - val_loss: 1.7316 - val_accuracy: 0.5514\n",
      "Epoch 133/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4245 - accuracy: 0.4117 - val_loss: 1.7310 - val_accuracy: 0.5514\n",
      "Epoch 134/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4423 - accuracy: 0.4070 - val_loss: 1.7316 - val_accuracy: 0.5514\n",
      "Epoch 135/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2595 - accuracy: 0.4344 - val_loss: 1.7245 - val_accuracy: 0.5514\n",
      "Epoch 136/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4061 - accuracy: 0.4046 - val_loss: 1.7218 - val_accuracy: 0.5514\n",
      "Epoch 137/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4002 - accuracy: 0.4113 - val_loss: 1.7211 - val_accuracy: 0.5514\n",
      "Epoch 138/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4227 - accuracy: 0.4128 - val_loss: 1.7206 - val_accuracy: 0.5514\n",
      "Epoch 139/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4331 - accuracy: 0.4074 - val_loss: 1.7202 - val_accuracy: 0.5514\n",
      "Epoch 140/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4319 - accuracy: 0.4125 - val_loss: 1.7199 - val_accuracy: 0.5514\n",
      "Epoch 141/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3423 - accuracy: 0.4226 - val_loss: 1.7172 - val_accuracy: 0.5514\n",
      "Epoch 142/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4011 - accuracy: 0.4125 - val_loss: 1.7152 - val_accuracy: 0.5514\n",
      "Epoch 143/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3600 - accuracy: 0.4305 - val_loss: 1.7120 - val_accuracy: 0.5514\n",
      "Epoch 144/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3722 - accuracy: 0.4238 - val_loss: 1.7089 - val_accuracy: 0.5514\n",
      "Epoch 145/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3362 - accuracy: 0.4230 - val_loss: 1.7059 - val_accuracy: 0.5514\n",
      "Epoch 146/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3965 - accuracy: 0.4164 - val_loss: 1.7060 - val_accuracy: 0.5514\n",
      "Epoch 147/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4298 - accuracy: 0.4175 - val_loss: 1.7058 - val_accuracy: 0.5514\n",
      "Epoch 148/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3662 - accuracy: 0.4344 - val_loss: 1.7041 - val_accuracy: 0.5514\n",
      "Epoch 149/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3990 - accuracy: 0.4215 - val_loss: 1.7038 - val_accuracy: 0.5514\n",
      "Epoch 150/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4004 - accuracy: 0.4195 - val_loss: 1.7033 - val_accuracy: 0.5421\n",
      "Epoch 151/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4014 - accuracy: 0.4172 - val_loss: 1.7024 - val_accuracy: 0.5421\n",
      "Epoch 152/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4570 - accuracy: 0.4128 - val_loss: 1.7044 - val_accuracy: 0.5421\n",
      "Epoch 153/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3847 - accuracy: 0.4219 - val_loss: 1.7030 - val_accuracy: 0.5514\n",
      "Epoch 154/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3601 - accuracy: 0.4305 - val_loss: 1.7018 - val_accuracy: 0.5607\n",
      "Epoch 155/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3479 - accuracy: 0.4301 - val_loss: 1.6985 - val_accuracy: 0.5421\n",
      "Epoch 156/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3465 - accuracy: 0.4183 - val_loss: 1.6963 - val_accuracy: 0.5514\n",
      "Epoch 157/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3997 - accuracy: 0.4219 - val_loss: 1.6957 - val_accuracy: 0.5514\n",
      "Epoch 158/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3975 - accuracy: 0.4226 - val_loss: 1.6959 - val_accuracy: 0.5607\n",
      "Epoch 159/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3645 - accuracy: 0.4191 - val_loss: 1.6936 - val_accuracy: 0.5607\n",
      "Epoch 160/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3809 - accuracy: 0.4140 - val_loss: 1.6932 - val_accuracy: 0.5514\n",
      "Epoch 161/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3467 - accuracy: 0.4313 - val_loss: 1.6905 - val_accuracy: 0.5607\n",
      "Epoch 162/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3633 - accuracy: 0.4160 - val_loss: 1.6898 - val_accuracy: 0.5514\n",
      "Epoch 163/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3480 - accuracy: 0.4203 - val_loss: 1.6873 - val_accuracy: 0.5514\n",
      "Epoch 164/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3679 - accuracy: 0.4207 - val_loss: 1.6853 - val_accuracy: 0.5514\n",
      "Epoch 165/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3184 - accuracy: 0.4332 - val_loss: 1.6826 - val_accuracy: 0.5514\n",
      "Epoch 166/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3538 - accuracy: 0.4309 - val_loss: 1.6818 - val_accuracy: 0.5514\n",
      "Epoch 167/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3647 - accuracy: 0.4203 - val_loss: 1.6811 - val_accuracy: 0.5514\n",
      "Epoch 168/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3898 - accuracy: 0.4093 - val_loss: 1.6817 - val_accuracy: 0.5514\n",
      "Epoch 169/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3284 - accuracy: 0.4238 - val_loss: 1.6799 - val_accuracy: 0.5514\n",
      "Epoch 170/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3775 - accuracy: 0.4168 - val_loss: 1.6786 - val_accuracy: 0.5514\n",
      "Epoch 171/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3928 - accuracy: 0.4160 - val_loss: 1.6792 - val_accuracy: 0.5514\n",
      "Epoch 172/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3885 - accuracy: 0.4187 - val_loss: 1.6790 - val_accuracy: 0.5514\n",
      "Epoch 173/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3246 - accuracy: 0.4309 - val_loss: 1.6769 - val_accuracy: 0.5514\n",
      "Epoch 174/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3305 - accuracy: 0.4277 - val_loss: 1.6751 - val_accuracy: 0.5514\n",
      "Epoch 175/200\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 2.3520 - accuracy: 0.4207 - val_loss: 1.6741 - val_accuracy: 0.5514\n",
      "Epoch 176/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3829 - accuracy: 0.4168 - val_loss: 1.6745 - val_accuracy: 0.5514\n",
      "Epoch 177/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3869 - accuracy: 0.4140 - val_loss: 1.6759 - val_accuracy: 0.5514\n",
      "Epoch 178/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3748 - accuracy: 0.4230 - val_loss: 1.6767 - val_accuracy: 0.5514\n",
      "Epoch 179/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2919 - accuracy: 0.4289 - val_loss: 1.6748 - val_accuracy: 0.5514\n",
      "Epoch 180/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3928 - accuracy: 0.4219 - val_loss: 1.6754 - val_accuracy: 0.5421\n",
      "Epoch 181/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3628 - accuracy: 0.4250 - val_loss: 1.6741 - val_accuracy: 0.5421\n",
      "Epoch 182/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3192 - accuracy: 0.4313 - val_loss: 1.6729 - val_accuracy: 0.5421\n",
      "Epoch 183/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3847 - accuracy: 0.4215 - val_loss: 1.6720 - val_accuracy: 0.5421\n",
      "Epoch 184/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4204 - accuracy: 0.4226 - val_loss: 1.6727 - val_accuracy: 0.5421\n",
      "Epoch 185/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3280 - accuracy: 0.4320 - val_loss: 1.6707 - val_accuracy: 0.5421\n",
      "Epoch 186/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3588 - accuracy: 0.4242 - val_loss: 1.6704 - val_accuracy: 0.5421\n",
      "Epoch 187/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2993 - accuracy: 0.4219 - val_loss: 1.6680 - val_accuracy: 0.5421\n",
      "Epoch 188/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4210 - accuracy: 0.4168 - val_loss: 1.6697 - val_accuracy: 0.5421\n",
      "Epoch 189/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3594 - accuracy: 0.4242 - val_loss: 1.6694 - val_accuracy: 0.5421\n",
      "Epoch 190/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 2.3374 - accuracy: 0.4246 - val_loss: 1.6687 - val_accuracy: 0.5421\n",
      "Epoch 191/200\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 2.3335 - accuracy: 0.4410 - val_loss: 1.6662 - val_accuracy: 0.5421\n",
      "Epoch 192/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3009 - accuracy: 0.4426 - val_loss: 1.6633 - val_accuracy: 0.5421\n",
      "Epoch 193/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3417 - accuracy: 0.4258 - val_loss: 1.6619 - val_accuracy: 0.5421\n",
      "Epoch 194/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3153 - accuracy: 0.4293 - val_loss: 1.6597 - val_accuracy: 0.5421\n",
      "Epoch 195/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3581 - accuracy: 0.4125 - val_loss: 1.6601 - val_accuracy: 0.5421\n",
      "Epoch 196/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3107 - accuracy: 0.4289 - val_loss: 1.6578 - val_accuracy: 0.5421\n",
      "Epoch 197/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3378 - accuracy: 0.4222 - val_loss: 1.6578 - val_accuracy: 0.5421\n",
      "Epoch 198/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2637 - accuracy: 0.4418 - val_loss: 1.6538 - val_accuracy: 0.5421\n",
      "Epoch 199/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3844 - accuracy: 0.4140 - val_loss: 1.6554 - val_accuracy: 0.5421\n",
      "Epoch 200/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3008 - accuracy: 0.4383 - val_loss: 1.6536 - val_accuracy: 0.5421\n",
      "0.5420560836791992 {'loss': 2.300823450088501, 'accuracy': 0.43830788135528564, 'val_loss': 1.6535708904266357, 'val_accuracy': 0.5420560836791992}\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 29)]              0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 41)                1230      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 75)                3150      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 75)                0         \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 75)                0         \n",
      "=================================================================\n",
      "Total params: 4,380\n",
      "Trainable params: 4,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 4.7471 - accuracy: 0.0043 - val_loss: 4.5513 - val_accuracy: 0.0093\n",
      "Epoch 2/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.6684 - accuracy: 0.0086 - val_loss: 4.5043 - val_accuracy: 0.0093\n",
      "Epoch 3/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.6277 - accuracy: 0.0094 - val_loss: 4.4562 - val_accuracy: 0.0093\n",
      "Epoch 4/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.5685 - accuracy: 0.0145 - val_loss: 4.4071 - val_accuracy: 0.0093\n",
      "Epoch 5/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.5004 - accuracy: 0.0161 - val_loss: 4.3558 - val_accuracy: 0.0187\n",
      "Epoch 6/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.4555 - accuracy: 0.0200 - val_loss: 4.3023 - val_accuracy: 0.0187\n",
      "Epoch 7/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.3862 - accuracy: 0.0270 - val_loss: 4.2484 - val_accuracy: 0.0187\n",
      "Epoch 8/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.3083 - accuracy: 0.0302 - val_loss: 4.1946 - val_accuracy: 0.0280\n",
      "Epoch 9/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.2612 - accuracy: 0.0447 - val_loss: 4.1393 - val_accuracy: 0.0374\n",
      "Epoch 10/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.1881 - accuracy: 0.0517 - val_loss: 4.0832 - val_accuracy: 0.0374\n",
      "Epoch 11/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.1245 - accuracy: 0.0615 - val_loss: 4.0282 - val_accuracy: 0.0374\n",
      "Epoch 12/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.0883 - accuracy: 0.0689 - val_loss: 3.9742 - val_accuracy: 0.0654\n",
      "Epoch 13/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.0229 - accuracy: 0.0768 - val_loss: 3.9206 - val_accuracy: 0.0841\n",
      "Epoch 14/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.9981 - accuracy: 0.0862 - val_loss: 3.8689 - val_accuracy: 0.0841\n",
      "Epoch 15/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 3.9329 - accuracy: 0.0956 - val_loss: 3.8181 - val_accuracy: 0.0841\n",
      "Epoch 16/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.8727 - accuracy: 0.1030 - val_loss: 3.7669 - val_accuracy: 0.0935\n",
      "Epoch 17/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 3.8002 - accuracy: 0.1159 - val_loss: 3.7156 - val_accuracy: 0.0935\n",
      "Epoch 18/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 3.7148 - accuracy: 0.1371 - val_loss: 3.6641 - val_accuracy: 0.1215\n",
      "Epoch 19/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.6945 - accuracy: 0.1465 - val_loss: 3.6147 - val_accuracy: 0.1308\n",
      "Epoch 20/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.6854 - accuracy: 0.1563 - val_loss: 3.5670 - val_accuracy: 0.1589\n",
      "Epoch 21/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.6135 - accuracy: 0.1669 - val_loss: 3.5204 - val_accuracy: 0.1589\n",
      "Epoch 22/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.5688 - accuracy: 0.1763 - val_loss: 3.4738 - val_accuracy: 0.1869\n",
      "Epoch 23/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.5437 - accuracy: 0.1880 - val_loss: 3.4294 - val_accuracy: 0.2150\n",
      "Epoch 24/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.4743 - accuracy: 0.2064 - val_loss: 3.3840 - val_accuracy: 0.2430\n",
      "Epoch 25/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 3.4695 - accuracy: 0.2162 - val_loss: 3.3410 - val_accuracy: 0.2523\n",
      "Epoch 26/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 3.4184 - accuracy: 0.2311 - val_loss: 3.2992 - val_accuracy: 0.2523\n",
      "Epoch 27/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 3.3915 - accuracy: 0.2538 - val_loss: 3.2583 - val_accuracy: 0.2617\n",
      "Epoch 28/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.3388 - accuracy: 0.2660 - val_loss: 3.2172 - val_accuracy: 0.2617\n",
      "Epoch 29/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.3067 - accuracy: 0.2754 - val_loss: 3.1767 - val_accuracy: 0.2804\n",
      "Epoch 30/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.2526 - accuracy: 0.3004 - val_loss: 3.1363 - val_accuracy: 0.2804\n",
      "Epoch 31/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.2251 - accuracy: 0.3067 - val_loss: 3.0966 - val_accuracy: 0.2991\n",
      "Epoch 32/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.1792 - accuracy: 0.3075 - val_loss: 3.0574 - val_accuracy: 0.3178\n",
      "Epoch 33/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.1574 - accuracy: 0.3235 - val_loss: 3.0196 - val_accuracy: 0.3271\n",
      "Epoch 34/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.1701 - accuracy: 0.3188 - val_loss: 2.9834 - val_accuracy: 0.3645\n",
      "Epoch 35/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 3.1222 - accuracy: 0.3369 - val_loss: 2.9479 - val_accuracy: 0.3738\n",
      "Epoch 36/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.0479 - accuracy: 0.3447 - val_loss: 2.9118 - val_accuracy: 0.3832\n",
      "Epoch 37/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.0672 - accuracy: 0.3588 - val_loss: 2.8770 - val_accuracy: 0.4019\n",
      "Epoch 38/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.0322 - accuracy: 0.3623 - val_loss: 2.8429 - val_accuracy: 0.4019\n",
      "Epoch 39/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 3.0481 - accuracy: 0.3600 - val_loss: 2.8104 - val_accuracy: 0.4019\n",
      "Epoch 40/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.9861 - accuracy: 0.3604 - val_loss: 2.7783 - val_accuracy: 0.4299\n",
      "Epoch 41/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.9073 - accuracy: 0.3741 - val_loss: 2.7457 - val_accuracy: 0.4299\n",
      "Epoch 42/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.8968 - accuracy: 0.3678 - val_loss: 2.7137 - val_accuracy: 0.4299\n",
      "Epoch 43/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.8283 - accuracy: 0.3909 - val_loss: 2.6819 - val_accuracy: 0.4393\n",
      "Epoch 44/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.9152 - accuracy: 0.3741 - val_loss: 2.6532 - val_accuracy: 0.4393\n",
      "Epoch 45/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.8460 - accuracy: 0.3819 - val_loss: 2.6239 - val_accuracy: 0.4486\n",
      "Epoch 46/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.8605 - accuracy: 0.3823 - val_loss: 2.5961 - val_accuracy: 0.4486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.8498 - accuracy: 0.3858 - val_loss: 2.5688 - val_accuracy: 0.4486\n",
      "Epoch 48/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.8219 - accuracy: 0.3815 - val_loss: 2.5426 - val_accuracy: 0.4579\n",
      "Epoch 49/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.8039 - accuracy: 0.3897 - val_loss: 2.5168 - val_accuracy: 0.4486\n",
      "Epoch 50/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.8057 - accuracy: 0.3866 - val_loss: 2.4923 - val_accuracy: 0.4393\n",
      "Epoch 51/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.7756 - accuracy: 0.3843 - val_loss: 2.4684 - val_accuracy: 0.4486\n",
      "Epoch 52/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.7340 - accuracy: 0.3909 - val_loss: 2.4445 - val_accuracy: 0.4486\n",
      "Epoch 53/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.7366 - accuracy: 0.3964 - val_loss: 2.4210 - val_accuracy: 0.4579\n",
      "Epoch 54/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.6889 - accuracy: 0.4003 - val_loss: 2.3977 - val_accuracy: 0.4673\n",
      "Epoch 55/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.7233 - accuracy: 0.3909 - val_loss: 2.3762 - val_accuracy: 0.4673\n",
      "Epoch 56/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.6995 - accuracy: 0.3976 - val_loss: 2.3554 - val_accuracy: 0.4860\n",
      "Epoch 57/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.6595 - accuracy: 0.4027 - val_loss: 2.3338 - val_accuracy: 0.4766\n",
      "Epoch 58/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.6496 - accuracy: 0.4085 - val_loss: 2.3134 - val_accuracy: 0.4860\n",
      "Epoch 59/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.6164 - accuracy: 0.4074 - val_loss: 2.2929 - val_accuracy: 0.4860\n",
      "Epoch 60/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.6096 - accuracy: 0.4089 - val_loss: 2.2731 - val_accuracy: 0.4860\n",
      "Epoch 61/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.6142 - accuracy: 0.4027 - val_loss: 2.2540 - val_accuracy: 0.4860\n",
      "Epoch 62/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.6510 - accuracy: 0.3991 - val_loss: 2.2369 - val_accuracy: 0.4860\n",
      "Epoch 63/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.6490 - accuracy: 0.4023 - val_loss: 2.2208 - val_accuracy: 0.4860\n",
      "Epoch 64/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.6237 - accuracy: 0.3964 - val_loss: 2.2047 - val_accuracy: 0.4860\n",
      "Epoch 65/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.6042 - accuracy: 0.3921 - val_loss: 2.1894 - val_accuracy: 0.4953\n",
      "Epoch 66/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.5677 - accuracy: 0.4156 - val_loss: 2.1737 - val_accuracy: 0.4766\n",
      "Epoch 67/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5767 - accuracy: 0.4031 - val_loss: 2.1579 - val_accuracy: 0.4766\n",
      "Epoch 68/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5760 - accuracy: 0.4034 - val_loss: 2.1439 - val_accuracy: 0.4860\n",
      "Epoch 69/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.5759 - accuracy: 0.4015 - val_loss: 2.1303 - val_accuracy: 0.4953\n",
      "Epoch 70/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5323 - accuracy: 0.4113 - val_loss: 2.1164 - val_accuracy: 0.4860\n",
      "Epoch 71/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5661 - accuracy: 0.4027 - val_loss: 2.1041 - val_accuracy: 0.4953\n",
      "Epoch 72/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5191 - accuracy: 0.4160 - val_loss: 2.0914 - val_accuracy: 0.4953\n",
      "Epoch 73/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4984 - accuracy: 0.4097 - val_loss: 2.0780 - val_accuracy: 0.4953\n",
      "Epoch 74/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5155 - accuracy: 0.4109 - val_loss: 2.0658 - val_accuracy: 0.5047\n",
      "Epoch 75/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4683 - accuracy: 0.4203 - val_loss: 2.0537 - val_accuracy: 0.5047\n",
      "Epoch 76/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4707 - accuracy: 0.4168 - val_loss: 2.0426 - val_accuracy: 0.5047\n",
      "Epoch 77/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5596 - accuracy: 0.4058 - val_loss: 2.0325 - val_accuracy: 0.5047\n",
      "Epoch 78/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5010 - accuracy: 0.4085 - val_loss: 2.0230 - val_accuracy: 0.5047\n",
      "Epoch 79/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5405 - accuracy: 0.3972 - val_loss: 2.0133 - val_accuracy: 0.5047\n",
      "Epoch 80/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5139 - accuracy: 0.4097 - val_loss: 2.0056 - val_accuracy: 0.5047\n",
      "Epoch 81/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4898 - accuracy: 0.4117 - val_loss: 1.9968 - val_accuracy: 0.5047\n",
      "Epoch 82/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4334 - accuracy: 0.4156 - val_loss: 1.9872 - val_accuracy: 0.5047\n",
      "Epoch 83/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4829 - accuracy: 0.4081 - val_loss: 1.9784 - val_accuracy: 0.5047\n",
      "Epoch 84/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4144 - accuracy: 0.4234 - val_loss: 1.9699 - val_accuracy: 0.5047\n",
      "Epoch 85/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4827 - accuracy: 0.4093 - val_loss: 1.9623 - val_accuracy: 0.5047\n",
      "Epoch 86/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4586 - accuracy: 0.4144 - val_loss: 1.9547 - val_accuracy: 0.5047\n",
      "Epoch 87/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4571 - accuracy: 0.4117 - val_loss: 1.9477 - val_accuracy: 0.5047\n",
      "Epoch 88/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4030 - accuracy: 0.4293 - val_loss: 1.9389 - val_accuracy: 0.5047\n",
      "Epoch 89/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4755 - accuracy: 0.4203 - val_loss: 1.9318 - val_accuracy: 0.5047\n",
      "Epoch 90/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4320 - accuracy: 0.4101 - val_loss: 1.9254 - val_accuracy: 0.4953\n",
      "Epoch 91/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3379 - accuracy: 0.4356 - val_loss: 1.9165 - val_accuracy: 0.4953\n",
      "Epoch 92/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4575 - accuracy: 0.4238 - val_loss: 1.9114 - val_accuracy: 0.4953\n",
      "Epoch 93/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4809 - accuracy: 0.4031 - val_loss: 1.9059 - val_accuracy: 0.4953\n",
      "Epoch 94/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5318 - accuracy: 0.4062 - val_loss: 1.9038 - val_accuracy: 0.4953\n",
      "Epoch 95/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4521 - accuracy: 0.4109 - val_loss: 1.9003 - val_accuracy: 0.4953\n",
      "Epoch 96/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4307 - accuracy: 0.4074 - val_loss: 1.8955 - val_accuracy: 0.4953\n",
      "Epoch 97/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4893 - accuracy: 0.3964 - val_loss: 1.8925 - val_accuracy: 0.4953\n",
      "Epoch 98/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5147 - accuracy: 0.3890 - val_loss: 1.8908 - val_accuracy: 0.4953\n",
      "Epoch 99/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4029 - accuracy: 0.4093 - val_loss: 1.8864 - val_accuracy: 0.4953\n",
      "Epoch 100/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4292 - accuracy: 0.4128 - val_loss: 1.8822 - val_accuracy: 0.4953\n",
      "Epoch 101/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3619 - accuracy: 0.4234 - val_loss: 1.8761 - val_accuracy: 0.4953\n",
      "Epoch 102/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4893 - accuracy: 0.4160 - val_loss: 1.8739 - val_accuracy: 0.4953\n",
      "Epoch 103/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4268 - accuracy: 0.4175 - val_loss: 1.8714 - val_accuracy: 0.4953\n",
      "Epoch 104/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4373 - accuracy: 0.4226 - val_loss: 1.8686 - val_accuracy: 0.4953\n",
      "Epoch 105/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4070 - accuracy: 0.4097 - val_loss: 1.8646 - val_accuracy: 0.4860\n",
      "Epoch 106/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4534 - accuracy: 0.4187 - val_loss: 1.8625 - val_accuracy: 0.4860\n",
      "Epoch 107/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4693 - accuracy: 0.4093 - val_loss: 1.8611 - val_accuracy: 0.4860\n",
      "Epoch 108/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4262 - accuracy: 0.4164 - val_loss: 1.8581 - val_accuracy: 0.4860\n",
      "Epoch 109/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4919 - accuracy: 0.3980 - val_loss: 1.8580 - val_accuracy: 0.4860\n",
      "Epoch 110/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5197 - accuracy: 0.3976 - val_loss: 1.8586 - val_accuracy: 0.4860\n",
      "Epoch 111/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3983 - accuracy: 0.4164 - val_loss: 1.8554 - val_accuracy: 0.4860\n",
      "Epoch 112/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4097 - accuracy: 0.4121 - val_loss: 1.8516 - val_accuracy: 0.4860\n",
      "Epoch 113/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4150 - accuracy: 0.4148 - val_loss: 1.8493 - val_accuracy: 0.4860\n",
      "Epoch 114/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4609 - accuracy: 0.3972 - val_loss: 1.8466 - val_accuracy: 0.4860\n",
      "Epoch 115/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4565 - accuracy: 0.4081 - val_loss: 1.8450 - val_accuracy: 0.4860\n",
      "Epoch 116/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4436 - accuracy: 0.4058 - val_loss: 1.8429 - val_accuracy: 0.4860\n",
      "Epoch 117/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4862 - accuracy: 0.4109 - val_loss: 1.8428 - val_accuracy: 0.4860\n",
      "Epoch 118/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4120 - accuracy: 0.4156 - val_loss: 1.8407 - val_accuracy: 0.4860\n",
      "Epoch 119/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4349 - accuracy: 0.4199 - val_loss: 1.8398 - val_accuracy: 0.4860\n",
      "Epoch 120/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4605 - accuracy: 0.4031 - val_loss: 1.8383 - val_accuracy: 0.4860\n",
      "Epoch 121/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4223 - accuracy: 0.4187 - val_loss: 1.8380 - val_accuracy: 0.4860\n",
      "Epoch 122/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4165 - accuracy: 0.4070 - val_loss: 1.8357 - val_accuracy: 0.4860\n",
      "Epoch 123/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3882 - accuracy: 0.4168 - val_loss: 1.8335 - val_accuracy: 0.4953\n",
      "Epoch 124/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5328 - accuracy: 0.3901 - val_loss: 1.8339 - val_accuracy: 0.4953\n",
      "Epoch 125/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4043 - accuracy: 0.4113 - val_loss: 1.8324 - val_accuracy: 0.4953\n",
      "Epoch 126/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3284 - accuracy: 0.4234 - val_loss: 1.8275 - val_accuracy: 0.4953\n",
      "Epoch 127/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4050 - accuracy: 0.4203 - val_loss: 1.8254 - val_accuracy: 0.4953\n",
      "Epoch 128/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4312 - accuracy: 0.4078 - val_loss: 1.8241 - val_accuracy: 0.4953\n",
      "Epoch 129/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3307 - accuracy: 0.4222 - val_loss: 1.8205 - val_accuracy: 0.4953\n",
      "Epoch 130/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4329 - accuracy: 0.4058 - val_loss: 1.8198 - val_accuracy: 0.4953\n",
      "Epoch 131/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4170 - accuracy: 0.4042 - val_loss: 1.8187 - val_accuracy: 0.4953\n",
      "Epoch 132/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4384 - accuracy: 0.4140 - val_loss: 1.8182 - val_accuracy: 0.4953\n",
      "Epoch 133/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4394 - accuracy: 0.4097 - val_loss: 1.8176 - val_accuracy: 0.4953\n",
      "Epoch 134/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3564 - accuracy: 0.4199 - val_loss: 1.8159 - val_accuracy: 0.5047\n",
      "Epoch 135/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4546 - accuracy: 0.4078 - val_loss: 1.8161 - val_accuracy: 0.4953\n",
      "Epoch 136/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3902 - accuracy: 0.4179 - val_loss: 1.8146 - val_accuracy: 0.4953\n",
      "Epoch 137/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4254 - accuracy: 0.4105 - val_loss: 1.8140 - val_accuracy: 0.4953\n",
      "Epoch 138/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4467 - accuracy: 0.4097 - val_loss: 1.8128 - val_accuracy: 0.5047\n",
      "Epoch 139/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3877 - accuracy: 0.4105 - val_loss: 1.8118 - val_accuracy: 0.5047\n",
      "Epoch 140/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4838 - accuracy: 0.4089 - val_loss: 1.8129 - val_accuracy: 0.5047\n",
      "Epoch 141/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4228 - accuracy: 0.4226 - val_loss: 1.8125 - val_accuracy: 0.5140\n",
      "Epoch 142/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4045 - accuracy: 0.4207 - val_loss: 1.8117 - val_accuracy: 0.5140\n",
      "Epoch 143/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3618 - accuracy: 0.4211 - val_loss: 1.8095 - val_accuracy: 0.5140\n",
      "Epoch 144/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4102 - accuracy: 0.4034 - val_loss: 1.8085 - val_accuracy: 0.5047\n",
      "Epoch 145/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3954 - accuracy: 0.4293 - val_loss: 1.8068 - val_accuracy: 0.5140\n",
      "Epoch 146/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4283 - accuracy: 0.4128 - val_loss: 1.8065 - val_accuracy: 0.5140\n",
      "Epoch 147/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3981 - accuracy: 0.4203 - val_loss: 1.8056 - val_accuracy: 0.5327\n",
      "Epoch 148/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4189 - accuracy: 0.4109 - val_loss: 1.8031 - val_accuracy: 0.5234\n",
      "Epoch 149/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3646 - accuracy: 0.4121 - val_loss: 1.8019 - val_accuracy: 0.5234\n",
      "Epoch 150/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3758 - accuracy: 0.4238 - val_loss: 1.8005 - val_accuracy: 0.5047\n",
      "Epoch 151/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3604 - accuracy: 0.4301 - val_loss: 1.7986 - val_accuracy: 0.5140\n",
      "Epoch 152/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3546 - accuracy: 0.4309 - val_loss: 1.7961 - val_accuracy: 0.5140\n",
      "Epoch 153/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3622 - accuracy: 0.4289 - val_loss: 1.7948 - val_accuracy: 0.5140\n",
      "Epoch 154/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4080 - accuracy: 0.4152 - val_loss: 1.7941 - val_accuracy: 0.5421\n",
      "Epoch 155/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3959 - accuracy: 0.4289 - val_loss: 1.7941 - val_accuracy: 0.5327\n",
      "Epoch 156/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4164 - accuracy: 0.4215 - val_loss: 1.7948 - val_accuracy: 0.5327\n",
      "Epoch 157/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3769 - accuracy: 0.4230 - val_loss: 1.7938 - val_accuracy: 0.5327\n",
      "Epoch 158/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4254 - accuracy: 0.3972 - val_loss: 1.7947 - val_accuracy: 0.5327\n",
      "Epoch 159/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.5161 - accuracy: 0.3937 - val_loss: 1.7975 - val_accuracy: 0.5327\n",
      "Epoch 160/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4040 - accuracy: 0.4132 - val_loss: 1.7970 - val_accuracy: 0.5327\n",
      "Epoch 161/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4111 - accuracy: 0.4203 - val_loss: 1.7964 - val_accuracy: 0.5327\n",
      "Epoch 162/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4375 - accuracy: 0.4191 - val_loss: 1.7970 - val_accuracy: 0.5327\n",
      "Epoch 163/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3985 - accuracy: 0.4136 - val_loss: 1.7958 - val_accuracy: 0.5327\n",
      "Epoch 164/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3515 - accuracy: 0.4340 - val_loss: 1.7937 - val_accuracy: 0.5327\n",
      "Epoch 165/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.2975 - accuracy: 0.4438 - val_loss: 1.7904 - val_accuracy: 0.5327\n",
      "Epoch 166/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3650 - accuracy: 0.4273 - val_loss: 1.7876 - val_accuracy: 0.5327\n",
      "Epoch 167/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4119 - accuracy: 0.4179 - val_loss: 1.7877 - val_accuracy: 0.5327\n",
      "Epoch 168/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4413 - accuracy: 0.4062 - val_loss: 1.7867 - val_accuracy: 0.5327\n",
      "Epoch 169/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3973 - accuracy: 0.4187 - val_loss: 1.7870 - val_accuracy: 0.5327\n",
      "Epoch 170/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4136 - accuracy: 0.4172 - val_loss: 1.7862 - val_accuracy: 0.5327\n",
      "Epoch 171/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3676 - accuracy: 0.4113 - val_loss: 1.7851 - val_accuracy: 0.5327\n",
      "Epoch 172/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4176 - accuracy: 0.4191 - val_loss: 1.7855 - val_accuracy: 0.5327\n",
      "Epoch 173/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.4128 - accuracy: 0.4140 - val_loss: 1.7853 - val_accuracy: 0.5234\n",
      "Epoch 174/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4425 - accuracy: 0.4089 - val_loss: 1.7855 - val_accuracy: 0.5327\n",
      "Epoch 175/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.4387 - accuracy: 0.4222 - val_loss: 1.7872 - val_accuracy: 0.5234\n",
      "Epoch 176/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3896 - accuracy: 0.4168 - val_loss: 1.7867 - val_accuracy: 0.5234\n",
      "Epoch 177/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4010 - accuracy: 0.4109 - val_loss: 1.7860 - val_accuracy: 0.5234\n",
      "Epoch 178/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3663 - accuracy: 0.4297 - val_loss: 1.7833 - val_accuracy: 0.5234\n",
      "Epoch 179/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3633 - accuracy: 0.4309 - val_loss: 1.7829 - val_accuracy: 0.5234\n",
      "Epoch 180/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4287 - accuracy: 0.4132 - val_loss: 1.7821 - val_accuracy: 0.5234\n",
      "Epoch 181/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.4069 - accuracy: 0.4097 - val_loss: 1.7822 - val_accuracy: 0.5234\n",
      "Epoch 182/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4104 - accuracy: 0.4144 - val_loss: 1.7815 - val_accuracy: 0.5234\n",
      "Epoch 183/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3941 - accuracy: 0.4128 - val_loss: 1.7806 - val_accuracy: 0.5234\n",
      "Epoch 184/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3359 - accuracy: 0.4399 - val_loss: 1.7776 - val_accuracy: 0.5234\n",
      "Epoch 185/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.4332 - accuracy: 0.4121 - val_loss: 1.7765 - val_accuracy: 0.5234\n",
      "Epoch 186/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.3838 - accuracy: 0.4128 - val_loss: 1.7772 - val_accuracy: 0.5234\n",
      "Epoch 187/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.3737 - accuracy: 0.4199 - val_loss: 1.7770 - val_accuracy: 0.5234\n",
      "Epoch 188/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3725 - accuracy: 0.4144 - val_loss: 1.7766 - val_accuracy: 0.5234\n",
      "Epoch 189/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3598 - accuracy: 0.4175 - val_loss: 1.7748 - val_accuracy: 0.5234\n",
      "Epoch 190/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.4696 - accuracy: 0.4085 - val_loss: 1.7771 - val_accuracy: 0.5234\n",
      "Epoch 191/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3692 - accuracy: 0.4238 - val_loss: 1.7758 - val_accuracy: 0.5234\n",
      "Epoch 192/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4050 - accuracy: 0.4211 - val_loss: 1.7743 - val_accuracy: 0.5234\n",
      "Epoch 193/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3489 - accuracy: 0.4246 - val_loss: 1.7720 - val_accuracy: 0.5234\n",
      "Epoch 194/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.4335 - accuracy: 0.4132 - val_loss: 1.7728 - val_accuracy: 0.5140\n",
      "Epoch 195/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3954 - accuracy: 0.4305 - val_loss: 1.7716 - val_accuracy: 0.5140\n",
      "Epoch 196/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3202 - accuracy: 0.4281 - val_loss: 1.7682 - val_accuracy: 0.5140\n",
      "Epoch 197/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3586 - accuracy: 0.4125 - val_loss: 1.7666 - val_accuracy: 0.5140\n",
      "Epoch 198/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3616 - accuracy: 0.4191 - val_loss: 1.7658 - val_accuracy: 0.5140\n",
      "Epoch 199/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3309 - accuracy: 0.4293 - val_loss: 1.7643 - val_accuracy: 0.5140\n",
      "Epoch 200/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3775 - accuracy: 0.4297 - val_loss: 1.7634 - val_accuracy: 0.5140\n",
      "0.514018714427948 {'loss': 2.377525806427002, 'accuracy': 0.42969056963920593, 'val_loss': 1.7633767127990723, 'val_accuracy': 0.514018714427948}\n",
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, 29)]              0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 41)                1230      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 75)                3150      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 75)                0         \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 75)                0         \n",
      "=================================================================\n",
      "Total params: 4,380\n",
      "Trainable params: 4,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 5.0252 - accuracy: 0.0012 - val_loss: 4.5367 - val_accuracy: 0.0187\n",
      "Epoch 2/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.9166 - accuracy: 0.0024 - val_loss: 4.4710 - val_accuracy: 0.0187\n",
      "Epoch 3/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.8251 - accuracy: 0.0043 - val_loss: 4.4062 - val_accuracy: 0.0187\n",
      "Epoch 4/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.7475 - accuracy: 0.0090 - val_loss: 4.3404 - val_accuracy: 0.0467\n",
      "Epoch 5/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.6441 - accuracy: 0.0176 - val_loss: 4.2738 - val_accuracy: 0.0467\n",
      "Epoch 6/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.5561 - accuracy: 0.0259 - val_loss: 4.2078 - val_accuracy: 0.0561\n",
      "Epoch 7/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.5139 - accuracy: 0.0360 - val_loss: 4.1459 - val_accuracy: 0.0935\n",
      "Epoch 8/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.3983 - accuracy: 0.0611 - val_loss: 4.0821 - val_accuracy: 0.1121\n",
      "Epoch 9/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 2ms/step - loss: 4.3519 - accuracy: 0.0678 - val_loss: 4.0206 - val_accuracy: 0.1495\n",
      "Epoch 10/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.2621 - accuracy: 0.0952 - val_loss: 3.9596 - val_accuracy: 0.1869\n",
      "Epoch 11/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.2193 - accuracy: 0.1097 - val_loss: 3.9001 - val_accuracy: 0.2150\n",
      "Epoch 12/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.1426 - accuracy: 0.1269 - val_loss: 3.8410 - val_accuracy: 0.2336\n",
      "Epoch 13/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.0941 - accuracy: 0.1434 - val_loss: 3.7840 - val_accuracy: 0.2710\n",
      "Epoch 14/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.0212 - accuracy: 0.1657 - val_loss: 3.7270 - val_accuracy: 0.2804\n",
      "Epoch 15/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.9612 - accuracy: 0.1720 - val_loss: 3.6745 - val_accuracy: 0.2991\n",
      "Epoch 16/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.9322 - accuracy: 0.1915 - val_loss: 3.6249 - val_accuracy: 0.3178\n",
      "Epoch 17/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.8403 - accuracy: 0.2119 - val_loss: 3.5740 - val_accuracy: 0.3645\n",
      "Epoch 18/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.8213 - accuracy: 0.2174 - val_loss: 3.5281 - val_accuracy: 0.4019\n",
      "Epoch 19/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.7926 - accuracy: 0.2256 - val_loss: 3.4843 - val_accuracy: 0.4299\n",
      "Epoch 20/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.7702 - accuracy: 0.2291 - val_loss: 3.4425 - val_accuracy: 0.4299\n",
      "Epoch 21/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.7478 - accuracy: 0.2460 - val_loss: 3.4037 - val_accuracy: 0.4299\n",
      "Epoch 22/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6870 - accuracy: 0.2570 - val_loss: 3.3657 - val_accuracy: 0.4486\n",
      "Epoch 23/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.7101 - accuracy: 0.2476 - val_loss: 3.3323 - val_accuracy: 0.4673\n",
      "Epoch 24/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6710 - accuracy: 0.2624 - val_loss: 3.3023 - val_accuracy: 0.4953\n",
      "Epoch 25/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6203 - accuracy: 0.2675 - val_loss: 3.2683 - val_accuracy: 0.4953\n",
      "Epoch 26/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 3.5834 - accuracy: 0.2797 - val_loss: 3.2381 - val_accuracy: 0.4953\n",
      "Epoch 27/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 3.6202 - accuracy: 0.2754 - val_loss: 3.2132 - val_accuracy: 0.5047\n",
      "Epoch 28/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5439 - accuracy: 0.2914 - val_loss: 3.1882 - val_accuracy: 0.5140\n",
      "Epoch 29/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5518 - accuracy: 0.2859 - val_loss: 3.1636 - val_accuracy: 0.5327\n",
      "Epoch 30/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5196 - accuracy: 0.2942 - val_loss: 3.1411 - val_accuracy: 0.5421\n",
      "Epoch 31/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5160 - accuracy: 0.2930 - val_loss: 3.1186 - val_accuracy: 0.5607\n",
      "Epoch 32/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 3.5674 - accuracy: 0.2871 - val_loss: 3.0994 - val_accuracy: 0.5514\n",
      "Epoch 33/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.4992 - accuracy: 0.2981 - val_loss: 3.0820 - val_accuracy: 0.5514\n",
      "Epoch 34/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.4734 - accuracy: 0.2985 - val_loss: 3.0616 - val_accuracy: 0.5607\n",
      "Epoch 35/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5107 - accuracy: 0.2895 - val_loss: 3.0471 - val_accuracy: 0.5514\n",
      "Epoch 36/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.4132 - accuracy: 0.3134 - val_loss: 3.0289 - val_accuracy: 0.5514\n",
      "Epoch 37/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.4683 - accuracy: 0.2949 - val_loss: 3.0144 - val_accuracy: 0.5514\n",
      "Epoch 38/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.4396 - accuracy: 0.3047 - val_loss: 3.0024 - val_accuracy: 0.5607\n",
      "Epoch 39/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.4134 - accuracy: 0.3059 - val_loss: 2.9880 - val_accuracy: 0.5607\n",
      "Epoch 40/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.4307 - accuracy: 0.3020 - val_loss: 2.9793 - val_accuracy: 0.5607\n",
      "Epoch 41/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3998 - accuracy: 0.3083 - val_loss: 2.9686 - val_accuracy: 0.5607\n",
      "Epoch 42/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3903 - accuracy: 0.3063 - val_loss: 2.9580 - val_accuracy: 0.5607\n",
      "Epoch 43/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 3.4171 - accuracy: 0.3087 - val_loss: 2.9518 - val_accuracy: 0.5607\n",
      "Epoch 44/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3641 - accuracy: 0.3157 - val_loss: 2.9416 - val_accuracy: 0.5701\n",
      "Epoch 45/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 3.4386 - accuracy: 0.3008 - val_loss: 2.9382 - val_accuracy: 0.5701\n",
      "Epoch 46/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 3.4007 - accuracy: 0.3000 - val_loss: 2.9329 - val_accuracy: 0.5701\n",
      "Epoch 47/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.4148 - accuracy: 0.3032 - val_loss: 2.9284 - val_accuracy: 0.5701\n",
      "Epoch 48/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.4481 - accuracy: 0.2934 - val_loss: 2.9275 - val_accuracy: 0.5607\n",
      "Epoch 49/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3531 - accuracy: 0.3165 - val_loss: 2.9211 - val_accuracy: 0.5607\n",
      "Epoch 50/200\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 3.3322 - accuracy: 0.3173 - val_loss: 2.9140 - val_accuracy: 0.5607\n",
      "Epoch 51/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.4127 - accuracy: 0.3016 - val_loss: 2.9124 - val_accuracy: 0.5607\n",
      "Epoch 52/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3916 - accuracy: 0.3090 - val_loss: 2.9085 - val_accuracy: 0.5607\n",
      "Epoch 53/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.4152 - accuracy: 0.3016 - val_loss: 2.9050 - val_accuracy: 0.5607\n",
      "Epoch 54/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3822 - accuracy: 0.3106 - val_loss: 2.9028 - val_accuracy: 0.5607\n",
      "Epoch 55/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3543 - accuracy: 0.3216 - val_loss: 2.8997 - val_accuracy: 0.5701\n",
      "Epoch 56/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3057 - accuracy: 0.3267 - val_loss: 2.8961 - val_accuracy: 0.5701\n",
      "Epoch 57/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3532 - accuracy: 0.3216 - val_loss: 2.8940 - val_accuracy: 0.5701\n",
      "Epoch 58/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3746 - accuracy: 0.3184 - val_loss: 2.8915 - val_accuracy: 0.5701\n",
      "Epoch 59/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3861 - accuracy: 0.3079 - val_loss: 2.8899 - val_accuracy: 0.5701\n",
      "Epoch 60/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3585 - accuracy: 0.3255 - val_loss: 2.8876 - val_accuracy: 0.5794\n",
      "Epoch 61/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3901 - accuracy: 0.3149 - val_loss: 2.8876 - val_accuracy: 0.5794\n",
      "Epoch 62/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3890 - accuracy: 0.3122 - val_loss: 2.8853 - val_accuracy: 0.5794\n",
      "Epoch 63/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3845 - accuracy: 0.3118 - val_loss: 2.8833 - val_accuracy: 0.5794\n",
      "Epoch 64/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3576 - accuracy: 0.3286 - val_loss: 2.8799 - val_accuracy: 0.5794\n",
      "Epoch 65/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3706 - accuracy: 0.3157 - val_loss: 2.8803 - val_accuracy: 0.5794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3638 - accuracy: 0.3220 - val_loss: 2.8810 - val_accuracy: 0.5794\n",
      "Epoch 67/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.4135 - accuracy: 0.3212 - val_loss: 2.8827 - val_accuracy: 0.5794\n",
      "Epoch 68/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3851 - accuracy: 0.3184 - val_loss: 2.8839 - val_accuracy: 0.5794\n",
      "Epoch 69/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3563 - accuracy: 0.3263 - val_loss: 2.8813 - val_accuracy: 0.5794\n",
      "Epoch 70/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.4063 - accuracy: 0.3188 - val_loss: 2.8819 - val_accuracy: 0.5794\n",
      "Epoch 71/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3345 - accuracy: 0.3392 - val_loss: 2.8812 - val_accuracy: 0.5794\n",
      "Epoch 72/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3575 - accuracy: 0.3322 - val_loss: 2.8802 - val_accuracy: 0.5794\n",
      "Epoch 73/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3536 - accuracy: 0.3337 - val_loss: 2.8776 - val_accuracy: 0.5794\n",
      "Epoch 74/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3348 - accuracy: 0.3376 - val_loss: 2.8771 - val_accuracy: 0.5794\n",
      "Epoch 75/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 3.3075 - accuracy: 0.3510 - val_loss: 2.8740 - val_accuracy: 0.5794\n",
      "Epoch 76/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3572 - accuracy: 0.3431 - val_loss: 2.8740 - val_accuracy: 0.5794\n",
      "Epoch 77/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3521 - accuracy: 0.3373 - val_loss: 2.8755 - val_accuracy: 0.5794\n",
      "Epoch 78/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3675 - accuracy: 0.3373 - val_loss: 2.8737 - val_accuracy: 0.5794\n",
      "Epoch 79/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3034 - accuracy: 0.3596 - val_loss: 2.8698 - val_accuracy: 0.5794\n",
      "Epoch 80/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3342 - accuracy: 0.3537 - val_loss: 2.8678 - val_accuracy: 0.5888\n",
      "Epoch 81/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3382 - accuracy: 0.3549 - val_loss: 2.8659 - val_accuracy: 0.5888\n",
      "Epoch 82/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3307 - accuracy: 0.3494 - val_loss: 2.8651 - val_accuracy: 0.5888\n",
      "Epoch 83/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3515 - accuracy: 0.3498 - val_loss: 2.8660 - val_accuracy: 0.5888\n",
      "Epoch 84/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3574 - accuracy: 0.3467 - val_loss: 2.8671 - val_accuracy: 0.5888\n",
      "Epoch 85/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3807 - accuracy: 0.3529 - val_loss: 2.8686 - val_accuracy: 0.5888\n",
      "Epoch 86/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3651 - accuracy: 0.3490 - val_loss: 2.8704 - val_accuracy: 0.5888\n",
      "Epoch 87/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3705 - accuracy: 0.3533 - val_loss: 2.8706 - val_accuracy: 0.5888\n",
      "Epoch 88/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3269 - accuracy: 0.3635 - val_loss: 2.8693 - val_accuracy: 0.5888\n",
      "Epoch 89/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.2833 - accuracy: 0.3858 - val_loss: 2.8646 - val_accuracy: 0.5888\n",
      "Epoch 90/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 3.3165 - accuracy: 0.3655 - val_loss: 2.8635 - val_accuracy: 0.5888\n",
      "Epoch 91/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3487 - accuracy: 0.3580 - val_loss: 2.8635 - val_accuracy: 0.5981\n",
      "Epoch 92/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3640 - accuracy: 0.3490 - val_loss: 2.8629 - val_accuracy: 0.5981\n",
      "Epoch 93/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3390 - accuracy: 0.3596 - val_loss: 2.8638 - val_accuracy: 0.5981\n",
      "Epoch 94/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.4180 - accuracy: 0.3510 - val_loss: 2.8680 - val_accuracy: 0.5981\n",
      "Epoch 95/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3414 - accuracy: 0.3627 - val_loss: 2.8671 - val_accuracy: 0.5981\n",
      "Epoch 96/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3420 - accuracy: 0.3615 - val_loss: 2.8695 - val_accuracy: 0.5981\n",
      "Epoch 97/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3766 - accuracy: 0.3545 - val_loss: 2.8697 - val_accuracy: 0.6075\n",
      "Epoch 98/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3261 - accuracy: 0.3608 - val_loss: 2.8668 - val_accuracy: 0.5981\n",
      "Epoch 99/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3299 - accuracy: 0.3741 - val_loss: 2.8649 - val_accuracy: 0.6075\n",
      "Epoch 100/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3431 - accuracy: 0.3713 - val_loss: 2.8627 - val_accuracy: 0.6075\n",
      "Epoch 101/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.2995 - accuracy: 0.3799 - val_loss: 2.8612 - val_accuracy: 0.6075\n",
      "Epoch 102/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3152 - accuracy: 0.3674 - val_loss: 2.8593 - val_accuracy: 0.6075\n",
      "Epoch 103/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3315 - accuracy: 0.3670 - val_loss: 2.8601 - val_accuracy: 0.6075\n",
      "Epoch 104/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3148 - accuracy: 0.3831 - val_loss: 2.8567 - val_accuracy: 0.6075\n",
      "Epoch 105/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3049 - accuracy: 0.3784 - val_loss: 2.8551 - val_accuracy: 0.6075\n",
      "Epoch 106/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.2881 - accuracy: 0.3827 - val_loss: 2.8521 - val_accuracy: 0.6075\n",
      "Epoch 107/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.2885 - accuracy: 0.3854 - val_loss: 2.8484 - val_accuracy: 0.6075\n",
      "Epoch 108/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3411 - accuracy: 0.3811 - val_loss: 2.8465 - val_accuracy: 0.6075\n",
      "Epoch 109/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3266 - accuracy: 0.3721 - val_loss: 2.8454 - val_accuracy: 0.6075\n",
      "Epoch 110/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3190 - accuracy: 0.3745 - val_loss: 2.8484 - val_accuracy: 0.6168\n",
      "Epoch 111/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3214 - accuracy: 0.3709 - val_loss: 2.8495 - val_accuracy: 0.6168\n",
      "Epoch 112/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3296 - accuracy: 0.3627 - val_loss: 2.8477 - val_accuracy: 0.6075\n",
      "Epoch 113/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.2850 - accuracy: 0.3780 - val_loss: 2.8470 - val_accuracy: 0.6168\n",
      "Epoch 114/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3487 - accuracy: 0.3709 - val_loss: 2.8486 - val_accuracy: 0.6168\n",
      "Epoch 115/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3749 - accuracy: 0.3541 - val_loss: 2.8498 - val_accuracy: 0.6075\n",
      "Epoch 116/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3551 - accuracy: 0.3694 - val_loss: 2.8492 - val_accuracy: 0.6075\n",
      "Epoch 117/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.2992 - accuracy: 0.3846 - val_loss: 2.8475 - val_accuracy: 0.6075\n",
      "Epoch 118/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3554 - accuracy: 0.3639 - val_loss: 2.8472 - val_accuracy: 0.6168\n",
      "Epoch 119/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3407 - accuracy: 0.3811 - val_loss: 2.8456 - val_accuracy: 0.6168\n",
      "Epoch 120/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3599 - accuracy: 0.3658 - val_loss: 2.8467 - val_accuracy: 0.6168\n",
      "Epoch 121/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3286 - accuracy: 0.3721 - val_loss: 2.8464 - val_accuracy: 0.6168\n",
      "Epoch 122/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.2962 - accuracy: 0.3854 - val_loss: 2.8451 - val_accuracy: 0.6168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.2759 - accuracy: 0.3796 - val_loss: 2.8448 - val_accuracy: 0.6168\n",
      "Epoch 124/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3320 - accuracy: 0.3803 - val_loss: 2.8448 - val_accuracy: 0.6168\n",
      "Epoch 125/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3303 - accuracy: 0.3729 - val_loss: 2.8465 - val_accuracy: 0.6168\n",
      "Epoch 126/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3975 - accuracy: 0.3498 - val_loss: 2.8496 - val_accuracy: 0.6168\n",
      "Epoch 127/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3250 - accuracy: 0.3796 - val_loss: 2.8486 - val_accuracy: 0.6168\n",
      "Epoch 128/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3027 - accuracy: 0.3831 - val_loss: 2.8456 - val_accuracy: 0.6168\n",
      "Epoch 129/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3750 - accuracy: 0.3596 - val_loss: 2.8491 - val_accuracy: 0.6168\n",
      "Epoch 130/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3362 - accuracy: 0.3764 - val_loss: 2.8494 - val_accuracy: 0.6168\n",
      "Epoch 131/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3497 - accuracy: 0.3721 - val_loss: 2.8512 - val_accuracy: 0.6075\n",
      "Epoch 132/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3075 - accuracy: 0.3784 - val_loss: 2.8485 - val_accuracy: 0.6168\n",
      "Epoch 133/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3457 - accuracy: 0.3752 - val_loss: 2.8487 - val_accuracy: 0.6075\n",
      "Epoch 134/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.2972 - accuracy: 0.3866 - val_loss: 2.8457 - val_accuracy: 0.6075\n",
      "Epoch 135/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3364 - accuracy: 0.3796 - val_loss: 2.8456 - val_accuracy: 0.6168\n",
      "Epoch 136/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3330 - accuracy: 0.3784 - val_loss: 2.8464 - val_accuracy: 0.6168\n",
      "Epoch 137/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3012 - accuracy: 0.3721 - val_loss: 2.8439 - val_accuracy: 0.6168\n",
      "Epoch 138/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3737 - accuracy: 0.3725 - val_loss: 2.8465 - val_accuracy: 0.6168\n",
      "Epoch 139/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3566 - accuracy: 0.3811 - val_loss: 2.8491 - val_accuracy: 0.6168\n",
      "Epoch 140/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.2698 - accuracy: 0.3968 - val_loss: 2.8455 - val_accuracy: 0.6168\n",
      "Epoch 141/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3249 - accuracy: 0.3776 - val_loss: 2.8460 - val_accuracy: 0.6168\n",
      "Epoch 142/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3671 - accuracy: 0.3717 - val_loss: 2.8488 - val_accuracy: 0.6075\n",
      "Epoch 143/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.2548 - accuracy: 0.3917 - val_loss: 2.8450 - val_accuracy: 0.6168\n",
      "Epoch 144/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3522 - accuracy: 0.3713 - val_loss: 2.8460 - val_accuracy: 0.6168\n",
      "Epoch 145/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3398 - accuracy: 0.3749 - val_loss: 2.8449 - val_accuracy: 0.6168\n",
      "Epoch 146/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.2796 - accuracy: 0.3890 - val_loss: 2.8416 - val_accuracy: 0.6168\n",
      "Epoch 147/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3014 - accuracy: 0.3717 - val_loss: 2.8379 - val_accuracy: 0.6168\n",
      "Epoch 148/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.2948 - accuracy: 0.3854 - val_loss: 2.8339 - val_accuracy: 0.6168\n",
      "Epoch 149/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3107 - accuracy: 0.3921 - val_loss: 2.8354 - val_accuracy: 0.6168\n",
      "Epoch 150/200\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 3.3469 - accuracy: 0.3678 - val_loss: 2.8384 - val_accuracy: 0.6262\n",
      "Epoch 151/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3063 - accuracy: 0.3874 - val_loss: 2.8364 - val_accuracy: 0.6168\n",
      "Epoch 152/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3473 - accuracy: 0.3737 - val_loss: 2.8379 - val_accuracy: 0.6168\n",
      "Epoch 153/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3226 - accuracy: 0.3870 - val_loss: 2.8402 - val_accuracy: 0.6168\n",
      "Epoch 154/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3135 - accuracy: 0.3858 - val_loss: 2.8399 - val_accuracy: 0.6168\n",
      "Epoch 155/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3358 - accuracy: 0.3690 - val_loss: 2.8398 - val_accuracy: 0.6168\n",
      "Epoch 156/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3246 - accuracy: 0.3698 - val_loss: 2.8420 - val_accuracy: 0.6168\n",
      "Epoch 157/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3381 - accuracy: 0.3799 - val_loss: 2.8410 - val_accuracy: 0.6262\n",
      "Epoch 158/200\n",
      "160/160 [==============================] - ETA: 0s - loss: 3.2598 - accuracy: 0.39 - 0s 2ms/step - loss: 3.2598 - accuracy: 0.3940 - val_loss: 2.8368 - val_accuracy: 0.6262\n",
      "Epoch 159/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3573 - accuracy: 0.3780 - val_loss: 2.8393 - val_accuracy: 0.6262\n",
      "Epoch 160/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3224 - accuracy: 0.3772 - val_loss: 2.8418 - val_accuracy: 0.6262\n",
      "Epoch 161/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3163 - accuracy: 0.3721 - val_loss: 2.8410 - val_accuracy: 0.6262\n",
      "Epoch 162/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.2815 - accuracy: 0.3854 - val_loss: 2.8367 - val_accuracy: 0.6262\n",
      "Epoch 163/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.2542 - accuracy: 0.3893 - val_loss: 2.8331 - val_accuracy: 0.6355\n",
      "Epoch 164/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3401 - accuracy: 0.3752 - val_loss: 2.8349 - val_accuracy: 0.6355\n",
      "Epoch 165/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3363 - accuracy: 0.3733 - val_loss: 2.8335 - val_accuracy: 0.6262\n",
      "Epoch 166/200\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 3.3193 - accuracy: 0.3819 - val_loss: 2.8329 - val_accuracy: 0.6355\n",
      "Epoch 167/200\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 3.2858 - accuracy: 0.3862 - val_loss: 2.8308 - val_accuracy: 0.6262\n",
      "Epoch 168/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3272 - accuracy: 0.3843 - val_loss: 2.8310 - val_accuracy: 0.6355\n",
      "Epoch 169/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 3.3035 - accuracy: 0.3788 - val_loss: 2.8300 - val_accuracy: 0.6355\n",
      "Epoch 170/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 3.2768 - accuracy: 0.3909 - val_loss: 2.8282 - val_accuracy: 0.6355\n",
      "Epoch 171/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3095 - accuracy: 0.3819 - val_loss: 2.8290 - val_accuracy: 0.6355\n",
      "Epoch 172/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3517 - accuracy: 0.3749 - val_loss: 2.8299 - val_accuracy: 0.6262\n",
      "Epoch 173/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.2724 - accuracy: 0.3893 - val_loss: 2.8293 - val_accuracy: 0.6355\n",
      "Epoch 174/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3205 - accuracy: 0.3658 - val_loss: 2.8310 - val_accuracy: 0.6262\n",
      "Epoch 175/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3479 - accuracy: 0.3764 - val_loss: 2.8306 - val_accuracy: 0.6262\n",
      "Epoch 176/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3200 - accuracy: 0.3893 - val_loss: 2.8309 - val_accuracy: 0.6262\n",
      "Epoch 177/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3423 - accuracy: 0.3647 - val_loss: 2.8317 - val_accuracy: 0.6168\n",
      "Epoch 178/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3407 - accuracy: 0.3788 - val_loss: 2.8326 - val_accuracy: 0.6168\n",
      "Epoch 179/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 3ms/step - loss: 3.2960 - accuracy: 0.3835 - val_loss: 2.8319 - val_accuracy: 0.6168\n",
      "Epoch 180/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3032 - accuracy: 0.3815 - val_loss: 2.8324 - val_accuracy: 0.6168\n",
      "Epoch 181/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3615 - accuracy: 0.3662 - val_loss: 2.8325 - val_accuracy: 0.6168\n",
      "Epoch 182/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3416 - accuracy: 0.3768 - val_loss: 2.8307 - val_accuracy: 0.6168\n",
      "Epoch 183/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3031 - accuracy: 0.3862 - val_loss: 2.8291 - val_accuracy: 0.6168\n",
      "Epoch 184/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.2863 - accuracy: 0.3811 - val_loss: 2.8277 - val_accuracy: 0.6168\n",
      "Epoch 185/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3380 - accuracy: 0.3772 - val_loss: 2.8272 - val_accuracy: 0.6168\n",
      "Epoch 186/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.2717 - accuracy: 0.3846 - val_loss: 2.8248 - val_accuracy: 0.6168\n",
      "Epoch 187/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.2945 - accuracy: 0.3948 - val_loss: 2.8248 - val_accuracy: 0.6168\n",
      "Epoch 188/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3344 - accuracy: 0.3760 - val_loss: 2.8265 - val_accuracy: 0.6168\n",
      "Epoch 189/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.2849 - accuracy: 0.3890 - val_loss: 2.8252 - val_accuracy: 0.6168\n",
      "Epoch 190/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 3.3416 - accuracy: 0.3749 - val_loss: 2.8265 - val_accuracy: 0.6168\n",
      "Epoch 191/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3025 - accuracy: 0.3870 - val_loss: 2.8258 - val_accuracy: 0.6168\n",
      "Epoch 192/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.2605 - accuracy: 0.4034 - val_loss: 2.8202 - val_accuracy: 0.6075\n",
      "Epoch 193/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.2835 - accuracy: 0.3921 - val_loss: 2.8188 - val_accuracy: 0.6075\n",
      "Epoch 194/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3459 - accuracy: 0.3678 - val_loss: 2.8206 - val_accuracy: 0.6075\n",
      "Epoch 195/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3304 - accuracy: 0.3799 - val_loss: 2.8226 - val_accuracy: 0.6075\n",
      "Epoch 196/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.2637 - accuracy: 0.3956 - val_loss: 2.8213 - val_accuracy: 0.6075\n",
      "Epoch 197/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3130 - accuracy: 0.3803 - val_loss: 2.8197 - val_accuracy: 0.6075\n",
      "Epoch 198/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.2825 - accuracy: 0.3776 - val_loss: 2.8190 - val_accuracy: 0.6168\n",
      "Epoch 199/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.2849 - accuracy: 0.3874 - val_loss: 2.8178 - val_accuracy: 0.6168\n",
      "Epoch 200/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3006 - accuracy: 0.3784 - val_loss: 2.8192 - val_accuracy: 0.6168\n",
      "0.6168224215507507 {'loss': 3.3005502223968506, 'accuracy': 0.37837839126586914, 'val_loss': 2.8191776275634766, 'val_accuracy': 0.6168224215507507}\n",
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, 29)]              0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 41)                1230      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 75)                3150      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 75)                0         \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 75)                0         \n",
      "=================================================================\n",
      "Total params: 4,380\n",
      "Trainable params: 4,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 5.6411 - accuracy: 0.0000e+00 - val_loss: 4.4908 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.5771 - accuracy: 7.8339e-04 - val_loss: 4.4422 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.4970 - accuracy: 3.9170e-04 - val_loss: 4.3933 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.4413 - accuracy: 0.0020 - val_loss: 4.3456 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.3291 - accuracy: 0.0020 - val_loss: 4.2995 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.2124 - accuracy: 0.0020 - val_loss: 4.2531 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.2075 - accuracy: 0.0031 - val_loss: 4.2096 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.0946 - accuracy: 0.0043 - val_loss: 4.1657 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 5.0218 - accuracy: 0.0047 - val_loss: 4.1207 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 4.9437 - accuracy: 0.0055 - val_loss: 4.0767 - val_accuracy: 0.0093\n",
      "Epoch 11/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.8729 - accuracy: 0.0118 - val_loss: 4.0326 - val_accuracy: 0.0093\n",
      "Epoch 12/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.8123 - accuracy: 0.0121 - val_loss: 3.9900 - val_accuracy: 0.0093\n",
      "Epoch 13/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.7564 - accuracy: 0.0129 - val_loss: 3.9478 - val_accuracy: 0.0093\n",
      "Epoch 14/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.7155 - accuracy: 0.0212 - val_loss: 3.9077 - val_accuracy: 0.0187\n",
      "Epoch 15/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.6574 - accuracy: 0.0239 - val_loss: 3.8689 - val_accuracy: 0.0187\n",
      "Epoch 16/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.5618 - accuracy: 0.0325 - val_loss: 3.8293 - val_accuracy: 0.0280\n",
      "Epoch 17/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.5647 - accuracy: 0.0353 - val_loss: 3.7914 - val_accuracy: 0.0467\n",
      "Epoch 18/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.4668 - accuracy: 0.0341 - val_loss: 3.7536 - val_accuracy: 0.0467\n",
      "Epoch 19/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.4337 - accuracy: 0.0537 - val_loss: 3.7173 - val_accuracy: 0.0561\n",
      "Epoch 20/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.3736 - accuracy: 0.0650 - val_loss: 3.6806 - val_accuracy: 0.0841\n",
      "Epoch 21/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.3313 - accuracy: 0.0701 - val_loss: 3.6452 - val_accuracy: 0.0841\n",
      "Epoch 22/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.3134 - accuracy: 0.0779 - val_loss: 3.6103 - val_accuracy: 0.0935\n",
      "Epoch 23/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.2412 - accuracy: 0.0838 - val_loss: 3.5756 - val_accuracy: 0.0935\n",
      "Epoch 24/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.1509 - accuracy: 0.1061 - val_loss: 3.5410 - val_accuracy: 0.1215\n",
      "Epoch 25/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.1448 - accuracy: 0.1187 - val_loss: 3.5079 - val_accuracy: 0.1589\n",
      "Epoch 26/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.1106 - accuracy: 0.1277 - val_loss: 3.4761 - val_accuracy: 0.1682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.1083 - accuracy: 0.1355 - val_loss: 3.4455 - val_accuracy: 0.1869\n",
      "Epoch 28/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.0751 - accuracy: 0.1375 - val_loss: 3.4147 - val_accuracy: 0.2336\n",
      "Epoch 29/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.9909 - accuracy: 0.1673 - val_loss: 3.3832 - val_accuracy: 0.2710\n",
      "Epoch 30/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.9671 - accuracy: 0.1653 - val_loss: 3.3539 - val_accuracy: 0.2991\n",
      "Epoch 31/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.9264 - accuracy: 0.1700 - val_loss: 3.3255 - val_accuracy: 0.3178\n",
      "Epoch 32/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.9117 - accuracy: 0.1802 - val_loss: 3.2987 - val_accuracy: 0.3458\n",
      "Epoch 33/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.8609 - accuracy: 0.1951 - val_loss: 3.2718 - val_accuracy: 0.3645\n",
      "Epoch 34/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.8355 - accuracy: 0.2029 - val_loss: 3.2455 - val_accuracy: 0.3832\n",
      "Epoch 35/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.7905 - accuracy: 0.2111 - val_loss: 3.2203 - val_accuracy: 0.3925\n",
      "Epoch 36/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.7527 - accuracy: 0.2099 - val_loss: 3.1950 - val_accuracy: 0.3925\n",
      "Epoch 37/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.7664 - accuracy: 0.2158 - val_loss: 3.1711 - val_accuracy: 0.4019\n",
      "Epoch 38/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.7416 - accuracy: 0.2280 - val_loss: 3.1482 - val_accuracy: 0.4299\n",
      "Epoch 39/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.7028 - accuracy: 0.2382 - val_loss: 3.1249 - val_accuracy: 0.4393\n",
      "Epoch 40/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.7444 - accuracy: 0.2346 - val_loss: 3.1040 - val_accuracy: 0.4486\n",
      "Epoch 41/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.6931 - accuracy: 0.2335 - val_loss: 3.0827 - val_accuracy: 0.4579\n",
      "Epoch 42/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.6851 - accuracy: 0.2440 - val_loss: 3.0628 - val_accuracy: 0.4673\n",
      "Epoch 43/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.6632 - accuracy: 0.2476 - val_loss: 3.0446 - val_accuracy: 0.4766\n",
      "Epoch 44/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.5688 - accuracy: 0.2628 - val_loss: 3.0250 - val_accuracy: 0.4860\n",
      "Epoch 45/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.5266 - accuracy: 0.2761 - val_loss: 3.0045 - val_accuracy: 0.4860\n",
      "Epoch 46/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.5867 - accuracy: 0.2530 - val_loss: 2.9863 - val_accuracy: 0.4953\n",
      "Epoch 47/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.5248 - accuracy: 0.2711 - val_loss: 2.9684 - val_accuracy: 0.5047\n",
      "Epoch 48/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.5192 - accuracy: 0.2746 - val_loss: 2.9514 - val_accuracy: 0.4953\n",
      "Epoch 49/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.5392 - accuracy: 0.2660 - val_loss: 2.9353 - val_accuracy: 0.4953\n",
      "Epoch 50/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.5292 - accuracy: 0.2730 - val_loss: 2.9197 - val_accuracy: 0.4953\n",
      "Epoch 51/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.5026 - accuracy: 0.2785 - val_loss: 2.9044 - val_accuracy: 0.4953\n",
      "Epoch 52/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.4359 - accuracy: 0.2922 - val_loss: 2.8885 - val_accuracy: 0.4953\n",
      "Epoch 53/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.4623 - accuracy: 0.2836 - val_loss: 2.8737 - val_accuracy: 0.4953\n",
      "Epoch 54/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.4847 - accuracy: 0.2840 - val_loss: 2.8599 - val_accuracy: 0.5047\n",
      "Epoch 55/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.4558 - accuracy: 0.2879 - val_loss: 2.8463 - val_accuracy: 0.5047\n",
      "Epoch 56/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 3.4289 - accuracy: 0.2946 - val_loss: 2.8329 - val_accuracy: 0.5140\n",
      "Epoch 57/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.3665 - accuracy: 0.3040 - val_loss: 2.8195 - val_accuracy: 0.5140\n",
      "Epoch 58/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.3525 - accuracy: 0.3079 - val_loss: 2.8064 - val_accuracy: 0.5140\n",
      "Epoch 59/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.4148 - accuracy: 0.2977 - val_loss: 2.7944 - val_accuracy: 0.5140\n",
      "Epoch 60/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.3801 - accuracy: 0.3024 - val_loss: 2.7835 - val_accuracy: 0.5140\n",
      "Epoch 61/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.3910 - accuracy: 0.3059 - val_loss: 2.7717 - val_accuracy: 0.5140\n",
      "Epoch 62/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 3.3846 - accuracy: 0.3079 - val_loss: 2.7607 - val_accuracy: 0.5140\n",
      "Epoch 63/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 3.3960 - accuracy: 0.2949 - val_loss: 2.7510 - val_accuracy: 0.5140\n",
      "Epoch 64/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 3.3259 - accuracy: 0.3173 - val_loss: 2.7401 - val_accuracy: 0.5234\n",
      "Epoch 65/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.3159 - accuracy: 0.3165 - val_loss: 2.7298 - val_accuracy: 0.5234\n",
      "Epoch 66/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 3.4035 - accuracy: 0.2922 - val_loss: 2.7208 - val_accuracy: 0.5234\n",
      "Epoch 67/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 3.3744 - accuracy: 0.3110 - val_loss: 2.7126 - val_accuracy: 0.5327\n",
      "Epoch 68/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.2959 - accuracy: 0.3141 - val_loss: 2.7033 - val_accuracy: 0.5327\n",
      "Epoch 69/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 3.3078 - accuracy: 0.3118 - val_loss: 2.6935 - val_accuracy: 0.5327\n",
      "Epoch 70/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.3622 - accuracy: 0.3114 - val_loss: 2.6849 - val_accuracy: 0.5327\n",
      "Epoch 71/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.2872 - accuracy: 0.3130 - val_loss: 2.6762 - val_accuracy: 0.5327\n",
      "Epoch 72/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 3.2984 - accuracy: 0.3181 - val_loss: 2.6681 - val_accuracy: 0.5327\n",
      "Epoch 73/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 3.2786 - accuracy: 0.3169 - val_loss: 2.6610 - val_accuracy: 0.5327\n",
      "Epoch 74/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 3.2664 - accuracy: 0.3322 - val_loss: 2.6527 - val_accuracy: 0.5327\n",
      "Epoch 75/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.2569 - accuracy: 0.3263 - val_loss: 2.6438 - val_accuracy: 0.5421\n",
      "Epoch 76/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.2593 - accuracy: 0.3212 - val_loss: 2.6365 - val_accuracy: 0.5421\n",
      "Epoch 77/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 3.2714 - accuracy: 0.3278 - val_loss: 2.6290 - val_accuracy: 0.5421\n",
      "Epoch 78/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.2005 - accuracy: 0.3396 - val_loss: 2.6223 - val_accuracy: 0.5421\n",
      "Epoch 79/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.3104 - accuracy: 0.3079 - val_loss: 2.6177 - val_accuracy: 0.5421\n",
      "Epoch 80/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.2421 - accuracy: 0.3345 - val_loss: 2.6121 - val_accuracy: 0.5421\n",
      "Epoch 81/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.1977 - accuracy: 0.3388 - val_loss: 2.6049 - val_accuracy: 0.5421\n",
      "Epoch 82/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.2218 - accuracy: 0.3228 - val_loss: 2.5981 - val_accuracy: 0.5421\n",
      "Epoch 83/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.1578 - accuracy: 0.3447 - val_loss: 2.5915 - val_accuracy: 0.5421\n",
      "Epoch 84/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.2168 - accuracy: 0.3267 - val_loss: 2.5856 - val_accuracy: 0.5421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.2296 - accuracy: 0.3251 - val_loss: 2.5802 - val_accuracy: 0.5327\n",
      "Epoch 86/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.1676 - accuracy: 0.3369 - val_loss: 2.5738 - val_accuracy: 0.5421\n",
      "Epoch 87/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.1715 - accuracy: 0.3396 - val_loss: 2.5677 - val_accuracy: 0.5421\n",
      "Epoch 88/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.2198 - accuracy: 0.3247 - val_loss: 2.5618 - val_accuracy: 0.5514\n",
      "Epoch 89/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.1935 - accuracy: 0.3404 - val_loss: 2.5573 - val_accuracy: 0.5327\n",
      "Epoch 90/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.2323 - accuracy: 0.3325 - val_loss: 2.5520 - val_accuracy: 0.5421\n",
      "Epoch 91/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 3.1682 - accuracy: 0.3341 - val_loss: 2.5453 - val_accuracy: 0.5421\n",
      "Epoch 92/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.2154 - accuracy: 0.3224 - val_loss: 2.5422 - val_accuracy: 0.5421\n",
      "Epoch 93/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 3.1917 - accuracy: 0.3290 - val_loss: 2.5380 - val_accuracy: 0.5421\n",
      "Epoch 94/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 3.2234 - accuracy: 0.3275 - val_loss: 2.5340 - val_accuracy: 0.5421\n",
      "Epoch 95/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 3.1802 - accuracy: 0.3271 - val_loss: 2.5295 - val_accuracy: 0.5327\n",
      "Epoch 96/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 3.1338 - accuracy: 0.3443 - val_loss: 2.5237 - val_accuracy: 0.5327\n",
      "Epoch 97/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 3.1794 - accuracy: 0.3349 - val_loss: 2.5200 - val_accuracy: 0.5327\n",
      "Epoch 98/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.0895 - accuracy: 0.3494 - val_loss: 2.5136 - val_accuracy: 0.5327\n",
      "Epoch 99/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.1132 - accuracy: 0.3486 - val_loss: 2.5082 - val_accuracy: 0.5421\n",
      "Epoch 100/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.1517 - accuracy: 0.3267 - val_loss: 2.5043 - val_accuracy: 0.5421\n",
      "Epoch 101/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.1632 - accuracy: 0.3333 - val_loss: 2.5017 - val_accuracy: 0.5421\n",
      "Epoch 102/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.1201 - accuracy: 0.3459 - val_loss: 2.4980 - val_accuracy: 0.5327\n",
      "Epoch 103/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.1718 - accuracy: 0.3318 - val_loss: 2.4951 - val_accuracy: 0.5421\n",
      "Epoch 104/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.1065 - accuracy: 0.3470 - val_loss: 2.4919 - val_accuracy: 0.5421\n",
      "Epoch 105/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 3.0864 - accuracy: 0.3447 - val_loss: 2.4871 - val_accuracy: 0.5421\n",
      "Epoch 106/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 3.1177 - accuracy: 0.3302 - val_loss: 2.4841 - val_accuracy: 0.5421\n",
      "Epoch 107/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 3.0633 - accuracy: 0.3470 - val_loss: 2.4778 - val_accuracy: 0.5421\n",
      "Epoch 108/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.1652 - accuracy: 0.3228 - val_loss: 2.4754 - val_accuracy: 0.5421\n",
      "Epoch 109/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.0925 - accuracy: 0.3447 - val_loss: 2.4710 - val_accuracy: 0.5421\n",
      "Epoch 110/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.1048 - accuracy: 0.3459 - val_loss: 2.4671 - val_accuracy: 0.5421\n",
      "Epoch 111/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 3.1410 - accuracy: 0.3384 - val_loss: 2.4650 - val_accuracy: 0.5421\n",
      "Epoch 112/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.1255 - accuracy: 0.3333 - val_loss: 2.4633 - val_accuracy: 0.5421\n",
      "Epoch 113/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.0880 - accuracy: 0.3365 - val_loss: 2.4603 - val_accuracy: 0.5421\n",
      "Epoch 114/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 3.1336 - accuracy: 0.3333 - val_loss: 2.4580 - val_accuracy: 0.5421\n",
      "Epoch 115/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.0680 - accuracy: 0.3478 - val_loss: 2.4548 - val_accuracy: 0.5421\n",
      "Epoch 116/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.0488 - accuracy: 0.3572 - val_loss: 2.4519 - val_accuracy: 0.5421\n",
      "Epoch 117/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.0784 - accuracy: 0.3416 - val_loss: 2.4493 - val_accuracy: 0.5421\n",
      "Epoch 118/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 3.0707 - accuracy: 0.3443 - val_loss: 2.4484 - val_accuracy: 0.5421\n",
      "Epoch 119/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.1223 - accuracy: 0.3302 - val_loss: 2.4484 - val_accuracy: 0.5421\n",
      "Epoch 120/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.0788 - accuracy: 0.3384 - val_loss: 2.4466 - val_accuracy: 0.5327\n",
      "Epoch 121/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.0522 - accuracy: 0.3474 - val_loss: 2.4432 - val_accuracy: 0.5327\n",
      "Epoch 122/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.0560 - accuracy: 0.3498 - val_loss: 2.4396 - val_accuracy: 0.5327\n",
      "Epoch 123/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.0710 - accuracy: 0.3474 - val_loss: 2.4375 - val_accuracy: 0.5327\n",
      "Epoch 124/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 3.0669 - accuracy: 0.3451 - val_loss: 2.4353 - val_accuracy: 0.5327\n",
      "Epoch 125/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.1107 - accuracy: 0.3341 - val_loss: 2.4353 - val_accuracy: 0.5327\n",
      "Epoch 126/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.0786 - accuracy: 0.3404 - val_loss: 2.4351 - val_accuracy: 0.5327\n",
      "Epoch 127/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 3.0889 - accuracy: 0.3345 - val_loss: 2.4340 - val_accuracy: 0.5327\n",
      "Epoch 128/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 3.0537 - accuracy: 0.3470 - val_loss: 2.4311 - val_accuracy: 0.5327\n",
      "Epoch 129/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.0513 - accuracy: 0.3412 - val_loss: 2.4291 - val_accuracy: 0.5327\n",
      "Epoch 130/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.1321 - accuracy: 0.3294 - val_loss: 2.4279 - val_accuracy: 0.5327\n",
      "Epoch 131/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 3.0761 - accuracy: 0.3521 - val_loss: 2.4261 - val_accuracy: 0.5327\n",
      "Epoch 132/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.0179 - accuracy: 0.3557 - val_loss: 2.4259 - val_accuracy: 0.5327\n",
      "Epoch 133/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.0303 - accuracy: 0.3525 - val_loss: 2.4233 - val_accuracy: 0.5327\n",
      "Epoch 134/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 3.0604 - accuracy: 0.3431 - val_loss: 2.4215 - val_accuracy: 0.5327\n",
      "Epoch 135/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 3.0920 - accuracy: 0.3369 - val_loss: 2.4200 - val_accuracy: 0.5327\n",
      "Epoch 136/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.0540 - accuracy: 0.3470 - val_loss: 2.4184 - val_accuracy: 0.5327\n",
      "Epoch 137/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.0270 - accuracy: 0.3451 - val_loss: 2.4172 - val_accuracy: 0.5327\n",
      "Epoch 138/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.0281 - accuracy: 0.3592 - val_loss: 2.4161 - val_accuracy: 0.5234\n",
      "Epoch 139/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.0141 - accuracy: 0.3537 - val_loss: 2.4144 - val_accuracy: 0.5234\n",
      "Epoch 140/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.0608 - accuracy: 0.3439 - val_loss: 2.4125 - val_accuracy: 0.5234\n",
      "Epoch 141/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.0571 - accuracy: 0.3478 - val_loss: 2.4113 - val_accuracy: 0.5327\n",
      "Epoch 142/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 2ms/step - loss: 3.0809 - accuracy: 0.3329 - val_loss: 2.4109 - val_accuracy: 0.5327\n",
      "Epoch 143/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 3.0807 - accuracy: 0.3412 - val_loss: 2.4115 - val_accuracy: 0.5234\n",
      "Epoch 144/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.0723 - accuracy: 0.3392 - val_loss: 2.4117 - val_accuracy: 0.5234\n",
      "Epoch 145/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.0232 - accuracy: 0.3557 - val_loss: 2.4094 - val_accuracy: 0.5234\n",
      "Epoch 146/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.0342 - accuracy: 0.3600 - val_loss: 2.4080 - val_accuracy: 0.5234\n",
      "Epoch 147/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.0574 - accuracy: 0.3478 - val_loss: 2.4064 - val_accuracy: 0.5234\n",
      "Epoch 148/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.9894 - accuracy: 0.3596 - val_loss: 2.4053 - val_accuracy: 0.5234\n",
      "Epoch 149/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.9578 - accuracy: 0.3635 - val_loss: 2.4022 - val_accuracy: 0.5234\n",
      "Epoch 150/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.0205 - accuracy: 0.3525 - val_loss: 2.4012 - val_accuracy: 0.5234\n",
      "Epoch 151/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.0356 - accuracy: 0.3596 - val_loss: 2.3995 - val_accuracy: 0.5234\n",
      "Epoch 152/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.0480 - accuracy: 0.3506 - val_loss: 2.4002 - val_accuracy: 0.5234\n",
      "Epoch 153/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.0893 - accuracy: 0.3494 - val_loss: 2.3995 - val_accuracy: 0.5234\n",
      "Epoch 154/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.0350 - accuracy: 0.3521 - val_loss: 2.3995 - val_accuracy: 0.5327\n",
      "Epoch 155/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.0229 - accuracy: 0.3564 - val_loss: 2.3987 - val_accuracy: 0.5327\n",
      "Epoch 156/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.0158 - accuracy: 0.3568 - val_loss: 2.3971 - val_accuracy: 0.5327\n",
      "Epoch 157/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.0592 - accuracy: 0.3584 - val_loss: 2.3970 - val_accuracy: 0.5327\n",
      "Epoch 158/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.0321 - accuracy: 0.3666 - val_loss: 2.3969 - val_accuracy: 0.5327\n",
      "Epoch 159/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.0776 - accuracy: 0.3459 - val_loss: 2.3974 - val_accuracy: 0.5327\n",
      "Epoch 160/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.0208 - accuracy: 0.3608 - val_loss: 2.3958 - val_accuracy: 0.5327\n",
      "Epoch 161/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.9990 - accuracy: 0.3568 - val_loss: 2.3937 - val_accuracy: 0.5327\n",
      "Epoch 162/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.0762 - accuracy: 0.3502 - val_loss: 2.3956 - val_accuracy: 0.5327\n",
      "Epoch 163/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.0295 - accuracy: 0.3564 - val_loss: 2.3956 - val_accuracy: 0.5327\n",
      "Epoch 164/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.0770 - accuracy: 0.3431 - val_loss: 2.3976 - val_accuracy: 0.5327\n",
      "Epoch 165/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.0439 - accuracy: 0.3482 - val_loss: 2.3972 - val_accuracy: 0.5327\n",
      "Epoch 166/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.9944 - accuracy: 0.3658 - val_loss: 2.3959 - val_accuracy: 0.5327\n",
      "Epoch 167/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.0368 - accuracy: 0.3604 - val_loss: 2.3957 - val_accuracy: 0.5327\n",
      "Epoch 168/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.0739 - accuracy: 0.3435 - val_loss: 2.3971 - val_accuracy: 0.5327\n",
      "Epoch 169/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.9281 - accuracy: 0.3780 - val_loss: 2.3934 - val_accuracy: 0.5327\n",
      "Epoch 170/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.0311 - accuracy: 0.3604 - val_loss: 2.3929 - val_accuracy: 0.5327\n",
      "Epoch 171/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.9880 - accuracy: 0.3760 - val_loss: 2.3921 - val_accuracy: 0.5327\n",
      "Epoch 172/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.9734 - accuracy: 0.3749 - val_loss: 2.3901 - val_accuracy: 0.5327\n",
      "Epoch 173/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.0150 - accuracy: 0.3576 - val_loss: 2.3898 - val_accuracy: 0.5327\n",
      "Epoch 174/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.0708 - accuracy: 0.3604 - val_loss: 2.3892 - val_accuracy: 0.5327\n",
      "Epoch 175/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.0170 - accuracy: 0.3698 - val_loss: 2.3879 - val_accuracy: 0.5327\n",
      "Epoch 176/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.9708 - accuracy: 0.3721 - val_loss: 2.3858 - val_accuracy: 0.5327\n",
      "Epoch 177/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.0026 - accuracy: 0.3557 - val_loss: 2.3860 - val_accuracy: 0.5327\n",
      "Epoch 178/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.0242 - accuracy: 0.3521 - val_loss: 2.3860 - val_accuracy: 0.5327\n",
      "Epoch 179/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.0713 - accuracy: 0.3537 - val_loss: 2.3884 - val_accuracy: 0.5327\n",
      "Epoch 180/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.0255 - accuracy: 0.3651 - val_loss: 2.3884 - val_accuracy: 0.5327\n",
      "Epoch 181/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.0652 - accuracy: 0.3439 - val_loss: 2.3888 - val_accuracy: 0.5327\n",
      "Epoch 182/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.0344 - accuracy: 0.3588 - val_loss: 2.3890 - val_accuracy: 0.5327\n",
      "Epoch 183/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 3.0446 - accuracy: 0.3576 - val_loss: 2.3915 - val_accuracy: 0.5327\n",
      "Epoch 184/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.9934 - accuracy: 0.3674 - val_loss: 2.3895 - val_accuracy: 0.5327\n",
      "Epoch 185/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.0457 - accuracy: 0.3647 - val_loss: 2.3895 - val_accuracy: 0.5327\n",
      "Epoch 186/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.9861 - accuracy: 0.3752 - val_loss: 2.3878 - val_accuracy: 0.5327\n",
      "Epoch 187/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.9547 - accuracy: 0.3780 - val_loss: 2.3868 - val_accuracy: 0.5327\n",
      "Epoch 188/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.9944 - accuracy: 0.3647 - val_loss: 2.3849 - val_accuracy: 0.5327\n",
      "Epoch 189/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.9246 - accuracy: 0.3780 - val_loss: 2.3825 - val_accuracy: 0.5327\n",
      "Epoch 190/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.9824 - accuracy: 0.3623 - val_loss: 2.3811 - val_accuracy: 0.5327\n",
      "Epoch 191/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.0450 - accuracy: 0.3639 - val_loss: 2.3807 - val_accuracy: 0.5327\n",
      "Epoch 192/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.0108 - accuracy: 0.3674 - val_loss: 2.3803 - val_accuracy: 0.5327\n",
      "Epoch 193/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.9821 - accuracy: 0.3756 - val_loss: 2.3799 - val_accuracy: 0.5327\n",
      "Epoch 194/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.9910 - accuracy: 0.3772 - val_loss: 2.3793 - val_accuracy: 0.5421\n",
      "Epoch 195/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.0344 - accuracy: 0.3694 - val_loss: 2.3802 - val_accuracy: 0.5421\n",
      "Epoch 196/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.0343 - accuracy: 0.3572 - val_loss: 2.3817 - val_accuracy: 0.5421\n",
      "Epoch 197/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.9818 - accuracy: 0.3866 - val_loss: 2.3807 - val_accuracy: 0.5421\n",
      "Epoch 198/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.0214 - accuracy: 0.3643 - val_loss: 2.3808 - val_accuracy: 0.5421\n",
      "Epoch 199/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 2ms/step - loss: 3.0469 - accuracy: 0.3631 - val_loss: 2.3833 - val_accuracy: 0.5421\n",
      "Epoch 200/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.9490 - accuracy: 0.3768 - val_loss: 2.3832 - val_accuracy: 0.5421\n",
      "0.5420560836791992 {'loss': 2.948958158493042, 'accuracy': 0.37681159377098083, 'val_loss': 2.3832387924194336, 'val_accuracy': 0.5420560836791992}\n",
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         [(None, 29)]              0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 41)                1230      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 75)                3150      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 75)                0         \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 75)                0         \n",
      "=================================================================\n",
      "Total params: 4,380\n",
      "Trainable params: 4,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 6.8874 - accuracy: 0.0877 - val_loss: 3.8221 - val_accuracy: 0.0935\n",
      "Epoch 2/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 6.7407 - accuracy: 0.0909 - val_loss: 3.7761 - val_accuracy: 0.1028\n",
      "Epoch 3/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 6.4828 - accuracy: 0.0944 - val_loss: 3.7355 - val_accuracy: 0.1028\n",
      "Epoch 4/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 6.2570 - accuracy: 0.0991 - val_loss: 3.6937 - val_accuracy: 0.1215\n",
      "Epoch 5/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 6.1050 - accuracy: 0.1242 - val_loss: 3.6589 - val_accuracy: 0.1308\n",
      "Epoch 6/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 6.0733 - accuracy: 0.1171 - val_loss: 3.6301 - val_accuracy: 0.1308\n",
      "Epoch 7/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.8969 - accuracy: 0.1175 - val_loss: 3.6005 - val_accuracy: 0.1308\n",
      "Epoch 8/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.7790 - accuracy: 0.1222 - val_loss: 3.5756 - val_accuracy: 0.1402\n",
      "Epoch 9/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.6337 - accuracy: 0.1261 - val_loss: 3.5500 - val_accuracy: 0.1589\n",
      "Epoch 10/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.5505 - accuracy: 0.1206 - val_loss: 3.5271 - val_accuracy: 0.1589\n",
      "Epoch 11/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.4388 - accuracy: 0.1265 - val_loss: 3.5083 - val_accuracy: 0.1682\n",
      "Epoch 12/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.4290 - accuracy: 0.1199 - val_loss: 3.4911 - val_accuracy: 0.1776\n",
      "Epoch 13/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.2863 - accuracy: 0.1336 - val_loss: 3.4781 - val_accuracy: 0.1869\n",
      "Epoch 14/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.2578 - accuracy: 0.1214 - val_loss: 3.4672 - val_accuracy: 0.1963\n",
      "Epoch 15/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.0800 - accuracy: 0.1367 - val_loss: 3.4546 - val_accuracy: 0.2243\n",
      "Epoch 16/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.9739 - accuracy: 0.1344 - val_loss: 3.4455 - val_accuracy: 0.2617\n",
      "Epoch 17/200\n",
      "160/160 [==============================] - ETA: 0s - loss: 4.8781 - accuracy: 0.14 - 0s 2ms/step - loss: 4.8781 - accuracy: 0.1441 - val_loss: 3.4347 - val_accuracy: 0.2617\n",
      "Epoch 18/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.8552 - accuracy: 0.1398 - val_loss: 3.4272 - val_accuracy: 0.2617\n",
      "Epoch 19/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.7777 - accuracy: 0.1461 - val_loss: 3.4216 - val_accuracy: 0.2617\n",
      "Epoch 20/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.7221 - accuracy: 0.1422 - val_loss: 3.4148 - val_accuracy: 0.2897\n",
      "Epoch 21/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.5547 - accuracy: 0.1673 - val_loss: 3.4081 - val_accuracy: 0.3178\n",
      "Epoch 22/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.5026 - accuracy: 0.1708 - val_loss: 3.4001 - val_accuracy: 0.3271\n",
      "Epoch 23/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.4871 - accuracy: 0.1618 - val_loss: 3.3979 - val_accuracy: 0.3364\n",
      "Epoch 24/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.4576 - accuracy: 0.1547 - val_loss: 3.3961 - val_accuracy: 0.3364\n",
      "Epoch 25/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.3879 - accuracy: 0.1763 - val_loss: 3.3949 - val_accuracy: 0.3551\n",
      "Epoch 26/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.3266 - accuracy: 0.1778 - val_loss: 3.3918 - val_accuracy: 0.3645\n",
      "Epoch 27/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.3022 - accuracy: 0.1618 - val_loss: 3.3881 - val_accuracy: 0.3738\n",
      "Epoch 28/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.2998 - accuracy: 0.1657 - val_loss: 3.3917 - val_accuracy: 0.3832\n",
      "Epoch 29/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.2820 - accuracy: 0.1673 - val_loss: 3.3945 - val_accuracy: 0.3832\n",
      "Epoch 30/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.2292 - accuracy: 0.1684 - val_loss: 3.3966 - val_accuracy: 0.3832\n",
      "Epoch 31/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.1599 - accuracy: 0.1790 - val_loss: 3.3988 - val_accuracy: 0.3832\n",
      "Epoch 32/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.1767 - accuracy: 0.1778 - val_loss: 3.4001 - val_accuracy: 0.3832\n",
      "Epoch 33/200\n",
      "160/160 [==============================] - ETA: 0s - loss: 4.0638 - accuracy: 0.18 - 0s 2ms/step - loss: 4.0502 - accuracy: 0.1868 - val_loss: 3.3987 - val_accuracy: 0.3925\n",
      "Epoch 34/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 4.1147 - accuracy: 0.1782 - val_loss: 3.3987 - val_accuracy: 0.3925\n",
      "Epoch 35/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.1155 - accuracy: 0.1770 - val_loss: 3.4005 - val_accuracy: 0.4019\n",
      "Epoch 36/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.9715 - accuracy: 0.2005 - val_loss: 3.3996 - val_accuracy: 0.4112\n",
      "Epoch 37/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 3.9659 - accuracy: 0.2013 - val_loss: 3.3989 - val_accuracy: 0.4206\n",
      "Epoch 38/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.9506 - accuracy: 0.1935 - val_loss: 3.3966 - val_accuracy: 0.4486\n",
      "Epoch 39/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.9708 - accuracy: 0.2017 - val_loss: 3.3981 - val_accuracy: 0.4486\n",
      "Epoch 40/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.9656 - accuracy: 0.1947 - val_loss: 3.3972 - val_accuracy: 0.4393\n",
      "Epoch 41/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.8814 - accuracy: 0.2143 - val_loss: 3.3978 - val_accuracy: 0.4486\n",
      "Epoch 42/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.8778 - accuracy: 0.2088 - val_loss: 3.3998 - val_accuracy: 0.4579\n",
      "Epoch 43/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.9352 - accuracy: 0.1919 - val_loss: 3.4042 - val_accuracy: 0.4486\n",
      "Epoch 44/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.8888 - accuracy: 0.2013 - val_loss: 3.4063 - val_accuracy: 0.4486\n",
      "Epoch 45/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.8940 - accuracy: 0.2002 - val_loss: 3.4079 - val_accuracy: 0.4486\n",
      "Epoch 46/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 2ms/step - loss: 3.8690 - accuracy: 0.2064 - val_loss: 3.4057 - val_accuracy: 0.4486\n",
      "Epoch 47/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.8812 - accuracy: 0.2029 - val_loss: 3.4060 - val_accuracy: 0.4486\n",
      "Epoch 48/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.8214 - accuracy: 0.2056 - val_loss: 3.4021 - val_accuracy: 0.4486\n",
      "Epoch 49/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.8038 - accuracy: 0.2170 - val_loss: 3.3975 - val_accuracy: 0.4486\n",
      "Epoch 50/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.8713 - accuracy: 0.1951 - val_loss: 3.3974 - val_accuracy: 0.4579\n",
      "Epoch 51/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.8408 - accuracy: 0.2119 - val_loss: 3.3974 - val_accuracy: 0.4579\n",
      "Epoch 52/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.7877 - accuracy: 0.2209 - val_loss: 3.3944 - val_accuracy: 0.4579\n",
      "Epoch 53/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.7980 - accuracy: 0.2158 - val_loss: 3.3885 - val_accuracy: 0.4673\n",
      "Epoch 54/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.7934 - accuracy: 0.2225 - val_loss: 3.3814 - val_accuracy: 0.4766\n",
      "Epoch 55/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.7500 - accuracy: 0.2213 - val_loss: 3.3744 - val_accuracy: 0.4766\n",
      "Epoch 56/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.8241 - accuracy: 0.2060 - val_loss: 3.3734 - val_accuracy: 0.4766\n",
      "Epoch 57/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.7273 - accuracy: 0.2366 - val_loss: 3.3650 - val_accuracy: 0.4860\n",
      "Epoch 58/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.7124 - accuracy: 0.2370 - val_loss: 3.3556 - val_accuracy: 0.4766\n",
      "Epoch 59/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.7519 - accuracy: 0.2299 - val_loss: 3.3503 - val_accuracy: 0.4766\n",
      "Epoch 60/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.7268 - accuracy: 0.2385 - val_loss: 3.3457 - val_accuracy: 0.4766\n",
      "Epoch 61/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.7276 - accuracy: 0.2374 - val_loss: 3.3407 - val_accuracy: 0.4673\n",
      "Epoch 62/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.7542 - accuracy: 0.2323 - val_loss: 3.3373 - val_accuracy: 0.4579\n",
      "Epoch 63/200\n",
      "160/160 [==============================] - ETA: 0s - loss: 3.6793 - accuracy: 0.25 - 0s 2ms/step - loss: 3.6788 - accuracy: 0.2511 - val_loss: 3.3291 - val_accuracy: 0.4486\n",
      "Epoch 64/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.7244 - accuracy: 0.2315 - val_loss: 3.3226 - val_accuracy: 0.4393\n",
      "Epoch 65/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.7299 - accuracy: 0.2374 - val_loss: 3.3167 - val_accuracy: 0.4299\n",
      "Epoch 66/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6809 - accuracy: 0.2577 - val_loss: 3.3089 - val_accuracy: 0.4393\n",
      "Epoch 67/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6834 - accuracy: 0.2530 - val_loss: 3.3054 - val_accuracy: 0.4486\n",
      "Epoch 68/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6456 - accuracy: 0.2605 - val_loss: 3.2986 - val_accuracy: 0.4486\n",
      "Epoch 69/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6723 - accuracy: 0.2570 - val_loss: 3.2919 - val_accuracy: 0.4486\n",
      "Epoch 70/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.7342 - accuracy: 0.2464 - val_loss: 3.2899 - val_accuracy: 0.4486\n",
      "Epoch 71/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6402 - accuracy: 0.2581 - val_loss: 3.2834 - val_accuracy: 0.4486\n",
      "Epoch 72/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6639 - accuracy: 0.2558 - val_loss: 3.2789 - val_accuracy: 0.4486\n",
      "Epoch 73/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5873 - accuracy: 0.2761 - val_loss: 3.2717 - val_accuracy: 0.4486\n",
      "Epoch 74/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6513 - accuracy: 0.2656 - val_loss: 3.2666 - val_accuracy: 0.4486\n",
      "Epoch 75/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5840 - accuracy: 0.2875 - val_loss: 3.2602 - val_accuracy: 0.4486\n",
      "Epoch 76/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6191 - accuracy: 0.2738 - val_loss: 3.2555 - val_accuracy: 0.4486\n",
      "Epoch 77/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6044 - accuracy: 0.2844 - val_loss: 3.2513 - val_accuracy: 0.4486\n",
      "Epoch 78/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6466 - accuracy: 0.2730 - val_loss: 3.2518 - val_accuracy: 0.4393\n",
      "Epoch 79/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6508 - accuracy: 0.2761 - val_loss: 3.2519 - val_accuracy: 0.4673\n",
      "Epoch 80/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6382 - accuracy: 0.2699 - val_loss: 3.2530 - val_accuracy: 0.4579\n",
      "Epoch 81/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6479 - accuracy: 0.2773 - val_loss: 3.2516 - val_accuracy: 0.4579\n",
      "Epoch 82/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6032 - accuracy: 0.2793 - val_loss: 3.2482 - val_accuracy: 0.4579\n",
      "Epoch 83/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6691 - accuracy: 0.2695 - val_loss: 3.2490 - val_accuracy: 0.4673\n",
      "Epoch 84/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6771 - accuracy: 0.2797 - val_loss: 3.2486 - val_accuracy: 0.4766\n",
      "Epoch 85/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6306 - accuracy: 0.2879 - val_loss: 3.2478 - val_accuracy: 0.4860\n",
      "Epoch 86/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6440 - accuracy: 0.2855 - val_loss: 3.2477 - val_accuracy: 0.4766\n",
      "Epoch 87/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6118 - accuracy: 0.2883 - val_loss: 3.2437 - val_accuracy: 0.4766\n",
      "Epoch 88/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6268 - accuracy: 0.2993 - val_loss: 3.2439 - val_accuracy: 0.4673\n",
      "Epoch 89/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6133 - accuracy: 0.2859 - val_loss: 3.2394 - val_accuracy: 0.4673\n",
      "Epoch 90/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5778 - accuracy: 0.3051 - val_loss: 3.2381 - val_accuracy: 0.4673\n",
      "Epoch 91/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6161 - accuracy: 0.2973 - val_loss: 3.2372 - val_accuracy: 0.4673\n",
      "Epoch 92/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6535 - accuracy: 0.2942 - val_loss: 3.2367 - val_accuracy: 0.4673\n",
      "Epoch 93/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6831 - accuracy: 0.2801 - val_loss: 3.2400 - val_accuracy: 0.4673\n",
      "Epoch 94/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6242 - accuracy: 0.3020 - val_loss: 3.2405 - val_accuracy: 0.4673\n",
      "Epoch 95/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6755 - accuracy: 0.2859 - val_loss: 3.2480 - val_accuracy: 0.4673\n",
      "Epoch 96/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6157 - accuracy: 0.3028 - val_loss: 3.2437 - val_accuracy: 0.4579\n",
      "Epoch 97/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6625 - accuracy: 0.2855 - val_loss: 3.2455 - val_accuracy: 0.4579\n",
      "Epoch 98/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6629 - accuracy: 0.3020 - val_loss: 3.2452 - val_accuracy: 0.4673\n",
      "Epoch 99/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6785 - accuracy: 0.2805 - val_loss: 3.2468 - val_accuracy: 0.4673\n",
      "Epoch 100/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6427 - accuracy: 0.2930 - val_loss: 3.2454 - val_accuracy: 0.4673\n",
      "Epoch 101/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5992 - accuracy: 0.3126 - val_loss: 3.2436 - val_accuracy: 0.4673\n",
      "Epoch 102/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6484 - accuracy: 0.3036 - val_loss: 3.2449 - val_accuracy: 0.4673\n",
      "Epoch 103/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6334 - accuracy: 0.3083 - val_loss: 3.2454 - val_accuracy: 0.4673\n",
      "Epoch 104/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6282 - accuracy: 0.3079 - val_loss: 3.2469 - val_accuracy: 0.4673\n",
      "Epoch 105/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6505 - accuracy: 0.3087 - val_loss: 3.2470 - val_accuracy: 0.4673\n",
      "Epoch 106/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5592 - accuracy: 0.3224 - val_loss: 3.2407 - val_accuracy: 0.4673\n",
      "Epoch 107/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6049 - accuracy: 0.3184 - val_loss: 3.2407 - val_accuracy: 0.4673\n",
      "Epoch 108/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5871 - accuracy: 0.3306 - val_loss: 3.2365 - val_accuracy: 0.4673\n",
      "Epoch 109/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6553 - accuracy: 0.3087 - val_loss: 3.2384 - val_accuracy: 0.4673\n",
      "Epoch 110/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6170 - accuracy: 0.3157 - val_loss: 3.2372 - val_accuracy: 0.4673\n",
      "Epoch 111/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6180 - accuracy: 0.3137 - val_loss: 3.2358 - val_accuracy: 0.4766\n",
      "Epoch 112/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5983 - accuracy: 0.3126 - val_loss: 3.2344 - val_accuracy: 0.4766\n",
      "Epoch 113/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5785 - accuracy: 0.3173 - val_loss: 3.2305 - val_accuracy: 0.4860\n",
      "Epoch 114/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6452 - accuracy: 0.3071 - val_loss: 3.2314 - val_accuracy: 0.4860\n",
      "Epoch 115/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5985 - accuracy: 0.3235 - val_loss: 3.2308 - val_accuracy: 0.4766\n",
      "Epoch 116/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6267 - accuracy: 0.3145 - val_loss: 3.2312 - val_accuracy: 0.4766\n",
      "Epoch 117/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6114 - accuracy: 0.3161 - val_loss: 3.2293 - val_accuracy: 0.4860\n",
      "Epoch 118/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6389 - accuracy: 0.3216 - val_loss: 3.2314 - val_accuracy: 0.4860\n",
      "Epoch 119/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6208 - accuracy: 0.3192 - val_loss: 3.2303 - val_accuracy: 0.4860\n",
      "Epoch 120/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6563 - accuracy: 0.3071 - val_loss: 3.2327 - val_accuracy: 0.4860\n",
      "Epoch 121/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6095 - accuracy: 0.3141 - val_loss: 3.2370 - val_accuracy: 0.4766\n",
      "Epoch 122/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.7011 - accuracy: 0.3028 - val_loss: 3.2415 - val_accuracy: 0.4766\n",
      "Epoch 123/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5799 - accuracy: 0.3302 - val_loss: 3.2380 - val_accuracy: 0.4766\n",
      "Epoch 124/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6383 - accuracy: 0.3090 - val_loss: 3.2371 - val_accuracy: 0.4766\n",
      "Epoch 125/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6389 - accuracy: 0.3169 - val_loss: 3.2326 - val_accuracy: 0.4766\n",
      "Epoch 126/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6194 - accuracy: 0.3184 - val_loss: 3.2316 - val_accuracy: 0.4766\n",
      "Epoch 127/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6102 - accuracy: 0.3149 - val_loss: 3.2318 - val_accuracy: 0.4766\n",
      "Epoch 128/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5946 - accuracy: 0.3192 - val_loss: 3.2301 - val_accuracy: 0.4766\n",
      "Epoch 129/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5872 - accuracy: 0.3345 - val_loss: 3.2279 - val_accuracy: 0.4766\n",
      "Epoch 130/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6103 - accuracy: 0.3239 - val_loss: 3.2266 - val_accuracy: 0.4860\n",
      "Epoch 131/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6321 - accuracy: 0.3153 - val_loss: 3.2285 - val_accuracy: 0.4860\n",
      "Epoch 132/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5987 - accuracy: 0.3239 - val_loss: 3.2276 - val_accuracy: 0.4860\n",
      "Epoch 133/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6074 - accuracy: 0.3188 - val_loss: 3.2273 - val_accuracy: 0.4860\n",
      "Epoch 134/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6183 - accuracy: 0.3114 - val_loss: 3.2277 - val_accuracy: 0.4860\n",
      "Epoch 135/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5788 - accuracy: 0.3169 - val_loss: 3.2250 - val_accuracy: 0.4860\n",
      "Epoch 136/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6010 - accuracy: 0.3208 - val_loss: 3.2232 - val_accuracy: 0.4860\n",
      "Epoch 137/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6131 - accuracy: 0.3181 - val_loss: 3.2237 - val_accuracy: 0.4860\n",
      "Epoch 138/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5564 - accuracy: 0.3373 - val_loss: 3.2217 - val_accuracy: 0.4953\n",
      "Epoch 139/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6112 - accuracy: 0.3118 - val_loss: 3.2217 - val_accuracy: 0.4953\n",
      "Epoch 140/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6129 - accuracy: 0.3157 - val_loss: 3.2210 - val_accuracy: 0.5047\n",
      "Epoch 141/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6021 - accuracy: 0.3220 - val_loss: 3.2199 - val_accuracy: 0.5047\n",
      "Epoch 142/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5137 - accuracy: 0.3474 - val_loss: 3.2165 - val_accuracy: 0.4860\n",
      "Epoch 143/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5605 - accuracy: 0.3243 - val_loss: 3.2140 - val_accuracy: 0.5047\n",
      "Epoch 144/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5943 - accuracy: 0.3239 - val_loss: 3.2160 - val_accuracy: 0.4953\n",
      "Epoch 145/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5987 - accuracy: 0.3302 - val_loss: 3.2151 - val_accuracy: 0.4953\n",
      "Epoch 146/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5902 - accuracy: 0.3220 - val_loss: 3.2167 - val_accuracy: 0.5047\n",
      "Epoch 147/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5534 - accuracy: 0.3290 - val_loss: 3.2156 - val_accuracy: 0.4953\n",
      "Epoch 148/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6231 - accuracy: 0.3165 - val_loss: 3.2169 - val_accuracy: 0.4953\n",
      "Epoch 149/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5583 - accuracy: 0.3298 - val_loss: 3.2128 - val_accuracy: 0.4953\n",
      "Epoch 150/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6502 - accuracy: 0.3200 - val_loss: 3.2189 - val_accuracy: 0.4953\n",
      "Epoch 151/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5765 - accuracy: 0.3325 - val_loss: 3.2177 - val_accuracy: 0.4953\n",
      "Epoch 152/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5778 - accuracy: 0.3278 - val_loss: 3.2124 - val_accuracy: 0.4953\n",
      "Epoch 153/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5795 - accuracy: 0.3345 - val_loss: 3.2133 - val_accuracy: 0.4953\n",
      "Epoch 154/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6043 - accuracy: 0.3400 - val_loss: 3.2119 - val_accuracy: 0.4953\n",
      "Epoch 155/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5939 - accuracy: 0.3204 - val_loss: 3.2138 - val_accuracy: 0.4953\n",
      "Epoch 156/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6104 - accuracy: 0.3216 - val_loss: 3.2152 - val_accuracy: 0.4953\n",
      "Epoch 157/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5289 - accuracy: 0.3459 - val_loss: 3.2090 - val_accuracy: 0.4953\n",
      "Epoch 158/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5340 - accuracy: 0.3388 - val_loss: 3.2072 - val_accuracy: 0.4953\n",
      "Epoch 159/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6007 - accuracy: 0.3177 - val_loss: 3.2083 - val_accuracy: 0.5047\n",
      "Epoch 160/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6176 - accuracy: 0.3318 - val_loss: 3.2087 - val_accuracy: 0.5047\n",
      "Epoch 161/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5885 - accuracy: 0.3306 - val_loss: 3.2097 - val_accuracy: 0.5047\n",
      "Epoch 162/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5784 - accuracy: 0.3353 - val_loss: 3.2073 - val_accuracy: 0.5047\n",
      "Epoch 163/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5668 - accuracy: 0.3388 - val_loss: 3.2061 - val_accuracy: 0.5047\n",
      "Epoch 164/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6032 - accuracy: 0.3318 - val_loss: 3.2067 - val_accuracy: 0.5047\n",
      "Epoch 165/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6060 - accuracy: 0.3278 - val_loss: 3.2073 - val_accuracy: 0.5047\n",
      "Epoch 166/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5652 - accuracy: 0.3349 - val_loss: 3.2063 - val_accuracy: 0.5047\n",
      "Epoch 167/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5709 - accuracy: 0.3380 - val_loss: 3.2057 - val_accuracy: 0.5047\n",
      "Epoch 168/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6061 - accuracy: 0.3208 - val_loss: 3.2078 - val_accuracy: 0.5047\n",
      "Epoch 169/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6260 - accuracy: 0.3259 - val_loss: 3.2084 - val_accuracy: 0.5047\n",
      "Epoch 170/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5981 - accuracy: 0.3400 - val_loss: 3.2080 - val_accuracy: 0.4953\n",
      "Epoch 171/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5726 - accuracy: 0.3224 - val_loss: 3.2057 - val_accuracy: 0.5047\n",
      "Epoch 172/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5730 - accuracy: 0.3329 - val_loss: 3.2057 - val_accuracy: 0.5047\n",
      "Epoch 173/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5837 - accuracy: 0.3294 - val_loss: 3.2013 - val_accuracy: 0.5047\n",
      "Epoch 174/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6160 - accuracy: 0.3243 - val_loss: 3.2057 - val_accuracy: 0.5047\n",
      "Epoch 175/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5823 - accuracy: 0.3357 - val_loss: 3.2048 - val_accuracy: 0.5047\n",
      "Epoch 176/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5619 - accuracy: 0.3384 - val_loss: 3.2055 - val_accuracy: 0.4953\n",
      "Epoch 177/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6025 - accuracy: 0.3169 - val_loss: 3.2057 - val_accuracy: 0.4953\n",
      "Epoch 178/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5203 - accuracy: 0.3521 - val_loss: 3.2025 - val_accuracy: 0.4953\n",
      "Epoch 179/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5573 - accuracy: 0.3388 - val_loss: 3.2025 - val_accuracy: 0.5047\n",
      "Epoch 180/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6019 - accuracy: 0.3314 - val_loss: 3.2038 - val_accuracy: 0.5047\n",
      "Epoch 181/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5886 - accuracy: 0.3310 - val_loss: 3.2038 - val_accuracy: 0.5047\n",
      "Epoch 182/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5449 - accuracy: 0.3388 - val_loss: 3.2017 - val_accuracy: 0.5047\n",
      "Epoch 183/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5941 - accuracy: 0.3251 - val_loss: 3.2018 - val_accuracy: 0.5047\n",
      "Epoch 184/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6221 - accuracy: 0.3149 - val_loss: 3.2053 - val_accuracy: 0.5047\n",
      "Epoch 185/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5582 - accuracy: 0.3318 - val_loss: 3.2042 - val_accuracy: 0.5047\n",
      "Epoch 186/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6102 - accuracy: 0.3239 - val_loss: 3.2056 - val_accuracy: 0.5047\n",
      "Epoch 187/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6035 - accuracy: 0.3290 - val_loss: 3.2053 - val_accuracy: 0.5047\n",
      "Epoch 188/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5901 - accuracy: 0.3318 - val_loss: 3.2056 - val_accuracy: 0.5047\n",
      "Epoch 189/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6051 - accuracy: 0.3208 - val_loss: 3.2055 - val_accuracy: 0.5234\n",
      "Epoch 190/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5695 - accuracy: 0.3208 - val_loss: 3.2056 - val_accuracy: 0.5140\n",
      "Epoch 191/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6071 - accuracy: 0.3267 - val_loss: 3.2061 - val_accuracy: 0.5047\n",
      "Epoch 192/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5601 - accuracy: 0.3384 - val_loss: 3.2047 - val_accuracy: 0.4953\n",
      "Epoch 193/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5613 - accuracy: 0.3478 - val_loss: 3.2022 - val_accuracy: 0.5047\n",
      "Epoch 194/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5293 - accuracy: 0.3365 - val_loss: 3.2027 - val_accuracy: 0.4953\n",
      "Epoch 195/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6241 - accuracy: 0.3181 - val_loss: 3.2052 - val_accuracy: 0.4953\n",
      "Epoch 196/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5917 - accuracy: 0.3329 - val_loss: 3.2066 - val_accuracy: 0.4953\n",
      "Epoch 197/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5697 - accuracy: 0.3431 - val_loss: 3.2063 - val_accuracy: 0.5047\n",
      "Epoch 198/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5426 - accuracy: 0.3463 - val_loss: 3.2014 - val_accuracy: 0.5140\n",
      "Epoch 199/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6171 - accuracy: 0.3286 - val_loss: 3.2045 - val_accuracy: 0.4953\n",
      "Epoch 200/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5412 - accuracy: 0.3521 - val_loss: 3.1993 - val_accuracy: 0.5047\n",
      "0.5046728849411011 {'loss': 3.5411782264709473, 'accuracy': 0.35213473439216614, 'val_loss': 3.1992664337158203, 'val_accuracy': 0.5046728849411011}\n",
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         [(None, 29)]              0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 41)                1230      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 75)                3150      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 75)                0         \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 75)                0         \n",
      "=================================================================\n",
      "Total params: 4,380\n",
      "Trainable params: 4,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 7.3143 - accuracy: 3.9170e-04 - val_loss: 4.9418 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 7.2101 - accuracy: 0.0000e+00 - val_loss: 4.9133 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 7.0442 - accuracy: 3.9170e-04 - val_loss: 4.8848 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 6.9228 - accuracy: 0.0000e+00 - val_loss: 4.8562 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 2ms/step - loss: 6.8799 - accuracy: 3.9170e-04 - val_loss: 4.8284 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 6.7234 - accuracy: 7.8339e-04 - val_loss: 4.8001 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 6.6848 - accuracy: 0.0016 - val_loss: 4.7732 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 6.5769 - accuracy: 7.8339e-04 - val_loss: 4.7475 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 6.5022 - accuracy: 0.0020 - val_loss: 4.7223 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 6.3637 - accuracy: 0.0020 - val_loss: 4.6973 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 6.2809 - accuracy: 0.0031 - val_loss: 4.6727 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 6.1907 - accuracy: 0.0016 - val_loss: 4.6486 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 6.0877 - accuracy: 0.0055 - val_loss: 4.6249 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 6.0354 - accuracy: 0.0035 - val_loss: 4.6023 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.9566 - accuracy: 0.0035 - val_loss: 4.5800 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.8831 - accuracy: 0.0043 - val_loss: 4.5590 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.7928 - accuracy: 0.0086 - val_loss: 4.5370 - val_accuracy: 0.0093\n",
      "Epoch 18/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.7472 - accuracy: 0.0071 - val_loss: 4.5171 - val_accuracy: 0.0093\n",
      "Epoch 19/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.6629 - accuracy: 0.0114 - val_loss: 4.4966 - val_accuracy: 0.0093\n",
      "Epoch 20/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.5860 - accuracy: 0.0118 - val_loss: 4.4767 - val_accuracy: 0.0093\n",
      "Epoch 21/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.5524 - accuracy: 0.0145 - val_loss: 4.4570 - val_accuracy: 0.0093\n",
      "Epoch 22/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.4907 - accuracy: 0.0125 - val_loss: 4.4387 - val_accuracy: 0.0093\n",
      "Epoch 23/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.4155 - accuracy: 0.0149 - val_loss: 4.4194 - val_accuracy: 0.0093\n",
      "Epoch 24/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.3243 - accuracy: 0.0215 - val_loss: 4.4001 - val_accuracy: 0.0093\n",
      "Epoch 25/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.2801 - accuracy: 0.0243 - val_loss: 4.3817 - val_accuracy: 0.0093\n",
      "Epoch 26/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.2433 - accuracy: 0.0239 - val_loss: 4.3639 - val_accuracy: 0.0093\n",
      "Epoch 27/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.1821 - accuracy: 0.0274 - val_loss: 4.3460 - val_accuracy: 0.0093\n",
      "Epoch 28/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.1098 - accuracy: 0.0337 - val_loss: 4.3289 - val_accuracy: 0.0093\n",
      "Epoch 29/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.0500 - accuracy: 0.0372 - val_loss: 4.3117 - val_accuracy: 0.0093\n",
      "Epoch 30/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.0155 - accuracy: 0.0368 - val_loss: 4.2942 - val_accuracy: 0.0187\n",
      "Epoch 31/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.0074 - accuracy: 0.0400 - val_loss: 4.2785 - val_accuracy: 0.0187\n",
      "Epoch 32/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.9338 - accuracy: 0.0403 - val_loss: 4.2630 - val_accuracy: 0.0187\n",
      "Epoch 33/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.9084 - accuracy: 0.0376 - val_loss: 4.2475 - val_accuracy: 0.0280\n",
      "Epoch 34/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.8246 - accuracy: 0.0419 - val_loss: 4.2316 - val_accuracy: 0.0280\n",
      "Epoch 35/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.8046 - accuracy: 0.0474 - val_loss: 4.2159 - val_accuracy: 0.0374\n",
      "Epoch 36/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.7408 - accuracy: 0.0584 - val_loss: 4.2008 - val_accuracy: 0.0467\n",
      "Epoch 37/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.7283 - accuracy: 0.0517 - val_loss: 4.1860 - val_accuracy: 0.0467\n",
      "Epoch 38/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.6566 - accuracy: 0.0611 - val_loss: 4.1706 - val_accuracy: 0.0748\n",
      "Epoch 39/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.6645 - accuracy: 0.0568 - val_loss: 4.1567 - val_accuracy: 0.0748\n",
      "Epoch 40/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.6235 - accuracy: 0.0576 - val_loss: 4.1417 - val_accuracy: 0.0748\n",
      "Epoch 41/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.5674 - accuracy: 0.0701 - val_loss: 4.1266 - val_accuracy: 0.0748\n",
      "Epoch 42/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.5058 - accuracy: 0.0819 - val_loss: 4.1103 - val_accuracy: 0.0748\n",
      "Epoch 43/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.5073 - accuracy: 0.0729 - val_loss: 4.0951 - val_accuracy: 0.0748\n",
      "Epoch 44/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.5016 - accuracy: 0.0834 - val_loss: 4.0819 - val_accuracy: 0.0841\n",
      "Epoch 45/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.4510 - accuracy: 0.0834 - val_loss: 4.0685 - val_accuracy: 0.0841\n",
      "Epoch 46/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.3770 - accuracy: 0.0995 - val_loss: 4.0533 - val_accuracy: 0.1215\n",
      "Epoch 47/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.4087 - accuracy: 0.0909 - val_loss: 4.0395 - val_accuracy: 0.1308\n",
      "Epoch 48/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.3275 - accuracy: 0.1030 - val_loss: 4.0234 - val_accuracy: 0.1402\n",
      "Epoch 49/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.3459 - accuracy: 0.0948 - val_loss: 4.0072 - val_accuracy: 0.1495\n",
      "Epoch 50/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.2975 - accuracy: 0.1058 - val_loss: 3.9922 - val_accuracy: 0.1495\n",
      "Epoch 51/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.3050 - accuracy: 0.0979 - val_loss: 3.9765 - val_accuracy: 0.1495\n",
      "Epoch 52/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.2609 - accuracy: 0.1156 - val_loss: 3.9577 - val_accuracy: 0.1589\n",
      "Epoch 53/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.2152 - accuracy: 0.1242 - val_loss: 3.9399 - val_accuracy: 0.1682\n",
      "Epoch 54/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.1765 - accuracy: 0.1273 - val_loss: 3.9203 - val_accuracy: 0.1963\n",
      "Epoch 55/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.1656 - accuracy: 0.1375 - val_loss: 3.9033 - val_accuracy: 0.2056\n",
      "Epoch 56/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.1627 - accuracy: 0.1234 - val_loss: 3.8860 - val_accuracy: 0.2243\n",
      "Epoch 57/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.1076 - accuracy: 0.1426 - val_loss: 3.8666 - val_accuracy: 0.2243\n",
      "Epoch 58/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.0993 - accuracy: 0.1434 - val_loss: 3.8487 - val_accuracy: 0.2430\n",
      "Epoch 59/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.0521 - accuracy: 0.1512 - val_loss: 3.8286 - val_accuracy: 0.2430\n",
      "Epoch 60/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.0917 - accuracy: 0.1453 - val_loss: 3.8103 - val_accuracy: 0.2617\n",
      "Epoch 61/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.0234 - accuracy: 0.1559 - val_loss: 3.7915 - val_accuracy: 0.2617\n",
      "Epoch 62/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 2ms/step - loss: 4.0301 - accuracy: 0.1610 - val_loss: 3.7732 - val_accuracy: 0.2804\n",
      "Epoch 63/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.0423 - accuracy: 0.1516 - val_loss: 3.7560 - val_accuracy: 0.2897\n",
      "Epoch 64/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.0087 - accuracy: 0.1633 - val_loss: 3.7390 - val_accuracy: 0.3178\n",
      "Epoch 65/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.9868 - accuracy: 0.1637 - val_loss: 3.7211 - val_accuracy: 0.3364\n",
      "Epoch 66/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.9926 - accuracy: 0.1641 - val_loss: 3.7054 - val_accuracy: 0.3364\n",
      "Epoch 67/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.9570 - accuracy: 0.1720 - val_loss: 3.6917 - val_accuracy: 0.3178\n",
      "Epoch 68/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.0102 - accuracy: 0.1602 - val_loss: 3.6796 - val_accuracy: 0.3551\n",
      "Epoch 69/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.9267 - accuracy: 0.1806 - val_loss: 3.6654 - val_accuracy: 0.3738\n",
      "Epoch 70/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.9601 - accuracy: 0.1696 - val_loss: 3.6531 - val_accuracy: 0.3832\n",
      "Epoch 71/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.9341 - accuracy: 0.1790 - val_loss: 3.6404 - val_accuracy: 0.3832\n",
      "Epoch 72/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.9308 - accuracy: 0.1727 - val_loss: 3.6296 - val_accuracy: 0.3925\n",
      "Epoch 73/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.9314 - accuracy: 0.1731 - val_loss: 3.6172 - val_accuracy: 0.4112\n",
      "Epoch 74/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.9016 - accuracy: 0.1829 - val_loss: 3.6060 - val_accuracy: 0.4112\n",
      "Epoch 75/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.9146 - accuracy: 0.1849 - val_loss: 3.5970 - val_accuracy: 0.4112\n",
      "Epoch 76/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.8771 - accuracy: 0.1880 - val_loss: 3.5877 - val_accuracy: 0.4299\n",
      "Epoch 77/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.8773 - accuracy: 0.1911 - val_loss: 3.5776 - val_accuracy: 0.4486\n",
      "Epoch 78/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.8635 - accuracy: 0.1970 - val_loss: 3.5688 - val_accuracy: 0.4486\n",
      "Epoch 79/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 3.9027 - accuracy: 0.1837 - val_loss: 3.5632 - val_accuracy: 0.4486\n",
      "Epoch 80/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 3.8304 - accuracy: 0.1970 - val_loss: 3.5540 - val_accuracy: 0.4486\n",
      "Epoch 81/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 3.8455 - accuracy: 0.2013 - val_loss: 3.5456 - val_accuracy: 0.4579\n",
      "Epoch 82/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.8746 - accuracy: 0.1853 - val_loss: 3.5383 - val_accuracy: 0.4579\n",
      "Epoch 83/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 3.9005 - accuracy: 0.1864 - val_loss: 3.5365 - val_accuracy: 0.4579\n",
      "Epoch 84/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.8431 - accuracy: 0.2037 - val_loss: 3.5315 - val_accuracy: 0.4486\n",
      "Epoch 85/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.8400 - accuracy: 0.1970 - val_loss: 3.5242 - val_accuracy: 0.4579\n",
      "Epoch 86/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.8633 - accuracy: 0.1908 - val_loss: 3.5194 - val_accuracy: 0.4579\n",
      "Epoch 87/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.8112 - accuracy: 0.2092 - val_loss: 3.5123 - val_accuracy: 0.4486\n",
      "Epoch 88/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.7890 - accuracy: 0.2127 - val_loss: 3.5053 - val_accuracy: 0.4579\n",
      "Epoch 89/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.8074 - accuracy: 0.2072 - val_loss: 3.5011 - val_accuracy: 0.4579\n",
      "Epoch 90/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.8589 - accuracy: 0.1998 - val_loss: 3.4981 - val_accuracy: 0.4579\n",
      "Epoch 91/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.7782 - accuracy: 0.2146 - val_loss: 3.4937 - val_accuracy: 0.4486\n",
      "Epoch 92/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.8589 - accuracy: 0.1978 - val_loss: 3.4912 - val_accuracy: 0.4486\n",
      "Epoch 93/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.8260 - accuracy: 0.2009 - val_loss: 3.4886 - val_accuracy: 0.4486\n",
      "Epoch 94/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 3.8052 - accuracy: 0.2064 - val_loss: 3.4846 - val_accuracy: 0.4486\n",
      "Epoch 95/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.8097 - accuracy: 0.2096 - val_loss: 3.4819 - val_accuracy: 0.4579\n",
      "Epoch 96/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.8071 - accuracy: 0.2084 - val_loss: 3.4798 - val_accuracy: 0.4579\n",
      "Epoch 97/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.8434 - accuracy: 0.2033 - val_loss: 3.4785 - val_accuracy: 0.4579\n",
      "Epoch 98/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.7811 - accuracy: 0.2162 - val_loss: 3.4753 - val_accuracy: 0.4579\n",
      "Epoch 99/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.7550 - accuracy: 0.2213 - val_loss: 3.4713 - val_accuracy: 0.4673\n",
      "Epoch 100/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.8148 - accuracy: 0.2115 - val_loss: 3.4710 - val_accuracy: 0.4673\n",
      "Epoch 101/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.8032 - accuracy: 0.2166 - val_loss: 3.4686 - val_accuracy: 0.4766\n",
      "Epoch 102/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.8109 - accuracy: 0.2178 - val_loss: 3.4687 - val_accuracy: 0.4766\n",
      "Epoch 103/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.7597 - accuracy: 0.2280 - val_loss: 3.4663 - val_accuracy: 0.4766\n",
      "Epoch 104/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.7702 - accuracy: 0.2272 - val_loss: 3.4654 - val_accuracy: 0.4766\n",
      "Epoch 105/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 3.7709 - accuracy: 0.2229 - val_loss: 3.4623 - val_accuracy: 0.4766\n",
      "Epoch 106/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.7702 - accuracy: 0.2264 - val_loss: 3.4591 - val_accuracy: 0.4766\n",
      "Epoch 107/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.7395 - accuracy: 0.2382 - val_loss: 3.4571 - val_accuracy: 0.4766\n",
      "Epoch 108/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 3.7495 - accuracy: 0.2335 - val_loss: 3.4521 - val_accuracy: 0.4766\n",
      "Epoch 109/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.7738 - accuracy: 0.2237 - val_loss: 3.4506 - val_accuracy: 0.4860\n",
      "Epoch 110/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.7667 - accuracy: 0.2256 - val_loss: 3.4485 - val_accuracy: 0.4860\n",
      "Epoch 111/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.7883 - accuracy: 0.2162 - val_loss: 3.4472 - val_accuracy: 0.4860\n",
      "Epoch 112/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 3.7470 - accuracy: 0.2362 - val_loss: 3.4464 - val_accuracy: 0.4860\n",
      "Epoch 113/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.7771 - accuracy: 0.2295 - val_loss: 3.4466 - val_accuracy: 0.4860\n",
      "Epoch 114/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.7915 - accuracy: 0.2295 - val_loss: 3.4455 - val_accuracy: 0.4860\n",
      "Epoch 115/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.7944 - accuracy: 0.2303 - val_loss: 3.4478 - val_accuracy: 0.4860\n",
      "Epoch 116/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.7044 - accuracy: 0.2503 - val_loss: 3.4430 - val_accuracy: 0.4860\n",
      "Epoch 117/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.7728 - accuracy: 0.2421 - val_loss: 3.4421 - val_accuracy: 0.4860\n",
      "Epoch 118/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.7675 - accuracy: 0.2378 - val_loss: 3.4427 - val_accuracy: 0.4860\n",
      "Epoch 119/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 2ms/step - loss: 3.7056 - accuracy: 0.2495 - val_loss: 3.4393 - val_accuracy: 0.4953\n",
      "Epoch 120/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 3.7729 - accuracy: 0.2452 - val_loss: 3.4395 - val_accuracy: 0.4953\n",
      "Epoch 121/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.8241 - accuracy: 0.2362 - val_loss: 3.4409 - val_accuracy: 0.4953\n",
      "Epoch 122/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.8031 - accuracy: 0.2288 - val_loss: 3.4430 - val_accuracy: 0.4953\n",
      "Epoch 123/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.7546 - accuracy: 0.2503 - val_loss: 3.4389 - val_accuracy: 0.4953\n",
      "Epoch 124/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 3.7656 - accuracy: 0.2452 - val_loss: 3.4383 - val_accuracy: 0.5047\n",
      "Epoch 125/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 3.7672 - accuracy: 0.2421 - val_loss: 3.4383 - val_accuracy: 0.4953\n",
      "Epoch 126/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.7757 - accuracy: 0.2487 - val_loss: 3.4391 - val_accuracy: 0.4953\n",
      "Epoch 127/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.7490 - accuracy: 0.2491 - val_loss: 3.4393 - val_accuracy: 0.5047\n",
      "Epoch 128/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.7825 - accuracy: 0.2429 - val_loss: 3.4425 - val_accuracy: 0.4953\n",
      "Epoch 129/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.7638 - accuracy: 0.2648 - val_loss: 3.4429 - val_accuracy: 0.4953\n",
      "Epoch 130/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.8010 - accuracy: 0.2507 - val_loss: 3.4433 - val_accuracy: 0.4953\n",
      "Epoch 131/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.7500 - accuracy: 0.2620 - val_loss: 3.4432 - val_accuracy: 0.4953\n",
      "Epoch 132/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.7573 - accuracy: 0.2613 - val_loss: 3.4428 - val_accuracy: 0.4953\n",
      "Epoch 133/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.7284 - accuracy: 0.2734 - val_loss: 3.4393 - val_accuracy: 0.4953\n",
      "Epoch 134/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 3.7777 - accuracy: 0.2695 - val_loss: 3.4390 - val_accuracy: 0.4953\n",
      "Epoch 135/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.7949 - accuracy: 0.2585 - val_loss: 3.4386 - val_accuracy: 0.4953\n",
      "Epoch 136/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.7719 - accuracy: 0.2534 - val_loss: 3.4396 - val_accuracy: 0.4953\n",
      "Epoch 137/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.8159 - accuracy: 0.2487 - val_loss: 3.4394 - val_accuracy: 0.4953\n",
      "Epoch 138/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.7569 - accuracy: 0.2636 - val_loss: 3.4388 - val_accuracy: 0.4953\n",
      "Epoch 139/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.7343 - accuracy: 0.2714 - val_loss: 3.4366 - val_accuracy: 0.4953\n",
      "Epoch 140/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.7453 - accuracy: 0.2773 - val_loss: 3.4368 - val_accuracy: 0.4953\n",
      "Epoch 141/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.7155 - accuracy: 0.2714 - val_loss: 3.4326 - val_accuracy: 0.4953\n",
      "Epoch 142/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.7441 - accuracy: 0.2789 - val_loss: 3.4307 - val_accuracy: 0.4953\n",
      "Epoch 143/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.7549 - accuracy: 0.2797 - val_loss: 3.4312 - val_accuracy: 0.4953\n",
      "Epoch 144/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.7469 - accuracy: 0.2761 - val_loss: 3.4302 - val_accuracy: 0.4953\n",
      "Epoch 145/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.6768 - accuracy: 0.2918 - val_loss: 3.4265 - val_accuracy: 0.4953\n",
      "Epoch 146/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.6786 - accuracy: 0.2957 - val_loss: 3.4223 - val_accuracy: 0.5140\n",
      "Epoch 147/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.7323 - accuracy: 0.2855 - val_loss: 3.4207 - val_accuracy: 0.5140\n",
      "Epoch 148/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.7430 - accuracy: 0.2883 - val_loss: 3.4213 - val_accuracy: 0.5140\n",
      "Epoch 149/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.6723 - accuracy: 0.3004 - val_loss: 3.4165 - val_accuracy: 0.5140\n",
      "Epoch 150/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.7523 - accuracy: 0.2855 - val_loss: 3.4172 - val_accuracy: 0.5140\n",
      "Epoch 151/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.7823 - accuracy: 0.2761 - val_loss: 3.4179 - val_accuracy: 0.5140\n",
      "Epoch 152/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.7680 - accuracy: 0.2836 - val_loss: 3.4182 - val_accuracy: 0.5047\n",
      "Epoch 153/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.7271 - accuracy: 0.3008 - val_loss: 3.4191 - val_accuracy: 0.5047\n",
      "Epoch 154/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.7424 - accuracy: 0.2832 - val_loss: 3.4190 - val_accuracy: 0.5047\n",
      "Epoch 155/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.7038 - accuracy: 0.3020 - val_loss: 3.4155 - val_accuracy: 0.5047\n",
      "Epoch 156/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.7487 - accuracy: 0.2934 - val_loss: 3.4157 - val_accuracy: 0.5047\n",
      "Epoch 157/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.7912 - accuracy: 0.2848 - val_loss: 3.4183 - val_accuracy: 0.5047\n",
      "Epoch 158/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.7160 - accuracy: 0.3008 - val_loss: 3.4153 - val_accuracy: 0.5047\n",
      "Epoch 159/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.7147 - accuracy: 0.3012 - val_loss: 3.4143 - val_accuracy: 0.5047\n",
      "Epoch 160/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.6949 - accuracy: 0.3130 - val_loss: 3.4125 - val_accuracy: 0.5047\n",
      "Epoch 161/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.7643 - accuracy: 0.2961 - val_loss: 3.4120 - val_accuracy: 0.5047\n",
      "Epoch 162/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.7260 - accuracy: 0.2906 - val_loss: 3.4102 - val_accuracy: 0.5047\n",
      "Epoch 163/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.7603 - accuracy: 0.3024 - val_loss: 3.4129 - val_accuracy: 0.5047\n",
      "Epoch 164/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.7156 - accuracy: 0.3043 - val_loss: 3.4122 - val_accuracy: 0.5047\n",
      "Epoch 165/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.7313 - accuracy: 0.3016 - val_loss: 3.4114 - val_accuracy: 0.5047\n",
      "Epoch 166/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.6872 - accuracy: 0.3098 - val_loss: 3.4079 - val_accuracy: 0.4953\n",
      "Epoch 167/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.7184 - accuracy: 0.3126 - val_loss: 3.4051 - val_accuracy: 0.5140\n",
      "Epoch 168/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.7018 - accuracy: 0.3137 - val_loss: 3.4038 - val_accuracy: 0.5140\n",
      "Epoch 169/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.7005 - accuracy: 0.3161 - val_loss: 3.4012 - val_accuracy: 0.5140\n",
      "Epoch 170/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.7201 - accuracy: 0.2981 - val_loss: 3.4024 - val_accuracy: 0.5047\n",
      "Epoch 171/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.7553 - accuracy: 0.2930 - val_loss: 3.4045 - val_accuracy: 0.4953\n",
      "Epoch 172/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.7074 - accuracy: 0.3114 - val_loss: 3.4029 - val_accuracy: 0.5047\n",
      "Epoch 173/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.7004 - accuracy: 0.3114 - val_loss: 3.4024 - val_accuracy: 0.4953\n",
      "Epoch 174/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.6903 - accuracy: 0.3114 - val_loss: 3.4008 - val_accuracy: 0.4953\n",
      "Epoch 175/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.6781 - accuracy: 0.3192 - val_loss: 3.3975 - val_accuracy: 0.4953\n",
      "Epoch 176/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 2ms/step - loss: 3.6603 - accuracy: 0.3271 - val_loss: 3.3966 - val_accuracy: 0.5047\n",
      "Epoch 177/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.7175 - accuracy: 0.3126 - val_loss: 3.3946 - val_accuracy: 0.4953\n",
      "Epoch 178/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.7128 - accuracy: 0.3231 - val_loss: 3.3938 - val_accuracy: 0.5047\n",
      "Epoch 179/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.6981 - accuracy: 0.3192 - val_loss: 3.3922 - val_accuracy: 0.4953\n",
      "Epoch 180/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.7417 - accuracy: 0.3024 - val_loss: 3.3936 - val_accuracy: 0.4953\n",
      "Epoch 181/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.7195 - accuracy: 0.3047 - val_loss: 3.3937 - val_accuracy: 0.4953\n",
      "Epoch 182/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.6995 - accuracy: 0.3192 - val_loss: 3.3906 - val_accuracy: 0.4953\n",
      "Epoch 183/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.7385 - accuracy: 0.3040 - val_loss: 3.3910 - val_accuracy: 0.4953\n",
      "Epoch 184/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.6860 - accuracy: 0.3220 - val_loss: 3.3877 - val_accuracy: 0.5047\n",
      "Epoch 185/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.7080 - accuracy: 0.3208 - val_loss: 3.3842 - val_accuracy: 0.5047\n",
      "Epoch 186/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.6928 - accuracy: 0.3184 - val_loss: 3.3816 - val_accuracy: 0.5047\n",
      "Epoch 187/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.6767 - accuracy: 0.3235 - val_loss: 3.3783 - val_accuracy: 0.5047\n",
      "Epoch 188/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.6692 - accuracy: 0.3267 - val_loss: 3.3745 - val_accuracy: 0.4953\n",
      "Epoch 189/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.7017 - accuracy: 0.3263 - val_loss: 3.3693 - val_accuracy: 0.5047\n",
      "Epoch 190/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.6596 - accuracy: 0.3275 - val_loss: 3.3629 - val_accuracy: 0.5047\n",
      "Epoch 191/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.6790 - accuracy: 0.3177 - val_loss: 3.3601 - val_accuracy: 0.5047\n",
      "Epoch 192/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.6761 - accuracy: 0.3200 - val_loss: 3.3565 - val_accuracy: 0.5047\n",
      "Epoch 193/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.7284 - accuracy: 0.3094 - val_loss: 3.3521 - val_accuracy: 0.5047\n",
      "Epoch 194/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.6870 - accuracy: 0.3165 - val_loss: 3.3491 - val_accuracy: 0.5047\n",
      "Epoch 195/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.6889 - accuracy: 0.3177 - val_loss: 3.3416 - val_accuracy: 0.5047\n",
      "Epoch 196/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.6629 - accuracy: 0.3228 - val_loss: 3.3326 - val_accuracy: 0.4953\n",
      "Epoch 197/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.6452 - accuracy: 0.3310 - val_loss: 3.3240 - val_accuracy: 0.4953\n",
      "Epoch 198/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.6313 - accuracy: 0.3271 - val_loss: 3.3152 - val_accuracy: 0.5047\n",
      "Epoch 199/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.6506 - accuracy: 0.3239 - val_loss: 3.3061 - val_accuracy: 0.5047\n",
      "Epoch 200/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.6252 - accuracy: 0.3267 - val_loss: 3.2988 - val_accuracy: 0.5047\n",
      "0.5046728849411011 {'loss': 3.6251943111419678, 'accuracy': 0.3266744911670685, 'val_loss': 3.298799514770508, 'val_accuracy': 0.5046728849411011}\n",
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         [(None, 29)]              0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 41)                1230      \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 10)                420       \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,870\n",
      "Trainable params: 1,870\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 2.1550 - accuracy: 0.3337 - val_loss: 2.1245 - val_accuracy: 0.3645\n",
      "Epoch 2/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1184 - accuracy: 0.3799 - val_loss: 2.0827 - val_accuracy: 0.3832\n",
      "Epoch 3/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0832 - accuracy: 0.4046 - val_loss: 2.0420 - val_accuracy: 0.4112\n",
      "Epoch 4/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0486 - accuracy: 0.4222 - val_loss: 2.0017 - val_accuracy: 0.4393\n",
      "Epoch 5/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0150 - accuracy: 0.4324 - val_loss: 1.9615 - val_accuracy: 0.4860\n",
      "Epoch 6/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.9822 - accuracy: 0.4399 - val_loss: 1.9226 - val_accuracy: 0.4860\n",
      "Epoch 7/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.9495 - accuracy: 0.4426 - val_loss: 1.8854 - val_accuracy: 0.5140\n",
      "Epoch 8/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.9177 - accuracy: 0.4446 - val_loss: 1.8509 - val_accuracy: 0.5047\n",
      "Epoch 9/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.8867 - accuracy: 0.4458 - val_loss: 1.8183 - val_accuracy: 0.5047\n",
      "Epoch 10/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.8578 - accuracy: 0.4493 - val_loss: 1.7874 - val_accuracy: 0.5140\n",
      "Epoch 11/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.8307 - accuracy: 0.4516 - val_loss: 1.7595 - val_accuracy: 0.5234\n",
      "Epoch 12/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.8053 - accuracy: 0.4524 - val_loss: 1.7347 - val_accuracy: 0.5234\n",
      "Epoch 13/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.7825 - accuracy: 0.4532 - val_loss: 1.7125 - val_accuracy: 0.5234\n",
      "Epoch 14/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.7618 - accuracy: 0.4552 - val_loss: 1.6920 - val_accuracy: 0.5234\n",
      "Epoch 15/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.7433 - accuracy: 0.4575 - val_loss: 1.6731 - val_accuracy: 0.5234\n",
      "Epoch 16/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.7269 - accuracy: 0.4587 - val_loss: 1.6563 - val_accuracy: 0.5327\n",
      "Epoch 17/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.7122 - accuracy: 0.4599 - val_loss: 1.6413 - val_accuracy: 0.5421\n",
      "Epoch 18/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6991 - accuracy: 0.4606 - val_loss: 1.6279 - val_accuracy: 0.5421\n",
      "Epoch 19/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6873 - accuracy: 0.4634 - val_loss: 1.6159 - val_accuracy: 0.5514\n",
      "Epoch 20/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6768 - accuracy: 0.4622 - val_loss: 1.6049 - val_accuracy: 0.5514\n",
      "Epoch 21/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6674 - accuracy: 0.4642 - val_loss: 1.5955 - val_accuracy: 0.5514\n",
      "Epoch 22/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6590 - accuracy: 0.4649 - val_loss: 1.5870 - val_accuracy: 0.5514\n",
      "Epoch 23/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6516 - accuracy: 0.4665 - val_loss: 1.5789 - val_accuracy: 0.5421\n",
      "Epoch 24/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6448 - accuracy: 0.4669 - val_loss: 1.5719 - val_accuracy: 0.5421\n",
      "Epoch 25/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6387 - accuracy: 0.4681 - val_loss: 1.5650 - val_accuracy: 0.5421\n",
      "Epoch 26/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6330 - accuracy: 0.4696 - val_loss: 1.5593 - val_accuracy: 0.5421\n",
      "Epoch 27/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6280 - accuracy: 0.4689 - val_loss: 1.5537 - val_accuracy: 0.5421\n",
      "Epoch 28/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6233 - accuracy: 0.4696 - val_loss: 1.5489 - val_accuracy: 0.5421\n",
      "Epoch 29/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6190 - accuracy: 0.4708 - val_loss: 1.5443 - val_accuracy: 0.5421\n",
      "Epoch 30/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6152 - accuracy: 0.4720 - val_loss: 1.5399 - val_accuracy: 0.5421\n",
      "Epoch 31/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6116 - accuracy: 0.4724 - val_loss: 1.5362 - val_accuracy: 0.5421\n",
      "Epoch 32/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6083 - accuracy: 0.4724 - val_loss: 1.5325 - val_accuracy: 0.5421\n",
      "Epoch 33/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6053 - accuracy: 0.4728 - val_loss: 1.5294 - val_accuracy: 0.5421\n",
      "Epoch 34/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6025 - accuracy: 0.4728 - val_loss: 1.5267 - val_accuracy: 0.5421\n",
      "Epoch 35/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5999 - accuracy: 0.4724 - val_loss: 1.5239 - val_accuracy: 0.5421\n",
      "Epoch 36/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5974 - accuracy: 0.4736 - val_loss: 1.5216 - val_accuracy: 0.5421\n",
      "Epoch 37/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5951 - accuracy: 0.4736 - val_loss: 1.5194 - val_accuracy: 0.5421\n",
      "Epoch 38/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5931 - accuracy: 0.4755 - val_loss: 1.5174 - val_accuracy: 0.5421\n",
      "Epoch 39/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5911 - accuracy: 0.4747 - val_loss: 1.5156 - val_accuracy: 0.5421\n",
      "Epoch 40/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5893 - accuracy: 0.4759 - val_loss: 1.5140 - val_accuracy: 0.5234\n",
      "Epoch 41/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5876 - accuracy: 0.4763 - val_loss: 1.5125 - val_accuracy: 0.5234\n",
      "Epoch 42/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5860 - accuracy: 0.4771 - val_loss: 1.5113 - val_accuracy: 0.5234\n",
      "Epoch 43/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5845 - accuracy: 0.4763 - val_loss: 1.5100 - val_accuracy: 0.5327\n",
      "Epoch 44/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5831 - accuracy: 0.4759 - val_loss: 1.5088 - val_accuracy: 0.5327\n",
      "Epoch 45/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5819 - accuracy: 0.4759 - val_loss: 1.5080 - val_accuracy: 0.5327\n",
      "Epoch 46/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5806 - accuracy: 0.4767 - val_loss: 1.5066 - val_accuracy: 0.5327\n",
      "Epoch 47/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5796 - accuracy: 0.4763 - val_loss: 1.5057 - val_accuracy: 0.5327\n",
      "Epoch 48/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5786 - accuracy: 0.4775 - val_loss: 1.5046 - val_accuracy: 0.5234\n",
      "Epoch 49/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5776 - accuracy: 0.4787 - val_loss: 1.5039 - val_accuracy: 0.5234\n",
      "Epoch 50/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5767 - accuracy: 0.4790 - val_loss: 1.5030 - val_accuracy: 0.5234\n",
      "Epoch 51/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5758 - accuracy: 0.4787 - val_loss: 1.5025 - val_accuracy: 0.5234\n",
      "Epoch 52/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5750 - accuracy: 0.4767 - val_loss: 1.5016 - val_accuracy: 0.5234\n",
      "Epoch 53/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5743 - accuracy: 0.4767 - val_loss: 1.5009 - val_accuracy: 0.5234\n",
      "Epoch 54/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5735 - accuracy: 0.4767 - val_loss: 1.5002 - val_accuracy: 0.5234\n",
      "Epoch 55/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5729 - accuracy: 0.4767 - val_loss: 1.4995 - val_accuracy: 0.5234\n",
      "Epoch 56/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5722 - accuracy: 0.4779 - val_loss: 1.4987 - val_accuracy: 0.5234\n",
      "Epoch 57/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5717 - accuracy: 0.4775 - val_loss: 1.4979 - val_accuracy: 0.5234\n",
      "Epoch 58/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5711 - accuracy: 0.4794 - val_loss: 1.4973 - val_accuracy: 0.5234\n",
      "Epoch 59/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5706 - accuracy: 0.4798 - val_loss: 1.4968 - val_accuracy: 0.5234\n",
      "Epoch 60/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5701 - accuracy: 0.4806 - val_loss: 1.4963 - val_accuracy: 0.5234\n",
      "Epoch 61/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5695 - accuracy: 0.4822 - val_loss: 1.4956 - val_accuracy: 0.5234\n",
      "Epoch 62/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5691 - accuracy: 0.4826 - val_loss: 1.4951 - val_accuracy: 0.5234\n",
      "Epoch 63/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5686 - accuracy: 0.4818 - val_loss: 1.4946 - val_accuracy: 0.5234\n",
      "Epoch 64/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5682 - accuracy: 0.4826 - val_loss: 1.4941 - val_accuracy: 0.5234\n",
      "Epoch 65/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5678 - accuracy: 0.4818 - val_loss: 1.4938 - val_accuracy: 0.5234\n",
      "Epoch 66/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5674 - accuracy: 0.4830 - val_loss: 1.4933 - val_accuracy: 0.5234\n",
      "Epoch 67/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5671 - accuracy: 0.4826 - val_loss: 1.4927 - val_accuracy: 0.5234\n",
      "Epoch 68/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5667 - accuracy: 0.4837 - val_loss: 1.4928 - val_accuracy: 0.5234\n",
      "Epoch 69/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5663 - accuracy: 0.4834 - val_loss: 1.4925 - val_accuracy: 0.5234\n",
      "Epoch 70/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5660 - accuracy: 0.4830 - val_loss: 1.4919 - val_accuracy: 0.5234\n",
      "Epoch 71/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5656 - accuracy: 0.4841 - val_loss: 1.4912 - val_accuracy: 0.5234\n",
      "Epoch 72/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5653 - accuracy: 0.4841 - val_loss: 1.4910 - val_accuracy: 0.5234\n",
      "Epoch 73/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5650 - accuracy: 0.4845 - val_loss: 1.4905 - val_accuracy: 0.5234\n",
      "Epoch 74/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5646 - accuracy: 0.4841 - val_loss: 1.4905 - val_accuracy: 0.5234\n",
      "Epoch 75/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5643 - accuracy: 0.4853 - val_loss: 1.4897 - val_accuracy: 0.5140\n",
      "Epoch 76/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5640 - accuracy: 0.4845 - val_loss: 1.4897 - val_accuracy: 0.5140\n",
      "Epoch 77/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5637 - accuracy: 0.4834 - val_loss: 1.4891 - val_accuracy: 0.5140\n",
      "Epoch 78/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5634 - accuracy: 0.4841 - val_loss: 1.4886 - val_accuracy: 0.5140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5631 - accuracy: 0.4841 - val_loss: 1.4883 - val_accuracy: 0.5234\n",
      "Epoch 80/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5628 - accuracy: 0.4834 - val_loss: 1.4881 - val_accuracy: 0.5234\n",
      "Epoch 81/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5626 - accuracy: 0.4834 - val_loss: 1.4878 - val_accuracy: 0.5234\n",
      "Epoch 82/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5623 - accuracy: 0.4834 - val_loss: 1.4874 - val_accuracy: 0.5234\n",
      "Epoch 83/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5620 - accuracy: 0.4837 - val_loss: 1.4871 - val_accuracy: 0.5234\n",
      "Epoch 84/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5618 - accuracy: 0.4837 - val_loss: 1.4866 - val_accuracy: 0.5234\n",
      "Epoch 85/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5615 - accuracy: 0.4837 - val_loss: 1.4864 - val_accuracy: 0.5234\n",
      "Epoch 86/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5613 - accuracy: 0.4834 - val_loss: 1.4858 - val_accuracy: 0.5234\n",
      "Epoch 87/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5610 - accuracy: 0.4834 - val_loss: 1.4856 - val_accuracy: 0.5234\n",
      "Epoch 88/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5608 - accuracy: 0.4826 - val_loss: 1.4853 - val_accuracy: 0.5327\n",
      "Epoch 89/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5605 - accuracy: 0.4822 - val_loss: 1.4850 - val_accuracy: 0.5327\n",
      "Epoch 90/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5603 - accuracy: 0.4818 - val_loss: 1.4849 - val_accuracy: 0.5327\n",
      "Epoch 91/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5600 - accuracy: 0.4830 - val_loss: 1.4845 - val_accuracy: 0.5327\n",
      "Epoch 92/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5598 - accuracy: 0.4822 - val_loss: 1.4843 - val_accuracy: 0.5327\n",
      "Epoch 93/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5596 - accuracy: 0.4826 - val_loss: 1.4841 - val_accuracy: 0.5327\n",
      "Epoch 94/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5593 - accuracy: 0.4826 - val_loss: 1.4836 - val_accuracy: 0.5327\n",
      "Epoch 95/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5592 - accuracy: 0.4834 - val_loss: 1.4835 - val_accuracy: 0.5327\n",
      "Epoch 96/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5589 - accuracy: 0.4826 - val_loss: 1.4829 - val_accuracy: 0.5327\n",
      "Epoch 97/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5587 - accuracy: 0.4830 - val_loss: 1.4828 - val_accuracy: 0.5327\n",
      "Epoch 98/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5585 - accuracy: 0.4834 - val_loss: 1.4826 - val_accuracy: 0.5327\n",
      "Epoch 99/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5583 - accuracy: 0.4830 - val_loss: 1.4819 - val_accuracy: 0.5327\n",
      "Epoch 100/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5581 - accuracy: 0.4830 - val_loss: 1.4817 - val_accuracy: 0.5327\n",
      "Epoch 101/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5579 - accuracy: 0.4834 - val_loss: 1.4814 - val_accuracy: 0.5327\n",
      "Epoch 102/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5576 - accuracy: 0.4834 - val_loss: 1.4811 - val_accuracy: 0.5327\n",
      "Epoch 103/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5575 - accuracy: 0.4837 - val_loss: 1.4805 - val_accuracy: 0.5327\n",
      "Epoch 104/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5572 - accuracy: 0.4845 - val_loss: 1.4803 - val_accuracy: 0.5327\n",
      "Epoch 105/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5570 - accuracy: 0.4845 - val_loss: 1.4802 - val_accuracy: 0.5327\n",
      "Epoch 106/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5568 - accuracy: 0.4845 - val_loss: 1.4800 - val_accuracy: 0.5327\n",
      "Epoch 107/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5566 - accuracy: 0.4845 - val_loss: 1.4799 - val_accuracy: 0.5327\n",
      "Epoch 108/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5564 - accuracy: 0.4853 - val_loss: 1.4794 - val_accuracy: 0.5327\n",
      "Epoch 109/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5561 - accuracy: 0.4849 - val_loss: 1.4790 - val_accuracy: 0.5327\n",
      "Epoch 110/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5559 - accuracy: 0.4845 - val_loss: 1.4787 - val_accuracy: 0.5327\n",
      "Epoch 111/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5557 - accuracy: 0.4853 - val_loss: 1.4782 - val_accuracy: 0.5327\n",
      "Epoch 112/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5555 - accuracy: 0.4853 - val_loss: 1.4782 - val_accuracy: 0.5327\n",
      "Epoch 113/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5553 - accuracy: 0.4869 - val_loss: 1.4778 - val_accuracy: 0.5327\n",
      "Epoch 114/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5551 - accuracy: 0.4869 - val_loss: 1.4777 - val_accuracy: 0.5327\n",
      "Epoch 115/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5548 - accuracy: 0.4861 - val_loss: 1.4773 - val_accuracy: 0.5327\n",
      "Epoch 116/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5547 - accuracy: 0.4865 - val_loss: 1.4772 - val_accuracy: 0.5327\n",
      "Epoch 117/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5544 - accuracy: 0.4869 - val_loss: 1.4767 - val_accuracy: 0.5421\n",
      "Epoch 118/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5542 - accuracy: 0.4877 - val_loss: 1.4762 - val_accuracy: 0.5421\n",
      "Epoch 119/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5540 - accuracy: 0.4873 - val_loss: 1.4762 - val_accuracy: 0.5421\n",
      "Epoch 120/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5538 - accuracy: 0.4877 - val_loss: 1.4759 - val_accuracy: 0.5421\n",
      "Epoch 121/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5536 - accuracy: 0.4877 - val_loss: 1.4757 - val_accuracy: 0.5421\n",
      "Epoch 122/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5534 - accuracy: 0.4888 - val_loss: 1.4754 - val_accuracy: 0.5421\n",
      "Epoch 123/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5532 - accuracy: 0.4884 - val_loss: 1.4753 - val_accuracy: 0.5421\n",
      "Epoch 124/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5530 - accuracy: 0.4892 - val_loss: 1.4749 - val_accuracy: 0.5421\n",
      "Epoch 125/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5528 - accuracy: 0.4884 - val_loss: 1.4749 - val_accuracy: 0.5421\n",
      "Epoch 126/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5526 - accuracy: 0.4892 - val_loss: 1.4746 - val_accuracy: 0.5421\n",
      "Epoch 127/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5525 - accuracy: 0.4896 - val_loss: 1.4746 - val_accuracy: 0.5421\n",
      "Epoch 128/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5523 - accuracy: 0.4896 - val_loss: 1.4741 - val_accuracy: 0.5421\n",
      "Epoch 129/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5521 - accuracy: 0.4908 - val_loss: 1.4741 - val_accuracy: 0.5421\n",
      "Epoch 130/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5519 - accuracy: 0.4904 - val_loss: 1.4739 - val_accuracy: 0.5421\n",
      "Epoch 131/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5517 - accuracy: 0.4904 - val_loss: 1.4737 - val_accuracy: 0.5421\n",
      "Epoch 132/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5516 - accuracy: 0.4904 - val_loss: 1.4735 - val_accuracy: 0.5421\n",
      "Epoch 133/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5514 - accuracy: 0.4904 - val_loss: 1.4735 - val_accuracy: 0.5421\n",
      "Epoch 134/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5512 - accuracy: 0.4912 - val_loss: 1.4730 - val_accuracy: 0.5421\n",
      "Epoch 135/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5511 - accuracy: 0.4924 - val_loss: 1.4730 - val_accuracy: 0.5421\n",
      "Epoch 136/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5509 - accuracy: 0.4924 - val_loss: 1.4726 - val_accuracy: 0.5421\n",
      "Epoch 137/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5507 - accuracy: 0.4928 - val_loss: 1.4725 - val_accuracy: 0.5421\n",
      "Epoch 138/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5505 - accuracy: 0.4935 - val_loss: 1.4724 - val_accuracy: 0.5421\n",
      "Epoch 139/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5504 - accuracy: 0.4931 - val_loss: 1.4722 - val_accuracy: 0.5421\n",
      "Epoch 140/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5502 - accuracy: 0.4935 - val_loss: 1.4723 - val_accuracy: 0.5421\n",
      "Epoch 141/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5500 - accuracy: 0.4931 - val_loss: 1.4721 - val_accuracy: 0.5421\n",
      "Epoch 142/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5498 - accuracy: 0.4939 - val_loss: 1.4719 - val_accuracy: 0.5421\n",
      "Epoch 143/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5497 - accuracy: 0.4947 - val_loss: 1.4714 - val_accuracy: 0.5421\n",
      "Epoch 144/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5496 - accuracy: 0.4943 - val_loss: 1.4713 - val_accuracy: 0.5421\n",
      "Epoch 145/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5494 - accuracy: 0.4947 - val_loss: 1.4713 - val_accuracy: 0.5421\n",
      "Epoch 146/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5492 - accuracy: 0.4943 - val_loss: 1.4712 - val_accuracy: 0.5421\n",
      "Epoch 147/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5490 - accuracy: 0.4943 - val_loss: 1.4710 - val_accuracy: 0.5421\n",
      "Epoch 148/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5489 - accuracy: 0.4951 - val_loss: 1.4708 - val_accuracy: 0.5421\n",
      "Epoch 149/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5487 - accuracy: 0.4947 - val_loss: 1.4707 - val_accuracy: 0.5421\n",
      "Epoch 150/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5486 - accuracy: 0.4951 - val_loss: 1.4706 - val_accuracy: 0.5421\n",
      "Epoch 151/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5485 - accuracy: 0.4943 - val_loss: 1.4704 - val_accuracy: 0.5421\n",
      "Epoch 152/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5483 - accuracy: 0.4951 - val_loss: 1.4703 - val_accuracy: 0.5421\n",
      "Epoch 153/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5481 - accuracy: 0.4951 - val_loss: 1.4703 - val_accuracy: 0.5421\n",
      "Epoch 154/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5480 - accuracy: 0.4959 - val_loss: 1.4700 - val_accuracy: 0.5421\n",
      "Epoch 155/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5478 - accuracy: 0.4963 - val_loss: 1.4696 - val_accuracy: 0.5514\n",
      "Epoch 156/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5477 - accuracy: 0.4947 - val_loss: 1.4697 - val_accuracy: 0.5514\n",
      "Epoch 157/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5476 - accuracy: 0.4955 - val_loss: 1.4697 - val_accuracy: 0.5514\n",
      "Epoch 158/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5474 - accuracy: 0.4955 - val_loss: 1.4698 - val_accuracy: 0.5421\n",
      "Epoch 159/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5473 - accuracy: 0.4955 - val_loss: 1.4694 - val_accuracy: 0.5514\n",
      "Epoch 160/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5471 - accuracy: 0.4963 - val_loss: 1.4693 - val_accuracy: 0.5514\n",
      "Epoch 161/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5470 - accuracy: 0.4967 - val_loss: 1.4691 - val_accuracy: 0.5607\n",
      "Epoch 162/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5469 - accuracy: 0.4955 - val_loss: 1.4690 - val_accuracy: 0.5607\n",
      "Epoch 163/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5467 - accuracy: 0.4975 - val_loss: 1.4687 - val_accuracy: 0.5607\n",
      "Epoch 164/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5465 - accuracy: 0.4975 - val_loss: 1.4686 - val_accuracy: 0.5607\n",
      "Epoch 165/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5464 - accuracy: 0.4978 - val_loss: 1.4682 - val_accuracy: 0.5607\n",
      "Epoch 166/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5463 - accuracy: 0.4971 - val_loss: 1.4682 - val_accuracy: 0.5607\n",
      "Epoch 167/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5462 - accuracy: 0.4975 - val_loss: 1.4681 - val_accuracy: 0.5607\n",
      "Epoch 168/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5460 - accuracy: 0.4975 - val_loss: 1.4679 - val_accuracy: 0.5607\n",
      "Epoch 169/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5459 - accuracy: 0.4971 - val_loss: 1.4679 - val_accuracy: 0.5607\n",
      "Epoch 170/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5457 - accuracy: 0.4975 - val_loss: 1.4674 - val_accuracy: 0.5607\n",
      "Epoch 171/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5455 - accuracy: 0.4971 - val_loss: 1.4673 - val_accuracy: 0.5607\n",
      "Epoch 172/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5454 - accuracy: 0.4975 - val_loss: 1.4674 - val_accuracy: 0.5607\n",
      "Epoch 173/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5453 - accuracy: 0.4978 - val_loss: 1.4673 - val_accuracy: 0.5607\n",
      "Epoch 174/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5452 - accuracy: 0.4978 - val_loss: 1.4669 - val_accuracy: 0.5607\n",
      "Epoch 175/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5451 - accuracy: 0.4971 - val_loss: 1.4667 - val_accuracy: 0.5607\n",
      "Epoch 176/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5449 - accuracy: 0.4982 - val_loss: 1.4668 - val_accuracy: 0.5607\n",
      "Epoch 177/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5447 - accuracy: 0.4990 - val_loss: 1.4665 - val_accuracy: 0.5607\n",
      "Epoch 178/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5446 - accuracy: 0.4990 - val_loss: 1.4666 - val_accuracy: 0.5607\n",
      "Epoch 179/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5445 - accuracy: 0.4998 - val_loss: 1.4663 - val_accuracy: 0.5607\n",
      "Epoch 180/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5443 - accuracy: 0.4998 - val_loss: 1.4664 - val_accuracy: 0.5607\n",
      "Epoch 181/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5442 - accuracy: 0.4998 - val_loss: 1.4660 - val_accuracy: 0.5607\n",
      "Epoch 182/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5441 - accuracy: 0.4998 - val_loss: 1.4660 - val_accuracy: 0.5607\n",
      "Epoch 183/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5439 - accuracy: 0.5002 - val_loss: 1.4662 - val_accuracy: 0.5607\n",
      "Epoch 184/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5438 - accuracy: 0.5010 - val_loss: 1.4657 - val_accuracy: 0.5607\n",
      "Epoch 185/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5437 - accuracy: 0.5010 - val_loss: 1.4655 - val_accuracy: 0.5607\n",
      "Epoch 186/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5435 - accuracy: 0.5010 - val_loss: 1.4654 - val_accuracy: 0.5607\n",
      "Epoch 187/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5434 - accuracy: 0.5002 - val_loss: 1.4655 - val_accuracy: 0.5607\n",
      "Epoch 188/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5433 - accuracy: 0.5006 - val_loss: 1.4654 - val_accuracy: 0.5607\n",
      "Epoch 189/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5431 - accuracy: 0.5006 - val_loss: 1.4650 - val_accuracy: 0.5607\n",
      "Epoch 190/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5430 - accuracy: 0.5010 - val_loss: 1.4650 - val_accuracy: 0.5607\n",
      "Epoch 191/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5429 - accuracy: 0.5014 - val_loss: 1.4647 - val_accuracy: 0.5607\n",
      "Epoch 192/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5427 - accuracy: 0.5006 - val_loss: 1.4646 - val_accuracy: 0.5607\n",
      "Epoch 193/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5426 - accuracy: 0.5014 - val_loss: 1.4646 - val_accuracy: 0.5607\n",
      "Epoch 194/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5425 - accuracy: 0.5014 - val_loss: 1.4645 - val_accuracy: 0.5607\n",
      "Epoch 195/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5423 - accuracy: 0.5014 - val_loss: 1.4643 - val_accuracy: 0.5607\n",
      "Epoch 196/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5422 - accuracy: 0.5010 - val_loss: 1.4642 - val_accuracy: 0.5607\n",
      "Epoch 197/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5421 - accuracy: 0.5022 - val_loss: 1.4639 - val_accuracy: 0.5607\n",
      "Epoch 198/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5419 - accuracy: 0.5025 - val_loss: 1.4638 - val_accuracy: 0.5607\n",
      "Epoch 199/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5418 - accuracy: 0.5022 - val_loss: 1.4640 - val_accuracy: 0.5607\n",
      "Epoch 200/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5417 - accuracy: 0.5037 - val_loss: 1.4636 - val_accuracy: 0.5607\n",
      "0.5607476830482483 {'loss': 1.5416814088821411, 'accuracy': 0.5037211179733276, 'val_loss': 1.463592529296875, 'val_accuracy': 0.5607476830482483}\n",
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        [(None, 29)]              0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 41)                1230      \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 10)                420       \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,870\n",
      "Trainable params: 1,870\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 2.3537 - accuracy: 0.0548 - val_loss: 2.3402 - val_accuracy: 0.0841\n",
      "Epoch 2/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3448 - accuracy: 0.0678 - val_loss: 2.3314 - val_accuracy: 0.1028\n",
      "Epoch 3/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3359 - accuracy: 0.0752 - val_loss: 2.3228 - val_accuracy: 0.1028\n",
      "Epoch 4/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3269 - accuracy: 0.0866 - val_loss: 2.3136 - val_accuracy: 0.1028\n",
      "Epoch 5/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3176 - accuracy: 0.0991 - val_loss: 2.3042 - val_accuracy: 0.1308\n",
      "Epoch 6/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3081 - accuracy: 0.1124 - val_loss: 2.2950 - val_accuracy: 0.1402\n",
      "Epoch 7/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2982 - accuracy: 0.1257 - val_loss: 2.2855 - val_accuracy: 0.1589\n",
      "Epoch 8/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2882 - accuracy: 0.1387 - val_loss: 2.2751 - val_accuracy: 0.1589\n",
      "Epoch 9/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2781 - accuracy: 0.1512 - val_loss: 2.2652 - val_accuracy: 0.1869\n",
      "Epoch 10/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2682 - accuracy: 0.1665 - val_loss: 2.2555 - val_accuracy: 0.1963\n",
      "Epoch 11/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2585 - accuracy: 0.1755 - val_loss: 2.2462 - val_accuracy: 0.2150\n",
      "Epoch 12/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2492 - accuracy: 0.1904 - val_loss: 2.2374 - val_accuracy: 0.2150\n",
      "Epoch 13/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2405 - accuracy: 0.2045 - val_loss: 2.2287 - val_accuracy: 0.2150\n",
      "Epoch 14/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2320 - accuracy: 0.2115 - val_loss: 2.2208 - val_accuracy: 0.2150\n",
      "Epoch 15/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2239 - accuracy: 0.2170 - val_loss: 2.2130 - val_accuracy: 0.2243\n",
      "Epoch 16/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2162 - accuracy: 0.2268 - val_loss: 2.2052 - val_accuracy: 0.2243\n",
      "Epoch 17/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2085 - accuracy: 0.2350 - val_loss: 2.1979 - val_accuracy: 0.2617\n",
      "Epoch 18/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2010 - accuracy: 0.2425 - val_loss: 2.1908 - val_accuracy: 0.2617\n",
      "Epoch 19/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1937 - accuracy: 0.2476 - val_loss: 2.1841 - val_accuracy: 0.2710\n",
      "Epoch 20/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1863 - accuracy: 0.2523 - val_loss: 2.1777 - val_accuracy: 0.2710\n",
      "Epoch 21/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1790 - accuracy: 0.2573 - val_loss: 2.1712 - val_accuracy: 0.2710\n",
      "Epoch 22/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1721 - accuracy: 0.2597 - val_loss: 2.1650 - val_accuracy: 0.2710\n",
      "Epoch 23/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1654 - accuracy: 0.2613 - val_loss: 2.1587 - val_accuracy: 0.2710\n",
      "Epoch 24/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1588 - accuracy: 0.2660 - val_loss: 2.1524 - val_accuracy: 0.2710\n",
      "Epoch 25/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1524 - accuracy: 0.2675 - val_loss: 2.1464 - val_accuracy: 0.2710\n",
      "Epoch 26/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1463 - accuracy: 0.2699 - val_loss: 2.1403 - val_accuracy: 0.2804\n",
      "Epoch 27/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1402 - accuracy: 0.2707 - val_loss: 2.1344 - val_accuracy: 0.2804\n",
      "Epoch 28/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1342 - accuracy: 0.2730 - val_loss: 2.1285 - val_accuracy: 0.2804\n",
      "Epoch 29/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1283 - accuracy: 0.2742 - val_loss: 2.1225 - val_accuracy: 0.2804\n",
      "Epoch 30/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1225 - accuracy: 0.2754 - val_loss: 2.1165 - val_accuracy: 0.2804\n",
      "Epoch 31/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1169 - accuracy: 0.2773 - val_loss: 2.1103 - val_accuracy: 0.2804\n",
      "Epoch 32/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1114 - accuracy: 0.2793 - val_loss: 2.1045 - val_accuracy: 0.2804\n",
      "Epoch 33/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1061 - accuracy: 0.2805 - val_loss: 2.0988 - val_accuracy: 0.2804\n",
      "Epoch 34/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1009 - accuracy: 0.2808 - val_loss: 2.0932 - val_accuracy: 0.2804\n",
      "Epoch 35/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0959 - accuracy: 0.2816 - val_loss: 2.0877 - val_accuracy: 0.2804\n",
      "Epoch 36/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0909 - accuracy: 0.2828 - val_loss: 2.0824 - val_accuracy: 0.2804\n",
      "Epoch 37/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0862 - accuracy: 0.2828 - val_loss: 2.0771 - val_accuracy: 0.2804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0816 - accuracy: 0.2828 - val_loss: 2.0718 - val_accuracy: 0.2804\n",
      "Epoch 39/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0770 - accuracy: 0.2836 - val_loss: 2.0668 - val_accuracy: 0.2804\n",
      "Epoch 40/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0726 - accuracy: 0.2840 - val_loss: 2.0618 - val_accuracy: 0.2804\n",
      "Epoch 41/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0683 - accuracy: 0.2840 - val_loss: 2.0569 - val_accuracy: 0.2804\n",
      "Epoch 42/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0641 - accuracy: 0.2840 - val_loss: 2.0523 - val_accuracy: 0.2804\n",
      "Epoch 43/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0600 - accuracy: 0.2844 - val_loss: 2.0475 - val_accuracy: 0.2804\n",
      "Epoch 44/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0560 - accuracy: 0.2844 - val_loss: 2.0431 - val_accuracy: 0.2804\n",
      "Epoch 45/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0523 - accuracy: 0.2844 - val_loss: 2.0387 - val_accuracy: 0.2804\n",
      "Epoch 46/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0486 - accuracy: 0.2844 - val_loss: 2.0343 - val_accuracy: 0.2804\n",
      "Epoch 47/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0450 - accuracy: 0.2844 - val_loss: 2.0302 - val_accuracy: 0.2804\n",
      "Epoch 48/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0417 - accuracy: 0.2844 - val_loss: 2.0260 - val_accuracy: 0.2804\n",
      "Epoch 49/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0385 - accuracy: 0.2848 - val_loss: 2.0224 - val_accuracy: 0.2804\n",
      "Epoch 50/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0354 - accuracy: 0.2852 - val_loss: 2.0188 - val_accuracy: 0.2804\n",
      "Epoch 51/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0325 - accuracy: 0.2852 - val_loss: 2.0155 - val_accuracy: 0.2804\n",
      "Epoch 52/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0297 - accuracy: 0.2852 - val_loss: 2.0123 - val_accuracy: 0.2804\n",
      "Epoch 53/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0270 - accuracy: 0.2852 - val_loss: 2.0091 - val_accuracy: 0.2804\n",
      "Epoch 54/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0244 - accuracy: 0.2852 - val_loss: 2.0061 - val_accuracy: 0.2804\n",
      "Epoch 55/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0219 - accuracy: 0.2852 - val_loss: 2.0033 - val_accuracy: 0.2804\n",
      "Epoch 56/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0195 - accuracy: 0.2852 - val_loss: 2.0008 - val_accuracy: 0.2804\n",
      "Epoch 57/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0173 - accuracy: 0.2852 - val_loss: 1.9984 - val_accuracy: 0.2804\n",
      "Epoch 58/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0151 - accuracy: 0.2848 - val_loss: 1.9961 - val_accuracy: 0.2804\n",
      "Epoch 59/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0132 - accuracy: 0.2848 - val_loss: 1.9940 - val_accuracy: 0.2804\n",
      "Epoch 60/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0113 - accuracy: 0.2852 - val_loss: 1.9920 - val_accuracy: 0.2804\n",
      "Epoch 61/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0095 - accuracy: 0.2852 - val_loss: 1.9900 - val_accuracy: 0.2804\n",
      "Epoch 62/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0078 - accuracy: 0.2852 - val_loss: 1.9882 - val_accuracy: 0.2804\n",
      "Epoch 63/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0062 - accuracy: 0.2852 - val_loss: 1.9865 - val_accuracy: 0.2804\n",
      "Epoch 64/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0047 - accuracy: 0.2848 - val_loss: 1.9848 - val_accuracy: 0.2804\n",
      "Epoch 65/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0032 - accuracy: 0.2848 - val_loss: 1.9834 - val_accuracy: 0.2804\n",
      "Epoch 66/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0019 - accuracy: 0.2852 - val_loss: 1.9819 - val_accuracy: 0.2804\n",
      "Epoch 67/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0006 - accuracy: 0.2855 - val_loss: 1.9807 - val_accuracy: 0.2804\n",
      "Epoch 68/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9994 - accuracy: 0.2852 - val_loss: 1.9794 - val_accuracy: 0.2804\n",
      "Epoch 69/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9983 - accuracy: 0.2855 - val_loss: 1.9783 - val_accuracy: 0.2804\n",
      "Epoch 70/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9973 - accuracy: 0.2855 - val_loss: 1.9772 - val_accuracy: 0.2804\n",
      "Epoch 71/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9963 - accuracy: 0.2855 - val_loss: 1.9761 - val_accuracy: 0.2804\n",
      "Epoch 72/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9954 - accuracy: 0.2859 - val_loss: 1.9752 - val_accuracy: 0.2710\n",
      "Epoch 73/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9946 - accuracy: 0.2848 - val_loss: 1.9743 - val_accuracy: 0.2710\n",
      "Epoch 74/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9938 - accuracy: 0.2848 - val_loss: 1.9734 - val_accuracy: 0.2710\n",
      "Epoch 75/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9930 - accuracy: 0.2848 - val_loss: 1.9726 - val_accuracy: 0.2710\n",
      "Epoch 76/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9923 - accuracy: 0.2848 - val_loss: 1.9720 - val_accuracy: 0.2710\n",
      "Epoch 77/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9916 - accuracy: 0.2855 - val_loss: 1.9713 - val_accuracy: 0.2710\n",
      "Epoch 78/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9910 - accuracy: 0.2852 - val_loss: 1.9706 - val_accuracy: 0.2710\n",
      "Epoch 79/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9904 - accuracy: 0.2848 - val_loss: 1.9700 - val_accuracy: 0.2710\n",
      "Epoch 80/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9898 - accuracy: 0.2844 - val_loss: 1.9695 - val_accuracy: 0.2804\n",
      "Epoch 81/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9893 - accuracy: 0.2844 - val_loss: 1.9689 - val_accuracy: 0.2804\n",
      "Epoch 82/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9888 - accuracy: 0.2840 - val_loss: 1.9684 - val_accuracy: 0.2804\n",
      "Epoch 83/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9883 - accuracy: 0.2840 - val_loss: 1.9681 - val_accuracy: 0.2804\n",
      "Epoch 84/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9879 - accuracy: 0.2848 - val_loss: 1.9676 - val_accuracy: 0.2804\n",
      "Epoch 85/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9874 - accuracy: 0.2855 - val_loss: 1.9673 - val_accuracy: 0.2804\n",
      "Epoch 86/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9870 - accuracy: 0.2852 - val_loss: 1.9669 - val_accuracy: 0.2804\n",
      "Epoch 87/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9866 - accuracy: 0.2848 - val_loss: 1.9665 - val_accuracy: 0.2804\n",
      "Epoch 88/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9862 - accuracy: 0.2852 - val_loss: 1.9662 - val_accuracy: 0.2804\n",
      "Epoch 89/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9859 - accuracy: 0.2859 - val_loss: 1.9658 - val_accuracy: 0.2804\n",
      "Epoch 90/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9856 - accuracy: 0.2855 - val_loss: 1.9655 - val_accuracy: 0.2804\n",
      "Epoch 91/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9852 - accuracy: 0.2859 - val_loss: 1.9652 - val_accuracy: 0.2804\n",
      "Epoch 92/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9849 - accuracy: 0.2863 - val_loss: 1.9649 - val_accuracy: 0.2804\n",
      "Epoch 93/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9846 - accuracy: 0.2883 - val_loss: 1.9648 - val_accuracy: 0.2804\n",
      "Epoch 94/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9842 - accuracy: 0.2883 - val_loss: 1.9645 - val_accuracy: 0.2804\n",
      "Epoch 95/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9840 - accuracy: 0.2883 - val_loss: 1.9643 - val_accuracy: 0.2804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9837 - accuracy: 0.2899 - val_loss: 1.9640 - val_accuracy: 0.2804\n",
      "Epoch 97/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9834 - accuracy: 0.2906 - val_loss: 1.9637 - val_accuracy: 0.2804\n",
      "Epoch 98/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9831 - accuracy: 0.2918 - val_loss: 1.9635 - val_accuracy: 0.2804\n",
      "Epoch 99/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9828 - accuracy: 0.2918 - val_loss: 1.9633 - val_accuracy: 0.2804\n",
      "Epoch 100/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9826 - accuracy: 0.2922 - val_loss: 1.9631 - val_accuracy: 0.2804\n",
      "Epoch 101/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9823 - accuracy: 0.2914 - val_loss: 1.9628 - val_accuracy: 0.2804\n",
      "Epoch 102/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9821 - accuracy: 0.2914 - val_loss: 1.9626 - val_accuracy: 0.2804\n",
      "Epoch 103/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9818 - accuracy: 0.2922 - val_loss: 1.9625 - val_accuracy: 0.2804\n",
      "Epoch 104/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9816 - accuracy: 0.2930 - val_loss: 1.9623 - val_accuracy: 0.2804\n",
      "Epoch 105/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9813 - accuracy: 0.2938 - val_loss: 1.9621 - val_accuracy: 0.2804\n",
      "Epoch 106/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9811 - accuracy: 0.2938 - val_loss: 1.9618 - val_accuracy: 0.2804\n",
      "Epoch 107/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9809 - accuracy: 0.2946 - val_loss: 1.9617 - val_accuracy: 0.2804\n",
      "Epoch 108/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9807 - accuracy: 0.2949 - val_loss: 1.9615 - val_accuracy: 0.2804\n",
      "Epoch 109/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9805 - accuracy: 0.2946 - val_loss: 1.9615 - val_accuracy: 0.2897\n",
      "Epoch 110/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9802 - accuracy: 0.2942 - val_loss: 1.9613 - val_accuracy: 0.2897\n",
      "Epoch 111/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9800 - accuracy: 0.2938 - val_loss: 1.9610 - val_accuracy: 0.2897\n",
      "Epoch 112/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9798 - accuracy: 0.2946 - val_loss: 1.9610 - val_accuracy: 0.2897\n",
      "Epoch 113/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9796 - accuracy: 0.2949 - val_loss: 1.9607 - val_accuracy: 0.2897\n",
      "Epoch 114/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9794 - accuracy: 0.2961 - val_loss: 1.9606 - val_accuracy: 0.2897\n",
      "Epoch 115/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9791 - accuracy: 0.2953 - val_loss: 1.9604 - val_accuracy: 0.2897\n",
      "Epoch 116/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9790 - accuracy: 0.2953 - val_loss: 1.9602 - val_accuracy: 0.2897\n",
      "Epoch 117/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9788 - accuracy: 0.2957 - val_loss: 1.9602 - val_accuracy: 0.2897\n",
      "Epoch 118/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9785 - accuracy: 0.2965 - val_loss: 1.9600 - val_accuracy: 0.2897\n",
      "Epoch 119/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.9783 - accuracy: 0.2965 - val_loss: 1.9599 - val_accuracy: 0.2897\n",
      "Epoch 120/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 1.9782 - accuracy: 0.2953 - val_loss: 1.9598 - val_accuracy: 0.2991\n",
      "Epoch 121/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.9780 - accuracy: 0.2969 - val_loss: 1.9596 - val_accuracy: 0.2991\n",
      "Epoch 122/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.9778 - accuracy: 0.2965 - val_loss: 1.9595 - val_accuracy: 0.2991\n",
      "Epoch 123/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.9776 - accuracy: 0.2969 - val_loss: 1.9594 - val_accuracy: 0.2991\n",
      "Epoch 124/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.9774 - accuracy: 0.2965 - val_loss: 1.9592 - val_accuracy: 0.2991\n",
      "Epoch 125/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.9772 - accuracy: 0.2969 - val_loss: 1.9591 - val_accuracy: 0.2991\n",
      "Epoch 126/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.9770 - accuracy: 0.2965 - val_loss: 1.9590 - val_accuracy: 0.2991\n",
      "Epoch 127/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.9768 - accuracy: 0.2969 - val_loss: 1.9589 - val_accuracy: 0.2991\n",
      "Epoch 128/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.9766 - accuracy: 0.2977 - val_loss: 1.9587 - val_accuracy: 0.2991\n",
      "Epoch 129/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.9764 - accuracy: 0.2977 - val_loss: 1.9586 - val_accuracy: 0.2991\n",
      "Epoch 130/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.9763 - accuracy: 0.2973 - val_loss: 1.9585 - val_accuracy: 0.2991\n",
      "Epoch 131/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.9761 - accuracy: 0.2973 - val_loss: 1.9584 - val_accuracy: 0.2991\n",
      "Epoch 132/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.9759 - accuracy: 0.2969 - val_loss: 1.9582 - val_accuracy: 0.2991\n",
      "Epoch 133/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.9757 - accuracy: 0.2969 - val_loss: 1.9582 - val_accuracy: 0.2991\n",
      "Epoch 134/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.9756 - accuracy: 0.2969 - val_loss: 1.9581 - val_accuracy: 0.2991\n",
      "Epoch 135/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.9754 - accuracy: 0.2973 - val_loss: 1.9580 - val_accuracy: 0.2991\n",
      "Epoch 136/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9752 - accuracy: 0.2969 - val_loss: 1.9579 - val_accuracy: 0.2991\n",
      "Epoch 137/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9750 - accuracy: 0.2965 - val_loss: 1.9578 - val_accuracy: 0.2991\n",
      "Epoch 138/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9748 - accuracy: 0.2965 - val_loss: 1.9577 - val_accuracy: 0.2991\n",
      "Epoch 139/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9747 - accuracy: 0.2957 - val_loss: 1.9577 - val_accuracy: 0.2991\n",
      "Epoch 140/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.9745 - accuracy: 0.2957 - val_loss: 1.9576 - val_accuracy: 0.2991\n",
      "Epoch 141/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.9743 - accuracy: 0.2965 - val_loss: 1.9574 - val_accuracy: 0.2991\n",
      "Epoch 142/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9742 - accuracy: 0.2961 - val_loss: 1.9574 - val_accuracy: 0.2991\n",
      "Epoch 143/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.9740 - accuracy: 0.2965 - val_loss: 1.9573 - val_accuracy: 0.2991\n",
      "Epoch 144/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9738 - accuracy: 0.2973 - val_loss: 1.9571 - val_accuracy: 0.2991\n",
      "Epoch 145/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9737 - accuracy: 0.2969 - val_loss: 1.9570 - val_accuracy: 0.2991\n",
      "Epoch 146/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9735 - accuracy: 0.2985 - val_loss: 1.9569 - val_accuracy: 0.2991\n",
      "Epoch 147/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9733 - accuracy: 0.2981 - val_loss: 1.9568 - val_accuracy: 0.2991\n",
      "Epoch 148/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.9732 - accuracy: 0.2989 - val_loss: 1.9567 - val_accuracy: 0.2991\n",
      "Epoch 149/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.9730 - accuracy: 0.2985 - val_loss: 1.9566 - val_accuracy: 0.2991\n",
      "Epoch 150/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9728 - accuracy: 0.2989 - val_loss: 1.9564 - val_accuracy: 0.2991\n",
      "Epoch 151/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9727 - accuracy: 0.2985 - val_loss: 1.9563 - val_accuracy: 0.3084\n",
      "Epoch 152/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9725 - accuracy: 0.2981 - val_loss: 1.9561 - val_accuracy: 0.3084\n",
      "Epoch 153/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9724 - accuracy: 0.2989 - val_loss: 1.9560 - val_accuracy: 0.3084\n",
      "Epoch 154/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9722 - accuracy: 0.3000 - val_loss: 1.9559 - val_accuracy: 0.3084\n",
      "Epoch 155/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9721 - accuracy: 0.3000 - val_loss: 1.9558 - val_accuracy: 0.3084\n",
      "Epoch 156/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9719 - accuracy: 0.3000 - val_loss: 1.9556 - val_accuracy: 0.3084\n",
      "Epoch 157/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9717 - accuracy: 0.3000 - val_loss: 1.9555 - val_accuracy: 0.3084\n",
      "Epoch 158/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9716 - accuracy: 0.3008 - val_loss: 1.9554 - val_accuracy: 0.3084\n",
      "Epoch 159/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9714 - accuracy: 0.3004 - val_loss: 1.9552 - val_accuracy: 0.3084\n",
      "Epoch 160/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9713 - accuracy: 0.3016 - val_loss: 1.9551 - val_accuracy: 0.3084\n",
      "Epoch 161/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.9711 - accuracy: 0.3008 - val_loss: 1.9550 - val_accuracy: 0.3084\n",
      "Epoch 162/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9710 - accuracy: 0.3016 - val_loss: 1.9549 - val_accuracy: 0.2991\n",
      "Epoch 163/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.9708 - accuracy: 0.3016 - val_loss: 1.9547 - val_accuracy: 0.2991\n",
      "Epoch 164/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.9707 - accuracy: 0.3012 - val_loss: 1.9545 - val_accuracy: 0.2991\n",
      "Epoch 165/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9706 - accuracy: 0.3016 - val_loss: 1.9543 - val_accuracy: 0.2991\n",
      "Epoch 166/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.9704 - accuracy: 0.3008 - val_loss: 1.9543 - val_accuracy: 0.2991\n",
      "Epoch 167/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.9703 - accuracy: 0.3012 - val_loss: 1.9542 - val_accuracy: 0.2991\n",
      "Epoch 168/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9701 - accuracy: 0.3004 - val_loss: 1.9540 - val_accuracy: 0.2991\n",
      "Epoch 169/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9700 - accuracy: 0.3012 - val_loss: 1.9540 - val_accuracy: 0.2991\n",
      "Epoch 170/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9699 - accuracy: 0.3012 - val_loss: 1.9538 - val_accuracy: 0.2991\n",
      "Epoch 171/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9697 - accuracy: 0.3012 - val_loss: 1.9537 - val_accuracy: 0.2991\n",
      "Epoch 172/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.9696 - accuracy: 0.3016 - val_loss: 1.9536 - val_accuracy: 0.2991\n",
      "Epoch 173/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9695 - accuracy: 0.3008 - val_loss: 1.9534 - val_accuracy: 0.2991\n",
      "Epoch 174/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.9693 - accuracy: 0.3008 - val_loss: 1.9533 - val_accuracy: 0.2991\n",
      "Epoch 175/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.9692 - accuracy: 0.3012 - val_loss: 1.9532 - val_accuracy: 0.2991\n",
      "Epoch 176/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9691 - accuracy: 0.3012 - val_loss: 1.9531 - val_accuracy: 0.2991\n",
      "Epoch 177/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.9689 - accuracy: 0.3008 - val_loss: 1.9530 - val_accuracy: 0.2991\n",
      "Epoch 178/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9688 - accuracy: 0.3004 - val_loss: 1.9529 - val_accuracy: 0.2991\n",
      "Epoch 179/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9687 - accuracy: 0.2996 - val_loss: 1.9528 - val_accuracy: 0.2991\n",
      "Epoch 180/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9685 - accuracy: 0.3000 - val_loss: 1.9528 - val_accuracy: 0.2991\n",
      "Epoch 181/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9684 - accuracy: 0.3008 - val_loss: 1.9526 - val_accuracy: 0.2991\n",
      "Epoch 182/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9683 - accuracy: 0.3000 - val_loss: 1.9525 - val_accuracy: 0.2991\n",
      "Epoch 183/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9681 - accuracy: 0.3008 - val_loss: 1.9524 - val_accuracy: 0.2991\n",
      "Epoch 184/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9680 - accuracy: 0.3004 - val_loss: 1.9524 - val_accuracy: 0.2991\n",
      "Epoch 185/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9678 - accuracy: 0.3012 - val_loss: 1.9521 - val_accuracy: 0.2991\n",
      "Epoch 186/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.9677 - accuracy: 0.3004 - val_loss: 1.9520 - val_accuracy: 0.2991\n",
      "Epoch 187/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.9676 - accuracy: 0.3008 - val_loss: 1.9519 - val_accuracy: 0.2991\n",
      "Epoch 188/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9675 - accuracy: 0.3004 - val_loss: 1.9517 - val_accuracy: 0.2991\n",
      "Epoch 189/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.9673 - accuracy: 0.2996 - val_loss: 1.9516 - val_accuracy: 0.2991\n",
      "Epoch 190/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.9672 - accuracy: 0.3000 - val_loss: 1.9515 - val_accuracy: 0.2991\n",
      "Epoch 191/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 1.9671 - accuracy: 0.3004 - val_loss: 1.9514 - val_accuracy: 0.2991\n",
      "Epoch 192/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.9670 - accuracy: 0.2989 - val_loss: 1.9513 - val_accuracy: 0.2991\n",
      "Epoch 193/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.9668 - accuracy: 0.2981 - val_loss: 1.9512 - val_accuracy: 0.2991\n",
      "Epoch 194/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9667 - accuracy: 0.2985 - val_loss: 1.9510 - val_accuracy: 0.2991\n",
      "Epoch 195/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.9666 - accuracy: 0.2977 - val_loss: 1.9508 - val_accuracy: 0.2991\n",
      "Epoch 196/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9665 - accuracy: 0.2981 - val_loss: 1.9506 - val_accuracy: 0.2991\n",
      "Epoch 197/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9663 - accuracy: 0.2981 - val_loss: 1.9505 - val_accuracy: 0.2991\n",
      "Epoch 198/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9662 - accuracy: 0.2985 - val_loss: 1.9504 - val_accuracy: 0.2991\n",
      "Epoch 199/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.9661 - accuracy: 0.2985 - val_loss: 1.9502 - val_accuracy: 0.2991\n",
      "Epoch 200/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9660 - accuracy: 0.2985 - val_loss: 1.9501 - val_accuracy: 0.2991\n",
      "0.29906541109085083 {'loss': 1.9660307168960571, 'accuracy': 0.2984723746776581, 'val_loss': 1.9500761032104492, 'val_accuracy': 0.29906541109085083}\n",
      "Model: \"model_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_11 (InputLayer)        [(None, 29)]              0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 41)                1230      \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 10)                420       \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,870\n",
      "Trainable params: 1,870\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 2.4637 - accuracy: 0.0333 - val_loss: 2.3955 - val_accuracy: 0.0187\n",
      "Epoch 2/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4333 - accuracy: 0.0470 - val_loss: 2.3616 - val_accuracy: 0.0374\n",
      "Epoch 3/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3899 - accuracy: 0.0607 - val_loss: 2.3309 - val_accuracy: 0.0561\n",
      "Epoch 4/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 2.3596 - accuracy: 0.0866 - val_loss: 2.3048 - val_accuracy: 0.1028\n",
      "Epoch 5/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 2.3344 - accuracy: 0.1030 - val_loss: 2.2825 - val_accuracy: 0.1028\n",
      "Epoch 6/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3049 - accuracy: 0.1253 - val_loss: 2.2615 - val_accuracy: 0.1869\n",
      "Epoch 7/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2918 - accuracy: 0.1351 - val_loss: 2.2415 - val_accuracy: 0.1963\n",
      "Epoch 8/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2687 - accuracy: 0.1633 - val_loss: 2.2229 - val_accuracy: 0.2150\n",
      "Epoch 9/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 2.2381 - accuracy: 0.1857 - val_loss: 2.2055 - val_accuracy: 0.2243\n",
      "Epoch 10/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2318 - accuracy: 0.1990 - val_loss: 2.1880 - val_accuracy: 0.2430\n",
      "Epoch 11/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2206 - accuracy: 0.2099 - val_loss: 2.1721 - val_accuracy: 0.2617\n",
      "Epoch 12/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1837 - accuracy: 0.2401 - val_loss: 2.1567 - val_accuracy: 0.2710\n",
      "Epoch 13/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1719 - accuracy: 0.2503 - val_loss: 2.1407 - val_accuracy: 0.2991\n",
      "Epoch 14/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1699 - accuracy: 0.2526 - val_loss: 2.1249 - val_accuracy: 0.3178\n",
      "Epoch 15/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1555 - accuracy: 0.2656 - val_loss: 2.1086 - val_accuracy: 0.3271\n",
      "Epoch 16/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1292 - accuracy: 0.2769 - val_loss: 2.0923 - val_accuracy: 0.3364\n",
      "Epoch 17/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1170 - accuracy: 0.2906 - val_loss: 2.0765 - val_accuracy: 0.3364\n",
      "Epoch 18/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1132 - accuracy: 0.2922 - val_loss: 2.0622 - val_accuracy: 0.3458\n",
      "Epoch 19/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0893 - accuracy: 0.3216 - val_loss: 2.0472 - val_accuracy: 0.3738\n",
      "Epoch 20/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0871 - accuracy: 0.3130 - val_loss: 2.0325 - val_accuracy: 0.3832\n",
      "Epoch 21/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0722 - accuracy: 0.3380 - val_loss: 2.0175 - val_accuracy: 0.4019\n",
      "Epoch 22/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0421 - accuracy: 0.3521 - val_loss: 2.0021 - val_accuracy: 0.4299\n",
      "Epoch 23/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0425 - accuracy: 0.3431 - val_loss: 1.9864 - val_accuracy: 0.4299\n",
      "Epoch 24/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0336 - accuracy: 0.3529 - val_loss: 1.9705 - val_accuracy: 0.4393\n",
      "Epoch 25/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0115 - accuracy: 0.3725 - val_loss: 1.9541 - val_accuracy: 0.4299\n",
      "Epoch 26/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.9874 - accuracy: 0.3682 - val_loss: 1.9362 - val_accuracy: 0.4299\n",
      "Epoch 27/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.9826 - accuracy: 0.3729 - val_loss: 1.9177 - val_accuracy: 0.4486\n",
      "Epoch 28/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.9635 - accuracy: 0.3713 - val_loss: 1.8977 - val_accuracy: 0.4766\n",
      "Epoch 29/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.9623 - accuracy: 0.3698 - val_loss: 1.8775 - val_accuracy: 0.4860\n",
      "Epoch 30/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.9354 - accuracy: 0.3768 - val_loss: 1.8559 - val_accuracy: 0.4860\n",
      "Epoch 31/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.9247 - accuracy: 0.3796 - val_loss: 1.8338 - val_accuracy: 0.4860\n",
      "Epoch 32/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.8957 - accuracy: 0.3909 - val_loss: 1.8111 - val_accuracy: 0.4860\n",
      "Epoch 33/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.9085 - accuracy: 0.3702 - val_loss: 1.7892 - val_accuracy: 0.4860\n",
      "Epoch 34/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.8873 - accuracy: 0.3796 - val_loss: 1.7675 - val_accuracy: 0.4953\n",
      "Epoch 35/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.8545 - accuracy: 0.3925 - val_loss: 1.7442 - val_accuracy: 0.4953\n",
      "Epoch 36/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.8469 - accuracy: 0.3741 - val_loss: 1.7217 - val_accuracy: 0.5047\n",
      "Epoch 37/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.8275 - accuracy: 0.3897 - val_loss: 1.6998 - val_accuracy: 0.5047\n",
      "Epoch 38/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.8168 - accuracy: 0.3929 - val_loss: 1.6786 - val_accuracy: 0.5234\n",
      "Epoch 39/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.7978 - accuracy: 0.4066 - val_loss: 1.6574 - val_accuracy: 0.5140\n",
      "Epoch 40/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.7848 - accuracy: 0.4117 - val_loss: 1.6377 - val_accuracy: 0.5234\n",
      "Epoch 41/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.7488 - accuracy: 0.4183 - val_loss: 1.6172 - val_accuracy: 0.5327\n",
      "Epoch 42/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.7591 - accuracy: 0.4074 - val_loss: 1.5998 - val_accuracy: 0.5327\n",
      "Epoch 43/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.7694 - accuracy: 0.4031 - val_loss: 1.5846 - val_accuracy: 0.5234\n",
      "Epoch 44/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.7674 - accuracy: 0.3984 - val_loss: 1.5706 - val_accuracy: 0.5234\n",
      "Epoch 45/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 1.7419 - accuracy: 0.4081 - val_loss: 1.5557 - val_accuracy: 0.5234\n",
      "Epoch 46/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.7400 - accuracy: 0.4105 - val_loss: 1.5425 - val_accuracy: 0.5140\n",
      "Epoch 47/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.7238 - accuracy: 0.4038 - val_loss: 1.5292 - val_accuracy: 0.5327\n",
      "Epoch 48/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6982 - accuracy: 0.4105 - val_loss: 1.5162 - val_accuracy: 0.5327\n",
      "Epoch 49/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.7135 - accuracy: 0.4121 - val_loss: 1.5049 - val_accuracy: 0.5327\n",
      "Epoch 50/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6564 - accuracy: 0.4399 - val_loss: 1.4920 - val_accuracy: 0.5327\n",
      "Epoch 51/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.7328 - accuracy: 0.3940 - val_loss: 1.4846 - val_accuracy: 0.5140\n",
      "Epoch 52/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.7044 - accuracy: 0.4144 - val_loss: 1.4767 - val_accuracy: 0.5140\n",
      "Epoch 53/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.7367 - accuracy: 0.3987 - val_loss: 1.4708 - val_accuracy: 0.5140\n",
      "Epoch 54/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 1.7205 - accuracy: 0.4027 - val_loss: 1.4648 - val_accuracy: 0.5140\n",
      "Epoch 55/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6839 - accuracy: 0.4156 - val_loss: 1.4569 - val_accuracy: 0.5140\n",
      "Epoch 56/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.7030 - accuracy: 0.4105 - val_loss: 1.4505 - val_accuracy: 0.5140\n",
      "Epoch 57/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6678 - accuracy: 0.4262 - val_loss: 1.4439 - val_accuracy: 0.5140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.7005 - accuracy: 0.4136 - val_loss: 1.4394 - val_accuracy: 0.5140\n",
      "Epoch 59/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6813 - accuracy: 0.4132 - val_loss: 1.4333 - val_accuracy: 0.5140\n",
      "Epoch 60/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6693 - accuracy: 0.4234 - val_loss: 1.4280 - val_accuracy: 0.5140\n",
      "Epoch 61/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.7212 - accuracy: 0.3952 - val_loss: 1.4255 - val_accuracy: 0.5234\n",
      "Epoch 62/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6975 - accuracy: 0.4109 - val_loss: 1.4226 - val_accuracy: 0.5140\n",
      "Epoch 63/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6768 - accuracy: 0.4128 - val_loss: 1.4185 - val_accuracy: 0.5140\n",
      "Epoch 64/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6952 - accuracy: 0.4164 - val_loss: 1.4156 - val_accuracy: 0.5140\n",
      "Epoch 65/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6579 - accuracy: 0.4172 - val_loss: 1.4115 - val_accuracy: 0.5047\n",
      "Epoch 66/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6911 - accuracy: 0.4207 - val_loss: 1.4098 - val_accuracy: 0.5047\n",
      "Epoch 67/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6533 - accuracy: 0.4305 - val_loss: 1.4055 - val_accuracy: 0.5047\n",
      "Epoch 68/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6616 - accuracy: 0.4226 - val_loss: 1.4022 - val_accuracy: 0.5047\n",
      "Epoch 69/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6889 - accuracy: 0.4089 - val_loss: 1.3998 - val_accuracy: 0.4953\n",
      "Epoch 70/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6892 - accuracy: 0.4191 - val_loss: 1.3989 - val_accuracy: 0.4953\n",
      "Epoch 71/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.7028 - accuracy: 0.4136 - val_loss: 1.3984 - val_accuracy: 0.4953\n",
      "Epoch 72/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6554 - accuracy: 0.4215 - val_loss: 1.3960 - val_accuracy: 0.4953\n",
      "Epoch 73/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6786 - accuracy: 0.4187 - val_loss: 1.3940 - val_accuracy: 0.4953\n",
      "Epoch 74/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6762 - accuracy: 0.4230 - val_loss: 1.3932 - val_accuracy: 0.4953\n",
      "Epoch 75/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6644 - accuracy: 0.4234 - val_loss: 1.3906 - val_accuracy: 0.4860\n",
      "Epoch 76/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.7161 - accuracy: 0.4089 - val_loss: 1.3911 - val_accuracy: 0.4860\n",
      "Epoch 77/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6436 - accuracy: 0.4262 - val_loss: 1.3884 - val_accuracy: 0.4860\n",
      "Epoch 78/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6303 - accuracy: 0.4446 - val_loss: 1.3849 - val_accuracy: 0.4860\n",
      "Epoch 79/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6563 - accuracy: 0.4305 - val_loss: 1.3835 - val_accuracy: 0.4860\n",
      "Epoch 80/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6778 - accuracy: 0.4144 - val_loss: 1.3828 - val_accuracy: 0.4860\n",
      "Epoch 81/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6627 - accuracy: 0.4266 - val_loss: 1.3824 - val_accuracy: 0.4860\n",
      "Epoch 82/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6783 - accuracy: 0.4183 - val_loss: 1.3813 - val_accuracy: 0.4860\n",
      "Epoch 83/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6610 - accuracy: 0.4222 - val_loss: 1.3799 - val_accuracy: 0.4860\n",
      "Epoch 84/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6871 - accuracy: 0.4195 - val_loss: 1.3805 - val_accuracy: 0.4860\n",
      "Epoch 85/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 1.6697 - accuracy: 0.4258 - val_loss: 1.3802 - val_accuracy: 0.4860\n",
      "Epoch 86/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6643 - accuracy: 0.4313 - val_loss: 1.3795 - val_accuracy: 0.4860\n",
      "Epoch 87/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6528 - accuracy: 0.4269 - val_loss: 1.3772 - val_accuracy: 0.4953\n",
      "Epoch 88/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6530 - accuracy: 0.4262 - val_loss: 1.3755 - val_accuracy: 0.4860\n",
      "Epoch 89/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6689 - accuracy: 0.4305 - val_loss: 1.3756 - val_accuracy: 0.4860\n",
      "Epoch 90/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6954 - accuracy: 0.4105 - val_loss: 1.3770 - val_accuracy: 0.4860\n",
      "Epoch 91/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6879 - accuracy: 0.4128 - val_loss: 1.3774 - val_accuracy: 0.4860\n",
      "Epoch 92/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6707 - accuracy: 0.4195 - val_loss: 1.3766 - val_accuracy: 0.4860\n",
      "Epoch 93/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6828 - accuracy: 0.4168 - val_loss: 1.3767 - val_accuracy: 0.4860\n",
      "Epoch 94/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6536 - accuracy: 0.4266 - val_loss: 1.3757 - val_accuracy: 0.4860\n",
      "Epoch 95/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6698 - accuracy: 0.4254 - val_loss: 1.3748 - val_accuracy: 0.4860\n",
      "Epoch 96/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6465 - accuracy: 0.4371 - val_loss: 1.3731 - val_accuracy: 0.4860\n",
      "Epoch 97/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6247 - accuracy: 0.4442 - val_loss: 1.3701 - val_accuracy: 0.4953\n",
      "Epoch 98/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6620 - accuracy: 0.4285 - val_loss: 1.3699 - val_accuracy: 0.4953\n",
      "Epoch 99/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6652 - accuracy: 0.4301 - val_loss: 1.3693 - val_accuracy: 0.5047\n",
      "Epoch 100/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6639 - accuracy: 0.4356 - val_loss: 1.3693 - val_accuracy: 0.4953\n",
      "Epoch 101/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6514 - accuracy: 0.4269 - val_loss: 1.3683 - val_accuracy: 0.4953\n",
      "Epoch 102/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6609 - accuracy: 0.4250 - val_loss: 1.3682 - val_accuracy: 0.5047\n",
      "Epoch 103/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6535 - accuracy: 0.4328 - val_loss: 1.3671 - val_accuracy: 0.4953\n",
      "Epoch 104/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6637 - accuracy: 0.4187 - val_loss: 1.3671 - val_accuracy: 0.5047\n",
      "Epoch 105/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6513 - accuracy: 0.4281 - val_loss: 1.3666 - val_accuracy: 0.5047\n",
      "Epoch 106/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6312 - accuracy: 0.4281 - val_loss: 1.3645 - val_accuracy: 0.5047\n",
      "Epoch 107/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6691 - accuracy: 0.4281 - val_loss: 1.3642 - val_accuracy: 0.5047\n",
      "Epoch 108/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6843 - accuracy: 0.4219 - val_loss: 1.3656 - val_accuracy: 0.4953\n",
      "Epoch 109/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6758 - accuracy: 0.4324 - val_loss: 1.3663 - val_accuracy: 0.4953\n",
      "Epoch 110/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6516 - accuracy: 0.4336 - val_loss: 1.3654 - val_accuracy: 0.4953\n",
      "Epoch 111/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6338 - accuracy: 0.4465 - val_loss: 1.3632 - val_accuracy: 0.5047\n",
      "Epoch 112/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6784 - accuracy: 0.4191 - val_loss: 1.3637 - val_accuracy: 0.4953\n",
      "Epoch 113/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6534 - accuracy: 0.4422 - val_loss: 1.3634 - val_accuracy: 0.5047\n",
      "Epoch 114/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6558 - accuracy: 0.4363 - val_loss: 1.3628 - val_accuracy: 0.5047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6342 - accuracy: 0.4363 - val_loss: 1.3614 - val_accuracy: 0.4953\n",
      "Epoch 116/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6490 - accuracy: 0.4301 - val_loss: 1.3611 - val_accuracy: 0.4953\n",
      "Epoch 117/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6595 - accuracy: 0.4305 - val_loss: 1.3605 - val_accuracy: 0.4953\n",
      "Epoch 118/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6521 - accuracy: 0.4434 - val_loss: 1.3596 - val_accuracy: 0.5047\n",
      "Epoch 119/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6452 - accuracy: 0.4328 - val_loss: 1.3597 - val_accuracy: 0.5047\n",
      "Epoch 120/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6374 - accuracy: 0.4426 - val_loss: 1.3585 - val_accuracy: 0.5047\n",
      "Epoch 121/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6587 - accuracy: 0.4238 - val_loss: 1.3577 - val_accuracy: 0.5047\n",
      "Epoch 122/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6530 - accuracy: 0.4399 - val_loss: 1.3578 - val_accuracy: 0.5047\n",
      "Epoch 123/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6507 - accuracy: 0.4258 - val_loss: 1.3576 - val_accuracy: 0.5140\n",
      "Epoch 124/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6634 - accuracy: 0.4430 - val_loss: 1.3588 - val_accuracy: 0.5140\n",
      "Epoch 125/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6757 - accuracy: 0.4203 - val_loss: 1.3606 - val_accuracy: 0.5140\n",
      "Epoch 126/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6296 - accuracy: 0.4438 - val_loss: 1.3586 - val_accuracy: 0.5140\n",
      "Epoch 127/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6059 - accuracy: 0.4548 - val_loss: 1.3560 - val_accuracy: 0.5140\n",
      "Epoch 128/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6550 - accuracy: 0.4293 - val_loss: 1.3561 - val_accuracy: 0.5140\n",
      "Epoch 129/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6535 - accuracy: 0.4395 - val_loss: 1.3563 - val_accuracy: 0.5047\n",
      "Epoch 130/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6827 - accuracy: 0.4324 - val_loss: 1.3575 - val_accuracy: 0.5047\n",
      "Epoch 131/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6111 - accuracy: 0.4481 - val_loss: 1.3551 - val_accuracy: 0.5047\n",
      "Epoch 132/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6624 - accuracy: 0.4226 - val_loss: 1.3556 - val_accuracy: 0.5140\n",
      "Epoch 133/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6357 - accuracy: 0.4481 - val_loss: 1.3541 - val_accuracy: 0.5140\n",
      "Epoch 134/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6758 - accuracy: 0.4320 - val_loss: 1.3557 - val_accuracy: 0.5140\n",
      "Epoch 135/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6614 - accuracy: 0.4340 - val_loss: 1.3560 - val_accuracy: 0.5047\n",
      "Epoch 136/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6642 - accuracy: 0.4285 - val_loss: 1.3558 - val_accuracy: 0.5047\n",
      "Epoch 137/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6305 - accuracy: 0.4418 - val_loss: 1.3550 - val_accuracy: 0.5140\n",
      "Epoch 138/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6263 - accuracy: 0.4430 - val_loss: 1.3535 - val_accuracy: 0.5140\n",
      "Epoch 139/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6345 - accuracy: 0.4422 - val_loss: 1.3517 - val_accuracy: 0.5047\n",
      "Epoch 140/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6282 - accuracy: 0.4371 - val_loss: 1.3504 - val_accuracy: 0.5140\n",
      "Epoch 141/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6659 - accuracy: 0.4281 - val_loss: 1.3513 - val_accuracy: 0.5140\n",
      "Epoch 142/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6462 - accuracy: 0.4281 - val_loss: 1.3515 - val_accuracy: 0.5047\n",
      "Epoch 143/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6087 - accuracy: 0.4559 - val_loss: 1.3488 - val_accuracy: 0.5047\n",
      "Epoch 144/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6675 - accuracy: 0.4340 - val_loss: 1.3501 - val_accuracy: 0.5047\n",
      "Epoch 145/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6558 - accuracy: 0.4375 - val_loss: 1.3502 - val_accuracy: 0.5047\n",
      "Epoch 146/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6618 - accuracy: 0.4254 - val_loss: 1.3511 - val_accuracy: 0.5047\n",
      "Epoch 147/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6353 - accuracy: 0.4458 - val_loss: 1.3509 - val_accuracy: 0.5047\n",
      "Epoch 148/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6395 - accuracy: 0.4399 - val_loss: 1.3502 - val_accuracy: 0.5047\n",
      "Epoch 149/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6187 - accuracy: 0.4497 - val_loss: 1.3483 - val_accuracy: 0.5047\n",
      "Epoch 150/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6073 - accuracy: 0.4407 - val_loss: 1.3464 - val_accuracy: 0.5047\n",
      "Epoch 151/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6588 - accuracy: 0.4262 - val_loss: 1.3471 - val_accuracy: 0.5047\n",
      "Epoch 152/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6794 - accuracy: 0.4211 - val_loss: 1.3495 - val_accuracy: 0.5047\n",
      "Epoch 153/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6356 - accuracy: 0.4407 - val_loss: 1.3486 - val_accuracy: 0.5047\n",
      "Epoch 154/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6175 - accuracy: 0.4422 - val_loss: 1.3469 - val_accuracy: 0.5047\n",
      "Epoch 155/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6570 - accuracy: 0.4328 - val_loss: 1.3478 - val_accuracy: 0.5047\n",
      "Epoch 156/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6749 - accuracy: 0.4301 - val_loss: 1.3491 - val_accuracy: 0.5047\n",
      "Epoch 157/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6561 - accuracy: 0.4344 - val_loss: 1.3489 - val_accuracy: 0.5047\n",
      "Epoch 158/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6309 - accuracy: 0.4410 - val_loss: 1.3476 - val_accuracy: 0.5047\n",
      "Epoch 159/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6830 - accuracy: 0.4207 - val_loss: 1.3487 - val_accuracy: 0.5047\n",
      "Epoch 160/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6676 - accuracy: 0.4301 - val_loss: 1.3497 - val_accuracy: 0.5047\n",
      "Epoch 161/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6238 - accuracy: 0.4454 - val_loss: 1.3476 - val_accuracy: 0.5047\n",
      "Epoch 162/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6338 - accuracy: 0.4399 - val_loss: 1.3470 - val_accuracy: 0.5047\n",
      "Epoch 163/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6157 - accuracy: 0.4465 - val_loss: 1.3449 - val_accuracy: 0.5140\n",
      "Epoch 164/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6698 - accuracy: 0.4383 - val_loss: 1.3461 - val_accuracy: 0.5047\n",
      "Epoch 165/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 1.6643 - accuracy: 0.4266 - val_loss: 1.3467 - val_accuracy: 0.5047\n",
      "Epoch 166/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6462 - accuracy: 0.4336 - val_loss: 1.3468 - val_accuracy: 0.5047\n",
      "Epoch 167/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5982 - accuracy: 0.4567 - val_loss: 1.3441 - val_accuracy: 0.5047\n",
      "Epoch 168/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6309 - accuracy: 0.4352 - val_loss: 1.3430 - val_accuracy: 0.5140\n",
      "Epoch 169/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6864 - accuracy: 0.4183 - val_loss: 1.3447 - val_accuracy: 0.5047\n",
      "Epoch 170/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6278 - accuracy: 0.4360 - val_loss: 1.3435 - val_accuracy: 0.5140\n",
      "Epoch 171/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 3ms/step - loss: 1.6506 - accuracy: 0.4316 - val_loss: 1.3435 - val_accuracy: 0.5140\n",
      "Epoch 172/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6619 - accuracy: 0.4207 - val_loss: 1.3446 - val_accuracy: 0.5140\n",
      "Epoch 173/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6619 - accuracy: 0.4332 - val_loss: 1.3460 - val_accuracy: 0.5140\n",
      "Epoch 174/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6332 - accuracy: 0.4356 - val_loss: 1.3449 - val_accuracy: 0.5140\n",
      "Epoch 175/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6589 - accuracy: 0.4348 - val_loss: 1.3454 - val_accuracy: 0.5047\n",
      "Epoch 176/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6116 - accuracy: 0.4559 - val_loss: 1.3440 - val_accuracy: 0.5047\n",
      "Epoch 177/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6327 - accuracy: 0.4407 - val_loss: 1.3429 - val_accuracy: 0.5234\n",
      "Epoch 178/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 1.6534 - accuracy: 0.4363 - val_loss: 1.3436 - val_accuracy: 0.5140\n",
      "Epoch 179/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6173 - accuracy: 0.4465 - val_loss: 1.3421 - val_accuracy: 0.5140\n",
      "Epoch 180/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6344 - accuracy: 0.4407 - val_loss: 1.3418 - val_accuracy: 0.5140\n",
      "Epoch 181/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6491 - accuracy: 0.4266 - val_loss: 1.3416 - val_accuracy: 0.5140\n",
      "Epoch 182/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6206 - accuracy: 0.4497 - val_loss: 1.3407 - val_accuracy: 0.5234\n",
      "Epoch 183/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6516 - accuracy: 0.4407 - val_loss: 1.3418 - val_accuracy: 0.5234\n",
      "Epoch 184/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6362 - accuracy: 0.4446 - val_loss: 1.3419 - val_accuracy: 0.5234\n",
      "Epoch 185/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6390 - accuracy: 0.4379 - val_loss: 1.3416 - val_accuracy: 0.5234\n",
      "Epoch 186/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6295 - accuracy: 0.4442 - val_loss: 1.3405 - val_accuracy: 0.5234\n",
      "Epoch 187/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6009 - accuracy: 0.4587 - val_loss: 1.3381 - val_accuracy: 0.5234\n",
      "Epoch 188/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6604 - accuracy: 0.4301 - val_loss: 1.3393 - val_accuracy: 0.5234\n",
      "Epoch 189/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6493 - accuracy: 0.4332 - val_loss: 1.3403 - val_accuracy: 0.5234\n",
      "Epoch 190/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6577 - accuracy: 0.4305 - val_loss: 1.3404 - val_accuracy: 0.5234\n",
      "Epoch 191/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6375 - accuracy: 0.4414 - val_loss: 1.3404 - val_accuracy: 0.5234\n",
      "Epoch 192/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6266 - accuracy: 0.4391 - val_loss: 1.3396 - val_accuracy: 0.5234\n",
      "Epoch 193/200\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 1.6095 - accuracy: 0.4442 - val_loss: 1.3386 - val_accuracy: 0.5234\n",
      "Epoch 194/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 1.6425 - accuracy: 0.4344 - val_loss: 1.3384 - val_accuracy: 0.5234\n",
      "Epoch 195/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6516 - accuracy: 0.4375 - val_loss: 1.3381 - val_accuracy: 0.5234\n",
      "Epoch 196/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6551 - accuracy: 0.4313 - val_loss: 1.3387 - val_accuracy: 0.5234\n",
      "Epoch 197/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6461 - accuracy: 0.4363 - val_loss: 1.3393 - val_accuracy: 0.5234\n",
      "Epoch 198/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5898 - accuracy: 0.4599 - val_loss: 1.3368 - val_accuracy: 0.5234\n",
      "Epoch 199/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6360 - accuracy: 0.4403 - val_loss: 1.3356 - val_accuracy: 0.5234\n",
      "Epoch 200/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6451 - accuracy: 0.4375 - val_loss: 1.3365 - val_accuracy: 0.5234\n",
      "0.5233644843101501 {'loss': 1.6450891494750977, 'accuracy': 0.4375244677066803, 'val_loss': 1.3364527225494385, 'val_accuracy': 0.5233644843101501}\n",
      "Model: \"model_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_12 (InputLayer)        [(None, 29)]              0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 41)                1230      \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 10)                420       \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,870\n",
      "Trainable params: 1,870\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 3.1276 - accuracy: 0.0024 - val_loss: 2.9371 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.0797 - accuracy: 0.0012 - val_loss: 2.9001 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.0270 - accuracy: 0.0035 - val_loss: 2.8649 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.9818 - accuracy: 0.0024 - val_loss: 2.8319 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.9411 - accuracy: 0.0016 - val_loss: 2.8011 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.9092 - accuracy: 0.0016 - val_loss: 2.7716 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 2.8596 - accuracy: 3.9170e-04 - val_loss: 2.7440 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.8310 - accuracy: 0.0027 - val_loss: 2.7178 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.7981 - accuracy: 0.0024 - val_loss: 2.6931 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 2.7609 - accuracy: 0.0031 - val_loss: 2.6697 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.7379 - accuracy: 0.0035 - val_loss: 2.6476 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.7116 - accuracy: 0.0047 - val_loss: 2.6267 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.6842 - accuracy: 0.0071 - val_loss: 2.6071 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.6589 - accuracy: 0.0047 - val_loss: 2.5884 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.6392 - accuracy: 0.0067 - val_loss: 2.5705 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.6152 - accuracy: 0.0078 - val_loss: 2.5534 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5907 - accuracy: 0.0082 - val_loss: 2.5368 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.5833 - accuracy: 0.0082 - val_loss: 2.5211 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5576 - accuracy: 0.0071 - val_loss: 2.5059 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5305 - accuracy: 0.0145 - val_loss: 2.4914 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5292 - accuracy: 0.0125 - val_loss: 2.4779 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.5060 - accuracy: 0.0153 - val_loss: 2.4653 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4941 - accuracy: 0.0149 - val_loss: 2.4531 - val_accuracy: 0.0093\n",
      "Epoch 24/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4733 - accuracy: 0.0192 - val_loss: 2.4415 - val_accuracy: 0.0093\n",
      "Epoch 25/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.4706 - accuracy: 0.0200 - val_loss: 2.4311 - val_accuracy: 0.0187\n",
      "Epoch 26/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.4486 - accuracy: 0.0192 - val_loss: 2.4212 - val_accuracy: 0.0280\n",
      "Epoch 27/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.4362 - accuracy: 0.0255 - val_loss: 2.4115 - val_accuracy: 0.0280\n",
      "Epoch 28/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4217 - accuracy: 0.0337 - val_loss: 2.4024 - val_accuracy: 0.0280\n",
      "Epoch 29/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4111 - accuracy: 0.0321 - val_loss: 2.3934 - val_accuracy: 0.0467\n",
      "Epoch 30/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4049 - accuracy: 0.0341 - val_loss: 2.3849 - val_accuracy: 0.0374\n",
      "Epoch 31/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.3946 - accuracy: 0.0392 - val_loss: 2.3769 - val_accuracy: 0.0374\n",
      "Epoch 32/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.3899 - accuracy: 0.0454 - val_loss: 2.3690 - val_accuracy: 0.0374\n",
      "Epoch 33/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3759 - accuracy: 0.0431 - val_loss: 2.3612 - val_accuracy: 0.0374\n",
      "Epoch 34/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3770 - accuracy: 0.0415 - val_loss: 2.3545 - val_accuracy: 0.0374\n",
      "Epoch 35/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3630 - accuracy: 0.0513 - val_loss: 2.3475 - val_accuracy: 0.0374\n",
      "Epoch 36/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3551 - accuracy: 0.0537 - val_loss: 2.3411 - val_accuracy: 0.0374\n",
      "Epoch 37/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3563 - accuracy: 0.0591 - val_loss: 2.3345 - val_accuracy: 0.0467\n",
      "Epoch 38/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3387 - accuracy: 0.0529 - val_loss: 2.3273 - val_accuracy: 0.0467\n",
      "Epoch 39/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3370 - accuracy: 0.0635 - val_loss: 2.3208 - val_accuracy: 0.0467\n",
      "Epoch 40/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.3241 - accuracy: 0.0717 - val_loss: 2.3140 - val_accuracy: 0.0467\n",
      "Epoch 41/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3262 - accuracy: 0.0713 - val_loss: 2.3080 - val_accuracy: 0.0374\n",
      "Epoch 42/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3122 - accuracy: 0.0834 - val_loss: 2.3025 - val_accuracy: 0.0374\n",
      "Epoch 43/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3062 - accuracy: 0.0815 - val_loss: 2.2969 - val_accuracy: 0.0467\n",
      "Epoch 44/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3076 - accuracy: 0.0932 - val_loss: 2.2920 - val_accuracy: 0.0467\n",
      "Epoch 45/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3033 - accuracy: 0.0928 - val_loss: 2.2872 - val_accuracy: 0.0561\n",
      "Epoch 46/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2969 - accuracy: 0.1046 - val_loss: 2.2827 - val_accuracy: 0.0561\n",
      "Epoch 47/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2887 - accuracy: 0.1101 - val_loss: 2.2780 - val_accuracy: 0.0654\n",
      "Epoch 48/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2893 - accuracy: 0.1167 - val_loss: 2.2737 - val_accuracy: 0.0748\n",
      "Epoch 49/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2781 - accuracy: 0.1261 - val_loss: 2.2698 - val_accuracy: 0.0935\n",
      "Epoch 50/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2737 - accuracy: 0.1316 - val_loss: 2.2657 - val_accuracy: 0.0935\n",
      "Epoch 51/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2735 - accuracy: 0.1383 - val_loss: 2.2618 - val_accuracy: 0.1028\n",
      "Epoch 52/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2739 - accuracy: 0.1332 - val_loss: 2.2582 - val_accuracy: 0.1028\n",
      "Epoch 53/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.2734 - accuracy: 0.1547 - val_loss: 2.2548 - val_accuracy: 0.1028\n",
      "Epoch 54/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2739 - accuracy: 0.1441 - val_loss: 2.2514 - val_accuracy: 0.1121\n",
      "Epoch 55/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.2570 - accuracy: 0.1551 - val_loss: 2.2480 - val_accuracy: 0.1121\n",
      "Epoch 56/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.2545 - accuracy: 0.1684 - val_loss: 2.2444 - val_accuracy: 0.1402\n",
      "Epoch 57/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2498 - accuracy: 0.1829 - val_loss: 2.2408 - val_accuracy: 0.1495\n",
      "Epoch 58/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2520 - accuracy: 0.1735 - val_loss: 2.2375 - val_accuracy: 0.1682\n",
      "Epoch 59/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.2403 - accuracy: 0.2025 - val_loss: 2.2340 - val_accuracy: 0.1776\n",
      "Epoch 60/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.2457 - accuracy: 0.2060 - val_loss: 2.2301 - val_accuracy: 0.1963\n",
      "Epoch 61/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.2398 - accuracy: 0.2150 - val_loss: 2.2267 - val_accuracy: 0.2150\n",
      "Epoch 62/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.2282 - accuracy: 0.2241 - val_loss: 2.2232 - val_accuracy: 0.2523\n",
      "Epoch 63/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2387 - accuracy: 0.2221 - val_loss: 2.2199 - val_accuracy: 0.2617\n",
      "Epoch 64/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2276 - accuracy: 0.2472 - val_loss: 2.2161 - val_accuracy: 0.2523\n",
      "Epoch 65/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.2215 - accuracy: 0.2570 - val_loss: 2.2119 - val_accuracy: 0.2523\n",
      "Epoch 66/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 2.2198 - accuracy: 0.2448 - val_loss: 2.2078 - val_accuracy: 0.2710\n",
      "Epoch 67/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.2235 - accuracy: 0.2628 - val_loss: 2.2037 - val_accuracy: 0.2804\n",
      "Epoch 68/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2133 - accuracy: 0.2816 - val_loss: 2.1995 - val_accuracy: 0.2897\n",
      "Epoch 69/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.2145 - accuracy: 0.2738 - val_loss: 2.1952 - val_accuracy: 0.3084\n",
      "Epoch 70/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.2059 - accuracy: 0.2785 - val_loss: 2.1909 - val_accuracy: 0.3178\n",
      "Epoch 71/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.2037 - accuracy: 0.2930 - val_loss: 2.1867 - val_accuracy: 0.3271\n",
      "Epoch 72/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.1998 - accuracy: 0.3090 - val_loss: 2.1822 - val_accuracy: 0.3364\n",
      "Epoch 73/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.1959 - accuracy: 0.3055 - val_loss: 2.1776 - val_accuracy: 0.3458\n",
      "Epoch 74/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 3ms/step - loss: 2.1910 - accuracy: 0.3208 - val_loss: 2.1729 - val_accuracy: 0.3645\n",
      "Epoch 75/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.1942 - accuracy: 0.3149 - val_loss: 2.1684 - val_accuracy: 0.3738\n",
      "Epoch 76/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.1854 - accuracy: 0.3235 - val_loss: 2.1638 - val_accuracy: 0.3832\n",
      "Epoch 77/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.1781 - accuracy: 0.3200 - val_loss: 2.1590 - val_accuracy: 0.3832\n",
      "Epoch 78/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1767 - accuracy: 0.3247 - val_loss: 2.1540 - val_accuracy: 0.4019\n",
      "Epoch 79/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1607 - accuracy: 0.3337 - val_loss: 2.1486 - val_accuracy: 0.4019\n",
      "Epoch 80/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.1734 - accuracy: 0.3298 - val_loss: 2.1438 - val_accuracy: 0.4019\n",
      "Epoch 81/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1547 - accuracy: 0.3494 - val_loss: 2.1385 - val_accuracy: 0.3925\n",
      "Epoch 82/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.1665 - accuracy: 0.3369 - val_loss: 2.1336 - val_accuracy: 0.4019\n",
      "Epoch 83/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.1515 - accuracy: 0.3447 - val_loss: 2.1281 - val_accuracy: 0.4019\n",
      "Epoch 84/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1599 - accuracy: 0.3439 - val_loss: 2.1235 - val_accuracy: 0.4019\n",
      "Epoch 85/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1404 - accuracy: 0.3557 - val_loss: 2.1181 - val_accuracy: 0.4112\n",
      "Epoch 86/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1442 - accuracy: 0.3494 - val_loss: 2.1128 - val_accuracy: 0.4206\n",
      "Epoch 87/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1501 - accuracy: 0.3416 - val_loss: 2.1076 - val_accuracy: 0.4206\n",
      "Epoch 88/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1500 - accuracy: 0.3380 - val_loss: 2.1027 - val_accuracy: 0.4299\n",
      "Epoch 89/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1390 - accuracy: 0.3482 - val_loss: 2.0976 - val_accuracy: 0.4486\n",
      "Epoch 90/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.1213 - accuracy: 0.3647 - val_loss: 2.0919 - val_accuracy: 0.4486\n",
      "Epoch 91/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1323 - accuracy: 0.3459 - val_loss: 2.0866 - val_accuracy: 0.4579\n",
      "Epoch 92/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1140 - accuracy: 0.3584 - val_loss: 2.0808 - val_accuracy: 0.4579\n",
      "Epoch 93/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1296 - accuracy: 0.3443 - val_loss: 2.0758 - val_accuracy: 0.4579\n",
      "Epoch 94/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1155 - accuracy: 0.3510 - val_loss: 2.0707 - val_accuracy: 0.4673\n",
      "Epoch 95/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1219 - accuracy: 0.3510 - val_loss: 2.0659 - val_accuracy: 0.4673\n",
      "Epoch 96/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1197 - accuracy: 0.3514 - val_loss: 2.0609 - val_accuracy: 0.4673\n",
      "Epoch 97/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1109 - accuracy: 0.3564 - val_loss: 2.0558 - val_accuracy: 0.4673\n",
      "Epoch 98/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1116 - accuracy: 0.3517 - val_loss: 2.0512 - val_accuracy: 0.4673\n",
      "Epoch 99/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0805 - accuracy: 0.3666 - val_loss: 2.0457 - val_accuracy: 0.4673\n",
      "Epoch 100/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1090 - accuracy: 0.3478 - val_loss: 2.0410 - val_accuracy: 0.4673\n",
      "Epoch 101/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0837 - accuracy: 0.3721 - val_loss: 2.0357 - val_accuracy: 0.4673\n",
      "Epoch 102/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1005 - accuracy: 0.3592 - val_loss: 2.0314 - val_accuracy: 0.4673\n",
      "Epoch 103/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0869 - accuracy: 0.3580 - val_loss: 2.0270 - val_accuracy: 0.4673\n",
      "Epoch 104/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0972 - accuracy: 0.3623 - val_loss: 2.0231 - val_accuracy: 0.4673\n",
      "Epoch 105/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0738 - accuracy: 0.3643 - val_loss: 2.0183 - val_accuracy: 0.4673\n",
      "Epoch 106/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0842 - accuracy: 0.3533 - val_loss: 2.0141 - val_accuracy: 0.4673\n",
      "Epoch 107/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0760 - accuracy: 0.3631 - val_loss: 2.0098 - val_accuracy: 0.4673\n",
      "Epoch 108/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0642 - accuracy: 0.3670 - val_loss: 2.0049 - val_accuracy: 0.4673\n",
      "Epoch 109/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0631 - accuracy: 0.3717 - val_loss: 2.0006 - val_accuracy: 0.4673\n",
      "Epoch 110/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0620 - accuracy: 0.3611 - val_loss: 1.9962 - val_accuracy: 0.4673\n",
      "Epoch 111/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0598 - accuracy: 0.3694 - val_loss: 1.9922 - val_accuracy: 0.4673\n",
      "Epoch 112/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0699 - accuracy: 0.3619 - val_loss: 1.9888 - val_accuracy: 0.4673\n",
      "Epoch 113/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0481 - accuracy: 0.3752 - val_loss: 1.9839 - val_accuracy: 0.4673\n",
      "Epoch 114/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0494 - accuracy: 0.3741 - val_loss: 1.9799 - val_accuracy: 0.4673\n",
      "Epoch 115/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0474 - accuracy: 0.3694 - val_loss: 1.9760 - val_accuracy: 0.4673\n",
      "Epoch 116/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0566 - accuracy: 0.3678 - val_loss: 1.9723 - val_accuracy: 0.4673\n",
      "Epoch 117/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0479 - accuracy: 0.3698 - val_loss: 1.9681 - val_accuracy: 0.4673\n",
      "Epoch 118/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0335 - accuracy: 0.3709 - val_loss: 1.9640 - val_accuracy: 0.4673\n",
      "Epoch 119/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.0621 - accuracy: 0.3564 - val_loss: 1.9605 - val_accuracy: 0.4673\n",
      "Epoch 120/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0317 - accuracy: 0.3772 - val_loss: 1.9567 - val_accuracy: 0.4766\n",
      "Epoch 121/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0203 - accuracy: 0.3831 - val_loss: 1.9523 - val_accuracy: 0.4766\n",
      "Epoch 122/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0362 - accuracy: 0.3764 - val_loss: 1.9489 - val_accuracy: 0.4766\n",
      "Epoch 123/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0331 - accuracy: 0.3694 - val_loss: 1.9454 - val_accuracy: 0.4766\n",
      "Epoch 124/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0279 - accuracy: 0.3741 - val_loss: 1.9416 - val_accuracy: 0.4766\n",
      "Epoch 125/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0223 - accuracy: 0.3819 - val_loss: 1.9379 - val_accuracy: 0.4766\n",
      "Epoch 126/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0255 - accuracy: 0.3717 - val_loss: 1.9347 - val_accuracy: 0.4766\n",
      "Epoch 127/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0482 - accuracy: 0.3561 - val_loss: 1.9324 - val_accuracy: 0.4766\n",
      "Epoch 128/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0098 - accuracy: 0.3890 - val_loss: 1.9289 - val_accuracy: 0.4766\n",
      "Epoch 129/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0045 - accuracy: 0.3799 - val_loss: 1.9255 - val_accuracy: 0.4766\n",
      "Epoch 130/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0065 - accuracy: 0.3819 - val_loss: 1.9219 - val_accuracy: 0.4766\n",
      "Epoch 131/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9993 - accuracy: 0.3835 - val_loss: 1.9183 - val_accuracy: 0.4766\n",
      "Epoch 132/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9943 - accuracy: 0.3886 - val_loss: 1.9148 - val_accuracy: 0.4766\n",
      "Epoch 133/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9996 - accuracy: 0.3858 - val_loss: 1.9116 - val_accuracy: 0.4766\n",
      "Epoch 134/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.0151 - accuracy: 0.3725 - val_loss: 1.9085 - val_accuracy: 0.4766\n",
      "Epoch 135/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0024 - accuracy: 0.3752 - val_loss: 1.9060 - val_accuracy: 0.4766\n",
      "Epoch 136/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0028 - accuracy: 0.3796 - val_loss: 1.9032 - val_accuracy: 0.4766\n",
      "Epoch 137/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9949 - accuracy: 0.3850 - val_loss: 1.9006 - val_accuracy: 0.4766\n",
      "Epoch 138/200\n",
      "80/80 [==============================] - ETA: 0s - loss: 1.9982 - accuracy: 0.38 - 0s 2ms/step - loss: 1.9939 - accuracy: 0.3835 - val_loss: 1.8977 - val_accuracy: 0.4766\n",
      "Epoch 139/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.9955 - accuracy: 0.3803 - val_loss: 1.8954 - val_accuracy: 0.4766\n",
      "Epoch 140/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.9871 - accuracy: 0.3835 - val_loss: 1.8925 - val_accuracy: 0.4766\n",
      "Epoch 141/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0030 - accuracy: 0.3819 - val_loss: 1.8907 - val_accuracy: 0.4766\n",
      "Epoch 142/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9899 - accuracy: 0.3776 - val_loss: 1.8880 - val_accuracy: 0.4766\n",
      "Epoch 143/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9869 - accuracy: 0.3846 - val_loss: 1.8855 - val_accuracy: 0.4766\n",
      "Epoch 144/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9991 - accuracy: 0.3733 - val_loss: 1.8836 - val_accuracy: 0.4766\n",
      "Epoch 145/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9867 - accuracy: 0.3835 - val_loss: 1.8815 - val_accuracy: 0.4766\n",
      "Epoch 146/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9743 - accuracy: 0.3893 - val_loss: 1.8785 - val_accuracy: 0.4766\n",
      "Epoch 147/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9717 - accuracy: 0.3835 - val_loss: 1.8762 - val_accuracy: 0.4766\n",
      "Epoch 148/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9894 - accuracy: 0.3741 - val_loss: 1.8744 - val_accuracy: 0.4766\n",
      "Epoch 149/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0057 - accuracy: 0.3749 - val_loss: 1.8732 - val_accuracy: 0.4766\n",
      "Epoch 150/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9738 - accuracy: 0.3886 - val_loss: 1.8711 - val_accuracy: 0.4766\n",
      "Epoch 151/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9859 - accuracy: 0.3772 - val_loss: 1.8691 - val_accuracy: 0.4766\n",
      "Epoch 152/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9937 - accuracy: 0.3686 - val_loss: 1.8676 - val_accuracy: 0.4766\n",
      "Epoch 153/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9904 - accuracy: 0.3698 - val_loss: 1.8665 - val_accuracy: 0.4766\n",
      "Epoch 154/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9615 - accuracy: 0.3823 - val_loss: 1.8638 - val_accuracy: 0.4766\n",
      "Epoch 155/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9756 - accuracy: 0.3846 - val_loss: 1.8619 - val_accuracy: 0.4766\n",
      "Epoch 156/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9573 - accuracy: 0.3870 - val_loss: 1.8594 - val_accuracy: 0.4766\n",
      "Epoch 157/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9853 - accuracy: 0.3764 - val_loss: 1.8580 - val_accuracy: 0.4766\n",
      "Epoch 158/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9805 - accuracy: 0.3756 - val_loss: 1.8569 - val_accuracy: 0.4766\n",
      "Epoch 159/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9635 - accuracy: 0.3882 - val_loss: 1.8550 - val_accuracy: 0.4766\n",
      "Epoch 160/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9714 - accuracy: 0.3741 - val_loss: 1.8537 - val_accuracy: 0.4766\n",
      "Epoch 161/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.9691 - accuracy: 0.3819 - val_loss: 1.8521 - val_accuracy: 0.4766\n",
      "Epoch 162/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9621 - accuracy: 0.3909 - val_loss: 1.8502 - val_accuracy: 0.4766\n",
      "Epoch 163/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9460 - accuracy: 0.3940 - val_loss: 1.8482 - val_accuracy: 0.4766\n",
      "Epoch 164/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9682 - accuracy: 0.3776 - val_loss: 1.8466 - val_accuracy: 0.4766\n",
      "Epoch 165/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9661 - accuracy: 0.3796 - val_loss: 1.8449 - val_accuracy: 0.4766\n",
      "Epoch 166/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9635 - accuracy: 0.3807 - val_loss: 1.8428 - val_accuracy: 0.4766\n",
      "Epoch 167/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.9686 - accuracy: 0.3690 - val_loss: 1.8420 - val_accuracy: 0.4766\n",
      "Epoch 168/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9362 - accuracy: 0.3972 - val_loss: 1.8398 - val_accuracy: 0.4766\n",
      "Epoch 169/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9750 - accuracy: 0.3655 - val_loss: 1.8390 - val_accuracy: 0.4766\n",
      "Epoch 170/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9589 - accuracy: 0.3737 - val_loss: 1.8380 - val_accuracy: 0.4766\n",
      "Epoch 171/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9440 - accuracy: 0.3890 - val_loss: 1.8363 - val_accuracy: 0.4766\n",
      "Epoch 172/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.9441 - accuracy: 0.3850 - val_loss: 1.8342 - val_accuracy: 0.4766\n",
      "Epoch 173/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.9542 - accuracy: 0.3846 - val_loss: 1.8331 - val_accuracy: 0.4766\n",
      "Epoch 174/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9493 - accuracy: 0.3886 - val_loss: 1.8313 - val_accuracy: 0.4766\n",
      "Epoch 175/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9676 - accuracy: 0.3745 - val_loss: 1.8313 - val_accuracy: 0.4766\n",
      "Epoch 176/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9548 - accuracy: 0.3835 - val_loss: 1.8303 - val_accuracy: 0.4766\n",
      "Epoch 177/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9555 - accuracy: 0.3780 - val_loss: 1.8293 - val_accuracy: 0.4766\n",
      "Epoch 178/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9331 - accuracy: 0.3905 - val_loss: 1.8275 - val_accuracy: 0.4766\n",
      "Epoch 179/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9487 - accuracy: 0.3784 - val_loss: 1.8263 - val_accuracy: 0.4766\n",
      "Epoch 180/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.9383 - accuracy: 0.3850 - val_loss: 1.8250 - val_accuracy: 0.4766\n",
      "Epoch 181/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9414 - accuracy: 0.3878 - val_loss: 1.8231 - val_accuracy: 0.4766\n",
      "Epoch 182/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9515 - accuracy: 0.3807 - val_loss: 1.8223 - val_accuracy: 0.4766\n",
      "Epoch 183/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9566 - accuracy: 0.3792 - val_loss: 1.8224 - val_accuracy: 0.4766\n",
      "Epoch 184/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9365 - accuracy: 0.3760 - val_loss: 1.8211 - val_accuracy: 0.4766\n",
      "Epoch 185/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9610 - accuracy: 0.3749 - val_loss: 1.8204 - val_accuracy: 0.4766\n",
      "Epoch 186/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.9565 - accuracy: 0.3733 - val_loss: 1.8196 - val_accuracy: 0.4766\n",
      "Epoch 187/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.9538 - accuracy: 0.3796 - val_loss: 1.8191 - val_accuracy: 0.4766\n",
      "Epoch 188/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9453 - accuracy: 0.3784 - val_loss: 1.8181 - val_accuracy: 0.4766\n",
      "Epoch 189/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9562 - accuracy: 0.3815 - val_loss: 1.8176 - val_accuracy: 0.4766\n",
      "Epoch 190/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9742 - accuracy: 0.3619 - val_loss: 1.8174 - val_accuracy: 0.4766\n",
      "Epoch 191/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9307 - accuracy: 0.3846 - val_loss: 1.8162 - val_accuracy: 0.4766\n",
      "Epoch 192/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.9385 - accuracy: 0.3792 - val_loss: 1.8149 - val_accuracy: 0.4766\n",
      "Epoch 193/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9329 - accuracy: 0.3780 - val_loss: 1.8129 - val_accuracy: 0.4766\n",
      "Epoch 194/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9725 - accuracy: 0.3619 - val_loss: 1.8132 - val_accuracy: 0.4766\n",
      "Epoch 195/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9466 - accuracy: 0.3745 - val_loss: 1.8122 - val_accuracy: 0.4766\n",
      "Epoch 196/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9392 - accuracy: 0.3799 - val_loss: 1.8104 - val_accuracy: 0.4766\n",
      "Epoch 197/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9289 - accuracy: 0.3831 - val_loss: 1.8087 - val_accuracy: 0.4766\n",
      "Epoch 198/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.9495 - accuracy: 0.3705 - val_loss: 1.8085 - val_accuracy: 0.4766\n",
      "Epoch 199/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.9312 - accuracy: 0.3788 - val_loss: 1.8070 - val_accuracy: 0.4766\n",
      "Epoch 200/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9460 - accuracy: 0.3725 - val_loss: 1.8062 - val_accuracy: 0.4766\n",
      "0.47663551568984985 {'loss': 1.9460257291793823, 'accuracy': 0.3725029230117798, 'val_loss': 1.8061615228652954, 'val_accuracy': 0.47663551568984985}\n",
      "Model: \"model_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_13 (InputLayer)        [(None, 29)]              0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 41)                1230      \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 10)                420       \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,870\n",
      "Trainable params: 1,870\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 2.3720 - accuracy: 0.0917 - val_loss: 2.3449 - val_accuracy: 0.0935\n",
      "Epoch 2/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3516 - accuracy: 0.1077 - val_loss: 2.3353 - val_accuracy: 0.1215\n",
      "Epoch 3/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3419 - accuracy: 0.1159 - val_loss: 2.3274 - val_accuracy: 0.1589\n",
      "Epoch 4/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3288 - accuracy: 0.1387 - val_loss: 2.3199 - val_accuracy: 0.1963\n",
      "Epoch 5/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3263 - accuracy: 0.1465 - val_loss: 2.3134 - val_accuracy: 0.2336\n",
      "Epoch 6/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3199 - accuracy: 0.1422 - val_loss: 2.3073 - val_accuracy: 0.2710\n",
      "Epoch 7/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3080 - accuracy: 0.1594 - val_loss: 2.3016 - val_accuracy: 0.2710\n",
      "Epoch 8/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3074 - accuracy: 0.1653 - val_loss: 2.2956 - val_accuracy: 0.3084\n",
      "Epoch 9/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3023 - accuracy: 0.1782 - val_loss: 2.2894 - val_accuracy: 0.3178\n",
      "Epoch 10/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2895 - accuracy: 0.1923 - val_loss: 2.2823 - val_accuracy: 0.3271\n",
      "Epoch 11/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2886 - accuracy: 0.1900 - val_loss: 2.2756 - val_accuracy: 0.3364\n",
      "Epoch 12/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2856 - accuracy: 0.2080 - val_loss: 2.2688 - val_accuracy: 0.3551\n",
      "Epoch 13/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2787 - accuracy: 0.2107 - val_loss: 2.2624 - val_accuracy: 0.3645\n",
      "Epoch 14/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2871 - accuracy: 0.1943 - val_loss: 2.2575 - val_accuracy: 0.3738\n",
      "Epoch 15/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2792 - accuracy: 0.2013 - val_loss: 2.2525 - val_accuracy: 0.3832\n",
      "Epoch 16/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2679 - accuracy: 0.2190 - val_loss: 2.2469 - val_accuracy: 0.3925\n",
      "Epoch 17/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2774 - accuracy: 0.2029 - val_loss: 2.2416 - val_accuracy: 0.4019\n",
      "Epoch 18/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2706 - accuracy: 0.2096 - val_loss: 2.2361 - val_accuracy: 0.4112\n",
      "Epoch 19/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2693 - accuracy: 0.2186 - val_loss: 2.2316 - val_accuracy: 0.4112\n",
      "Epoch 20/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2597 - accuracy: 0.2248 - val_loss: 2.2266 - val_accuracy: 0.4299\n",
      "Epoch 21/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2651 - accuracy: 0.2178 - val_loss: 2.2223 - val_accuracy: 0.4299\n",
      "Epoch 22/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2574 - accuracy: 0.2244 - val_loss: 2.2174 - val_accuracy: 0.4299\n",
      "Epoch 23/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2577 - accuracy: 0.2143 - val_loss: 2.2131 - val_accuracy: 0.4299\n",
      "Epoch 24/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2560 - accuracy: 0.2268 - val_loss: 2.2094 - val_accuracy: 0.4299\n",
      "Epoch 25/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2354 - accuracy: 0.2523 - val_loss: 2.2042 - val_accuracy: 0.4299\n",
      "Epoch 26/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2405 - accuracy: 0.2350 - val_loss: 2.1997 - val_accuracy: 0.4393\n",
      "Epoch 27/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2478 - accuracy: 0.2217 - val_loss: 2.1951 - val_accuracy: 0.4393\n",
      "Epoch 28/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2341 - accuracy: 0.2483 - val_loss: 2.1901 - val_accuracy: 0.4393\n",
      "Epoch 29/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2349 - accuracy: 0.2413 - val_loss: 2.1862 - val_accuracy: 0.4393\n",
      "Epoch 30/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2425 - accuracy: 0.2389 - val_loss: 2.1825 - val_accuracy: 0.4393\n",
      "Epoch 31/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2181 - accuracy: 0.2554 - val_loss: 2.1778 - val_accuracy: 0.4486\n",
      "Epoch 32/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2272 - accuracy: 0.2401 - val_loss: 2.1733 - val_accuracy: 0.4486\n",
      "Epoch 33/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 2.2243 - accuracy: 0.2562 - val_loss: 2.1692 - val_accuracy: 0.4486\n",
      "Epoch 34/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2266 - accuracy: 0.2464 - val_loss: 2.1654 - val_accuracy: 0.4579\n",
      "Epoch 35/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2213 - accuracy: 0.2503 - val_loss: 2.1620 - val_accuracy: 0.4579\n",
      "Epoch 36/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2280 - accuracy: 0.2382 - val_loss: 2.1587 - val_accuracy: 0.4579\n",
      "Epoch 37/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1932 - accuracy: 0.2683 - val_loss: 2.1535 - val_accuracy: 0.4673\n",
      "Epoch 38/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2197 - accuracy: 0.2456 - val_loss: 2.1496 - val_accuracy: 0.4673\n",
      "Epoch 39/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1984 - accuracy: 0.2605 - val_loss: 2.1452 - val_accuracy: 0.4673\n",
      "Epoch 40/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2004 - accuracy: 0.2519 - val_loss: 2.1411 - val_accuracy: 0.4673\n",
      "Epoch 41/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1949 - accuracy: 0.2628 - val_loss: 2.1369 - val_accuracy: 0.4673\n",
      "Epoch 42/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1866 - accuracy: 0.2664 - val_loss: 2.1324 - val_accuracy: 0.4673\n",
      "Epoch 43/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1887 - accuracy: 0.2793 - val_loss: 2.1285 - val_accuracy: 0.4673\n",
      "Epoch 44/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1941 - accuracy: 0.2620 - val_loss: 2.1250 - val_accuracy: 0.4673\n",
      "Epoch 45/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1935 - accuracy: 0.2640 - val_loss: 2.1223 - val_accuracy: 0.4673\n",
      "Epoch 46/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1794 - accuracy: 0.2730 - val_loss: 2.1178 - val_accuracy: 0.4766\n",
      "Epoch 47/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1899 - accuracy: 0.2671 - val_loss: 2.1147 - val_accuracy: 0.4766\n",
      "Epoch 48/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1872 - accuracy: 0.2675 - val_loss: 2.1113 - val_accuracy: 0.4766\n",
      "Epoch 49/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1732 - accuracy: 0.2738 - val_loss: 2.1078 - val_accuracy: 0.4766\n",
      "Epoch 50/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1750 - accuracy: 0.2722 - val_loss: 2.1040 - val_accuracy: 0.4766\n",
      "Epoch 51/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1735 - accuracy: 0.2754 - val_loss: 2.1009 - val_accuracy: 0.4766\n",
      "Epoch 52/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1670 - accuracy: 0.2761 - val_loss: 2.0975 - val_accuracy: 0.4766\n",
      "Epoch 53/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1759 - accuracy: 0.2769 - val_loss: 2.0952 - val_accuracy: 0.4766\n",
      "Epoch 54/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1603 - accuracy: 0.2938 - val_loss: 2.0917 - val_accuracy: 0.4766\n",
      "Epoch 55/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 2.1674 - accuracy: 0.2816 - val_loss: 2.0894 - val_accuracy: 0.4766\n",
      "Epoch 56/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1657 - accuracy: 0.2816 - val_loss: 2.0863 - val_accuracy: 0.4766\n",
      "Epoch 57/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1711 - accuracy: 0.2820 - val_loss: 2.0842 - val_accuracy: 0.4766\n",
      "Epoch 58/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1533 - accuracy: 0.3016 - val_loss: 2.0810 - val_accuracy: 0.4766\n",
      "Epoch 59/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1490 - accuracy: 0.2949 - val_loss: 2.0782 - val_accuracy: 0.4766\n",
      "Epoch 60/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1708 - accuracy: 0.2793 - val_loss: 2.0763 - val_accuracy: 0.4766\n",
      "Epoch 61/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1432 - accuracy: 0.2946 - val_loss: 2.0731 - val_accuracy: 0.4766\n",
      "Epoch 62/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1386 - accuracy: 0.3012 - val_loss: 2.0700 - val_accuracy: 0.4766\n",
      "Epoch 63/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1425 - accuracy: 0.3020 - val_loss: 2.0668 - val_accuracy: 0.4766\n",
      "Epoch 64/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1480 - accuracy: 0.2996 - val_loss: 2.0641 - val_accuracy: 0.4766\n",
      "Epoch 65/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1448 - accuracy: 0.2961 - val_loss: 2.0618 - val_accuracy: 0.4766\n",
      "Epoch 66/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1674 - accuracy: 0.2781 - val_loss: 2.0605 - val_accuracy: 0.4766\n",
      "Epoch 67/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1556 - accuracy: 0.2930 - val_loss: 2.0586 - val_accuracy: 0.4766\n",
      "Epoch 68/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1578 - accuracy: 0.2930 - val_loss: 2.0572 - val_accuracy: 0.4766\n",
      "Epoch 69/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1523 - accuracy: 0.3043 - val_loss: 2.0553 - val_accuracy: 0.4766\n",
      "Epoch 70/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1278 - accuracy: 0.3106 - val_loss: 2.0519 - val_accuracy: 0.4766\n",
      "Epoch 71/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1349 - accuracy: 0.3020 - val_loss: 2.0496 - val_accuracy: 0.4766\n",
      "Epoch 72/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1418 - accuracy: 0.3106 - val_loss: 2.0472 - val_accuracy: 0.4766\n",
      "Epoch 73/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1417 - accuracy: 0.3063 - val_loss: 2.0447 - val_accuracy: 0.4766\n",
      "Epoch 74/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1331 - accuracy: 0.3137 - val_loss: 2.0424 - val_accuracy: 0.4766\n",
      "Epoch 75/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1374 - accuracy: 0.3036 - val_loss: 2.0406 - val_accuracy: 0.4766\n",
      "Epoch 76/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1239 - accuracy: 0.3220 - val_loss: 2.0377 - val_accuracy: 0.4766\n",
      "Epoch 77/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1351 - accuracy: 0.3110 - val_loss: 2.0358 - val_accuracy: 0.4766\n",
      "Epoch 78/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1218 - accuracy: 0.3181 - val_loss: 2.0336 - val_accuracy: 0.4766\n",
      "Epoch 79/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1342 - accuracy: 0.3118 - val_loss: 2.0318 - val_accuracy: 0.4766\n",
      "Epoch 80/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1286 - accuracy: 0.3114 - val_loss: 2.0299 - val_accuracy: 0.4766\n",
      "Epoch 81/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1346 - accuracy: 0.3157 - val_loss: 2.0281 - val_accuracy: 0.4766\n",
      "Epoch 82/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1299 - accuracy: 0.3165 - val_loss: 2.0260 - val_accuracy: 0.4766\n",
      "Epoch 83/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1359 - accuracy: 0.3169 - val_loss: 2.0245 - val_accuracy: 0.4766\n",
      "Epoch 84/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1118 - accuracy: 0.3333 - val_loss: 2.0220 - val_accuracy: 0.4766\n",
      "Epoch 85/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1169 - accuracy: 0.3282 - val_loss: 2.0198 - val_accuracy: 0.4766\n",
      "Epoch 86/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1208 - accuracy: 0.3243 - val_loss: 2.0173 - val_accuracy: 0.4766\n",
      "Epoch 87/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1214 - accuracy: 0.3141 - val_loss: 2.0155 - val_accuracy: 0.4766\n",
      "Epoch 88/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1274 - accuracy: 0.3184 - val_loss: 2.0137 - val_accuracy: 0.4766\n",
      "Epoch 89/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1237 - accuracy: 0.3275 - val_loss: 2.0120 - val_accuracy: 0.4766\n",
      "Epoch 90/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1271 - accuracy: 0.3177 - val_loss: 2.0101 - val_accuracy: 0.4766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1129 - accuracy: 0.3255 - val_loss: 2.0081 - val_accuracy: 0.4766\n",
      "Epoch 92/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0910 - accuracy: 0.3549 - val_loss: 2.0046 - val_accuracy: 0.4766\n",
      "Epoch 93/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1233 - accuracy: 0.3255 - val_loss: 2.0030 - val_accuracy: 0.4766\n",
      "Epoch 94/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0987 - accuracy: 0.3380 - val_loss: 2.0007 - val_accuracy: 0.4766\n",
      "Epoch 95/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1184 - accuracy: 0.3306 - val_loss: 1.9992 - val_accuracy: 0.4766\n",
      "Epoch 96/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1172 - accuracy: 0.3231 - val_loss: 1.9972 - val_accuracy: 0.4766\n",
      "Epoch 97/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1075 - accuracy: 0.3325 - val_loss: 1.9949 - val_accuracy: 0.4766\n",
      "Epoch 98/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1087 - accuracy: 0.3325 - val_loss: 1.9929 - val_accuracy: 0.4766\n",
      "Epoch 99/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 2.1036 - accuracy: 0.3365 - val_loss: 1.9907 - val_accuracy: 0.4766\n",
      "Epoch 100/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1009 - accuracy: 0.3369 - val_loss: 1.9892 - val_accuracy: 0.4766\n",
      "Epoch 101/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1037 - accuracy: 0.3396 - val_loss: 1.9876 - val_accuracy: 0.4766\n",
      "Epoch 102/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1052 - accuracy: 0.3365 - val_loss: 1.9850 - val_accuracy: 0.4766\n",
      "Epoch 103/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 2.0934 - accuracy: 0.3443 - val_loss: 1.9832 - val_accuracy: 0.4766\n",
      "Epoch 104/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0892 - accuracy: 0.3416 - val_loss: 1.9805 - val_accuracy: 0.4766\n",
      "Epoch 105/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0904 - accuracy: 0.3439 - val_loss: 1.9783 - val_accuracy: 0.4766\n",
      "Epoch 106/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0954 - accuracy: 0.3416 - val_loss: 1.9765 - val_accuracy: 0.4766\n",
      "Epoch 107/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0930 - accuracy: 0.3423 - val_loss: 1.9743 - val_accuracy: 0.4766\n",
      "Epoch 108/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0850 - accuracy: 0.3517 - val_loss: 1.9717 - val_accuracy: 0.4766\n",
      "Epoch 109/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1157 - accuracy: 0.3337 - val_loss: 1.9713 - val_accuracy: 0.4766\n",
      "Epoch 110/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0958 - accuracy: 0.3412 - val_loss: 1.9694 - val_accuracy: 0.4766\n",
      "Epoch 111/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0840 - accuracy: 0.3506 - val_loss: 1.9666 - val_accuracy: 0.4766\n",
      "Epoch 112/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0886 - accuracy: 0.3447 - val_loss: 1.9634 - val_accuracy: 0.4766\n",
      "Epoch 113/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1008 - accuracy: 0.3416 - val_loss: 1.9624 - val_accuracy: 0.4766\n",
      "Epoch 114/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0815 - accuracy: 0.3482 - val_loss: 1.9607 - val_accuracy: 0.4766\n",
      "Epoch 115/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0709 - accuracy: 0.3580 - val_loss: 1.9581 - val_accuracy: 0.4766\n",
      "Epoch 116/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0952 - accuracy: 0.3345 - val_loss: 1.9573 - val_accuracy: 0.4766\n",
      "Epoch 117/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0847 - accuracy: 0.3463 - val_loss: 1.9553 - val_accuracy: 0.4766\n",
      "Epoch 118/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 2.0881 - accuracy: 0.3380 - val_loss: 1.9539 - val_accuracy: 0.4766\n",
      "Epoch 119/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0894 - accuracy: 0.3467 - val_loss: 1.9525 - val_accuracy: 0.4766\n",
      "Epoch 120/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1019 - accuracy: 0.3392 - val_loss: 1.9517 - val_accuracy: 0.4766\n",
      "Epoch 121/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0757 - accuracy: 0.3561 - val_loss: 1.9497 - val_accuracy: 0.4766\n",
      "Epoch 122/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0919 - accuracy: 0.3467 - val_loss: 1.9484 - val_accuracy: 0.4766\n",
      "Epoch 123/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0721 - accuracy: 0.3514 - val_loss: 1.9475 - val_accuracy: 0.4766\n",
      "Epoch 124/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0764 - accuracy: 0.3549 - val_loss: 1.9460 - val_accuracy: 0.4766\n",
      "Epoch 125/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0863 - accuracy: 0.3514 - val_loss: 1.9443 - val_accuracy: 0.4766\n",
      "Epoch 126/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0935 - accuracy: 0.3423 - val_loss: 1.9434 - val_accuracy: 0.4766\n",
      "Epoch 127/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 2.0771 - accuracy: 0.3588 - val_loss: 1.9423 - val_accuracy: 0.4766\n",
      "Epoch 128/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1052 - accuracy: 0.3357 - val_loss: 1.9423 - val_accuracy: 0.4766\n",
      "Epoch 129/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0612 - accuracy: 0.3666 - val_loss: 1.9394 - val_accuracy: 0.4766\n",
      "Epoch 130/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0816 - accuracy: 0.3604 - val_loss: 1.9386 - val_accuracy: 0.4766\n",
      "Epoch 131/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0899 - accuracy: 0.3537 - val_loss: 1.9374 - val_accuracy: 0.4766\n",
      "Epoch 132/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0667 - accuracy: 0.3702 - val_loss: 1.9359 - val_accuracy: 0.4766\n",
      "Epoch 133/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0677 - accuracy: 0.3584 - val_loss: 1.9344 - val_accuracy: 0.4766\n",
      "Epoch 134/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0828 - accuracy: 0.3537 - val_loss: 1.9336 - val_accuracy: 0.4766\n",
      "Epoch 135/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0788 - accuracy: 0.3635 - val_loss: 1.9328 - val_accuracy: 0.4766\n",
      "Epoch 136/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0801 - accuracy: 0.3506 - val_loss: 1.9315 - val_accuracy: 0.4766\n",
      "Epoch 137/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0908 - accuracy: 0.3561 - val_loss: 1.9310 - val_accuracy: 0.4766\n",
      "Epoch 138/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0805 - accuracy: 0.3600 - val_loss: 1.9298 - val_accuracy: 0.4766\n",
      "Epoch 139/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0895 - accuracy: 0.3490 - val_loss: 1.9289 - val_accuracy: 0.4766\n",
      "Epoch 140/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0822 - accuracy: 0.3553 - val_loss: 1.9290 - val_accuracy: 0.4766\n",
      "Epoch 141/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0840 - accuracy: 0.3541 - val_loss: 1.9286 - val_accuracy: 0.4766\n",
      "Epoch 142/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0761 - accuracy: 0.3576 - val_loss: 1.9278 - val_accuracy: 0.4766\n",
      "Epoch 143/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0502 - accuracy: 0.3756 - val_loss: 1.9256 - val_accuracy: 0.4766\n",
      "Epoch 144/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0931 - accuracy: 0.3541 - val_loss: 1.9254 - val_accuracy: 0.4766\n",
      "Epoch 145/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1008 - accuracy: 0.3541 - val_loss: 1.9260 - val_accuracy: 0.4766\n",
      "Epoch 146/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0738 - accuracy: 0.3639 - val_loss: 1.9252 - val_accuracy: 0.4766\n",
      "Epoch 147/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0641 - accuracy: 0.3635 - val_loss: 1.9236 - val_accuracy: 0.4766\n",
      "Epoch 148/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0649 - accuracy: 0.3717 - val_loss: 1.9230 - val_accuracy: 0.4766\n",
      "Epoch 149/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0754 - accuracy: 0.3694 - val_loss: 1.9226 - val_accuracy: 0.4766\n",
      "Epoch 150/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0654 - accuracy: 0.3635 - val_loss: 1.9212 - val_accuracy: 0.4766\n",
      "Epoch 151/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0859 - accuracy: 0.3525 - val_loss: 1.9204 - val_accuracy: 0.4766\n",
      "Epoch 152/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0586 - accuracy: 0.3694 - val_loss: 1.9192 - val_accuracy: 0.4766\n",
      "Epoch 153/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0594 - accuracy: 0.3776 - val_loss: 1.9176 - val_accuracy: 0.4766\n",
      "Epoch 154/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0860 - accuracy: 0.3521 - val_loss: 1.9178 - val_accuracy: 0.4766\n",
      "Epoch 155/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0717 - accuracy: 0.3698 - val_loss: 1.9168 - val_accuracy: 0.4766\n",
      "Epoch 156/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0640 - accuracy: 0.3655 - val_loss: 1.9169 - val_accuracy: 0.4766\n",
      "Epoch 157/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0724 - accuracy: 0.3705 - val_loss: 1.9166 - val_accuracy: 0.4766\n",
      "Epoch 158/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0377 - accuracy: 0.3870 - val_loss: 1.9152 - val_accuracy: 0.4766\n",
      "Epoch 159/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0326 - accuracy: 0.3933 - val_loss: 1.9130 - val_accuracy: 0.4766\n",
      "Epoch 160/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0801 - accuracy: 0.3576 - val_loss: 1.9136 - val_accuracy: 0.4766\n",
      "Epoch 161/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0700 - accuracy: 0.3694 - val_loss: 1.9137 - val_accuracy: 0.4766\n",
      "Epoch 162/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0636 - accuracy: 0.3768 - val_loss: 1.9141 - val_accuracy: 0.4766\n",
      "Epoch 163/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0731 - accuracy: 0.3678 - val_loss: 1.9139 - val_accuracy: 0.4766\n",
      "Epoch 164/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0734 - accuracy: 0.3725 - val_loss: 1.9136 - val_accuracy: 0.4766\n",
      "Epoch 165/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0825 - accuracy: 0.3678 - val_loss: 1.9149 - val_accuracy: 0.4766\n",
      "Epoch 166/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0717 - accuracy: 0.3572 - val_loss: 1.9145 - val_accuracy: 0.4766\n",
      "Epoch 167/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0570 - accuracy: 0.3725 - val_loss: 1.9131 - val_accuracy: 0.4766\n",
      "Epoch 168/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0598 - accuracy: 0.3725 - val_loss: 1.9120 - val_accuracy: 0.4766\n",
      "Epoch 169/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0632 - accuracy: 0.3713 - val_loss: 1.9105 - val_accuracy: 0.4766\n",
      "Epoch 170/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0642 - accuracy: 0.3686 - val_loss: 1.9104 - val_accuracy: 0.4766\n",
      "Epoch 171/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0645 - accuracy: 0.3705 - val_loss: 1.9098 - val_accuracy: 0.4766\n",
      "Epoch 172/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0926 - accuracy: 0.3529 - val_loss: 1.9107 - val_accuracy: 0.4766\n",
      "Epoch 173/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0634 - accuracy: 0.3776 - val_loss: 1.9105 - val_accuracy: 0.4766\n",
      "Epoch 174/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0575 - accuracy: 0.3733 - val_loss: 1.9093 - val_accuracy: 0.4766\n",
      "Epoch 175/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0712 - accuracy: 0.3709 - val_loss: 1.9091 - val_accuracy: 0.4766\n",
      "Epoch 176/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0699 - accuracy: 0.3658 - val_loss: 1.9079 - val_accuracy: 0.4766\n",
      "Epoch 177/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0595 - accuracy: 0.3662 - val_loss: 1.9076 - val_accuracy: 0.4766\n",
      "Epoch 178/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0758 - accuracy: 0.3623 - val_loss: 1.9077 - val_accuracy: 0.4766\n",
      "Epoch 179/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0543 - accuracy: 0.3788 - val_loss: 1.9062 - val_accuracy: 0.4766\n",
      "Epoch 180/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0496 - accuracy: 0.3835 - val_loss: 1.9059 - val_accuracy: 0.4766\n",
      "Epoch 181/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0512 - accuracy: 0.3819 - val_loss: 1.9040 - val_accuracy: 0.4766\n",
      "Epoch 182/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0333 - accuracy: 0.3897 - val_loss: 1.9019 - val_accuracy: 0.4766\n",
      "Epoch 183/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0601 - accuracy: 0.3705 - val_loss: 1.9003 - val_accuracy: 0.4766\n",
      "Epoch 184/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0727 - accuracy: 0.3733 - val_loss: 1.8997 - val_accuracy: 0.4766\n",
      "Epoch 185/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0777 - accuracy: 0.3564 - val_loss: 1.9009 - val_accuracy: 0.4766\n",
      "Epoch 186/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0654 - accuracy: 0.3647 - val_loss: 1.9003 - val_accuracy: 0.4766\n",
      "Epoch 187/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0456 - accuracy: 0.3823 - val_loss: 1.8988 - val_accuracy: 0.4766\n",
      "Epoch 188/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 2.0635 - accuracy: 0.3717 - val_loss: 1.8985 - val_accuracy: 0.4766\n",
      "Epoch 189/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0693 - accuracy: 0.3651 - val_loss: 1.8977 - val_accuracy: 0.4766\n",
      "Epoch 190/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0531 - accuracy: 0.3725 - val_loss: 1.8964 - val_accuracy: 0.4766\n",
      "Epoch 191/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0664 - accuracy: 0.3670 - val_loss: 1.8960 - val_accuracy: 0.4766\n",
      "Epoch 192/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0707 - accuracy: 0.3698 - val_loss: 1.8965 - val_accuracy: 0.4766\n",
      "Epoch 193/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0599 - accuracy: 0.3792 - val_loss: 1.8959 - val_accuracy: 0.4766\n",
      "Epoch 194/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0630 - accuracy: 0.3717 - val_loss: 1.8960 - val_accuracy: 0.4766\n",
      "Epoch 195/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0717 - accuracy: 0.3588 - val_loss: 1.8968 - val_accuracy: 0.4766\n",
      "Epoch 196/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0604 - accuracy: 0.3721 - val_loss: 1.8960 - val_accuracy: 0.4766\n",
      "Epoch 197/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0592 - accuracy: 0.3690 - val_loss: 1.8947 - val_accuracy: 0.4766\n",
      "Epoch 198/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0470 - accuracy: 0.3858 - val_loss: 1.8931 - val_accuracy: 0.4766\n",
      "Epoch 199/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 2.0715 - accuracy: 0.3682 - val_loss: 1.8931 - val_accuracy: 0.4766\n",
      "Epoch 200/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0490 - accuracy: 0.3690 - val_loss: 1.8925 - val_accuracy: 0.4766\n",
      "0.47663551568984985 {'loss': 2.049022674560547, 'accuracy': 0.3689776659011841, 'val_loss': 1.8924561738967896, 'val_accuracy': 0.47663551568984985}\n",
      "Model: \"model_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_14 (InputLayer)        [(None, 29)]              0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 41)                1230      \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 10)                420       \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,870\n",
      "Trainable params: 1,870\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 3.2348 - accuracy: 0.0353 - val_loss: 2.7430 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 3.1779 - accuracy: 0.0403 - val_loss: 2.7149 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.1066 - accuracy: 0.0341 - val_loss: 2.6881 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.0463 - accuracy: 0.0364 - val_loss: 2.6634 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.9999 - accuracy: 0.0368 - val_loss: 2.6398 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.9256 - accuracy: 0.0466 - val_loss: 2.6171 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.8802 - accuracy: 0.0458 - val_loss: 2.5960 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.8488 - accuracy: 0.0462 - val_loss: 2.5767 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.8130 - accuracy: 0.0423 - val_loss: 2.5578 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.7827 - accuracy: 0.0435 - val_loss: 2.5404 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.7318 - accuracy: 0.0490 - val_loss: 2.5243 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.7083 - accuracy: 0.0384 - val_loss: 2.5090 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.6741 - accuracy: 0.0490 - val_loss: 2.4941 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.6556 - accuracy: 0.0443 - val_loss: 2.4803 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.6250 - accuracy: 0.0407 - val_loss: 2.4674 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5921 - accuracy: 0.0474 - val_loss: 2.4560 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5672 - accuracy: 0.0497 - val_loss: 2.4450 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.5518 - accuracy: 0.0470 - val_loss: 2.4342 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.5373 - accuracy: 0.0486 - val_loss: 2.4245 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.5118 - accuracy: 0.0490 - val_loss: 2.4159 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.5009 - accuracy: 0.0525 - val_loss: 2.4072 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4807 - accuracy: 0.0588 - val_loss: 2.3982 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4660 - accuracy: 0.0556 - val_loss: 2.3903 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4541 - accuracy: 0.0599 - val_loss: 2.3835 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4489 - accuracy: 0.0615 - val_loss: 2.3767 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4264 - accuracy: 0.0713 - val_loss: 2.3705 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4208 - accuracy: 0.0588 - val_loss: 2.3647 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4068 - accuracy: 0.0721 - val_loss: 2.3587 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4037 - accuracy: 0.0709 - val_loss: 2.3536 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.3994 - accuracy: 0.0678 - val_loss: 2.3486 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3934 - accuracy: 0.0783 - val_loss: 2.3436 - val_accuracy: 0.0093\n",
      "Epoch 32/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 2.3816 - accuracy: 0.0736 - val_loss: 2.3383 - val_accuracy: 0.0093\n",
      "Epoch 33/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3743 - accuracy: 0.0823 - val_loss: 2.3338 - val_accuracy: 0.0093\n",
      "Epoch 34/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3687 - accuracy: 0.0873 - val_loss: 2.3283 - val_accuracy: 0.0093\n",
      "Epoch 35/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3656 - accuracy: 0.0897 - val_loss: 2.3239 - val_accuracy: 0.0093\n",
      "Epoch 36/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.3573 - accuracy: 0.0920 - val_loss: 2.3194 - val_accuracy: 0.0093\n",
      "Epoch 37/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3519 - accuracy: 0.0940 - val_loss: 2.3157 - val_accuracy: 0.0093\n",
      "Epoch 38/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3526 - accuracy: 0.0952 - val_loss: 2.3119 - val_accuracy: 0.0187\n",
      "Epoch 39/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3453 - accuracy: 0.0936 - val_loss: 2.3083 - val_accuracy: 0.0187\n",
      "Epoch 40/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3316 - accuracy: 0.1105 - val_loss: 2.3035 - val_accuracy: 0.0187\n",
      "Epoch 41/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3417 - accuracy: 0.1140 - val_loss: 2.2997 - val_accuracy: 0.0280\n",
      "Epoch 42/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3346 - accuracy: 0.1077 - val_loss: 2.2965 - val_accuracy: 0.0280\n",
      "Epoch 43/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3283 - accuracy: 0.1218 - val_loss: 2.2925 - val_accuracy: 0.0280\n",
      "Epoch 44/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3288 - accuracy: 0.1210 - val_loss: 2.2887 - val_accuracy: 0.0280\n",
      "Epoch 45/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3114 - accuracy: 0.1320 - val_loss: 2.2847 - val_accuracy: 0.0280\n",
      "Epoch 46/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3186 - accuracy: 0.1261 - val_loss: 2.2823 - val_accuracy: 0.0374\n",
      "Epoch 47/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3156 - accuracy: 0.1488 - val_loss: 2.2792 - val_accuracy: 0.0374\n",
      "Epoch 48/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3142 - accuracy: 0.1496 - val_loss: 2.2767 - val_accuracy: 0.0374\n",
      "Epoch 49/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3172 - accuracy: 0.1391 - val_loss: 2.2742 - val_accuracy: 0.0374\n",
      "Epoch 50/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3088 - accuracy: 0.1422 - val_loss: 2.2719 - val_accuracy: 0.0467\n",
      "Epoch 51/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3101 - accuracy: 0.1410 - val_loss: 2.2698 - val_accuracy: 0.0654\n",
      "Epoch 52/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3063 - accuracy: 0.1453 - val_loss: 2.2674 - val_accuracy: 0.0748\n",
      "Epoch 53/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3064 - accuracy: 0.1520 - val_loss: 2.2650 - val_accuracy: 0.0841\n",
      "Epoch 54/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2907 - accuracy: 0.1743 - val_loss: 2.2618 - val_accuracy: 0.0841\n",
      "Epoch 55/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2931 - accuracy: 0.1676 - val_loss: 2.2588 - val_accuracy: 0.0935\n",
      "Epoch 56/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.2939 - accuracy: 0.1629 - val_loss: 2.2564 - val_accuracy: 0.1028\n",
      "Epoch 57/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.2884 - accuracy: 0.1731 - val_loss: 2.2539 - val_accuracy: 0.1308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2877 - accuracy: 0.1876 - val_loss: 2.2519 - val_accuracy: 0.1308\n",
      "Epoch 59/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.2845 - accuracy: 0.1786 - val_loss: 2.2499 - val_accuracy: 0.1682\n",
      "Epoch 60/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2823 - accuracy: 0.1935 - val_loss: 2.2474 - val_accuracy: 0.1682\n",
      "Epoch 61/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2760 - accuracy: 0.1947 - val_loss: 2.2451 - val_accuracy: 0.1776\n",
      "Epoch 62/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2747 - accuracy: 0.1962 - val_loss: 2.2429 - val_accuracy: 0.1869\n",
      "Epoch 63/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2819 - accuracy: 0.1892 - val_loss: 2.2414 - val_accuracy: 0.1963\n",
      "Epoch 64/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2851 - accuracy: 0.1970 - val_loss: 2.2401 - val_accuracy: 0.2150\n",
      "Epoch 65/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2738 - accuracy: 0.2072 - val_loss: 2.2378 - val_accuracy: 0.2150\n",
      "Epoch 66/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2649 - accuracy: 0.2017 - val_loss: 2.2356 - val_accuracy: 0.2243\n",
      "Epoch 67/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.2768 - accuracy: 0.2045 - val_loss: 2.2344 - val_accuracy: 0.2243\n",
      "Epoch 68/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.2649 - accuracy: 0.2123 - val_loss: 2.2319 - val_accuracy: 0.2336\n",
      "Epoch 69/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2589 - accuracy: 0.2166 - val_loss: 2.2291 - val_accuracy: 0.2430\n",
      "Epoch 70/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2615 - accuracy: 0.2221 - val_loss: 2.2264 - val_accuracy: 0.2430\n",
      "Epoch 71/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2729 - accuracy: 0.2268 - val_loss: 2.2252 - val_accuracy: 0.2430\n",
      "Epoch 72/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2707 - accuracy: 0.2241 - val_loss: 2.2246 - val_accuracy: 0.2523\n",
      "Epoch 73/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2654 - accuracy: 0.2237 - val_loss: 2.2237 - val_accuracy: 0.2523\n",
      "Epoch 74/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2599 - accuracy: 0.2256 - val_loss: 2.2215 - val_accuracy: 0.2523\n",
      "Epoch 75/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2585 - accuracy: 0.2421 - val_loss: 2.2196 - val_accuracy: 0.2710\n",
      "Epoch 76/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2496 - accuracy: 0.2432 - val_loss: 2.2167 - val_accuracy: 0.2710\n",
      "Epoch 77/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2578 - accuracy: 0.2436 - val_loss: 2.2140 - val_accuracy: 0.2804\n",
      "Epoch 78/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2668 - accuracy: 0.2244 - val_loss: 2.2124 - val_accuracy: 0.2897\n",
      "Epoch 79/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2461 - accuracy: 0.2464 - val_loss: 2.2108 - val_accuracy: 0.2991\n",
      "Epoch 80/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2601 - accuracy: 0.2495 - val_loss: 2.2100 - val_accuracy: 0.2991\n",
      "Epoch 81/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2418 - accuracy: 0.2546 - val_loss: 2.2076 - val_accuracy: 0.3084\n",
      "Epoch 82/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2560 - accuracy: 0.2405 - val_loss: 2.2058 - val_accuracy: 0.3178\n",
      "Epoch 83/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2618 - accuracy: 0.2432 - val_loss: 2.2053 - val_accuracy: 0.3271\n",
      "Epoch 84/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2503 - accuracy: 0.2526 - val_loss: 2.2035 - val_accuracy: 0.3271\n",
      "Epoch 85/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2492 - accuracy: 0.2589 - val_loss: 2.2018 - val_accuracy: 0.3551\n",
      "Epoch 86/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2416 - accuracy: 0.2671 - val_loss: 2.1996 - val_accuracy: 0.3551\n",
      "Epoch 87/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2456 - accuracy: 0.2660 - val_loss: 2.1974 - val_accuracy: 0.3738\n",
      "Epoch 88/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2388 - accuracy: 0.2617 - val_loss: 2.1951 - val_accuracy: 0.3925\n",
      "Epoch 89/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2369 - accuracy: 0.2703 - val_loss: 2.1926 - val_accuracy: 0.4019\n",
      "Epoch 90/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2384 - accuracy: 0.2613 - val_loss: 2.1910 - val_accuracy: 0.4112\n",
      "Epoch 91/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2330 - accuracy: 0.2730 - val_loss: 2.1888 - val_accuracy: 0.4206\n",
      "Epoch 92/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2331 - accuracy: 0.2808 - val_loss: 2.1867 - val_accuracy: 0.4206\n",
      "Epoch 93/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2449 - accuracy: 0.2734 - val_loss: 2.1849 - val_accuracy: 0.4206\n",
      "Epoch 94/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2350 - accuracy: 0.2828 - val_loss: 2.1836 - val_accuracy: 0.4206\n",
      "Epoch 95/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2320 - accuracy: 0.2805 - val_loss: 2.1818 - val_accuracy: 0.4206\n",
      "Epoch 96/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2135 - accuracy: 0.2852 - val_loss: 2.1780 - val_accuracy: 0.4299\n",
      "Epoch 97/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2410 - accuracy: 0.2750 - val_loss: 2.1772 - val_accuracy: 0.4299\n",
      "Epoch 98/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2270 - accuracy: 0.2910 - val_loss: 2.1751 - val_accuracy: 0.4299\n",
      "Epoch 99/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2316 - accuracy: 0.2930 - val_loss: 2.1733 - val_accuracy: 0.4393\n",
      "Epoch 100/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2192 - accuracy: 0.2930 - val_loss: 2.1707 - val_accuracy: 0.4393\n",
      "Epoch 101/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2147 - accuracy: 0.2914 - val_loss: 2.1676 - val_accuracy: 0.4486\n",
      "Epoch 102/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2209 - accuracy: 0.2820 - val_loss: 2.1659 - val_accuracy: 0.4393\n",
      "Epoch 103/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2244 - accuracy: 0.2816 - val_loss: 2.1639 - val_accuracy: 0.4393\n",
      "Epoch 104/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2164 - accuracy: 0.2961 - val_loss: 2.1614 - val_accuracy: 0.4486\n",
      "Epoch 105/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2392 - accuracy: 0.2781 - val_loss: 2.1612 - val_accuracy: 0.4486\n",
      "Epoch 106/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2192 - accuracy: 0.2918 - val_loss: 2.1598 - val_accuracy: 0.4486\n",
      "Epoch 107/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2107 - accuracy: 0.2985 - val_loss: 2.1572 - val_accuracy: 0.4579\n",
      "Epoch 108/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2177 - accuracy: 0.2930 - val_loss: 2.1553 - val_accuracy: 0.4673\n",
      "Epoch 109/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2211 - accuracy: 0.2938 - val_loss: 2.1538 - val_accuracy: 0.4673\n",
      "Epoch 110/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2079 - accuracy: 0.2989 - val_loss: 2.1511 - val_accuracy: 0.4673\n",
      "Epoch 111/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2106 - accuracy: 0.3020 - val_loss: 2.1494 - val_accuracy: 0.4860\n",
      "Epoch 112/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2131 - accuracy: 0.3083 - val_loss: 2.1473 - val_accuracy: 0.4860\n",
      "Epoch 113/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2211 - accuracy: 0.2902 - val_loss: 2.1464 - val_accuracy: 0.4766\n",
      "Epoch 114/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2156 - accuracy: 0.3016 - val_loss: 2.1450 - val_accuracy: 0.4673\n",
      "Epoch 115/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2119 - accuracy: 0.3141 - val_loss: 2.1427 - val_accuracy: 0.4673\n",
      "Epoch 116/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2084 - accuracy: 0.3036 - val_loss: 2.1398 - val_accuracy: 0.4766\n",
      "Epoch 117/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2087 - accuracy: 0.3032 - val_loss: 2.1384 - val_accuracy: 0.4766\n",
      "Epoch 118/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2159 - accuracy: 0.2965 - val_loss: 2.1373 - val_accuracy: 0.4766\n",
      "Epoch 119/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1896 - accuracy: 0.3173 - val_loss: 2.1332 - val_accuracy: 0.4766\n",
      "Epoch 120/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2037 - accuracy: 0.2961 - val_loss: 2.1310 - val_accuracy: 0.4860\n",
      "Epoch 121/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1903 - accuracy: 0.3141 - val_loss: 2.1283 - val_accuracy: 0.4953\n",
      "Epoch 122/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.1863 - accuracy: 0.3094 - val_loss: 2.1254 - val_accuracy: 0.5047\n",
      "Epoch 123/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2063 - accuracy: 0.2946 - val_loss: 2.1237 - val_accuracy: 0.5047\n",
      "Epoch 124/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1941 - accuracy: 0.2973 - val_loss: 2.1215 - val_accuracy: 0.5140\n",
      "Epoch 125/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.1977 - accuracy: 0.2985 - val_loss: 2.1192 - val_accuracy: 0.5234\n",
      "Epoch 126/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.1774 - accuracy: 0.3028 - val_loss: 2.1167 - val_accuracy: 0.5234\n",
      "Epoch 127/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1908 - accuracy: 0.2899 - val_loss: 2.1141 - val_accuracy: 0.5234\n",
      "Epoch 128/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1840 - accuracy: 0.3032 - val_loss: 2.1117 - val_accuracy: 0.5140\n",
      "Epoch 129/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1721 - accuracy: 0.3028 - val_loss: 2.1092 - val_accuracy: 0.5047\n",
      "Epoch 130/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1691 - accuracy: 0.3079 - val_loss: 2.1056 - val_accuracy: 0.4953\n",
      "Epoch 131/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1900 - accuracy: 0.2855 - val_loss: 2.1044 - val_accuracy: 0.4953\n",
      "Epoch 132/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1670 - accuracy: 0.2985 - val_loss: 2.1012 - val_accuracy: 0.4953\n",
      "Epoch 133/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1740 - accuracy: 0.2973 - val_loss: 2.0990 - val_accuracy: 0.4953\n",
      "Epoch 134/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1723 - accuracy: 0.2981 - val_loss: 2.0975 - val_accuracy: 0.4860\n",
      "Epoch 135/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1820 - accuracy: 0.2844 - val_loss: 2.0968 - val_accuracy: 0.4860\n",
      "Epoch 136/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1538 - accuracy: 0.2989 - val_loss: 2.0933 - val_accuracy: 0.4860\n",
      "Epoch 137/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1838 - accuracy: 0.2781 - val_loss: 2.0914 - val_accuracy: 0.4860\n",
      "Epoch 138/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1699 - accuracy: 0.2852 - val_loss: 2.0897 - val_accuracy: 0.4860\n",
      "Epoch 139/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1536 - accuracy: 0.3043 - val_loss: 2.0873 - val_accuracy: 0.4860\n",
      "Epoch 140/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1523 - accuracy: 0.2969 - val_loss: 2.0843 - val_accuracy: 0.4860\n",
      "Epoch 141/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1772 - accuracy: 0.2769 - val_loss: 2.0827 - val_accuracy: 0.4860\n",
      "Epoch 142/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1558 - accuracy: 0.2961 - val_loss: 2.0806 - val_accuracy: 0.4860\n",
      "Epoch 143/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1693 - accuracy: 0.2906 - val_loss: 2.0788 - val_accuracy: 0.4860\n",
      "Epoch 144/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1742 - accuracy: 0.2828 - val_loss: 2.0783 - val_accuracy: 0.4860\n",
      "Epoch 145/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1586 - accuracy: 0.2805 - val_loss: 2.0749 - val_accuracy: 0.4860\n",
      "Epoch 146/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1513 - accuracy: 0.2930 - val_loss: 2.0722 - val_accuracy: 0.4860\n",
      "Epoch 147/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1556 - accuracy: 0.2836 - val_loss: 2.0707 - val_accuracy: 0.4860\n",
      "Epoch 148/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1526 - accuracy: 0.2957 - val_loss: 2.0688 - val_accuracy: 0.4860\n",
      "Epoch 149/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1483 - accuracy: 0.2969 - val_loss: 2.0665 - val_accuracy: 0.4953\n",
      "Epoch 150/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1427 - accuracy: 0.2957 - val_loss: 2.0634 - val_accuracy: 0.4860\n",
      "Epoch 151/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.1495 - accuracy: 0.2961 - val_loss: 2.0616 - val_accuracy: 0.4860\n",
      "Epoch 152/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1460 - accuracy: 0.2797 - val_loss: 2.0602 - val_accuracy: 0.4860\n",
      "Epoch 153/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.1246 - accuracy: 0.3134 - val_loss: 2.0565 - val_accuracy: 0.4860\n",
      "Epoch 154/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1157 - accuracy: 0.3047 - val_loss: 2.0521 - val_accuracy: 0.4860\n",
      "Epoch 155/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1371 - accuracy: 0.2910 - val_loss: 2.0498 - val_accuracy: 0.4860\n",
      "Epoch 156/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.1202 - accuracy: 0.3051 - val_loss: 2.0466 - val_accuracy: 0.4860\n",
      "Epoch 157/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1317 - accuracy: 0.2973 - val_loss: 2.0452 - val_accuracy: 0.4860\n",
      "Epoch 158/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1111 - accuracy: 0.3177 - val_loss: 2.0420 - val_accuracy: 0.4766\n",
      "Epoch 159/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.1178 - accuracy: 0.3051 - val_loss: 2.0379 - val_accuracy: 0.4673\n",
      "Epoch 160/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.1200 - accuracy: 0.3118 - val_loss: 2.0359 - val_accuracy: 0.4766\n",
      "Epoch 161/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1327 - accuracy: 0.3071 - val_loss: 2.0336 - val_accuracy: 0.4673\n",
      "Epoch 162/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.1293 - accuracy: 0.2985 - val_loss: 2.0325 - val_accuracy: 0.4673\n",
      "Epoch 163/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.1273 - accuracy: 0.3098 - val_loss: 2.0298 - val_accuracy: 0.4673\n",
      "Epoch 164/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.1129 - accuracy: 0.3149 - val_loss: 2.0275 - val_accuracy: 0.4673\n",
      "Epoch 165/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1266 - accuracy: 0.3016 - val_loss: 2.0259 - val_accuracy: 0.4673\n",
      "Epoch 166/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 2.1278 - accuracy: 0.3043 - val_loss: 2.0244 - val_accuracy: 0.4673\n",
      "Epoch 167/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 2.1174 - accuracy: 0.3087 - val_loss: 2.0223 - val_accuracy: 0.4673\n",
      "Epoch 168/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1280 - accuracy: 0.3040 - val_loss: 2.0212 - val_accuracy: 0.4766\n",
      "Epoch 169/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1282 - accuracy: 0.3079 - val_loss: 2.0197 - val_accuracy: 0.4766\n",
      "Epoch 170/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1041 - accuracy: 0.3157 - val_loss: 2.0166 - val_accuracy: 0.4766\n",
      "Epoch 171/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1216 - accuracy: 0.3016 - val_loss: 2.0149 - val_accuracy: 0.4766\n",
      "Epoch 172/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 4ms/step - loss: 2.1051 - accuracy: 0.3271 - val_loss: 2.0120 - val_accuracy: 0.4766\n",
      "Epoch 173/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.1229 - accuracy: 0.3067 - val_loss: 2.0112 - val_accuracy: 0.4766\n",
      "Epoch 174/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.1179 - accuracy: 0.3208 - val_loss: 2.0094 - val_accuracy: 0.4766\n",
      "Epoch 175/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 2.1144 - accuracy: 0.3024 - val_loss: 2.0076 - val_accuracy: 0.4766\n",
      "Epoch 176/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1002 - accuracy: 0.3243 - val_loss: 2.0059 - val_accuracy: 0.4766\n",
      "Epoch 177/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1187 - accuracy: 0.3228 - val_loss: 2.0038 - val_accuracy: 0.4766\n",
      "Epoch 178/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.1004 - accuracy: 0.3220 - val_loss: 2.0017 - val_accuracy: 0.4766\n",
      "Epoch 179/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1010 - accuracy: 0.3188 - val_loss: 1.9994 - val_accuracy: 0.4766\n",
      "Epoch 180/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.1257 - accuracy: 0.2989 - val_loss: 1.9989 - val_accuracy: 0.4766\n",
      "Epoch 181/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0963 - accuracy: 0.3212 - val_loss: 1.9968 - val_accuracy: 0.4766\n",
      "Epoch 182/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0964 - accuracy: 0.3177 - val_loss: 1.9949 - val_accuracy: 0.4766\n",
      "Epoch 183/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1011 - accuracy: 0.3231 - val_loss: 1.9929 - val_accuracy: 0.4766\n",
      "Epoch 184/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0920 - accuracy: 0.3271 - val_loss: 1.9904 - val_accuracy: 0.4766\n",
      "Epoch 185/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1024 - accuracy: 0.3196 - val_loss: 1.9887 - val_accuracy: 0.4766\n",
      "Epoch 186/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 2.1034 - accuracy: 0.3251 - val_loss: 1.9878 - val_accuracy: 0.4766\n",
      "Epoch 187/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.0872 - accuracy: 0.3235 - val_loss: 1.9846 - val_accuracy: 0.4766\n",
      "Epoch 188/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1001 - accuracy: 0.3231 - val_loss: 1.9832 - val_accuracy: 0.4766\n",
      "Epoch 189/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.0896 - accuracy: 0.3259 - val_loss: 1.9804 - val_accuracy: 0.4766\n",
      "Epoch 190/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0978 - accuracy: 0.3188 - val_loss: 1.9793 - val_accuracy: 0.4766\n",
      "Epoch 191/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0942 - accuracy: 0.3122 - val_loss: 1.9775 - val_accuracy: 0.4766\n",
      "Epoch 192/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.0945 - accuracy: 0.3286 - val_loss: 1.9767 - val_accuracy: 0.4766\n",
      "Epoch 193/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.0787 - accuracy: 0.3267 - val_loss: 1.9740 - val_accuracy: 0.4766\n",
      "Epoch 194/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0907 - accuracy: 0.3314 - val_loss: 1.9718 - val_accuracy: 0.4766\n",
      "Epoch 195/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1012 - accuracy: 0.3184 - val_loss: 1.9699 - val_accuracy: 0.4766\n",
      "Epoch 196/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0930 - accuracy: 0.3134 - val_loss: 1.9676 - val_accuracy: 0.4766\n",
      "Epoch 197/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0824 - accuracy: 0.3251 - val_loss: 1.9655 - val_accuracy: 0.4766\n",
      "Epoch 198/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.0758 - accuracy: 0.3275 - val_loss: 1.9633 - val_accuracy: 0.4766\n",
      "Epoch 199/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.0824 - accuracy: 0.3275 - val_loss: 1.9611 - val_accuracy: 0.4766\n",
      "Epoch 200/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.0920 - accuracy: 0.3137 - val_loss: 1.9598 - val_accuracy: 0.4766\n",
      "0.47663551568984985 {'loss': 2.0919721126556396, 'accuracy': 0.3137485384941101, 'val_loss': 1.9597609043121338, 'val_accuracy': 0.47663551568984985}\n",
      "Model: \"model_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_15 (InputLayer)        [(None, 29)]              0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 41)                1230      \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 10)                420       \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,870\n",
      "Trainable params: 1,870\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 2.9530 - accuracy: 0.1696 - val_loss: 2.3883 - val_accuracy: 0.1682\n",
      "Epoch 2/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.8550 - accuracy: 0.1594 - val_loss: 2.3697 - val_accuracy: 0.1776\n",
      "Epoch 3/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.7537 - accuracy: 0.1708 - val_loss: 2.3543 - val_accuracy: 0.1869\n",
      "Epoch 4/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.6856 - accuracy: 0.1770 - val_loss: 2.3407 - val_accuracy: 0.1869\n",
      "Epoch 5/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.6150 - accuracy: 0.1817 - val_loss: 2.3293 - val_accuracy: 0.2056\n",
      "Epoch 6/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.5574 - accuracy: 0.1770 - val_loss: 2.3212 - val_accuracy: 0.2150\n",
      "Epoch 7/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.5226 - accuracy: 0.1751 - val_loss: 2.3139 - val_accuracy: 0.2056\n",
      "Epoch 8/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4838 - accuracy: 0.1712 - val_loss: 2.3081 - val_accuracy: 0.1869\n",
      "Epoch 9/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4502 - accuracy: 0.1723 - val_loss: 2.3035 - val_accuracy: 0.1869\n",
      "Epoch 10/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 2.4334 - accuracy: 0.1653 - val_loss: 2.3001 - val_accuracy: 0.1869\n",
      "Epoch 11/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3899 - accuracy: 0.1841 - val_loss: 2.2974 - val_accuracy: 0.1776\n",
      "Epoch 12/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3704 - accuracy: 0.1908 - val_loss: 2.2950 - val_accuracy: 0.1869\n",
      "Epoch 13/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 2.3551 - accuracy: 0.1817 - val_loss: 2.2934 - val_accuracy: 0.2056\n",
      "Epoch 14/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3455 - accuracy: 0.1900 - val_loss: 2.2921 - val_accuracy: 0.2056\n",
      "Epoch 15/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3436 - accuracy: 0.1915 - val_loss: 2.2912 - val_accuracy: 0.2056\n",
      "Epoch 16/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3203 - accuracy: 0.1990 - val_loss: 2.2904 - val_accuracy: 0.2056\n",
      "Epoch 17/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3271 - accuracy: 0.2017 - val_loss: 2.2901 - val_accuracy: 0.2056\n",
      "Epoch 18/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3154 - accuracy: 0.1990 - val_loss: 2.2901 - val_accuracy: 0.2056\n",
      "Epoch 19/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3105 - accuracy: 0.1962 - val_loss: 2.2897 - val_accuracy: 0.1963\n",
      "Epoch 20/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3030 - accuracy: 0.2080 - val_loss: 2.2891 - val_accuracy: 0.1963\n",
      "Epoch 21/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3114 - accuracy: 0.1998 - val_loss: 2.2886 - val_accuracy: 0.1963\n",
      "Epoch 22/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 2.3050 - accuracy: 0.2037 - val_loss: 2.2878 - val_accuracy: 0.1963\n",
      "Epoch 23/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 2.3070 - accuracy: 0.2111 - val_loss: 2.2874 - val_accuracy: 0.1963\n",
      "Epoch 24/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3088 - accuracy: 0.2123 - val_loss: 2.2874 - val_accuracy: 0.2056\n",
      "Epoch 25/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3007 - accuracy: 0.2096 - val_loss: 2.2868 - val_accuracy: 0.1963\n",
      "Epoch 26/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3007 - accuracy: 0.2182 - val_loss: 2.2866 - val_accuracy: 0.2150\n",
      "Epoch 27/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2874 - accuracy: 0.2119 - val_loss: 2.2862 - val_accuracy: 0.2150\n",
      "Epoch 28/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2944 - accuracy: 0.2229 - val_loss: 2.2860 - val_accuracy: 0.2243\n",
      "Epoch 29/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2982 - accuracy: 0.2225 - val_loss: 2.2857 - val_accuracy: 0.2243\n",
      "Epoch 30/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2879 - accuracy: 0.2166 - val_loss: 2.2851 - val_accuracy: 0.2243\n",
      "Epoch 31/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2881 - accuracy: 0.2158 - val_loss: 2.2845 - val_accuracy: 0.2336\n",
      "Epoch 32/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2951 - accuracy: 0.2162 - val_loss: 2.2841 - val_accuracy: 0.2336\n",
      "Epoch 33/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2805 - accuracy: 0.2252 - val_loss: 2.2834 - val_accuracy: 0.2336\n",
      "Epoch 34/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2887 - accuracy: 0.2201 - val_loss: 2.2831 - val_accuracy: 0.2336\n",
      "Epoch 35/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2766 - accuracy: 0.2303 - val_loss: 2.2823 - val_accuracy: 0.2336\n",
      "Epoch 36/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2888 - accuracy: 0.2291 - val_loss: 2.2820 - val_accuracy: 0.2336\n",
      "Epoch 37/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2884 - accuracy: 0.2256 - val_loss: 2.2816 - val_accuracy: 0.2336\n",
      "Epoch 38/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2870 - accuracy: 0.2241 - val_loss: 2.2813 - val_accuracy: 0.2336\n",
      "Epoch 39/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2831 - accuracy: 0.2319 - val_loss: 2.2807 - val_accuracy: 0.2336\n",
      "Epoch 40/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2893 - accuracy: 0.2291 - val_loss: 2.2800 - val_accuracy: 0.2430\n",
      "Epoch 41/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2832 - accuracy: 0.2311 - val_loss: 2.2796 - val_accuracy: 0.2430\n",
      "Epoch 42/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2799 - accuracy: 0.2374 - val_loss: 2.2792 - val_accuracy: 0.2430\n",
      "Epoch 43/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2798 - accuracy: 0.2374 - val_loss: 2.2788 - val_accuracy: 0.2430\n",
      "Epoch 44/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2801 - accuracy: 0.2346 - val_loss: 2.2783 - val_accuracy: 0.2430\n",
      "Epoch 45/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2793 - accuracy: 0.2319 - val_loss: 2.2777 - val_accuracy: 0.2523\n",
      "Epoch 46/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2835 - accuracy: 0.2354 - val_loss: 2.2769 - val_accuracy: 0.2523\n",
      "Epoch 47/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2864 - accuracy: 0.2335 - val_loss: 2.2763 - val_accuracy: 0.2523\n",
      "Epoch 48/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2739 - accuracy: 0.2468 - val_loss: 2.2756 - val_accuracy: 0.2523\n",
      "Epoch 49/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 2.2859 - accuracy: 0.2382 - val_loss: 2.2754 - val_accuracy: 0.2523\n",
      "Epoch 50/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 2.2773 - accuracy: 0.2409 - val_loss: 2.2748 - val_accuracy: 0.2523\n",
      "Epoch 51/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 2.2744 - accuracy: 0.2452 - val_loss: 2.2736 - val_accuracy: 0.2617\n",
      "Epoch 52/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2754 - accuracy: 0.2425 - val_loss: 2.2731 - val_accuracy: 0.2710\n",
      "Epoch 53/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2752 - accuracy: 0.2472 - val_loss: 2.2726 - val_accuracy: 0.2617\n",
      "Epoch 54/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2767 - accuracy: 0.2432 - val_loss: 2.2720 - val_accuracy: 0.2710\n",
      "Epoch 55/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2730 - accuracy: 0.2382 - val_loss: 2.2713 - val_accuracy: 0.2710\n",
      "Epoch 56/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2716 - accuracy: 0.2479 - val_loss: 2.2704 - val_accuracy: 0.2710\n",
      "Epoch 57/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2737 - accuracy: 0.2503 - val_loss: 2.2700 - val_accuracy: 0.2804\n",
      "Epoch 58/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2760 - accuracy: 0.2519 - val_loss: 2.2696 - val_accuracy: 0.2804\n",
      "Epoch 59/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2717 - accuracy: 0.2448 - val_loss: 2.2689 - val_accuracy: 0.2804\n",
      "Epoch 60/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2694 - accuracy: 0.2491 - val_loss: 2.2680 - val_accuracy: 0.2804\n",
      "Epoch 61/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2746 - accuracy: 0.2444 - val_loss: 2.2676 - val_accuracy: 0.2804\n",
      "Epoch 62/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2757 - accuracy: 0.2472 - val_loss: 2.2672 - val_accuracy: 0.2804\n",
      "Epoch 63/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2717 - accuracy: 0.2483 - val_loss: 2.2665 - val_accuracy: 0.2804\n",
      "Epoch 64/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2721 - accuracy: 0.2597 - val_loss: 2.2661 - val_accuracy: 0.2804\n",
      "Epoch 65/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 2.2731 - accuracy: 0.2538 - val_loss: 2.2658 - val_accuracy: 0.2804\n",
      "Epoch 66/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2755 - accuracy: 0.2566 - val_loss: 2.2651 - val_accuracy: 0.2804\n",
      "Epoch 67/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2657 - accuracy: 0.2589 - val_loss: 2.2642 - val_accuracy: 0.2804\n",
      "Epoch 68/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2696 - accuracy: 0.2577 - val_loss: 2.2635 - val_accuracy: 0.2804\n",
      "Epoch 69/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2707 - accuracy: 0.2624 - val_loss: 2.2628 - val_accuracy: 0.2804\n",
      "Epoch 70/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2568 - accuracy: 0.2644 - val_loss: 2.2614 - val_accuracy: 0.2710\n",
      "Epoch 71/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2710 - accuracy: 0.2538 - val_loss: 2.2610 - val_accuracy: 0.2804\n",
      "Epoch 72/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2696 - accuracy: 0.2573 - val_loss: 2.2600 - val_accuracy: 0.2804\n",
      "Epoch 73/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2682 - accuracy: 0.2605 - val_loss: 2.2597 - val_accuracy: 0.2804\n",
      "Epoch 74/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2709 - accuracy: 0.2526 - val_loss: 2.2587 - val_accuracy: 0.2804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2728 - accuracy: 0.2562 - val_loss: 2.2585 - val_accuracy: 0.2804\n",
      "Epoch 76/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2685 - accuracy: 0.2542 - val_loss: 2.2581 - val_accuracy: 0.2804\n",
      "Epoch 77/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2670 - accuracy: 0.2573 - val_loss: 2.2577 - val_accuracy: 0.2804\n",
      "Epoch 78/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2697 - accuracy: 0.2593 - val_loss: 2.2573 - val_accuracy: 0.2804\n",
      "Epoch 79/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2684 - accuracy: 0.2562 - val_loss: 2.2571 - val_accuracy: 0.2804\n",
      "Epoch 80/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2591 - accuracy: 0.2585 - val_loss: 2.2564 - val_accuracy: 0.2804\n",
      "Epoch 81/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2645 - accuracy: 0.2660 - val_loss: 2.2558 - val_accuracy: 0.2804\n",
      "Epoch 82/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2673 - accuracy: 0.2597 - val_loss: 2.2556 - val_accuracy: 0.2804\n",
      "Epoch 83/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2655 - accuracy: 0.2632 - val_loss: 2.2553 - val_accuracy: 0.2804\n",
      "Epoch 84/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2651 - accuracy: 0.2636 - val_loss: 2.2549 - val_accuracy: 0.2804\n",
      "Epoch 85/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2613 - accuracy: 0.2664 - val_loss: 2.2548 - val_accuracy: 0.2804\n",
      "Epoch 86/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2729 - accuracy: 0.2652 - val_loss: 2.2548 - val_accuracy: 0.2804\n",
      "Epoch 87/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2689 - accuracy: 0.2640 - val_loss: 2.2546 - val_accuracy: 0.2804\n",
      "Epoch 88/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2725 - accuracy: 0.2636 - val_loss: 2.2546 - val_accuracy: 0.2804\n",
      "Epoch 89/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2600 - accuracy: 0.2691 - val_loss: 2.2536 - val_accuracy: 0.2804\n",
      "Epoch 90/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2601 - accuracy: 0.2671 - val_loss: 2.2529 - val_accuracy: 0.2804\n",
      "Epoch 91/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2568 - accuracy: 0.2648 - val_loss: 2.2524 - val_accuracy: 0.2804\n",
      "Epoch 92/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2594 - accuracy: 0.2617 - val_loss: 2.2516 - val_accuracy: 0.2804\n",
      "Epoch 93/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2671 - accuracy: 0.2632 - val_loss: 2.2514 - val_accuracy: 0.2804\n",
      "Epoch 94/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2592 - accuracy: 0.2695 - val_loss: 2.2506 - val_accuracy: 0.2804\n",
      "Epoch 95/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2634 - accuracy: 0.2640 - val_loss: 2.2504 - val_accuracy: 0.2804\n",
      "Epoch 96/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2698 - accuracy: 0.2636 - val_loss: 2.2502 - val_accuracy: 0.2804\n",
      "Epoch 97/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2567 - accuracy: 0.2667 - val_loss: 2.2497 - val_accuracy: 0.2804\n",
      "Epoch 98/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2583 - accuracy: 0.2679 - val_loss: 2.2496 - val_accuracy: 0.2804\n",
      "Epoch 99/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2650 - accuracy: 0.2624 - val_loss: 2.2494 - val_accuracy: 0.2804\n",
      "Epoch 100/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2638 - accuracy: 0.2613 - val_loss: 2.2491 - val_accuracy: 0.2804\n",
      "Epoch 101/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2588 - accuracy: 0.2711 - val_loss: 2.2489 - val_accuracy: 0.2804\n",
      "Epoch 102/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2592 - accuracy: 0.2675 - val_loss: 2.2490 - val_accuracy: 0.2804\n",
      "Epoch 103/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2675 - accuracy: 0.2695 - val_loss: 2.2492 - val_accuracy: 0.2804\n",
      "Epoch 104/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2599 - accuracy: 0.2793 - val_loss: 2.2487 - val_accuracy: 0.2804\n",
      "Epoch 105/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2628 - accuracy: 0.2675 - val_loss: 2.2491 - val_accuracy: 0.2804\n",
      "Epoch 106/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2677 - accuracy: 0.2738 - val_loss: 2.2489 - val_accuracy: 0.2804\n",
      "Epoch 107/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2622 - accuracy: 0.2707 - val_loss: 2.2487 - val_accuracy: 0.2804\n",
      "Epoch 108/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2609 - accuracy: 0.2597 - val_loss: 2.2488 - val_accuracy: 0.2804\n",
      "Epoch 109/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2708 - accuracy: 0.2675 - val_loss: 2.2491 - val_accuracy: 0.2804\n",
      "Epoch 110/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2655 - accuracy: 0.2769 - val_loss: 2.2492 - val_accuracy: 0.2804\n",
      "Epoch 111/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2642 - accuracy: 0.2726 - val_loss: 2.2488 - val_accuracy: 0.2804\n",
      "Epoch 112/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2634 - accuracy: 0.2683 - val_loss: 2.2490 - val_accuracy: 0.2804\n",
      "Epoch 113/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2606 - accuracy: 0.2730 - val_loss: 2.2483 - val_accuracy: 0.2804\n",
      "Epoch 114/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2603 - accuracy: 0.2726 - val_loss: 2.2480 - val_accuracy: 0.2804\n",
      "Epoch 115/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2662 - accuracy: 0.2691 - val_loss: 2.2479 - val_accuracy: 0.2804\n",
      "Epoch 116/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 2.2523 - accuracy: 0.2648 - val_loss: 2.2474 - val_accuracy: 0.2804\n",
      "Epoch 117/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2486 - accuracy: 0.2675 - val_loss: 2.2468 - val_accuracy: 0.2804\n",
      "Epoch 118/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2650 - accuracy: 0.2707 - val_loss: 2.2471 - val_accuracy: 0.2804\n",
      "Epoch 119/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2615 - accuracy: 0.2687 - val_loss: 2.2472 - val_accuracy: 0.2804\n",
      "Epoch 120/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2600 - accuracy: 0.2707 - val_loss: 2.2472 - val_accuracy: 0.2804\n",
      "Epoch 121/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2628 - accuracy: 0.2683 - val_loss: 2.2471 - val_accuracy: 0.2804\n",
      "Epoch 122/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2572 - accuracy: 0.2742 - val_loss: 2.2471 - val_accuracy: 0.2804\n",
      "Epoch 123/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2631 - accuracy: 0.2675 - val_loss: 2.2468 - val_accuracy: 0.2804\n",
      "Epoch 124/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2609 - accuracy: 0.2652 - val_loss: 2.2468 - val_accuracy: 0.2804\n",
      "Epoch 125/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2578 - accuracy: 0.2711 - val_loss: 2.2466 - val_accuracy: 0.2804\n",
      "Epoch 126/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2620 - accuracy: 0.2750 - val_loss: 2.2462 - val_accuracy: 0.2897\n",
      "Epoch 127/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2532 - accuracy: 0.2640 - val_loss: 2.2458 - val_accuracy: 0.2804\n",
      "Epoch 128/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2593 - accuracy: 0.2730 - val_loss: 2.2455 - val_accuracy: 0.2804\n",
      "Epoch 129/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2654 - accuracy: 0.2660 - val_loss: 2.2455 - val_accuracy: 0.2804\n",
      "Epoch 130/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2620 - accuracy: 0.2773 - val_loss: 2.2456 - val_accuracy: 0.2804\n",
      "Epoch 131/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2580 - accuracy: 0.2718 - val_loss: 2.2454 - val_accuracy: 0.2897\n",
      "Epoch 132/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2550 - accuracy: 0.2691 - val_loss: 2.2448 - val_accuracy: 0.2710\n",
      "Epoch 133/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2585 - accuracy: 0.2664 - val_loss: 2.2451 - val_accuracy: 0.2710\n",
      "Epoch 134/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2654 - accuracy: 0.2636 - val_loss: 2.2453 - val_accuracy: 0.2710\n",
      "Epoch 135/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2575 - accuracy: 0.2711 - val_loss: 2.2453 - val_accuracy: 0.2804\n",
      "Epoch 136/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2461 - accuracy: 0.2707 - val_loss: 2.2447 - val_accuracy: 0.2804\n",
      "Epoch 137/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2590 - accuracy: 0.2667 - val_loss: 2.2444 - val_accuracy: 0.2804\n",
      "Epoch 138/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2498 - accuracy: 0.2703 - val_loss: 2.2437 - val_accuracy: 0.2804\n",
      "Epoch 139/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2622 - accuracy: 0.2718 - val_loss: 2.2441 - val_accuracy: 0.2804\n",
      "Epoch 140/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2558 - accuracy: 0.2742 - val_loss: 2.2435 - val_accuracy: 0.2804\n",
      "Epoch 141/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2565 - accuracy: 0.2624 - val_loss: 2.2434 - val_accuracy: 0.2804\n",
      "Epoch 142/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2624 - accuracy: 0.2671 - val_loss: 2.2435 - val_accuracy: 0.2804\n",
      "Epoch 143/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2525 - accuracy: 0.2597 - val_loss: 2.2434 - val_accuracy: 0.2804\n",
      "Epoch 144/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2511 - accuracy: 0.2664 - val_loss: 2.2430 - val_accuracy: 0.2804\n",
      "Epoch 145/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2558 - accuracy: 0.2652 - val_loss: 2.2428 - val_accuracy: 0.2804\n",
      "Epoch 146/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2574 - accuracy: 0.2554 - val_loss: 2.2429 - val_accuracy: 0.2804\n",
      "Epoch 147/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2612 - accuracy: 0.2667 - val_loss: 2.2430 - val_accuracy: 0.2804\n",
      "Epoch 148/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2409 - accuracy: 0.2734 - val_loss: 2.2422 - val_accuracy: 0.2804\n",
      "Epoch 149/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2480 - accuracy: 0.2628 - val_loss: 2.2418 - val_accuracy: 0.2804\n",
      "Epoch 150/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2400 - accuracy: 0.2683 - val_loss: 2.2409 - val_accuracy: 0.2804\n",
      "Epoch 151/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2624 - accuracy: 0.2636 - val_loss: 2.2412 - val_accuracy: 0.2804\n",
      "Epoch 152/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2602 - accuracy: 0.2660 - val_loss: 2.2411 - val_accuracy: 0.2804\n",
      "Epoch 153/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2507 - accuracy: 0.2613 - val_loss: 2.2406 - val_accuracy: 0.2804\n",
      "Epoch 154/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2530 - accuracy: 0.2526 - val_loss: 2.2402 - val_accuracy: 0.2804\n",
      "Epoch 155/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2554 - accuracy: 0.2585 - val_loss: 2.2403 - val_accuracy: 0.2804\n",
      "Epoch 156/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2470 - accuracy: 0.2671 - val_loss: 2.2401 - val_accuracy: 0.2804\n",
      "Epoch 157/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2438 - accuracy: 0.2691 - val_loss: 2.2398 - val_accuracy: 0.2804\n",
      "Epoch 158/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2443 - accuracy: 0.2609 - val_loss: 2.2392 - val_accuracy: 0.2804\n",
      "Epoch 159/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2367 - accuracy: 0.2687 - val_loss: 2.2385 - val_accuracy: 0.2804\n",
      "Epoch 160/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2507 - accuracy: 0.2699 - val_loss: 2.2382 - val_accuracy: 0.2804\n",
      "Epoch 161/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2448 - accuracy: 0.2644 - val_loss: 2.2378 - val_accuracy: 0.2804\n",
      "Epoch 162/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2559 - accuracy: 0.2679 - val_loss: 2.2377 - val_accuracy: 0.2804\n",
      "Epoch 163/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2583 - accuracy: 0.2581 - val_loss: 2.2373 - val_accuracy: 0.2804\n",
      "Epoch 164/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2517 - accuracy: 0.2558 - val_loss: 2.2372 - val_accuracy: 0.2804\n",
      "Epoch 165/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2551 - accuracy: 0.2577 - val_loss: 2.2366 - val_accuracy: 0.2617\n",
      "Epoch 166/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2440 - accuracy: 0.2687 - val_loss: 2.2356 - val_accuracy: 0.2617\n",
      "Epoch 167/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2559 - accuracy: 0.2577 - val_loss: 2.2353 - val_accuracy: 0.2617\n",
      "Epoch 168/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2550 - accuracy: 0.2515 - val_loss: 2.2351 - val_accuracy: 0.2617\n",
      "Epoch 169/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2528 - accuracy: 0.2581 - val_loss: 2.2352 - val_accuracy: 0.2617\n",
      "Epoch 170/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2471 - accuracy: 0.2550 - val_loss: 2.2345 - val_accuracy: 0.2617\n",
      "Epoch 171/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2444 - accuracy: 0.2562 - val_loss: 2.2334 - val_accuracy: 0.2617\n",
      "Epoch 172/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2554 - accuracy: 0.2570 - val_loss: 2.2331 - val_accuracy: 0.2617\n",
      "Epoch 173/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2339 - accuracy: 0.2526 - val_loss: 2.2322 - val_accuracy: 0.2617\n",
      "Epoch 174/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2518 - accuracy: 0.2636 - val_loss: 2.2319 - val_accuracy: 0.2617\n",
      "Epoch 175/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2406 - accuracy: 0.2570 - val_loss: 2.2312 - val_accuracy: 0.2430\n",
      "Epoch 176/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2539 - accuracy: 0.2542 - val_loss: 2.2313 - val_accuracy: 0.2336\n",
      "Epoch 177/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2423 - accuracy: 0.2644 - val_loss: 2.2309 - val_accuracy: 0.2336\n",
      "Epoch 178/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2403 - accuracy: 0.2683 - val_loss: 2.2301 - val_accuracy: 0.2336\n",
      "Epoch 179/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2429 - accuracy: 0.2613 - val_loss: 2.2298 - val_accuracy: 0.2336\n",
      "Epoch 180/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2590 - accuracy: 0.2613 - val_loss: 2.2300 - val_accuracy: 0.2243\n",
      "Epoch 181/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2477 - accuracy: 0.2609 - val_loss: 2.2295 - val_accuracy: 0.2243\n",
      "Epoch 182/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2429 - accuracy: 0.2585 - val_loss: 2.2288 - val_accuracy: 0.2243\n",
      "Epoch 183/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2402 - accuracy: 0.2640 - val_loss: 2.2282 - val_accuracy: 0.2243\n",
      "Epoch 184/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2493 - accuracy: 0.2589 - val_loss: 2.2275 - val_accuracy: 0.2243\n",
      "Epoch 185/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2393 - accuracy: 0.2609 - val_loss: 2.2270 - val_accuracy: 0.2243\n",
      "Epoch 186/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2402 - accuracy: 0.2605 - val_loss: 2.2262 - val_accuracy: 0.2243\n",
      "Epoch 187/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2458 - accuracy: 0.2581 - val_loss: 2.2254 - val_accuracy: 0.2243\n",
      "Epoch 188/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2425 - accuracy: 0.2538 - val_loss: 2.2246 - val_accuracy: 0.2243\n",
      "Epoch 189/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2372 - accuracy: 0.2601 - val_loss: 2.2243 - val_accuracy: 0.2243\n",
      "Epoch 190/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2401 - accuracy: 0.2648 - val_loss: 2.2239 - val_accuracy: 0.2243\n",
      "Epoch 191/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2447 - accuracy: 0.2601 - val_loss: 2.2235 - val_accuracy: 0.2150\n",
      "Epoch 192/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2433 - accuracy: 0.2597 - val_loss: 2.2229 - val_accuracy: 0.2150\n",
      "Epoch 193/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2487 - accuracy: 0.2667 - val_loss: 2.2225 - val_accuracy: 0.2056\n",
      "Epoch 194/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2245 - accuracy: 0.2691 - val_loss: 2.2216 - val_accuracy: 0.2150\n",
      "Epoch 195/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2362 - accuracy: 0.2691 - val_loss: 2.2205 - val_accuracy: 0.2150\n",
      "Epoch 196/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2429 - accuracy: 0.2648 - val_loss: 2.2203 - val_accuracy: 0.2150\n",
      "Epoch 197/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2307 - accuracy: 0.2597 - val_loss: 2.2198 - val_accuracy: 0.2243\n",
      "Epoch 198/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2346 - accuracy: 0.2636 - val_loss: 2.2188 - val_accuracy: 0.2243\n",
      "Epoch 199/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2438 - accuracy: 0.2581 - val_loss: 2.2190 - val_accuracy: 0.2150\n",
      "Epoch 200/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2477 - accuracy: 0.2530 - val_loss: 2.2187 - val_accuracy: 0.2243\n",
      "0.22429905831813812 {'loss': 2.2476909160614014, 'accuracy': 0.25303563475608826, 'val_loss': 2.218731641769409, 'val_accuracy': 0.22429905831813812}\n",
      "Model: \"model_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_16 (InputLayer)        [(None, 29)]              0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 41)                1230      \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 10)                420       \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,870\n",
      "Trainable params: 1,870\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 3.1714 - accuracy: 0.1387 - val_loss: 2.4905 - val_accuracy: 0.0187\n",
      "Epoch 2/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.0826 - accuracy: 0.1312 - val_loss: 2.4654 - val_accuracy: 0.0280\n",
      "Epoch 3/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.0432 - accuracy: 0.1481 - val_loss: 2.4436 - val_accuracy: 0.0374\n",
      "Epoch 4/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.9382 - accuracy: 0.1434 - val_loss: 2.4234 - val_accuracy: 0.0374\n",
      "Epoch 5/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.9378 - accuracy: 0.1488 - val_loss: 2.4036 - val_accuracy: 0.0374\n",
      "Epoch 6/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.8688 - accuracy: 0.1441 - val_loss: 2.3850 - val_accuracy: 0.0374\n",
      "Epoch 7/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.8497 - accuracy: 0.1434 - val_loss: 2.3664 - val_accuracy: 0.0374\n",
      "Epoch 8/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.7989 - accuracy: 0.1398 - val_loss: 2.3488 - val_accuracy: 0.0374\n",
      "Epoch 9/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.7677 - accuracy: 0.1363 - val_loss: 2.3325 - val_accuracy: 0.0374\n",
      "Epoch 10/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.6957 - accuracy: 0.1488 - val_loss: 2.3181 - val_accuracy: 0.0374\n",
      "Epoch 11/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.6573 - accuracy: 0.1516 - val_loss: 2.3034 - val_accuracy: 0.0467\n",
      "Epoch 12/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.6493 - accuracy: 0.1453 - val_loss: 2.2901 - val_accuracy: 0.0467\n",
      "Epoch 13/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5865 - accuracy: 0.1645 - val_loss: 2.2767 - val_accuracy: 0.0561\n",
      "Epoch 14/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5570 - accuracy: 0.1767 - val_loss: 2.2638 - val_accuracy: 0.0561\n",
      "Epoch 15/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.5451 - accuracy: 0.1559 - val_loss: 2.2530 - val_accuracy: 0.0654\n",
      "Epoch 16/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5322 - accuracy: 0.1665 - val_loss: 2.2424 - val_accuracy: 0.0748\n",
      "Epoch 17/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4929 - accuracy: 0.1735 - val_loss: 2.2328 - val_accuracy: 0.0841\n",
      "Epoch 18/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4914 - accuracy: 0.1731 - val_loss: 2.2231 - val_accuracy: 0.1121\n",
      "Epoch 19/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4727 - accuracy: 0.1849 - val_loss: 2.2136 - val_accuracy: 0.1215\n",
      "Epoch 20/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4187 - accuracy: 0.1896 - val_loss: 2.2045 - val_accuracy: 0.1308\n",
      "Epoch 21/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4214 - accuracy: 0.1900 - val_loss: 2.1954 - val_accuracy: 0.1402\n",
      "Epoch 22/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4018 - accuracy: 0.1974 - val_loss: 2.1885 - val_accuracy: 0.1402\n",
      "Epoch 23/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3727 - accuracy: 0.2060 - val_loss: 2.1807 - val_accuracy: 0.1402\n",
      "Epoch 24/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3794 - accuracy: 0.1966 - val_loss: 2.1742 - val_accuracy: 0.1402\n",
      "Epoch 25/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3678 - accuracy: 0.2013 - val_loss: 2.1679 - val_accuracy: 0.1495\n",
      "Epoch 26/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3392 - accuracy: 0.2143 - val_loss: 2.1627 - val_accuracy: 0.1682\n",
      "Epoch 27/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3244 - accuracy: 0.2201 - val_loss: 2.1573 - val_accuracy: 0.1869\n",
      "Epoch 28/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3282 - accuracy: 0.2135 - val_loss: 2.1515 - val_accuracy: 0.2056\n",
      "Epoch 29/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3157 - accuracy: 0.2209 - val_loss: 2.1461 - val_accuracy: 0.2056\n",
      "Epoch 30/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2979 - accuracy: 0.2158 - val_loss: 2.1418 - val_accuracy: 0.2150\n",
      "Epoch 31/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3038 - accuracy: 0.2221 - val_loss: 2.1371 - val_accuracy: 0.2150\n",
      "Epoch 32/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2926 - accuracy: 0.2260 - val_loss: 2.1321 - val_accuracy: 0.2430\n",
      "Epoch 33/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2794 - accuracy: 0.2241 - val_loss: 2.1272 - val_accuracy: 0.2523\n",
      "Epoch 34/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2971 - accuracy: 0.2237 - val_loss: 2.1234 - val_accuracy: 0.2523\n",
      "Epoch 35/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2720 - accuracy: 0.2221 - val_loss: 2.1191 - val_accuracy: 0.2617\n",
      "Epoch 36/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2802 - accuracy: 0.2291 - val_loss: 2.1146 - val_accuracy: 0.2523\n",
      "Epoch 37/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2717 - accuracy: 0.2327 - val_loss: 2.1109 - val_accuracy: 0.2804\n",
      "Epoch 38/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2727 - accuracy: 0.2299 - val_loss: 2.1065 - val_accuracy: 0.2897\n",
      "Epoch 39/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2550 - accuracy: 0.2291 - val_loss: 2.1033 - val_accuracy: 0.2897\n",
      "Epoch 40/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2524 - accuracy: 0.2307 - val_loss: 2.0998 - val_accuracy: 0.3178\n",
      "Epoch 41/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2299 - accuracy: 0.2432 - val_loss: 2.0959 - val_accuracy: 0.3364\n",
      "Epoch 42/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2634 - accuracy: 0.2366 - val_loss: 2.0920 - val_accuracy: 0.3458\n",
      "Epoch 43/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2336 - accuracy: 0.2452 - val_loss: 2.0885 - val_accuracy: 0.3645\n",
      "Epoch 44/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2427 - accuracy: 0.2487 - val_loss: 2.0851 - val_accuracy: 0.3832\n",
      "Epoch 45/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2062 - accuracy: 0.2511 - val_loss: 2.0805 - val_accuracy: 0.3832\n",
      "Epoch 46/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2321 - accuracy: 0.2570 - val_loss: 2.0772 - val_accuracy: 0.3925\n",
      "Epoch 47/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2334 - accuracy: 0.2479 - val_loss: 2.0742 - val_accuracy: 0.3925\n",
      "Epoch 48/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2072 - accuracy: 0.2577 - val_loss: 2.0703 - val_accuracy: 0.3925\n",
      "Epoch 49/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2149 - accuracy: 0.2432 - val_loss: 2.0658 - val_accuracy: 0.4019\n",
      "Epoch 50/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2105 - accuracy: 0.2613 - val_loss: 2.0614 - val_accuracy: 0.4112\n",
      "Epoch 51/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2072 - accuracy: 0.2609 - val_loss: 2.0583 - val_accuracy: 0.4112\n",
      "Epoch 52/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2074 - accuracy: 0.2624 - val_loss: 2.0556 - val_accuracy: 0.4112\n",
      "Epoch 53/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1892 - accuracy: 0.2667 - val_loss: 2.0519 - val_accuracy: 0.4112\n",
      "Epoch 54/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1746 - accuracy: 0.2816 - val_loss: 2.0479 - val_accuracy: 0.4206\n",
      "Epoch 55/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1949 - accuracy: 0.2750 - val_loss: 2.0442 - val_accuracy: 0.4299\n",
      "Epoch 56/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1906 - accuracy: 0.2730 - val_loss: 2.0411 - val_accuracy: 0.4206\n",
      "Epoch 57/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.1917 - accuracy: 0.2683 - val_loss: 2.0385 - val_accuracy: 0.4299\n",
      "Epoch 58/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1946 - accuracy: 0.2581 - val_loss: 2.0357 - val_accuracy: 0.4299\n",
      "Epoch 59/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1652 - accuracy: 0.2812 - val_loss: 2.0320 - val_accuracy: 0.4299\n",
      "Epoch 60/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1784 - accuracy: 0.2789 - val_loss: 2.0283 - val_accuracy: 0.4393\n",
      "Epoch 61/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1500 - accuracy: 0.2953 - val_loss: 2.0240 - val_accuracy: 0.4579\n",
      "Epoch 62/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1612 - accuracy: 0.2789 - val_loss: 2.0208 - val_accuracy: 0.4673\n",
      "Epoch 63/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 2.1439 - accuracy: 0.2910 - val_loss: 2.0174 - val_accuracy: 0.4766\n",
      "Epoch 64/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1594 - accuracy: 0.2773 - val_loss: 2.0146 - val_accuracy: 0.4766\n",
      "Epoch 65/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1586 - accuracy: 0.2879 - val_loss: 2.0117 - val_accuracy: 0.4766\n",
      "Epoch 66/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1749 - accuracy: 0.2722 - val_loss: 2.0095 - val_accuracy: 0.4766\n",
      "Epoch 67/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1366 - accuracy: 0.2953 - val_loss: 2.0063 - val_accuracy: 0.4673\n",
      "Epoch 68/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1437 - accuracy: 0.2938 - val_loss: 2.0024 - val_accuracy: 0.4766\n",
      "Epoch 69/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1419 - accuracy: 0.2867 - val_loss: 1.9997 - val_accuracy: 0.4766\n",
      "Epoch 70/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1431 - accuracy: 0.2875 - val_loss: 1.9973 - val_accuracy: 0.4673\n",
      "Epoch 71/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.1552 - accuracy: 0.2832 - val_loss: 1.9954 - val_accuracy: 0.4766\n",
      "Epoch 72/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1487 - accuracy: 0.2765 - val_loss: 1.9934 - val_accuracy: 0.4766\n",
      "Epoch 73/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1572 - accuracy: 0.2902 - val_loss: 1.9919 - val_accuracy: 0.4766\n",
      "Epoch 74/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1502 - accuracy: 0.2910 - val_loss: 1.9897 - val_accuracy: 0.4860\n",
      "Epoch 75/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1543 - accuracy: 0.2793 - val_loss: 1.9885 - val_accuracy: 0.4953\n",
      "Epoch 76/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1503 - accuracy: 0.2867 - val_loss: 1.9864 - val_accuracy: 0.4953\n",
      "Epoch 77/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1225 - accuracy: 0.2996 - val_loss: 1.9830 - val_accuracy: 0.5047\n",
      "Epoch 78/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1382 - accuracy: 0.2942 - val_loss: 1.9806 - val_accuracy: 0.4860\n",
      "Epoch 79/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1377 - accuracy: 0.2887 - val_loss: 1.9791 - val_accuracy: 0.4860\n",
      "Epoch 80/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1275 - accuracy: 0.2996 - val_loss: 1.9774 - val_accuracy: 0.4860\n",
      "Epoch 81/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1495 - accuracy: 0.2769 - val_loss: 1.9757 - val_accuracy: 0.5047\n",
      "Epoch 82/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1387 - accuracy: 0.2828 - val_loss: 1.9741 - val_accuracy: 0.5047\n",
      "Epoch 83/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1444 - accuracy: 0.2859 - val_loss: 1.9721 - val_accuracy: 0.5047\n",
      "Epoch 84/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1219 - accuracy: 0.2957 - val_loss: 1.9699 - val_accuracy: 0.5047\n",
      "Epoch 85/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1344 - accuracy: 0.2926 - val_loss: 1.9683 - val_accuracy: 0.4953\n",
      "Epoch 86/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1457 - accuracy: 0.2867 - val_loss: 1.9667 - val_accuracy: 0.5047\n",
      "Epoch 87/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1300 - accuracy: 0.2902 - val_loss: 1.9643 - val_accuracy: 0.5047\n",
      "Epoch 88/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1397 - accuracy: 0.2879 - val_loss: 1.9632 - val_accuracy: 0.5047\n",
      "Epoch 89/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1134 - accuracy: 0.3110 - val_loss: 1.9610 - val_accuracy: 0.5140\n",
      "Epoch 90/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1496 - accuracy: 0.2871 - val_loss: 1.9594 - val_accuracy: 0.5140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1215 - accuracy: 0.2922 - val_loss: 1.9576 - val_accuracy: 0.5140\n",
      "Epoch 92/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1247 - accuracy: 0.3012 - val_loss: 1.9557 - val_accuracy: 0.5047\n",
      "Epoch 93/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1075 - accuracy: 0.3079 - val_loss: 1.9529 - val_accuracy: 0.5047\n",
      "Epoch 94/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1179 - accuracy: 0.3051 - val_loss: 1.9508 - val_accuracy: 0.5047\n",
      "Epoch 95/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1209 - accuracy: 0.2938 - val_loss: 1.9491 - val_accuracy: 0.5140\n",
      "Epoch 96/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1113 - accuracy: 0.2981 - val_loss: 1.9479 - val_accuracy: 0.5140\n",
      "Epoch 97/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1058 - accuracy: 0.3114 - val_loss: 1.9464 - val_accuracy: 0.5140\n",
      "Epoch 98/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1143 - accuracy: 0.3024 - val_loss: 1.9443 - val_accuracy: 0.5140\n",
      "Epoch 99/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1362 - accuracy: 0.3008 - val_loss: 1.9433 - val_accuracy: 0.5140\n",
      "Epoch 100/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1260 - accuracy: 0.2993 - val_loss: 1.9428 - val_accuracy: 0.5140\n",
      "Epoch 101/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1062 - accuracy: 0.3181 - val_loss: 1.9416 - val_accuracy: 0.5140\n",
      "Epoch 102/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1072 - accuracy: 0.3079 - val_loss: 1.9395 - val_accuracy: 0.5140\n",
      "Epoch 103/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1080 - accuracy: 0.3118 - val_loss: 1.9375 - val_accuracy: 0.5140\n",
      "Epoch 104/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1134 - accuracy: 0.3028 - val_loss: 1.9361 - val_accuracy: 0.5234\n",
      "Epoch 105/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0939 - accuracy: 0.3235 - val_loss: 1.9346 - val_accuracy: 0.5234\n",
      "Epoch 106/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1039 - accuracy: 0.3059 - val_loss: 1.9335 - val_accuracy: 0.5234\n",
      "Epoch 107/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0863 - accuracy: 0.3173 - val_loss: 1.9307 - val_accuracy: 0.5140\n",
      "Epoch 108/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1189 - accuracy: 0.3036 - val_loss: 1.9314 - val_accuracy: 0.5234\n",
      "Epoch 109/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1183 - accuracy: 0.3055 - val_loss: 1.9306 - val_accuracy: 0.5234\n",
      "Epoch 110/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1059 - accuracy: 0.3098 - val_loss: 1.9292 - val_accuracy: 0.5234\n",
      "Epoch 111/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0973 - accuracy: 0.3157 - val_loss: 1.9285 - val_accuracy: 0.5234\n",
      "Epoch 112/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1359 - accuracy: 0.2914 - val_loss: 1.9291 - val_accuracy: 0.5234\n",
      "Epoch 113/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1029 - accuracy: 0.3165 - val_loss: 1.9266 - val_accuracy: 0.5234\n",
      "Epoch 114/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0962 - accuracy: 0.3255 - val_loss: 1.9254 - val_accuracy: 0.5047\n",
      "Epoch 115/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0952 - accuracy: 0.3118 - val_loss: 1.9236 - val_accuracy: 0.5047\n",
      "Epoch 116/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1119 - accuracy: 0.3087 - val_loss: 1.9242 - val_accuracy: 0.5140\n",
      "Epoch 117/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.0887 - accuracy: 0.3255 - val_loss: 1.9226 - val_accuracy: 0.5047\n",
      "Epoch 118/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0789 - accuracy: 0.3325 - val_loss: 1.9199 - val_accuracy: 0.5140\n",
      "Epoch 119/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0946 - accuracy: 0.3141 - val_loss: 1.9191 - val_accuracy: 0.5047\n",
      "Epoch 120/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0890 - accuracy: 0.3212 - val_loss: 1.9170 - val_accuracy: 0.5047\n",
      "Epoch 121/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1251 - accuracy: 0.3055 - val_loss: 1.9182 - val_accuracy: 0.5047\n",
      "Epoch 122/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0912 - accuracy: 0.3114 - val_loss: 1.9170 - val_accuracy: 0.5047\n",
      "Epoch 123/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1010 - accuracy: 0.3157 - val_loss: 1.9169 - val_accuracy: 0.5140\n",
      "Epoch 124/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0977 - accuracy: 0.3165 - val_loss: 1.9167 - val_accuracy: 0.5140\n",
      "Epoch 125/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1148 - accuracy: 0.3055 - val_loss: 1.9158 - val_accuracy: 0.5234\n",
      "Epoch 126/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0799 - accuracy: 0.3282 - val_loss: 1.9144 - val_accuracy: 0.5234\n",
      "Epoch 127/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1112 - accuracy: 0.3126 - val_loss: 1.9140 - val_accuracy: 0.5140\n",
      "Epoch 128/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1044 - accuracy: 0.3153 - val_loss: 1.9143 - val_accuracy: 0.5140\n",
      "Epoch 129/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1010 - accuracy: 0.3216 - val_loss: 1.9138 - val_accuracy: 0.5140\n",
      "Epoch 130/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0808 - accuracy: 0.3310 - val_loss: 1.9126 - val_accuracy: 0.5047\n",
      "Epoch 131/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0501 - accuracy: 0.3412 - val_loss: 1.9100 - val_accuracy: 0.5047\n",
      "Epoch 132/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1059 - accuracy: 0.3161 - val_loss: 1.9096 - val_accuracy: 0.5140\n",
      "Epoch 133/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1031 - accuracy: 0.3122 - val_loss: 1.9094 - val_accuracy: 0.5140\n",
      "Epoch 134/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1130 - accuracy: 0.3173 - val_loss: 1.9097 - val_accuracy: 0.5047\n",
      "Epoch 135/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1002 - accuracy: 0.3208 - val_loss: 1.9093 - val_accuracy: 0.5047\n",
      "Epoch 136/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0908 - accuracy: 0.3286 - val_loss: 1.9072 - val_accuracy: 0.5047\n",
      "Epoch 137/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0780 - accuracy: 0.3278 - val_loss: 1.9063 - val_accuracy: 0.5140\n",
      "Epoch 138/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0752 - accuracy: 0.3243 - val_loss: 1.9054 - val_accuracy: 0.5047\n",
      "Epoch 139/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0715 - accuracy: 0.3345 - val_loss: 1.9029 - val_accuracy: 0.5140\n",
      "Epoch 140/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0955 - accuracy: 0.3220 - val_loss: 1.9018 - val_accuracy: 0.5140\n",
      "Epoch 141/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1067 - accuracy: 0.3114 - val_loss: 1.9031 - val_accuracy: 0.5140\n",
      "Epoch 142/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.0869 - accuracy: 0.3255 - val_loss: 1.9030 - val_accuracy: 0.5140\n",
      "Epoch 143/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 2.0969 - accuracy: 0.3259 - val_loss: 1.9022 - val_accuracy: 0.5140\n",
      "Epoch 144/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0879 - accuracy: 0.3141 - val_loss: 1.9027 - val_accuracy: 0.5140\n",
      "Epoch 145/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.0833 - accuracy: 0.3251 - val_loss: 1.9013 - val_accuracy: 0.5140\n",
      "Epoch 146/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.0901 - accuracy: 0.3267 - val_loss: 1.9007 - val_accuracy: 0.5140\n",
      "Epoch 147/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.0866 - accuracy: 0.3184 - val_loss: 1.9005 - val_accuracy: 0.5140\n",
      "Epoch 148/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 3ms/step - loss: 2.0726 - accuracy: 0.3239 - val_loss: 1.8996 - val_accuracy: 0.5140\n",
      "Epoch 149/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.0855 - accuracy: 0.3251 - val_loss: 1.8994 - val_accuracy: 0.5140\n",
      "Epoch 150/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.1066 - accuracy: 0.3235 - val_loss: 1.9008 - val_accuracy: 0.5234\n",
      "Epoch 151/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0658 - accuracy: 0.3349 - val_loss: 1.8990 - val_accuracy: 0.5234\n",
      "Epoch 152/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.0629 - accuracy: 0.3322 - val_loss: 1.8978 - val_accuracy: 0.5234\n",
      "Epoch 153/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0992 - accuracy: 0.3290 - val_loss: 1.8973 - val_accuracy: 0.5234\n",
      "Epoch 154/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0907 - accuracy: 0.3322 - val_loss: 1.8971 - val_accuracy: 0.5234\n",
      "Epoch 155/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0847 - accuracy: 0.3130 - val_loss: 1.8964 - val_accuracy: 0.5234\n",
      "Epoch 156/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0739 - accuracy: 0.3474 - val_loss: 1.8949 - val_accuracy: 0.5234\n",
      "Epoch 157/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1102 - accuracy: 0.3212 - val_loss: 1.8957 - val_accuracy: 0.5234\n",
      "Epoch 158/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0675 - accuracy: 0.3388 - val_loss: 1.8955 - val_accuracy: 0.5234\n",
      "Epoch 159/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0857 - accuracy: 0.3306 - val_loss: 1.8952 - val_accuracy: 0.5234\n",
      "Epoch 160/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0874 - accuracy: 0.3325 - val_loss: 1.8952 - val_accuracy: 0.5234\n",
      "Epoch 161/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0969 - accuracy: 0.3200 - val_loss: 1.8947 - val_accuracy: 0.5234\n",
      "Epoch 162/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0771 - accuracy: 0.3345 - val_loss: 1.8936 - val_accuracy: 0.5234\n",
      "Epoch 163/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0726 - accuracy: 0.3357 - val_loss: 1.8931 - val_accuracy: 0.5234\n",
      "Epoch 164/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0780 - accuracy: 0.3396 - val_loss: 1.8925 - val_accuracy: 0.5234\n",
      "Epoch 165/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1056 - accuracy: 0.3204 - val_loss: 1.8932 - val_accuracy: 0.5234\n",
      "Epoch 166/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0864 - accuracy: 0.3247 - val_loss: 1.8927 - val_accuracy: 0.5234\n",
      "Epoch 167/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0641 - accuracy: 0.3423 - val_loss: 1.8908 - val_accuracy: 0.5234\n",
      "Epoch 168/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0680 - accuracy: 0.3314 - val_loss: 1.8899 - val_accuracy: 0.5234\n",
      "Epoch 169/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0860 - accuracy: 0.3325 - val_loss: 1.8895 - val_accuracy: 0.5234\n",
      "Epoch 170/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0517 - accuracy: 0.3557 - val_loss: 1.8874 - val_accuracy: 0.5234\n",
      "Epoch 171/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0674 - accuracy: 0.3369 - val_loss: 1.8868 - val_accuracy: 0.5234\n",
      "Epoch 172/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1013 - accuracy: 0.3255 - val_loss: 1.8875 - val_accuracy: 0.5234\n",
      "Epoch 173/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0850 - accuracy: 0.3278 - val_loss: 1.8878 - val_accuracy: 0.5234\n",
      "Epoch 174/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0999 - accuracy: 0.3263 - val_loss: 1.8877 - val_accuracy: 0.5234\n",
      "Epoch 175/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0783 - accuracy: 0.3275 - val_loss: 1.8872 - val_accuracy: 0.5234\n",
      "Epoch 176/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0700 - accuracy: 0.3290 - val_loss: 1.8867 - val_accuracy: 0.5234\n",
      "Epoch 177/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0669 - accuracy: 0.3486 - val_loss: 1.8859 - val_accuracy: 0.5234\n",
      "Epoch 178/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0864 - accuracy: 0.3169 - val_loss: 1.8856 - val_accuracy: 0.5234\n",
      "Epoch 179/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0801 - accuracy: 0.3427 - val_loss: 1.8853 - val_accuracy: 0.5234\n",
      "Epoch 180/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0929 - accuracy: 0.3231 - val_loss: 1.8871 - val_accuracy: 0.5234\n",
      "Epoch 181/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0869 - accuracy: 0.3314 - val_loss: 1.8873 - val_accuracy: 0.5234\n",
      "Epoch 182/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1021 - accuracy: 0.3271 - val_loss: 1.8885 - val_accuracy: 0.5234\n",
      "Epoch 183/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0609 - accuracy: 0.3416 - val_loss: 1.8869 - val_accuracy: 0.5234\n",
      "Epoch 184/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0836 - accuracy: 0.3314 - val_loss: 1.8872 - val_accuracy: 0.5234\n",
      "Epoch 185/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0796 - accuracy: 0.3396 - val_loss: 1.8878 - val_accuracy: 0.5234\n",
      "Epoch 186/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0783 - accuracy: 0.3345 - val_loss: 1.8878 - val_accuracy: 0.5234\n",
      "Epoch 187/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0778 - accuracy: 0.3259 - val_loss: 1.8870 - val_accuracy: 0.5234\n",
      "Epoch 188/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0932 - accuracy: 0.3208 - val_loss: 1.8881 - val_accuracy: 0.5234\n",
      "Epoch 189/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0643 - accuracy: 0.3443 - val_loss: 1.8869 - val_accuracy: 0.5234\n",
      "Epoch 190/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0612 - accuracy: 0.3388 - val_loss: 1.8864 - val_accuracy: 0.5234\n",
      "Epoch 191/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1019 - accuracy: 0.3259 - val_loss: 1.8864 - val_accuracy: 0.5234\n",
      "Epoch 192/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0687 - accuracy: 0.3325 - val_loss: 1.8872 - val_accuracy: 0.5234\n",
      "Epoch 193/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1034 - accuracy: 0.3184 - val_loss: 1.8882 - val_accuracy: 0.5234\n",
      "Epoch 194/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0734 - accuracy: 0.3325 - val_loss: 1.8877 - val_accuracy: 0.5234\n",
      "Epoch 195/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0562 - accuracy: 0.3376 - val_loss: 1.8861 - val_accuracy: 0.5234\n",
      "Epoch 196/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0954 - accuracy: 0.3200 - val_loss: 1.8865 - val_accuracy: 0.5234\n",
      "Epoch 197/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0654 - accuracy: 0.3388 - val_loss: 1.8880 - val_accuracy: 0.5234\n",
      "Epoch 198/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0684 - accuracy: 0.3514 - val_loss: 1.8872 - val_accuracy: 0.5234\n",
      "Epoch 199/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0780 - accuracy: 0.3384 - val_loss: 1.8860 - val_accuracy: 0.5234\n",
      "Epoch 200/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0935 - accuracy: 0.3314 - val_loss: 1.8869 - val_accuracy: 0.5234\n",
      "0.5233644843101501 {'loss': 2.0935239791870117, 'accuracy': 0.331374853849411, 'val_loss': 1.8868650197982788, 'val_accuracy': 0.5233644843101501}\n",
      "Model: \"model_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_17 (InputLayer)        [(None, 29)]              0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 41)                1230      \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 75)                3150      \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 75)                0         \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 75)                0         \n",
      "=================================================================\n",
      "Total params: 4,380\n",
      "Trainable params: 4,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 2ms/step - loss: 4.6877 - accuracy: 0.0024 - val_loss: 4.7916 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.6788 - accuracy: 0.0024 - val_loss: 4.7835 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.6700 - accuracy: 0.0024 - val_loss: 4.7755 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.6612 - accuracy: 0.0024 - val_loss: 4.7675 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.6523 - accuracy: 0.0024 - val_loss: 4.7595 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.6435 - accuracy: 0.0031 - val_loss: 4.7515 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.6347 - accuracy: 0.0031 - val_loss: 4.7435 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.6258 - accuracy: 0.0031 - val_loss: 4.7355 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.6170 - accuracy: 0.0031 - val_loss: 4.7275 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.6081 - accuracy: 0.0035 - val_loss: 4.7195 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.5993 - accuracy: 0.0035 - val_loss: 4.7115 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.5904 - accuracy: 0.0035 - val_loss: 4.7035 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.5816 - accuracy: 0.0035 - val_loss: 4.6956 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.5728 - accuracy: 0.0035 - val_loss: 4.6876 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.5640 - accuracy: 0.0035 - val_loss: 4.6797 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.5552 - accuracy: 0.0039 - val_loss: 4.6717 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.5464 - accuracy: 0.0039 - val_loss: 4.6638 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.5375 - accuracy: 0.0039 - val_loss: 4.6559 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.5287 - accuracy: 0.0039 - val_loss: 4.6479 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.5199 - accuracy: 0.0039 - val_loss: 4.6400 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.5110 - accuracy: 0.0039 - val_loss: 4.6321 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.5022 - accuracy: 0.0047 - val_loss: 4.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.4933 - accuracy: 0.0047 - val_loss: 4.6164 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.4845 - accuracy: 0.0055 - val_loss: 4.6085 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.4756 - accuracy: 0.0055 - val_loss: 4.6007 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.4668 - accuracy: 0.0055 - val_loss: 4.5929 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.4579 - accuracy: 0.0063 - val_loss: 4.5851 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.4491 - accuracy: 0.0063 - val_loss: 4.5774 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.4402 - accuracy: 0.0063 - val_loss: 4.5696 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.4314 - accuracy: 0.0067 - val_loss: 4.5619 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.4226 - accuracy: 0.0067 - val_loss: 4.5542 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.4137 - accuracy: 0.0067 - val_loss: 4.5466 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.4049 - accuracy: 0.0067 - val_loss: 4.5387 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.3961 - accuracy: 0.0067 - val_loss: 4.5309 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.3872 - accuracy: 0.0071 - val_loss: 4.5230 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.3784 - accuracy: 0.0078 - val_loss: 4.5151 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.3696 - accuracy: 0.0078 - val_loss: 4.5070 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.3607 - accuracy: 0.0082 - val_loss: 4.4990 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.3519 - accuracy: 0.0086 - val_loss: 4.4909 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.3430 - accuracy: 0.0086 - val_loss: 4.4828 - val_accuracy: 0.0093\n",
      "Epoch 41/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.3341 - accuracy: 0.0086 - val_loss: 4.4747 - val_accuracy: 0.0187\n",
      "Epoch 42/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.3252 - accuracy: 0.0090 - val_loss: 4.4666 - val_accuracy: 0.0187\n",
      "Epoch 43/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.3163 - accuracy: 0.0098 - val_loss: 4.4585 - val_accuracy: 0.0187\n",
      "Epoch 44/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.3074 - accuracy: 0.0106 - val_loss: 4.4504 - val_accuracy: 0.0187\n",
      "Epoch 45/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.2984 - accuracy: 0.0118 - val_loss: 4.4423 - val_accuracy: 0.0187\n",
      "Epoch 46/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.2895 - accuracy: 0.0125 - val_loss: 4.4343 - val_accuracy: 0.0187\n",
      "Epoch 47/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.2805 - accuracy: 0.0129 - val_loss: 4.4263 - val_accuracy: 0.0187\n",
      "Epoch 48/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.2716 - accuracy: 0.0145 - val_loss: 4.4183 - val_accuracy: 0.0187\n",
      "Epoch 49/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.2626 - accuracy: 0.0149 - val_loss: 4.4102 - val_accuracy: 0.0187\n",
      "Epoch 50/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.2536 - accuracy: 0.0157 - val_loss: 4.4023 - val_accuracy: 0.0187\n",
      "Epoch 51/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.2447 - accuracy: 0.0168 - val_loss: 4.3942 - val_accuracy: 0.0187\n",
      "Epoch 52/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.2356 - accuracy: 0.0172 - val_loss: 4.3860 - val_accuracy: 0.0187\n",
      "Epoch 53/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.2265 - accuracy: 0.0172 - val_loss: 4.3778 - val_accuracy: 0.0187\n",
      "Epoch 54/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.2175 - accuracy: 0.0176 - val_loss: 4.3694 - val_accuracy: 0.0187\n",
      "Epoch 55/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.2084 - accuracy: 0.0176 - val_loss: 4.3610 - val_accuracy: 0.0280\n",
      "Epoch 56/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.1993 - accuracy: 0.0192 - val_loss: 4.3526 - val_accuracy: 0.0280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.1903 - accuracy: 0.0200 - val_loss: 4.3443 - val_accuracy: 0.0280\n",
      "Epoch 58/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.1812 - accuracy: 0.0215 - val_loss: 4.3359 - val_accuracy: 0.0280\n",
      "Epoch 59/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.1722 - accuracy: 0.0235 - val_loss: 4.3276 - val_accuracy: 0.0280\n",
      "Epoch 60/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.1632 - accuracy: 0.0239 - val_loss: 4.3191 - val_accuracy: 0.0280\n",
      "Epoch 61/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.1541 - accuracy: 0.0243 - val_loss: 4.3107 - val_accuracy: 0.0280\n",
      "Epoch 62/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.1450 - accuracy: 0.0251 - val_loss: 4.3023 - val_accuracy: 0.0280\n",
      "Epoch 63/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.1359 - accuracy: 0.0266 - val_loss: 4.2938 - val_accuracy: 0.0280\n",
      "Epoch 64/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.1266 - accuracy: 0.0274 - val_loss: 4.2854 - val_accuracy: 0.0280\n",
      "Epoch 65/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.1174 - accuracy: 0.0290 - val_loss: 4.2769 - val_accuracy: 0.0280\n",
      "Epoch 66/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.1082 - accuracy: 0.0302 - val_loss: 4.2686 - val_accuracy: 0.0280\n",
      "Epoch 67/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.0989 - accuracy: 0.0313 - val_loss: 4.2601 - val_accuracy: 0.0374\n",
      "Epoch 68/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.0895 - accuracy: 0.0333 - val_loss: 4.2517 - val_accuracy: 0.0374\n",
      "Epoch 69/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.0802 - accuracy: 0.0341 - val_loss: 4.2432 - val_accuracy: 0.0374\n",
      "Epoch 70/200\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 4.0707 - accuracy: 0.0368 - val_loss: 4.2346 - val_accuracy: 0.0374\n",
      "Epoch 71/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.0612 - accuracy: 0.0384 - val_loss: 4.2259 - val_accuracy: 0.0467\n",
      "Epoch 72/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 4.0517 - accuracy: 0.0411 - val_loss: 4.2173 - val_accuracy: 0.0467\n",
      "Epoch 73/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 4.0421 - accuracy: 0.0415 - val_loss: 4.2086 - val_accuracy: 0.0467\n",
      "Epoch 74/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.0325 - accuracy: 0.0415 - val_loss: 4.2000 - val_accuracy: 0.0467\n",
      "Epoch 75/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.0229 - accuracy: 0.0431 - val_loss: 4.1912 - val_accuracy: 0.0467\n",
      "Epoch 76/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.0132 - accuracy: 0.0443 - val_loss: 4.1824 - val_accuracy: 0.0467\n",
      "Epoch 77/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.0036 - accuracy: 0.0454 - val_loss: 4.1737 - val_accuracy: 0.0467\n",
      "Epoch 78/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.9939 - accuracy: 0.0482 - val_loss: 4.1649 - val_accuracy: 0.0467\n",
      "Epoch 79/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.9842 - accuracy: 0.0501 - val_loss: 4.1561 - val_accuracy: 0.0467\n",
      "Epoch 80/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.9744 - accuracy: 0.0513 - val_loss: 4.1473 - val_accuracy: 0.0467\n",
      "Epoch 81/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.9645 - accuracy: 0.0548 - val_loss: 4.1386 - val_accuracy: 0.0467\n",
      "Epoch 82/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.9546 - accuracy: 0.0564 - val_loss: 4.1298 - val_accuracy: 0.0467\n",
      "Epoch 83/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.9447 - accuracy: 0.0584 - val_loss: 4.1210 - val_accuracy: 0.0561\n",
      "Epoch 84/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.9347 - accuracy: 0.0619 - val_loss: 4.1122 - val_accuracy: 0.0561\n",
      "Epoch 85/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.9246 - accuracy: 0.0666 - val_loss: 4.1031 - val_accuracy: 0.0654\n",
      "Epoch 86/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.9145 - accuracy: 0.0682 - val_loss: 4.0938 - val_accuracy: 0.0654\n",
      "Epoch 87/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.9044 - accuracy: 0.0709 - val_loss: 4.0845 - val_accuracy: 0.0654\n",
      "Epoch 88/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.8943 - accuracy: 0.0725 - val_loss: 4.0751 - val_accuracy: 0.0654\n",
      "Epoch 89/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.8842 - accuracy: 0.0740 - val_loss: 4.0656 - val_accuracy: 0.0654\n",
      "Epoch 90/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 3.8741 - accuracy: 0.0764 - val_loss: 4.0562 - val_accuracy: 0.0654\n",
      "Epoch 91/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.8640 - accuracy: 0.0783 - val_loss: 4.0468 - val_accuracy: 0.0654\n",
      "Epoch 92/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.8539 - accuracy: 0.0783 - val_loss: 4.0372 - val_accuracy: 0.0654\n",
      "Epoch 93/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.8438 - accuracy: 0.0799 - val_loss: 4.0273 - val_accuracy: 0.0654\n",
      "Epoch 94/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.8336 - accuracy: 0.0826 - val_loss: 4.0175 - val_accuracy: 0.0654\n",
      "Epoch 95/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.8234 - accuracy: 0.0846 - val_loss: 4.0077 - val_accuracy: 0.0748\n",
      "Epoch 96/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.8131 - accuracy: 0.0870 - val_loss: 3.9979 - val_accuracy: 0.0841\n",
      "Epoch 97/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.8027 - accuracy: 0.0885 - val_loss: 3.9880 - val_accuracy: 0.0841\n",
      "Epoch 98/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.7923 - accuracy: 0.0901 - val_loss: 3.9780 - val_accuracy: 0.0841\n",
      "Epoch 99/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.7820 - accuracy: 0.0917 - val_loss: 3.9677 - val_accuracy: 0.0841\n",
      "Epoch 100/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.7716 - accuracy: 0.0944 - val_loss: 3.9576 - val_accuracy: 0.0841\n",
      "Epoch 101/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.7611 - accuracy: 0.0987 - val_loss: 3.9473 - val_accuracy: 0.0841\n",
      "Epoch 102/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.7507 - accuracy: 0.1038 - val_loss: 3.9369 - val_accuracy: 0.0935\n",
      "Epoch 103/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.7402 - accuracy: 0.1065 - val_loss: 3.9265 - val_accuracy: 0.0935\n",
      "Epoch 104/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.7297 - accuracy: 0.1085 - val_loss: 3.9162 - val_accuracy: 0.0935\n",
      "Epoch 105/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.7193 - accuracy: 0.1128 - val_loss: 3.9057 - val_accuracy: 0.0935\n",
      "Epoch 106/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.7089 - accuracy: 0.1148 - val_loss: 3.8952 - val_accuracy: 0.0935\n",
      "Epoch 107/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6984 - accuracy: 0.1183 - val_loss: 3.8848 - val_accuracy: 0.0935\n",
      "Epoch 108/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6880 - accuracy: 0.1214 - val_loss: 3.8743 - val_accuracy: 0.0935\n",
      "Epoch 109/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6775 - accuracy: 0.1226 - val_loss: 3.8638 - val_accuracy: 0.0935\n",
      "Epoch 110/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6670 - accuracy: 0.1261 - val_loss: 3.8532 - val_accuracy: 0.0935\n",
      "Epoch 111/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6565 - accuracy: 0.1289 - val_loss: 3.8427 - val_accuracy: 0.0935\n",
      "Epoch 112/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6461 - accuracy: 0.1316 - val_loss: 3.8321 - val_accuracy: 0.0935\n",
      "Epoch 113/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6356 - accuracy: 0.1324 - val_loss: 3.8214 - val_accuracy: 0.0935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6251 - accuracy: 0.1375 - val_loss: 3.8108 - val_accuracy: 0.0935\n",
      "Epoch 115/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6147 - accuracy: 0.1402 - val_loss: 3.8002 - val_accuracy: 0.0935\n",
      "Epoch 116/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6042 - accuracy: 0.1434 - val_loss: 3.7895 - val_accuracy: 0.0935\n",
      "Epoch 117/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5937 - accuracy: 0.1465 - val_loss: 3.7789 - val_accuracy: 0.0935\n",
      "Epoch 118/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5832 - accuracy: 0.1485 - val_loss: 3.7682 - val_accuracy: 0.1028\n",
      "Epoch 119/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5728 - accuracy: 0.1547 - val_loss: 3.7576 - val_accuracy: 0.1028\n",
      "Epoch 120/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5623 - accuracy: 0.1563 - val_loss: 3.7470 - val_accuracy: 0.1028\n",
      "Epoch 121/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5519 - accuracy: 0.1598 - val_loss: 3.7365 - val_accuracy: 0.1121\n",
      "Epoch 122/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5414 - accuracy: 0.1606 - val_loss: 3.7260 - val_accuracy: 0.1121\n",
      "Epoch 123/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5310 - accuracy: 0.1606 - val_loss: 3.7153 - val_accuracy: 0.1121\n",
      "Epoch 124/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5205 - accuracy: 0.1618 - val_loss: 3.7046 - val_accuracy: 0.1121\n",
      "Epoch 125/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5101 - accuracy: 0.1626 - val_loss: 3.6940 - val_accuracy: 0.1121\n",
      "Epoch 126/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.4997 - accuracy: 0.1669 - val_loss: 3.6832 - val_accuracy: 0.1121\n",
      "Epoch 127/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.4893 - accuracy: 0.1696 - val_loss: 3.6724 - val_accuracy: 0.1121\n",
      "Epoch 128/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.4789 - accuracy: 0.1716 - val_loss: 3.6615 - val_accuracy: 0.1121\n",
      "Epoch 129/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.4685 - accuracy: 0.1739 - val_loss: 3.6506 - val_accuracy: 0.1121\n",
      "Epoch 130/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.4581 - accuracy: 0.1770 - val_loss: 3.6398 - val_accuracy: 0.1121\n",
      "Epoch 131/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.4477 - accuracy: 0.1782 - val_loss: 3.6290 - val_accuracy: 0.1121\n",
      "Epoch 132/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.4373 - accuracy: 0.1810 - val_loss: 3.6182 - val_accuracy: 0.1121\n",
      "Epoch 133/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.4269 - accuracy: 0.1837 - val_loss: 3.6074 - val_accuracy: 0.1121\n",
      "Epoch 134/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.4166 - accuracy: 0.1880 - val_loss: 3.5967 - val_accuracy: 0.1121\n",
      "Epoch 135/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.4062 - accuracy: 0.1900 - val_loss: 3.5860 - val_accuracy: 0.1121\n",
      "Epoch 136/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3959 - accuracy: 0.1939 - val_loss: 3.5753 - val_accuracy: 0.1121\n",
      "Epoch 137/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 3.3856 - accuracy: 0.1962 - val_loss: 3.5647 - val_accuracy: 0.1308\n",
      "Epoch 138/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 3.3753 - accuracy: 0.1978 - val_loss: 3.5540 - val_accuracy: 0.1308\n",
      "Epoch 139/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3651 - accuracy: 0.2005 - val_loss: 3.5433 - val_accuracy: 0.1308\n",
      "Epoch 140/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3548 - accuracy: 0.2037 - val_loss: 3.5327 - val_accuracy: 0.1402\n",
      "Epoch 141/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3446 - accuracy: 0.2068 - val_loss: 3.5222 - val_accuracy: 0.1402\n",
      "Epoch 142/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3344 - accuracy: 0.2088 - val_loss: 3.5116 - val_accuracy: 0.1402\n",
      "Epoch 143/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3242 - accuracy: 0.2107 - val_loss: 3.5011 - val_accuracy: 0.1402\n",
      "Epoch 144/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3141 - accuracy: 0.2146 - val_loss: 3.4907 - val_accuracy: 0.1402\n",
      "Epoch 145/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3039 - accuracy: 0.2182 - val_loss: 3.4800 - val_accuracy: 0.1402\n",
      "Epoch 146/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.2938 - accuracy: 0.2221 - val_loss: 3.4693 - val_accuracy: 0.1495\n",
      "Epoch 147/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.2837 - accuracy: 0.2237 - val_loss: 3.4587 - val_accuracy: 0.1495\n",
      "Epoch 148/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.2737 - accuracy: 0.2252 - val_loss: 3.4481 - val_accuracy: 0.1495\n",
      "Epoch 149/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.2636 - accuracy: 0.2256 - val_loss: 3.4376 - val_accuracy: 0.1495\n",
      "Epoch 150/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.2536 - accuracy: 0.2272 - val_loss: 3.4270 - val_accuracy: 0.1495\n",
      "Epoch 151/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.2436 - accuracy: 0.2307 - val_loss: 3.4165 - val_accuracy: 0.1495\n",
      "Epoch 152/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.2337 - accuracy: 0.2323 - val_loss: 3.4060 - val_accuracy: 0.1495\n",
      "Epoch 153/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.2237 - accuracy: 0.2350 - val_loss: 3.3956 - val_accuracy: 0.1495\n",
      "Epoch 154/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.2138 - accuracy: 0.2366 - val_loss: 3.3851 - val_accuracy: 0.1495\n",
      "Epoch 155/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.2039 - accuracy: 0.2378 - val_loss: 3.3746 - val_accuracy: 0.1495\n",
      "Epoch 156/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.1940 - accuracy: 0.2401 - val_loss: 3.3642 - val_accuracy: 0.1495\n",
      "Epoch 157/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.1841 - accuracy: 0.2417 - val_loss: 3.3539 - val_accuracy: 0.1495\n",
      "Epoch 158/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.1743 - accuracy: 0.2432 - val_loss: 3.3435 - val_accuracy: 0.1495\n",
      "Epoch 159/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.1645 - accuracy: 0.2452 - val_loss: 3.3333 - val_accuracy: 0.1589\n",
      "Epoch 160/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.1547 - accuracy: 0.2476 - val_loss: 3.3229 - val_accuracy: 0.1776\n",
      "Epoch 161/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.1450 - accuracy: 0.2487 - val_loss: 3.3127 - val_accuracy: 0.1869\n",
      "Epoch 162/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.1353 - accuracy: 0.2483 - val_loss: 3.3024 - val_accuracy: 0.1869\n",
      "Epoch 163/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.1255 - accuracy: 0.2507 - val_loss: 3.2921 - val_accuracy: 0.1963\n",
      "Epoch 164/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.1159 - accuracy: 0.2530 - val_loss: 3.2817 - val_accuracy: 0.1963\n",
      "Epoch 165/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.1062 - accuracy: 0.2546 - val_loss: 3.2715 - val_accuracy: 0.2056\n",
      "Epoch 166/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.0966 - accuracy: 0.2581 - val_loss: 3.2611 - val_accuracy: 0.2056\n",
      "Epoch 167/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.0870 - accuracy: 0.2605 - val_loss: 3.2510 - val_accuracy: 0.2056\n",
      "Epoch 168/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.0774 - accuracy: 0.2632 - val_loss: 3.2408 - val_accuracy: 0.2056\n",
      "Epoch 169/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.0679 - accuracy: 0.2640 - val_loss: 3.2306 - val_accuracy: 0.2056\n",
      "Epoch 170/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 2ms/step - loss: 3.0584 - accuracy: 0.2656 - val_loss: 3.2205 - val_accuracy: 0.2056\n",
      "Epoch 171/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.0489 - accuracy: 0.2675 - val_loss: 3.2104 - val_accuracy: 0.2243\n",
      "Epoch 172/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.0394 - accuracy: 0.2703 - val_loss: 3.2003 - val_accuracy: 0.2336\n",
      "Epoch 173/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.0300 - accuracy: 0.2718 - val_loss: 3.1903 - val_accuracy: 0.2336\n",
      "Epoch 174/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.0206 - accuracy: 0.2718 - val_loss: 3.1803 - val_accuracy: 0.2336\n",
      "Epoch 175/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.0112 - accuracy: 0.2734 - val_loss: 3.1703 - val_accuracy: 0.2336\n",
      "Epoch 176/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.0018 - accuracy: 0.2734 - val_loss: 3.1603 - val_accuracy: 0.2430\n",
      "Epoch 177/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.9925 - accuracy: 0.2730 - val_loss: 3.1503 - val_accuracy: 0.2617\n",
      "Epoch 178/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.9832 - accuracy: 0.2734 - val_loss: 3.1404 - val_accuracy: 0.2617\n",
      "Epoch 179/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.9739 - accuracy: 0.2750 - val_loss: 3.1305 - val_accuracy: 0.2617\n",
      "Epoch 180/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.9646 - accuracy: 0.2758 - val_loss: 3.1207 - val_accuracy: 0.2710\n",
      "Epoch 181/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.9554 - accuracy: 0.2765 - val_loss: 3.1108 - val_accuracy: 0.2710\n",
      "Epoch 182/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.9462 - accuracy: 0.2789 - val_loss: 3.1010 - val_accuracy: 0.2710\n",
      "Epoch 183/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.9370 - accuracy: 0.2801 - val_loss: 3.0912 - val_accuracy: 0.2710\n",
      "Epoch 184/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.9278 - accuracy: 0.2816 - val_loss: 3.0814 - val_accuracy: 0.2710\n",
      "Epoch 185/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.9187 - accuracy: 0.2855 - val_loss: 3.0717 - val_accuracy: 0.2710\n",
      "Epoch 186/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.9096 - accuracy: 0.2871 - val_loss: 3.0619 - val_accuracy: 0.2710\n",
      "Epoch 187/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.9006 - accuracy: 0.2879 - val_loss: 3.0522 - val_accuracy: 0.2710\n",
      "Epoch 188/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.8915 - accuracy: 0.2918 - val_loss: 3.0426 - val_accuracy: 0.2710\n",
      "Epoch 189/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.8825 - accuracy: 0.2949 - val_loss: 3.0330 - val_accuracy: 0.2804\n",
      "Epoch 190/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.8735 - accuracy: 0.2981 - val_loss: 3.0234 - val_accuracy: 0.2804\n",
      "Epoch 191/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.8646 - accuracy: 0.2993 - val_loss: 3.0138 - val_accuracy: 0.2804\n",
      "Epoch 192/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.8557 - accuracy: 0.3016 - val_loss: 3.0043 - val_accuracy: 0.2804\n",
      "Epoch 193/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.8468 - accuracy: 0.3055 - val_loss: 2.9948 - val_accuracy: 0.2804\n",
      "Epoch 194/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.8379 - accuracy: 0.3090 - val_loss: 2.9853 - val_accuracy: 0.2804\n",
      "Epoch 195/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.8291 - accuracy: 0.3102 - val_loss: 2.9759 - val_accuracy: 0.2804\n",
      "Epoch 196/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.8203 - accuracy: 0.3122 - val_loss: 2.9664 - val_accuracy: 0.2804\n",
      "Epoch 197/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.8115 - accuracy: 0.3153 - val_loss: 2.9571 - val_accuracy: 0.2804\n",
      "Epoch 198/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.8028 - accuracy: 0.3177 - val_loss: 2.9478 - val_accuracy: 0.2804\n",
      "Epoch 199/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.7941 - accuracy: 0.3224 - val_loss: 2.9385 - val_accuracy: 0.2804\n",
      "Epoch 200/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.7854 - accuracy: 0.3251 - val_loss: 2.9292 - val_accuracy: 0.2710\n",
      "0.2710280418395996 {'loss': 2.785413980484009, 'accuracy': 0.32510772347450256, 'val_loss': 2.92917799949646, 'val_accuracy': 0.2710280418395996}\n",
      "Model: \"model_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_18 (InputLayer)        [(None, 29)]              0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 41)                1230      \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 75)                3150      \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 75)                0         \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 75)                0         \n",
      "=================================================================\n",
      "Total params: 4,380\n",
      "Trainable params: 4,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.5859 - accuracy: 0.0071 - val_loss: 4.6491 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.5820 - accuracy: 0.0078 - val_loss: 4.6456 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.5781 - accuracy: 0.0082 - val_loss: 4.6421 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.5742 - accuracy: 0.0082 - val_loss: 4.6386 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.5703 - accuracy: 0.0082 - val_loss: 4.6351 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.5664 - accuracy: 0.0082 - val_loss: 4.6316 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.5626 - accuracy: 0.0086 - val_loss: 4.6281 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.5587 - accuracy: 0.0090 - val_loss: 4.6246 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.5548 - accuracy: 0.0090 - val_loss: 4.6210 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.5509 - accuracy: 0.0094 - val_loss: 4.6175 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.5471 - accuracy: 0.0094 - val_loss: 4.6140 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.5432 - accuracy: 0.0098 - val_loss: 4.6104 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.5394 - accuracy: 0.0098 - val_loss: 4.6069 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.5355 - accuracy: 0.0098 - val_loss: 4.6034 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.5317 - accuracy: 0.0098 - val_loss: 4.5999 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.5278 - accuracy: 0.0098 - val_loss: 4.5963 - val_accuracy: 0.0093\n",
      "Epoch 17/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.5239 - accuracy: 0.0102 - val_loss: 4.5928 - val_accuracy: 0.0093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.5201 - accuracy: 0.0102 - val_loss: 4.5893 - val_accuracy: 0.0187\n",
      "Epoch 19/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.5162 - accuracy: 0.0102 - val_loss: 4.5858 - val_accuracy: 0.0187\n",
      "Epoch 20/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.5124 - accuracy: 0.0102 - val_loss: 4.5822 - val_accuracy: 0.0187\n",
      "Epoch 21/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.5085 - accuracy: 0.0106 - val_loss: 4.5786 - val_accuracy: 0.0187\n",
      "Epoch 22/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.5047 - accuracy: 0.0106 - val_loss: 4.5750 - val_accuracy: 0.0187\n",
      "Epoch 23/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.5008 - accuracy: 0.0106 - val_loss: 4.5715 - val_accuracy: 0.0187\n",
      "Epoch 24/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.4970 - accuracy: 0.0106 - val_loss: 4.5679 - val_accuracy: 0.0187\n",
      "Epoch 25/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.4931 - accuracy: 0.0114 - val_loss: 4.5643 - val_accuracy: 0.0187\n",
      "Epoch 26/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.4893 - accuracy: 0.0125 - val_loss: 4.5608 - val_accuracy: 0.0187\n",
      "Epoch 27/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.4855 - accuracy: 0.0125 - val_loss: 4.5572 - val_accuracy: 0.0187\n",
      "Epoch 28/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.4816 - accuracy: 0.0125 - val_loss: 4.5537 - val_accuracy: 0.0280\n",
      "Epoch 29/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.4778 - accuracy: 0.0141 - val_loss: 4.5501 - val_accuracy: 0.0280\n",
      "Epoch 30/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.4739 - accuracy: 0.0141 - val_loss: 4.5466 - val_accuracy: 0.0280\n",
      "Epoch 31/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.4701 - accuracy: 0.0141 - val_loss: 4.5430 - val_accuracy: 0.0280\n",
      "Epoch 32/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.4663 - accuracy: 0.0145 - val_loss: 4.5395 - val_accuracy: 0.0280\n",
      "Epoch 33/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.4624 - accuracy: 0.0145 - val_loss: 4.5359 - val_accuracy: 0.0280\n",
      "Epoch 34/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.4586 - accuracy: 0.0153 - val_loss: 4.5324 - val_accuracy: 0.0280\n",
      "Epoch 35/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.4548 - accuracy: 0.0153 - val_loss: 4.5288 - val_accuracy: 0.0280\n",
      "Epoch 36/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.4509 - accuracy: 0.0157 - val_loss: 4.5253 - val_accuracy: 0.0280\n",
      "Epoch 37/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.4471 - accuracy: 0.0161 - val_loss: 4.5218 - val_accuracy: 0.0280\n",
      "Epoch 38/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.4433 - accuracy: 0.0168 - val_loss: 4.5182 - val_accuracy: 0.0280\n",
      "Epoch 39/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.4395 - accuracy: 0.0172 - val_loss: 4.5147 - val_accuracy: 0.0280\n",
      "Epoch 40/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.4357 - accuracy: 0.0172 - val_loss: 4.5112 - val_accuracy: 0.0280\n",
      "Epoch 41/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.4318 - accuracy: 0.0172 - val_loss: 4.5077 - val_accuracy: 0.0280\n",
      "Epoch 42/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.4280 - accuracy: 0.0172 - val_loss: 4.5041 - val_accuracy: 0.0280\n",
      "Epoch 43/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.4242 - accuracy: 0.0176 - val_loss: 4.5006 - val_accuracy: 0.0280\n",
      "Epoch 44/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.4204 - accuracy: 0.0176 - val_loss: 4.4970 - val_accuracy: 0.0280\n",
      "Epoch 45/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.4166 - accuracy: 0.0180 - val_loss: 4.4935 - val_accuracy: 0.0280\n",
      "Epoch 46/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.4128 - accuracy: 0.0188 - val_loss: 4.4899 - val_accuracy: 0.0280\n",
      "Epoch 47/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.4090 - accuracy: 0.0192 - val_loss: 4.4863 - val_accuracy: 0.0280\n",
      "Epoch 48/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.4051 - accuracy: 0.0200 - val_loss: 4.4828 - val_accuracy: 0.0280\n",
      "Epoch 49/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.4013 - accuracy: 0.0200 - val_loss: 4.4792 - val_accuracy: 0.0280\n",
      "Epoch 50/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.3975 - accuracy: 0.0200 - val_loss: 4.4756 - val_accuracy: 0.0280\n",
      "Epoch 51/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.3937 - accuracy: 0.0215 - val_loss: 4.4720 - val_accuracy: 0.0374\n",
      "Epoch 52/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.3899 - accuracy: 0.0215 - val_loss: 4.4684 - val_accuracy: 0.0374\n",
      "Epoch 53/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.3861 - accuracy: 0.0219 - val_loss: 4.4648 - val_accuracy: 0.0374\n",
      "Epoch 54/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.3823 - accuracy: 0.0223 - val_loss: 4.4612 - val_accuracy: 0.0374\n",
      "Epoch 55/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.3785 - accuracy: 0.0227 - val_loss: 4.4576 - val_accuracy: 0.0374\n",
      "Epoch 56/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.3747 - accuracy: 0.0231 - val_loss: 4.4540 - val_accuracy: 0.0374\n",
      "Epoch 57/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.3709 - accuracy: 0.0231 - val_loss: 4.4504 - val_accuracy: 0.0374\n",
      "Epoch 58/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.3671 - accuracy: 0.0231 - val_loss: 4.4468 - val_accuracy: 0.0467\n",
      "Epoch 59/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.3633 - accuracy: 0.0243 - val_loss: 4.4432 - val_accuracy: 0.0467\n",
      "Epoch 60/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.3595 - accuracy: 0.0255 - val_loss: 4.4397 - val_accuracy: 0.0467\n",
      "Epoch 61/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.3557 - accuracy: 0.0259 - val_loss: 4.4361 - val_accuracy: 0.0467\n",
      "Epoch 62/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.3519 - accuracy: 0.0262 - val_loss: 4.4325 - val_accuracy: 0.0467\n",
      "Epoch 63/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.3481 - accuracy: 0.0266 - val_loss: 4.4289 - val_accuracy: 0.0467\n",
      "Epoch 64/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.3444 - accuracy: 0.0266 - val_loss: 4.4253 - val_accuracy: 0.0561\n",
      "Epoch 65/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.3406 - accuracy: 0.0270 - val_loss: 4.4217 - val_accuracy: 0.0561\n",
      "Epoch 66/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.3368 - accuracy: 0.0270 - val_loss: 4.4181 - val_accuracy: 0.0561\n",
      "Epoch 67/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.3330 - accuracy: 0.0274 - val_loss: 4.4144 - val_accuracy: 0.0561\n",
      "Epoch 68/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.3292 - accuracy: 0.0278 - val_loss: 4.4108 - val_accuracy: 0.0561\n",
      "Epoch 69/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.3255 - accuracy: 0.0282 - val_loss: 4.4071 - val_accuracy: 0.0561\n",
      "Epoch 70/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.3217 - accuracy: 0.0286 - val_loss: 4.4035 - val_accuracy: 0.0561\n",
      "Epoch 71/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.3179 - accuracy: 0.0294 - val_loss: 4.3998 - val_accuracy: 0.0561\n",
      "Epoch 72/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.3142 - accuracy: 0.0302 - val_loss: 4.3961 - val_accuracy: 0.0561\n",
      "Epoch 73/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.3104 - accuracy: 0.0309 - val_loss: 4.3925 - val_accuracy: 0.0561\n",
      "Epoch 74/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.3066 - accuracy: 0.0313 - val_loss: 4.3888 - val_accuracy: 0.0561\n",
      "Epoch 75/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.3029 - accuracy: 0.0317 - val_loss: 4.3851 - val_accuracy: 0.0561\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.2991 - accuracy: 0.0325 - val_loss: 4.3815 - val_accuracy: 0.0561\n",
      "Epoch 77/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.2953 - accuracy: 0.0333 - val_loss: 4.3778 - val_accuracy: 0.0561\n",
      "Epoch 78/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.2916 - accuracy: 0.0341 - val_loss: 4.3742 - val_accuracy: 0.0561\n",
      "Epoch 79/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.2878 - accuracy: 0.0349 - val_loss: 4.3706 - val_accuracy: 0.0561\n",
      "Epoch 80/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.2841 - accuracy: 0.0349 - val_loss: 4.3669 - val_accuracy: 0.0561\n",
      "Epoch 81/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.2803 - accuracy: 0.0349 - val_loss: 4.3633 - val_accuracy: 0.0561\n",
      "Epoch 82/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.2765 - accuracy: 0.0353 - val_loss: 4.3597 - val_accuracy: 0.0561\n",
      "Epoch 83/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.2728 - accuracy: 0.0356 - val_loss: 4.3561 - val_accuracy: 0.0561\n",
      "Epoch 84/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.2691 - accuracy: 0.0360 - val_loss: 4.3524 - val_accuracy: 0.0561\n",
      "Epoch 85/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.2653 - accuracy: 0.0388 - val_loss: 4.3489 - val_accuracy: 0.0561\n",
      "Epoch 86/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.2616 - accuracy: 0.0400 - val_loss: 4.3453 - val_accuracy: 0.0561\n",
      "Epoch 87/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.2579 - accuracy: 0.0411 - val_loss: 4.3417 - val_accuracy: 0.0561\n",
      "Epoch 88/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.2541 - accuracy: 0.0427 - val_loss: 4.3381 - val_accuracy: 0.0561\n",
      "Epoch 89/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.2504 - accuracy: 0.0443 - val_loss: 4.3345 - val_accuracy: 0.0561\n",
      "Epoch 90/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.2467 - accuracy: 0.0466 - val_loss: 4.3309 - val_accuracy: 0.0561\n",
      "Epoch 91/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.2430 - accuracy: 0.0482 - val_loss: 4.3273 - val_accuracy: 0.0561\n",
      "Epoch 92/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.2393 - accuracy: 0.0482 - val_loss: 4.3237 - val_accuracy: 0.0561\n",
      "Epoch 93/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.2356 - accuracy: 0.0486 - val_loss: 4.3202 - val_accuracy: 0.0561\n",
      "Epoch 94/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.2318 - accuracy: 0.0501 - val_loss: 4.3166 - val_accuracy: 0.0561\n",
      "Epoch 95/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.2281 - accuracy: 0.0501 - val_loss: 4.3130 - val_accuracy: 0.0561\n",
      "Epoch 96/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.2244 - accuracy: 0.0513 - val_loss: 4.3095 - val_accuracy: 0.0561\n",
      "Epoch 97/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.2208 - accuracy: 0.0525 - val_loss: 4.3059 - val_accuracy: 0.0561\n",
      "Epoch 98/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.2171 - accuracy: 0.0544 - val_loss: 4.3024 - val_accuracy: 0.0561\n",
      "Epoch 99/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.2133 - accuracy: 0.0552 - val_loss: 4.2988 - val_accuracy: 0.0561\n",
      "Epoch 100/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.2096 - accuracy: 0.0556 - val_loss: 4.2953 - val_accuracy: 0.0561\n",
      "Epoch 101/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.2059 - accuracy: 0.0560 - val_loss: 4.2917 - val_accuracy: 0.0561\n",
      "Epoch 102/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.2022 - accuracy: 0.0568 - val_loss: 4.2882 - val_accuracy: 0.0561\n",
      "Epoch 103/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.1985 - accuracy: 0.0588 - val_loss: 4.2847 - val_accuracy: 0.0561\n",
      "Epoch 104/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.1949 - accuracy: 0.0588 - val_loss: 4.2811 - val_accuracy: 0.0561\n",
      "Epoch 105/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.1912 - accuracy: 0.0588 - val_loss: 4.2776 - val_accuracy: 0.0561\n",
      "Epoch 106/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.1875 - accuracy: 0.0599 - val_loss: 4.2741 - val_accuracy: 0.0561\n",
      "Epoch 107/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.1838 - accuracy: 0.0611 - val_loss: 4.2706 - val_accuracy: 0.0561\n",
      "Epoch 108/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.1802 - accuracy: 0.0619 - val_loss: 4.2671 - val_accuracy: 0.0561\n",
      "Epoch 109/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.1765 - accuracy: 0.0627 - val_loss: 4.2636 - val_accuracy: 0.0561\n",
      "Epoch 110/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.1728 - accuracy: 0.0635 - val_loss: 4.2601 - val_accuracy: 0.0561\n",
      "Epoch 111/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.1692 - accuracy: 0.0654 - val_loss: 4.2566 - val_accuracy: 0.0654\n",
      "Epoch 112/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.1655 - accuracy: 0.0666 - val_loss: 4.2531 - val_accuracy: 0.0654\n",
      "Epoch 113/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.1618 - accuracy: 0.0678 - val_loss: 4.2496 - val_accuracy: 0.0654\n",
      "Epoch 114/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.1582 - accuracy: 0.0685 - val_loss: 4.2461 - val_accuracy: 0.0654\n",
      "Epoch 115/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 4.1546 - accuracy: 0.0713 - val_loss: 4.2427 - val_accuracy: 0.0748\n",
      "Epoch 116/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.1509 - accuracy: 0.0740 - val_loss: 4.2392 - val_accuracy: 0.0748\n",
      "Epoch 117/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.1472 - accuracy: 0.0744 - val_loss: 4.2357 - val_accuracy: 0.0748\n",
      "Epoch 118/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.1436 - accuracy: 0.0768 - val_loss: 4.2321 - val_accuracy: 0.0748\n",
      "Epoch 119/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.1399 - accuracy: 0.0787 - val_loss: 4.2286 - val_accuracy: 0.0748\n",
      "Epoch 120/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.1363 - accuracy: 0.0799 - val_loss: 4.2251 - val_accuracy: 0.0748\n",
      "Epoch 121/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.1326 - accuracy: 0.0807 - val_loss: 4.2216 - val_accuracy: 0.0748\n",
      "Epoch 122/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.1290 - accuracy: 0.0823 - val_loss: 4.2180 - val_accuracy: 0.0748\n",
      "Epoch 123/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.1253 - accuracy: 0.0830 - val_loss: 4.2145 - val_accuracy: 0.0748\n",
      "Epoch 124/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.1217 - accuracy: 0.0846 - val_loss: 4.2110 - val_accuracy: 0.0748\n",
      "Epoch 125/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.1180 - accuracy: 0.0870 - val_loss: 4.2074 - val_accuracy: 0.0748\n",
      "Epoch 126/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.1144 - accuracy: 0.0877 - val_loss: 4.2039 - val_accuracy: 0.0748\n",
      "Epoch 127/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.1108 - accuracy: 0.0901 - val_loss: 4.2004 - val_accuracy: 0.0748\n",
      "Epoch 128/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.1071 - accuracy: 0.0920 - val_loss: 4.1969 - val_accuracy: 0.0748\n",
      "Epoch 129/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.1035 - accuracy: 0.0928 - val_loss: 4.1934 - val_accuracy: 0.0748\n",
      "Epoch 130/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.0999 - accuracy: 0.0960 - val_loss: 4.1899 - val_accuracy: 0.0748\n",
      "Epoch 131/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.0962 - accuracy: 0.0967 - val_loss: 4.1864 - val_accuracy: 0.0841\n",
      "Epoch 132/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.0926 - accuracy: 0.0975 - val_loss: 4.1829 - val_accuracy: 0.0841\n",
      "Epoch 133/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 2ms/step - loss: 4.0890 - accuracy: 0.0995 - val_loss: 4.1794 - val_accuracy: 0.0841\n",
      "Epoch 134/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.0854 - accuracy: 0.0995 - val_loss: 4.1759 - val_accuracy: 0.0841\n",
      "Epoch 135/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.0818 - accuracy: 0.1003 - val_loss: 4.1725 - val_accuracy: 0.0841\n",
      "Epoch 136/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.0781 - accuracy: 0.1026 - val_loss: 4.1689 - val_accuracy: 0.0935\n",
      "Epoch 137/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.0745 - accuracy: 0.1042 - val_loss: 4.1654 - val_accuracy: 0.0935\n",
      "Epoch 138/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.0709 - accuracy: 0.1054 - val_loss: 4.1619 - val_accuracy: 0.0935\n",
      "Epoch 139/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.0673 - accuracy: 0.1069 - val_loss: 4.1584 - val_accuracy: 0.0935\n",
      "Epoch 140/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.0637 - accuracy: 0.1085 - val_loss: 4.1548 - val_accuracy: 0.1028\n",
      "Epoch 141/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.0601 - accuracy: 0.1085 - val_loss: 4.1513 - val_accuracy: 0.1121\n",
      "Epoch 142/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.0565 - accuracy: 0.1093 - val_loss: 4.1478 - val_accuracy: 0.1121\n",
      "Epoch 143/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.0529 - accuracy: 0.1101 - val_loss: 4.1443 - val_accuracy: 0.1121\n",
      "Epoch 144/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.0493 - accuracy: 0.1105 - val_loss: 4.1408 - val_accuracy: 0.1121\n",
      "Epoch 145/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.0456 - accuracy: 0.1124 - val_loss: 4.1373 - val_accuracy: 0.1121\n",
      "Epoch 146/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.0420 - accuracy: 0.1148 - val_loss: 4.1338 - val_accuracy: 0.1121\n",
      "Epoch 147/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.0384 - accuracy: 0.1152 - val_loss: 4.1303 - val_accuracy: 0.1121\n",
      "Epoch 148/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.0348 - accuracy: 0.1167 - val_loss: 4.1268 - val_accuracy: 0.1121\n",
      "Epoch 149/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.0312 - accuracy: 0.1187 - val_loss: 4.1233 - val_accuracy: 0.1121\n",
      "Epoch 150/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.0276 - accuracy: 0.1199 - val_loss: 4.1198 - val_accuracy: 0.1308\n",
      "Epoch 151/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.0240 - accuracy: 0.1214 - val_loss: 4.1164 - val_accuracy: 0.1308\n",
      "Epoch 152/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.0204 - accuracy: 0.1234 - val_loss: 4.1129 - val_accuracy: 0.1308\n",
      "Epoch 153/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.0168 - accuracy: 0.1246 - val_loss: 4.1094 - val_accuracy: 0.1308\n",
      "Epoch 154/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.0132 - accuracy: 0.1261 - val_loss: 4.1060 - val_accuracy: 0.1402\n",
      "Epoch 155/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.0096 - accuracy: 0.1273 - val_loss: 4.1025 - val_accuracy: 0.1402\n",
      "Epoch 156/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.0060 - accuracy: 0.1297 - val_loss: 4.0991 - val_accuracy: 0.1402\n",
      "Epoch 157/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.0025 - accuracy: 0.1312 - val_loss: 4.0957 - val_accuracy: 0.1402\n",
      "Epoch 158/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.9989 - accuracy: 0.1347 - val_loss: 4.0922 - val_accuracy: 0.1402\n",
      "Epoch 159/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.9953 - accuracy: 0.1367 - val_loss: 4.0888 - val_accuracy: 0.1495\n",
      "Epoch 160/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.9917 - accuracy: 0.1383 - val_loss: 4.0854 - val_accuracy: 0.1495\n",
      "Epoch 161/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.9882 - accuracy: 0.1410 - val_loss: 4.0820 - val_accuracy: 0.1495\n",
      "Epoch 162/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.9846 - accuracy: 0.1426 - val_loss: 4.0786 - val_accuracy: 0.1495\n",
      "Epoch 163/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.9810 - accuracy: 0.1449 - val_loss: 4.0751 - val_accuracy: 0.1495\n",
      "Epoch 164/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.9774 - accuracy: 0.1465 - val_loss: 4.0717 - val_accuracy: 0.1495\n",
      "Epoch 165/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.9738 - accuracy: 0.1488 - val_loss: 4.0683 - val_accuracy: 0.1495\n",
      "Epoch 166/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.9702 - accuracy: 0.1488 - val_loss: 4.0649 - val_accuracy: 0.1495\n",
      "Epoch 167/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.9666 - accuracy: 0.1504 - val_loss: 4.0615 - val_accuracy: 0.1495\n",
      "Epoch 168/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.9630 - accuracy: 0.1524 - val_loss: 4.0581 - val_accuracy: 0.1495\n",
      "Epoch 169/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.9594 - accuracy: 0.1528 - val_loss: 4.0547 - val_accuracy: 0.1589\n",
      "Epoch 170/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.9558 - accuracy: 0.1559 - val_loss: 4.0513 - val_accuracy: 0.1589\n",
      "Epoch 171/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.9522 - accuracy: 0.1567 - val_loss: 4.0479 - val_accuracy: 0.1589\n",
      "Epoch 172/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.9486 - accuracy: 0.1590 - val_loss: 4.0445 - val_accuracy: 0.1682\n",
      "Epoch 173/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.9450 - accuracy: 0.1606 - val_loss: 4.0411 - val_accuracy: 0.1682\n",
      "Epoch 174/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.9414 - accuracy: 0.1618 - val_loss: 4.0378 - val_accuracy: 0.1682\n",
      "Epoch 175/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.9378 - accuracy: 0.1641 - val_loss: 4.0344 - val_accuracy: 0.1776\n",
      "Epoch 176/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.9342 - accuracy: 0.1669 - val_loss: 4.0310 - val_accuracy: 0.1869\n",
      "Epoch 177/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.9306 - accuracy: 0.1684 - val_loss: 4.0277 - val_accuracy: 0.1869\n",
      "Epoch 178/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.9270 - accuracy: 0.1704 - val_loss: 4.0243 - val_accuracy: 0.1869\n",
      "Epoch 179/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.9234 - accuracy: 0.1716 - val_loss: 4.0210 - val_accuracy: 0.1869\n",
      "Epoch 180/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.9198 - accuracy: 0.1747 - val_loss: 4.0176 - val_accuracy: 0.1869\n",
      "Epoch 181/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.9163 - accuracy: 0.1759 - val_loss: 4.0143 - val_accuracy: 0.1869\n",
      "Epoch 182/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.9127 - accuracy: 0.1782 - val_loss: 4.0110 - val_accuracy: 0.1869\n",
      "Epoch 183/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.9091 - accuracy: 0.1790 - val_loss: 4.0077 - val_accuracy: 0.1869\n",
      "Epoch 184/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.9056 - accuracy: 0.1817 - val_loss: 4.0044 - val_accuracy: 0.1869\n",
      "Epoch 185/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.9020 - accuracy: 0.1837 - val_loss: 4.0011 - val_accuracy: 0.1869\n",
      "Epoch 186/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.8984 - accuracy: 0.1853 - val_loss: 3.9978 - val_accuracy: 0.1963\n",
      "Epoch 187/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.8949 - accuracy: 0.1876 - val_loss: 3.9945 - val_accuracy: 0.1963\n",
      "Epoch 188/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.8913 - accuracy: 0.1880 - val_loss: 3.9912 - val_accuracy: 0.1963\n",
      "Epoch 189/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.8877 - accuracy: 0.1892 - val_loss: 3.9880 - val_accuracy: 0.1963\n",
      "Epoch 190/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 2ms/step - loss: 3.8841 - accuracy: 0.1919 - val_loss: 3.9847 - val_accuracy: 0.1963\n",
      "Epoch 191/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.8805 - accuracy: 0.1931 - val_loss: 3.9814 - val_accuracy: 0.2056\n",
      "Epoch 192/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.8769 - accuracy: 0.1951 - val_loss: 3.9782 - val_accuracy: 0.2056\n",
      "Epoch 193/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.8734 - accuracy: 0.1970 - val_loss: 3.9749 - val_accuracy: 0.2056\n",
      "Epoch 194/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.8698 - accuracy: 0.1978 - val_loss: 3.9716 - val_accuracy: 0.2056\n",
      "Epoch 195/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.8662 - accuracy: 0.1994 - val_loss: 3.9684 - val_accuracy: 0.2056\n",
      "Epoch 196/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.8626 - accuracy: 0.2005 - val_loss: 3.9651 - val_accuracy: 0.2056\n",
      "Epoch 197/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.8590 - accuracy: 0.2033 - val_loss: 3.9618 - val_accuracy: 0.2056\n",
      "Epoch 198/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.8554 - accuracy: 0.2045 - val_loss: 3.9586 - val_accuracy: 0.2056\n",
      "Epoch 199/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.8518 - accuracy: 0.2072 - val_loss: 3.9553 - val_accuracy: 0.2056\n",
      "Epoch 200/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.8482 - accuracy: 0.2088 - val_loss: 3.9521 - val_accuracy: 0.2056\n",
      "0.20560747385025024 {'loss': 3.84824800491333, 'accuracy': 0.20877398550510406, 'val_loss': 3.952089309692383, 'val_accuracy': 0.20560747385025024}\n",
      "Model: \"model_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_19 (InputLayer)        [(None, 29)]              0         \n",
      "_________________________________________________________________\n",
      "flatten_18 (Flatten)         (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 41)                1230      \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 75)                3150      \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 75)                0         \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 75)                0         \n",
      "=================================================================\n",
      "Total params: 4,380\n",
      "Trainable params: 4,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 4.2140 - accuracy: 0.0658 - val_loss: 4.0366 - val_accuracy: 0.0654\n",
      "Epoch 2/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.1836 - accuracy: 0.0697 - val_loss: 4.0279 - val_accuracy: 0.0654\n",
      "Epoch 3/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.1926 - accuracy: 0.0736 - val_loss: 4.0191 - val_accuracy: 0.0654\n",
      "Epoch 4/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.1664 - accuracy: 0.0717 - val_loss: 4.0103 - val_accuracy: 0.0654\n",
      "Epoch 5/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.1671 - accuracy: 0.0721 - val_loss: 4.0017 - val_accuracy: 0.0654\n",
      "Epoch 6/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.1460 - accuracy: 0.0764 - val_loss: 3.9931 - val_accuracy: 0.0654\n",
      "Epoch 7/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.1418 - accuracy: 0.0736 - val_loss: 3.9845 - val_accuracy: 0.0654\n",
      "Epoch 8/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.1602 - accuracy: 0.0725 - val_loss: 3.9759 - val_accuracy: 0.0654\n",
      "Epoch 9/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.1255 - accuracy: 0.0799 - val_loss: 3.9673 - val_accuracy: 0.0654\n",
      "Epoch 10/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.1020 - accuracy: 0.0795 - val_loss: 3.9586 - val_accuracy: 0.0654\n",
      "Epoch 11/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.1054 - accuracy: 0.0791 - val_loss: 3.9499 - val_accuracy: 0.0654\n",
      "Epoch 12/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.1317 - accuracy: 0.0838 - val_loss: 3.9414 - val_accuracy: 0.0654\n",
      "Epoch 13/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.0911 - accuracy: 0.0846 - val_loss: 3.9328 - val_accuracy: 0.0654\n",
      "Epoch 14/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.1106 - accuracy: 0.0776 - val_loss: 3.9243 - val_accuracy: 0.0654\n",
      "Epoch 15/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.0985 - accuracy: 0.0838 - val_loss: 3.9157 - val_accuracy: 0.0654\n",
      "Epoch 16/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.1043 - accuracy: 0.0850 - val_loss: 3.9071 - val_accuracy: 0.0654\n",
      "Epoch 17/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.0820 - accuracy: 0.0897 - val_loss: 3.8987 - val_accuracy: 0.0654\n",
      "Epoch 18/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.0366 - accuracy: 0.0870 - val_loss: 3.8900 - val_accuracy: 0.0654\n",
      "Epoch 19/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.0559 - accuracy: 0.0924 - val_loss: 3.8815 - val_accuracy: 0.0654\n",
      "Epoch 20/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.0588 - accuracy: 0.0873 - val_loss: 3.8729 - val_accuracy: 0.0654\n",
      "Epoch 21/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.0279 - accuracy: 0.0917 - val_loss: 3.8643 - val_accuracy: 0.0654\n",
      "Epoch 22/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.0543 - accuracy: 0.0975 - val_loss: 3.8560 - val_accuracy: 0.0654\n",
      "Epoch 23/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.9724 - accuracy: 0.1003 - val_loss: 3.8474 - val_accuracy: 0.0654\n",
      "Epoch 24/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.0094 - accuracy: 0.0995 - val_loss: 3.8390 - val_accuracy: 0.0748\n",
      "Epoch 25/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.0026 - accuracy: 0.0964 - val_loss: 3.8306 - val_accuracy: 0.0748\n",
      "Epoch 26/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.0190 - accuracy: 0.1042 - val_loss: 3.8223 - val_accuracy: 0.0748\n",
      "Epoch 27/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.0005 - accuracy: 0.1014 - val_loss: 3.8139 - val_accuracy: 0.0841\n",
      "Epoch 28/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.9859 - accuracy: 0.1069 - val_loss: 3.8057 - val_accuracy: 0.0841\n",
      "Epoch 29/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.9742 - accuracy: 0.0999 - val_loss: 3.7972 - val_accuracy: 0.0935\n",
      "Epoch 30/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.9532 - accuracy: 0.1042 - val_loss: 3.7887 - val_accuracy: 0.0935\n",
      "Epoch 31/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.9671 - accuracy: 0.1108 - val_loss: 3.7804 - val_accuracy: 0.0935\n",
      "Epoch 32/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.9280 - accuracy: 0.1140 - val_loss: 3.7720 - val_accuracy: 0.1121\n",
      "Epoch 33/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.9255 - accuracy: 0.1097 - val_loss: 3.7637 - val_accuracy: 0.1121\n",
      "Epoch 34/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.9046 - accuracy: 0.1128 - val_loss: 3.7553 - val_accuracy: 0.1121\n",
      "Epoch 35/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.8885 - accuracy: 0.1148 - val_loss: 3.7469 - val_accuracy: 0.1121\n",
      "Epoch 36/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.8708 - accuracy: 0.1175 - val_loss: 3.7384 - val_accuracy: 0.1121\n",
      "Epoch 37/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.8743 - accuracy: 0.1159 - val_loss: 3.7301 - val_accuracy: 0.1121\n",
      "Epoch 38/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 2ms/step - loss: 3.8959 - accuracy: 0.1218 - val_loss: 3.7218 - val_accuracy: 0.1121\n",
      "Epoch 39/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.8746 - accuracy: 0.1222 - val_loss: 3.7135 - val_accuracy: 0.1028\n",
      "Epoch 40/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.8524 - accuracy: 0.1246 - val_loss: 3.7051 - val_accuracy: 0.1028\n",
      "Epoch 41/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.8948 - accuracy: 0.1210 - val_loss: 3.6971 - val_accuracy: 0.1121\n",
      "Epoch 42/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.8570 - accuracy: 0.1238 - val_loss: 3.6889 - val_accuracy: 0.1121\n",
      "Epoch 43/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.8197 - accuracy: 0.1355 - val_loss: 3.6806 - val_accuracy: 0.1121\n",
      "Epoch 44/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.7763 - accuracy: 0.1324 - val_loss: 3.6721 - val_accuracy: 0.1121\n",
      "Epoch 45/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.8168 - accuracy: 0.1355 - val_loss: 3.6638 - val_accuracy: 0.1121\n",
      "Epoch 46/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.8150 - accuracy: 0.1289 - val_loss: 3.6557 - val_accuracy: 0.1121\n",
      "Epoch 47/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.8121 - accuracy: 0.1304 - val_loss: 3.6476 - val_accuracy: 0.1121\n",
      "Epoch 48/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.7819 - accuracy: 0.1367 - val_loss: 3.6395 - val_accuracy: 0.1121\n",
      "Epoch 49/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.7687 - accuracy: 0.1359 - val_loss: 3.6313 - val_accuracy: 0.1121\n",
      "Epoch 50/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.7807 - accuracy: 0.1371 - val_loss: 3.6230 - val_accuracy: 0.1121\n",
      "Epoch 51/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.7519 - accuracy: 0.1543 - val_loss: 3.6146 - val_accuracy: 0.1121\n",
      "Epoch 52/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.7723 - accuracy: 0.1445 - val_loss: 3.6066 - val_accuracy: 0.1121\n",
      "Epoch 53/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.7401 - accuracy: 0.1441 - val_loss: 3.5985 - val_accuracy: 0.1215\n",
      "Epoch 54/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.7525 - accuracy: 0.1465 - val_loss: 3.5903 - val_accuracy: 0.1215\n",
      "Epoch 55/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.7388 - accuracy: 0.1453 - val_loss: 3.5822 - val_accuracy: 0.1215\n",
      "Epoch 56/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.7136 - accuracy: 0.1532 - val_loss: 3.5740 - val_accuracy: 0.1215\n",
      "Epoch 57/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6951 - accuracy: 0.1492 - val_loss: 3.5657 - val_accuracy: 0.1215\n",
      "Epoch 58/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6997 - accuracy: 0.1610 - val_loss: 3.5578 - val_accuracy: 0.1215\n",
      "Epoch 59/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.7353 - accuracy: 0.1524 - val_loss: 3.5498 - val_accuracy: 0.1215\n",
      "Epoch 60/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.7111 - accuracy: 0.1532 - val_loss: 3.5418 - val_accuracy: 0.1215\n",
      "Epoch 61/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6665 - accuracy: 0.1641 - val_loss: 3.5337 - val_accuracy: 0.1215\n",
      "Epoch 62/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6782 - accuracy: 0.1594 - val_loss: 3.5256 - val_accuracy: 0.1215\n",
      "Epoch 63/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6991 - accuracy: 0.1669 - val_loss: 3.5179 - val_accuracy: 0.1308\n",
      "Epoch 64/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6624 - accuracy: 0.1594 - val_loss: 3.5098 - val_accuracy: 0.1308\n",
      "Epoch 65/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6846 - accuracy: 0.1626 - val_loss: 3.5019 - val_accuracy: 0.1308\n",
      "Epoch 66/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6061 - accuracy: 0.1676 - val_loss: 3.4939 - val_accuracy: 0.1402\n",
      "Epoch 67/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6509 - accuracy: 0.1676 - val_loss: 3.4860 - val_accuracy: 0.1402\n",
      "Epoch 68/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6605 - accuracy: 0.1637 - val_loss: 3.4782 - val_accuracy: 0.1402\n",
      "Epoch 69/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6095 - accuracy: 0.1688 - val_loss: 3.4701 - val_accuracy: 0.1402\n",
      "Epoch 70/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6544 - accuracy: 0.1649 - val_loss: 3.4624 - val_accuracy: 0.1402\n",
      "Epoch 71/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6400 - accuracy: 0.1653 - val_loss: 3.4546 - val_accuracy: 0.1495\n",
      "Epoch 72/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6387 - accuracy: 0.1763 - val_loss: 3.4470 - val_accuracy: 0.1495\n",
      "Epoch 73/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6279 - accuracy: 0.1810 - val_loss: 3.4393 - val_accuracy: 0.1495\n",
      "Epoch 74/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5902 - accuracy: 0.1853 - val_loss: 3.4314 - val_accuracy: 0.1495\n",
      "Epoch 75/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5703 - accuracy: 0.1864 - val_loss: 3.4235 - val_accuracy: 0.1495\n",
      "Epoch 76/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5571 - accuracy: 0.1814 - val_loss: 3.4157 - val_accuracy: 0.1495\n",
      "Epoch 77/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5465 - accuracy: 0.1810 - val_loss: 3.4078 - val_accuracy: 0.1495\n",
      "Epoch 78/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5899 - accuracy: 0.1814 - val_loss: 3.4001 - val_accuracy: 0.1495\n",
      "Epoch 79/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5659 - accuracy: 0.1880 - val_loss: 3.3924 - val_accuracy: 0.1495\n",
      "Epoch 80/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5616 - accuracy: 0.1829 - val_loss: 3.3847 - val_accuracy: 0.1589\n",
      "Epoch 81/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5602 - accuracy: 0.1927 - val_loss: 3.3771 - val_accuracy: 0.1589\n",
      "Epoch 82/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5427 - accuracy: 0.1904 - val_loss: 3.3693 - val_accuracy: 0.1589\n",
      "Epoch 83/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5082 - accuracy: 0.1974 - val_loss: 3.3616 - val_accuracy: 0.1589\n",
      "Epoch 84/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5542 - accuracy: 0.1978 - val_loss: 3.3540 - val_accuracy: 0.1589\n",
      "Epoch 85/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5103 - accuracy: 0.1962 - val_loss: 3.3463 - val_accuracy: 0.1589\n",
      "Epoch 86/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.4809 - accuracy: 0.1986 - val_loss: 3.3385 - val_accuracy: 0.1682\n",
      "Epoch 87/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.5170 - accuracy: 0.1908 - val_loss: 3.3309 - val_accuracy: 0.1682\n",
      "Epoch 88/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.4786 - accuracy: 0.2037 - val_loss: 3.3232 - val_accuracy: 0.1682\n",
      "Epoch 89/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.4995 - accuracy: 0.2017 - val_loss: 3.3155 - val_accuracy: 0.1776\n",
      "Epoch 90/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.4419 - accuracy: 0.2193 - val_loss: 3.3077 - val_accuracy: 0.1776\n",
      "Epoch 91/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.4375 - accuracy: 0.2096 - val_loss: 3.2999 - val_accuracy: 0.1776\n",
      "Epoch 92/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.4430 - accuracy: 0.2158 - val_loss: 3.2922 - val_accuracy: 0.1776\n",
      "Epoch 93/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.4798 - accuracy: 0.2064 - val_loss: 3.2847 - val_accuracy: 0.1776\n",
      "Epoch 94/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.4891 - accuracy: 0.2068 - val_loss: 3.2772 - val_accuracy: 0.1776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.4344 - accuracy: 0.2084 - val_loss: 3.2696 - val_accuracy: 0.1776\n",
      "Epoch 96/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.4515 - accuracy: 0.2170 - val_loss: 3.2621 - val_accuracy: 0.1776\n",
      "Epoch 97/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.4002 - accuracy: 0.2170 - val_loss: 3.2544 - val_accuracy: 0.1776\n",
      "Epoch 98/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.4431 - accuracy: 0.2170 - val_loss: 3.2470 - val_accuracy: 0.1869\n",
      "Epoch 99/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.4482 - accuracy: 0.2205 - val_loss: 3.2396 - val_accuracy: 0.1869\n",
      "Epoch 100/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3781 - accuracy: 0.2256 - val_loss: 3.2321 - val_accuracy: 0.1869\n",
      "Epoch 101/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3849 - accuracy: 0.2233 - val_loss: 3.2246 - val_accuracy: 0.1869\n",
      "Epoch 102/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.4170 - accuracy: 0.2244 - val_loss: 3.2170 - val_accuracy: 0.1869\n",
      "Epoch 103/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.4069 - accuracy: 0.2158 - val_loss: 3.2095 - val_accuracy: 0.1869\n",
      "Epoch 104/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3885 - accuracy: 0.2217 - val_loss: 3.2020 - val_accuracy: 0.1963\n",
      "Epoch 105/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3786 - accuracy: 0.2362 - val_loss: 3.1945 - val_accuracy: 0.1963\n",
      "Epoch 106/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3742 - accuracy: 0.2323 - val_loss: 3.1871 - val_accuracy: 0.1963\n",
      "Epoch 107/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3674 - accuracy: 0.2272 - val_loss: 3.1796 - val_accuracy: 0.1963\n",
      "Epoch 108/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3338 - accuracy: 0.2335 - val_loss: 3.1720 - val_accuracy: 0.1963\n",
      "Epoch 109/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3252 - accuracy: 0.2401 - val_loss: 3.1645 - val_accuracy: 0.1963\n",
      "Epoch 110/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3410 - accuracy: 0.2460 - val_loss: 3.1570 - val_accuracy: 0.1963\n",
      "Epoch 111/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3211 - accuracy: 0.2464 - val_loss: 3.1496 - val_accuracy: 0.1963\n",
      "Epoch 112/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3104 - accuracy: 0.2432 - val_loss: 3.1421 - val_accuracy: 0.1963\n",
      "Epoch 113/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3092 - accuracy: 0.2444 - val_loss: 3.1348 - val_accuracy: 0.1963\n",
      "Epoch 114/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3174 - accuracy: 0.2291 - val_loss: 3.1274 - val_accuracy: 0.1963\n",
      "Epoch 115/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3024 - accuracy: 0.2589 - val_loss: 3.1201 - val_accuracy: 0.1963\n",
      "Epoch 116/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3072 - accuracy: 0.2397 - val_loss: 3.1128 - val_accuracy: 0.2056\n",
      "Epoch 117/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.2881 - accuracy: 0.2479 - val_loss: 3.1055 - val_accuracy: 0.2056\n",
      "Epoch 118/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3023 - accuracy: 0.2417 - val_loss: 3.0982 - val_accuracy: 0.2056\n",
      "Epoch 119/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.3037 - accuracy: 0.2413 - val_loss: 3.0910 - val_accuracy: 0.2056\n",
      "Epoch 120/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.2933 - accuracy: 0.2503 - val_loss: 3.0838 - val_accuracy: 0.2056\n",
      "Epoch 121/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.2481 - accuracy: 0.2617 - val_loss: 3.0764 - val_accuracy: 0.2056\n",
      "Epoch 122/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.2664 - accuracy: 0.2581 - val_loss: 3.0692 - val_accuracy: 0.2056\n",
      "Epoch 123/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.2769 - accuracy: 0.2526 - val_loss: 3.0620 - val_accuracy: 0.2150\n",
      "Epoch 124/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.2561 - accuracy: 0.2566 - val_loss: 3.0548 - val_accuracy: 0.2150\n",
      "Epoch 125/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.2366 - accuracy: 0.2609 - val_loss: 3.0476 - val_accuracy: 0.2243\n",
      "Epoch 126/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.2497 - accuracy: 0.2628 - val_loss: 3.0406 - val_accuracy: 0.2243\n",
      "Epoch 127/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.2150 - accuracy: 0.2699 - val_loss: 3.0333 - val_accuracy: 0.2243\n",
      "Epoch 128/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.1884 - accuracy: 0.2797 - val_loss: 3.0261 - val_accuracy: 0.2150\n",
      "Epoch 129/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.1984 - accuracy: 0.2667 - val_loss: 3.0188 - val_accuracy: 0.2150\n",
      "Epoch 130/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.1939 - accuracy: 0.2652 - val_loss: 3.0116 - val_accuracy: 0.2150\n",
      "Epoch 131/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.2141 - accuracy: 0.2742 - val_loss: 3.0046 - val_accuracy: 0.2150\n",
      "Epoch 132/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.1980 - accuracy: 0.2722 - val_loss: 2.9974 - val_accuracy: 0.2150\n",
      "Epoch 133/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.1737 - accuracy: 0.2691 - val_loss: 2.9901 - val_accuracy: 0.2243\n",
      "Epoch 134/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.1723 - accuracy: 0.2711 - val_loss: 2.9829 - val_accuracy: 0.2243\n",
      "Epoch 135/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.2246 - accuracy: 0.2738 - val_loss: 2.9759 - val_accuracy: 0.2243\n",
      "Epoch 136/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.1110 - accuracy: 0.2961 - val_loss: 2.9687 - val_accuracy: 0.2336\n",
      "Epoch 137/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.1623 - accuracy: 0.2902 - val_loss: 2.9617 - val_accuracy: 0.2336\n",
      "Epoch 138/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.1764 - accuracy: 0.2754 - val_loss: 2.9547 - val_accuracy: 0.2523\n",
      "Epoch 139/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.1474 - accuracy: 0.2754 - val_loss: 2.9478 - val_accuracy: 0.2523\n",
      "Epoch 140/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.1280 - accuracy: 0.2840 - val_loss: 2.9407 - val_accuracy: 0.2523\n",
      "Epoch 141/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.1000 - accuracy: 0.2875 - val_loss: 2.9337 - val_accuracy: 0.2523\n",
      "Epoch 142/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.1606 - accuracy: 0.2852 - val_loss: 2.9267 - val_accuracy: 0.2523\n",
      "Epoch 143/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.1371 - accuracy: 0.2852 - val_loss: 2.9198 - val_accuracy: 0.2523\n",
      "Epoch 144/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.1084 - accuracy: 0.3004 - val_loss: 2.9128 - val_accuracy: 0.2523\n",
      "Epoch 145/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.1388 - accuracy: 0.2820 - val_loss: 2.9060 - val_accuracy: 0.2523\n",
      "Epoch 146/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.1115 - accuracy: 0.2934 - val_loss: 2.8992 - val_accuracy: 0.2523\n",
      "Epoch 147/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.0862 - accuracy: 0.2812 - val_loss: 2.8921 - val_accuracy: 0.2523\n",
      "Epoch 148/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.0948 - accuracy: 0.2946 - val_loss: 2.8852 - val_accuracy: 0.2523\n",
      "Epoch 149/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.0480 - accuracy: 0.3032 - val_loss: 2.8781 - val_accuracy: 0.2523\n",
      "Epoch 150/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.0930 - accuracy: 0.3020 - val_loss: 2.8713 - val_accuracy: 0.2430\n",
      "Epoch 151/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 2ms/step - loss: 3.0770 - accuracy: 0.3016 - val_loss: 2.8646 - val_accuracy: 0.2523\n",
      "Epoch 152/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.0360 - accuracy: 0.2989 - val_loss: 2.8575 - val_accuracy: 0.2710\n",
      "Epoch 153/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.0745 - accuracy: 0.2875 - val_loss: 2.8507 - val_accuracy: 0.2710\n",
      "Epoch 154/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.0807 - accuracy: 0.2961 - val_loss: 2.8440 - val_accuracy: 0.2710\n",
      "Epoch 155/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.0450 - accuracy: 0.3047 - val_loss: 2.8373 - val_accuracy: 0.2897\n",
      "Epoch 156/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.0397 - accuracy: 0.3165 - val_loss: 2.8304 - val_accuracy: 0.2897\n",
      "Epoch 157/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.0573 - accuracy: 0.2946 - val_loss: 2.8236 - val_accuracy: 0.2991\n",
      "Epoch 158/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.0117 - accuracy: 0.3145 - val_loss: 2.8168 - val_accuracy: 0.3084\n",
      "Epoch 159/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.0439 - accuracy: 0.3134 - val_loss: 2.8100 - val_accuracy: 0.3178\n",
      "Epoch 160/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.9494 - accuracy: 0.3177 - val_loss: 2.8030 - val_accuracy: 0.3271\n",
      "Epoch 161/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.0255 - accuracy: 0.3157 - val_loss: 2.7963 - val_accuracy: 0.3271\n",
      "Epoch 162/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.9667 - accuracy: 0.3196 - val_loss: 2.7894 - val_accuracy: 0.3271\n",
      "Epoch 163/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.9907 - accuracy: 0.3208 - val_loss: 2.7827 - val_accuracy: 0.3271\n",
      "Epoch 164/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.0407 - accuracy: 0.3165 - val_loss: 2.7761 - val_accuracy: 0.3271\n",
      "Epoch 165/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.9766 - accuracy: 0.3239 - val_loss: 2.7694 - val_accuracy: 0.3271\n",
      "Epoch 166/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.9902 - accuracy: 0.3271 - val_loss: 2.7628 - val_accuracy: 0.3458\n",
      "Epoch 167/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.9653 - accuracy: 0.3298 - val_loss: 2.7561 - val_accuracy: 0.3458\n",
      "Epoch 168/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.9500 - accuracy: 0.3106 - val_loss: 2.7494 - val_accuracy: 0.3458\n",
      "Epoch 169/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.9280 - accuracy: 0.3255 - val_loss: 2.7427 - val_accuracy: 0.3458\n",
      "Epoch 170/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.9471 - accuracy: 0.3231 - val_loss: 2.7359 - val_accuracy: 0.3551\n",
      "Epoch 171/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.9915 - accuracy: 0.3192 - val_loss: 2.7295 - val_accuracy: 0.3551\n",
      "Epoch 172/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.9429 - accuracy: 0.3294 - val_loss: 2.7229 - val_accuracy: 0.3551\n",
      "Epoch 173/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.9353 - accuracy: 0.3286 - val_loss: 2.7162 - val_accuracy: 0.3458\n",
      "Epoch 174/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.9567 - accuracy: 0.3208 - val_loss: 2.7098 - val_accuracy: 0.3458\n",
      "Epoch 175/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.9472 - accuracy: 0.3224 - val_loss: 2.7033 - val_accuracy: 0.3458\n",
      "Epoch 176/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.9641 - accuracy: 0.3098 - val_loss: 2.6969 - val_accuracy: 0.3458\n",
      "Epoch 177/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.9099 - accuracy: 0.3341 - val_loss: 2.6904 - val_accuracy: 0.3458\n",
      "Epoch 178/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.9499 - accuracy: 0.3259 - val_loss: 2.6841 - val_accuracy: 0.3458\n",
      "Epoch 179/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.9257 - accuracy: 0.3145 - val_loss: 2.6777 - val_accuracy: 0.3458\n",
      "Epoch 180/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.9259 - accuracy: 0.3298 - val_loss: 2.6712 - val_accuracy: 0.3458\n",
      "Epoch 181/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.9373 - accuracy: 0.3310 - val_loss: 2.6650 - val_accuracy: 0.3458\n",
      "Epoch 182/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.9295 - accuracy: 0.3145 - val_loss: 2.6587 - val_accuracy: 0.3458\n",
      "Epoch 183/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.9174 - accuracy: 0.3286 - val_loss: 2.6524 - val_accuracy: 0.3551\n",
      "Epoch 184/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.8807 - accuracy: 0.3451 - val_loss: 2.6460 - val_accuracy: 0.3551\n",
      "Epoch 185/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.9070 - accuracy: 0.3369 - val_loss: 2.6398 - val_accuracy: 0.3551\n",
      "Epoch 186/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.8366 - accuracy: 0.3443 - val_loss: 2.6333 - val_accuracy: 0.3551\n",
      "Epoch 187/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.8854 - accuracy: 0.3376 - val_loss: 2.6270 - val_accuracy: 0.3551\n",
      "Epoch 188/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.8781 - accuracy: 0.3423 - val_loss: 2.6208 - val_accuracy: 0.3551\n",
      "Epoch 189/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.8694 - accuracy: 0.3486 - val_loss: 2.6146 - val_accuracy: 0.3551\n",
      "Epoch 190/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.8949 - accuracy: 0.3447 - val_loss: 2.6084 - val_accuracy: 0.3645\n",
      "Epoch 191/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.8771 - accuracy: 0.3255 - val_loss: 2.6023 - val_accuracy: 0.3645\n",
      "Epoch 192/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.8844 - accuracy: 0.3337 - val_loss: 2.5962 - val_accuracy: 0.3645\n",
      "Epoch 193/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.8458 - accuracy: 0.3392 - val_loss: 2.5901 - val_accuracy: 0.3645\n",
      "Epoch 194/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.8930 - accuracy: 0.3400 - val_loss: 2.5841 - val_accuracy: 0.3645\n",
      "Epoch 195/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.8243 - accuracy: 0.3478 - val_loss: 2.5780 - val_accuracy: 0.3645\n",
      "Epoch 196/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.8274 - accuracy: 0.3502 - val_loss: 2.5718 - val_accuracy: 0.3738\n",
      "Epoch 197/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.8754 - accuracy: 0.3325 - val_loss: 2.5660 - val_accuracy: 0.3738\n",
      "Epoch 198/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.8669 - accuracy: 0.3408 - val_loss: 2.5600 - val_accuracy: 0.3832\n",
      "Epoch 199/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.8864 - accuracy: 0.3369 - val_loss: 2.5543 - val_accuracy: 0.3738\n",
      "Epoch 200/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.8564 - accuracy: 0.3478 - val_loss: 2.5484 - val_accuracy: 0.3738\n",
      "0.37383177876472473 {'loss': 2.8564412593841553, 'accuracy': 0.3478260934352875, 'val_loss': 2.5484273433685303, 'val_accuracy': 0.37383177876472473}\n",
      "Model: \"model_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_20 (InputLayer)        [(None, 29)]              0         \n",
      "_________________________________________________________________\n",
      "flatten_19 (Flatten)         (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 41)                1230      \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 75)                3150      \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 75)                0         \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 75)                0         \n",
      "=================================================================\n",
      "Total params: 4,380\n",
      "Trainable params: 4,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.7579 - accuracy: 0.0020 - val_loss: 4.4367 - val_accuracy: 0.0093\n",
      "Epoch 2/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.7626 - accuracy: 0.0020 - val_loss: 4.4319 - val_accuracy: 0.0093\n",
      "Epoch 3/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.7717 - accuracy: 7.8339e-04 - val_loss: 4.4272 - val_accuracy: 0.0093\n",
      "Epoch 4/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.7711 - accuracy: 0.0016 - val_loss: 4.4225 - val_accuracy: 0.0093\n",
      "Epoch 5/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.7542 - accuracy: 0.0016 - val_loss: 4.4177 - val_accuracy: 0.0093\n",
      "Epoch 6/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.7470 - accuracy: 0.0012 - val_loss: 4.4128 - val_accuracy: 0.0093\n",
      "Epoch 7/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.7352 - accuracy: 0.0020 - val_loss: 4.4081 - val_accuracy: 0.0093\n",
      "Epoch 8/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.7413 - accuracy: 0.0047 - val_loss: 4.4034 - val_accuracy: 0.0093\n",
      "Epoch 9/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.7399 - accuracy: 0.0027 - val_loss: 4.3987 - val_accuracy: 0.0093\n",
      "Epoch 10/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.7447 - accuracy: 0.0016 - val_loss: 4.3940 - val_accuracy: 0.0093\n",
      "Epoch 11/200\n",
      "80/80 [==============================] - ETA: 0s - loss: 4.7351 - accuracy: 0.0038 - 0s 2ms/step - loss: 4.7372 - accuracy: 0.0051 - val_loss: 4.3893 - val_accuracy: 0.0093\n",
      "Epoch 12/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.7155 - accuracy: 0.0027 - val_loss: 4.3846 - val_accuracy: 0.0093\n",
      "Epoch 13/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.7107 - accuracy: 0.0043 - val_loss: 4.3798 - val_accuracy: 0.0093\n",
      "Epoch 14/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.7133 - accuracy: 0.0035 - val_loss: 4.3752 - val_accuracy: 0.0093\n",
      "Epoch 15/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.6736 - accuracy: 0.0043 - val_loss: 4.3703 - val_accuracy: 0.0093\n",
      "Epoch 16/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.6991 - accuracy: 0.0039 - val_loss: 4.3656 - val_accuracy: 0.0093\n",
      "Epoch 17/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.6905 - accuracy: 0.0031 - val_loss: 4.3608 - val_accuracy: 0.0093\n",
      "Epoch 18/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.6962 - accuracy: 0.0027 - val_loss: 4.3561 - val_accuracy: 0.0093\n",
      "Epoch 19/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.6855 - accuracy: 0.0024 - val_loss: 4.3514 - val_accuracy: 0.0093\n",
      "Epoch 20/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.6524 - accuracy: 0.0027 - val_loss: 4.3466 - val_accuracy: 0.0093\n",
      "Epoch 21/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.6724 - accuracy: 0.0027 - val_loss: 4.3419 - val_accuracy: 0.0093\n",
      "Epoch 22/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.6686 - accuracy: 0.0051 - val_loss: 4.3373 - val_accuracy: 0.0093\n",
      "Epoch 23/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.6377 - accuracy: 0.0059 - val_loss: 4.3326 - val_accuracy: 0.0093\n",
      "Epoch 24/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.6461 - accuracy: 0.0071 - val_loss: 4.3279 - val_accuracy: 0.0093\n",
      "Epoch 25/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.6557 - accuracy: 0.0055 - val_loss: 4.3232 - val_accuracy: 0.0093\n",
      "Epoch 26/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.6532 - accuracy: 0.0071 - val_loss: 4.3187 - val_accuracy: 0.0093\n",
      "Epoch 27/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.6284 - accuracy: 0.0063 - val_loss: 4.3141 - val_accuracy: 0.0093\n",
      "Epoch 28/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.6406 - accuracy: 0.0059 - val_loss: 4.3095 - val_accuracy: 0.0093\n",
      "Epoch 29/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.6171 - accuracy: 0.0047 - val_loss: 4.3048 - val_accuracy: 0.0093\n",
      "Epoch 30/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.6219 - accuracy: 0.0039 - val_loss: 4.3002 - val_accuracy: 0.0093\n",
      "Epoch 31/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.6083 - accuracy: 0.0059 - val_loss: 4.2955 - val_accuracy: 0.0093\n",
      "Epoch 32/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.5913 - accuracy: 0.0051 - val_loss: 4.2908 - val_accuracy: 0.0093\n",
      "Epoch 33/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.6054 - accuracy: 0.0059 - val_loss: 4.2863 - val_accuracy: 0.0093\n",
      "Epoch 34/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.6035 - accuracy: 0.0090 - val_loss: 4.2817 - val_accuracy: 0.0093\n",
      "Epoch 35/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.6073 - accuracy: 0.0043 - val_loss: 4.2771 - val_accuracy: 0.0187\n",
      "Epoch 36/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.6105 - accuracy: 0.0059 - val_loss: 4.2726 - val_accuracy: 0.0187\n",
      "Epoch 37/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.5914 - accuracy: 0.0094 - val_loss: 4.2680 - val_accuracy: 0.0187\n",
      "Epoch 38/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.5501 - accuracy: 0.0074 - val_loss: 4.2633 - val_accuracy: 0.0187\n",
      "Epoch 39/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.5812 - accuracy: 0.0071 - val_loss: 4.2586 - val_accuracy: 0.0187\n",
      "Epoch 40/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.5561 - accuracy: 0.0078 - val_loss: 4.2539 - val_accuracy: 0.0187\n",
      "Epoch 41/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.5584 - accuracy: 0.0071 - val_loss: 4.2493 - val_accuracy: 0.0187\n",
      "Epoch 42/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.5644 - accuracy: 0.0055 - val_loss: 4.2448 - val_accuracy: 0.0187\n",
      "Epoch 43/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.5338 - accuracy: 0.0106 - val_loss: 4.2402 - val_accuracy: 0.0187\n",
      "Epoch 44/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.5470 - accuracy: 0.0114 - val_loss: 4.2356 - val_accuracy: 0.0187\n",
      "Epoch 45/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.5474 - accuracy: 0.0106 - val_loss: 4.2310 - val_accuracy: 0.0187\n",
      "Epoch 46/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.5614 - accuracy: 0.0106 - val_loss: 4.2266 - val_accuracy: 0.0187\n",
      "Epoch 47/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.5334 - accuracy: 0.0118 - val_loss: 4.2221 - val_accuracy: 0.0187\n",
      "Epoch 48/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.5355 - accuracy: 0.0125 - val_loss: 4.2176 - val_accuracy: 0.0187\n",
      "Epoch 49/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.5258 - accuracy: 0.0133 - val_loss: 4.2131 - val_accuracy: 0.0187\n",
      "Epoch 50/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.5225 - accuracy: 0.0157 - val_loss: 4.2086 - val_accuracy: 0.0187\n",
      "Epoch 51/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.5041 - accuracy: 0.0165 - val_loss: 4.2040 - val_accuracy: 0.0187\n",
      "Epoch 52/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.5064 - accuracy: 0.0149 - val_loss: 4.1995 - val_accuracy: 0.0187\n",
      "Epoch 53/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.4843 - accuracy: 0.0145 - val_loss: 4.1949 - val_accuracy: 0.0187\n",
      "Epoch 54/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.4884 - accuracy: 0.0137 - val_loss: 4.1903 - val_accuracy: 0.0280\n",
      "Epoch 55/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.5015 - accuracy: 0.0129 - val_loss: 4.1859 - val_accuracy: 0.0280\n",
      "Epoch 56/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.4957 - accuracy: 0.0129 - val_loss: 4.1814 - val_accuracy: 0.0280\n",
      "Epoch 57/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.4735 - accuracy: 0.0176 - val_loss: 4.1769 - val_accuracy: 0.0280\n",
      "Epoch 58/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 2ms/step - loss: 4.4860 - accuracy: 0.0168 - val_loss: 4.1724 - val_accuracy: 0.0280\n",
      "Epoch 59/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.4823 - accuracy: 0.0149 - val_loss: 4.1680 - val_accuracy: 0.0280\n",
      "Epoch 60/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.4595 - accuracy: 0.0176 - val_loss: 4.1635 - val_accuracy: 0.0280\n",
      "Epoch 61/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.4631 - accuracy: 0.0188 - val_loss: 4.1590 - val_accuracy: 0.0280\n",
      "Epoch 62/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.4601 - accuracy: 0.0176 - val_loss: 4.1545 - val_accuracy: 0.0280\n",
      "Epoch 63/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.4578 - accuracy: 0.0192 - val_loss: 4.1501 - val_accuracy: 0.0280\n",
      "Epoch 64/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.4480 - accuracy: 0.0180 - val_loss: 4.1456 - val_accuracy: 0.0280\n",
      "Epoch 65/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.4315 - accuracy: 0.0227 - val_loss: 4.1411 - val_accuracy: 0.0280\n",
      "Epoch 66/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.4457 - accuracy: 0.0235 - val_loss: 4.1366 - val_accuracy: 0.0374\n",
      "Epoch 67/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 4.4402 - accuracy: 0.0223 - val_loss: 4.1322 - val_accuracy: 0.0374\n",
      "Epoch 68/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.4413 - accuracy: 0.0219 - val_loss: 4.1278 - val_accuracy: 0.0374\n",
      "Epoch 69/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.4491 - accuracy: 0.0200 - val_loss: 4.1234 - val_accuracy: 0.0374\n",
      "Epoch 70/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.3997 - accuracy: 0.0235 - val_loss: 4.1189 - val_accuracy: 0.0374\n",
      "Epoch 71/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.3878 - accuracy: 0.0266 - val_loss: 4.1144 - val_accuracy: 0.0374\n",
      "Epoch 72/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.3953 - accuracy: 0.0227 - val_loss: 4.1099 - val_accuracy: 0.0374\n",
      "Epoch 73/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.3893 - accuracy: 0.0235 - val_loss: 4.1055 - val_accuracy: 0.0374\n",
      "Epoch 74/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.4090 - accuracy: 0.0259 - val_loss: 4.1012 - val_accuracy: 0.0374\n",
      "Epoch 75/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.4174 - accuracy: 0.0215 - val_loss: 4.0969 - val_accuracy: 0.0374\n",
      "Epoch 76/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.3816 - accuracy: 0.0321 - val_loss: 4.0925 - val_accuracy: 0.0374\n",
      "Epoch 77/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.3783 - accuracy: 0.0266 - val_loss: 4.0880 - val_accuracy: 0.0374\n",
      "Epoch 78/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.3834 - accuracy: 0.0298 - val_loss: 4.0837 - val_accuracy: 0.0374\n",
      "Epoch 79/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.3999 - accuracy: 0.0274 - val_loss: 4.0794 - val_accuracy: 0.0467\n",
      "Epoch 80/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.3651 - accuracy: 0.0251 - val_loss: 4.0750 - val_accuracy: 0.0561\n",
      "Epoch 81/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.3630 - accuracy: 0.0294 - val_loss: 4.0706 - val_accuracy: 0.0561\n",
      "Epoch 82/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.3512 - accuracy: 0.0341 - val_loss: 4.0662 - val_accuracy: 0.0561\n",
      "Epoch 83/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.3420 - accuracy: 0.0353 - val_loss: 4.0618 - val_accuracy: 0.0561\n",
      "Epoch 84/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.3508 - accuracy: 0.0298 - val_loss: 4.0574 - val_accuracy: 0.0561\n",
      "Epoch 85/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.3264 - accuracy: 0.0384 - val_loss: 4.0530 - val_accuracy: 0.0561\n",
      "Epoch 86/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.3456 - accuracy: 0.0302 - val_loss: 4.0487 - val_accuracy: 0.0561\n",
      "Epoch 87/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.3417 - accuracy: 0.0345 - val_loss: 4.0444 - val_accuracy: 0.0561\n",
      "Epoch 88/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.3528 - accuracy: 0.0368 - val_loss: 4.0401 - val_accuracy: 0.0561\n",
      "Epoch 89/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.3250 - accuracy: 0.0329 - val_loss: 4.0358 - val_accuracy: 0.0561\n",
      "Epoch 90/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.3229 - accuracy: 0.0368 - val_loss: 4.0315 - val_accuracy: 0.0654\n",
      "Epoch 91/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.3155 - accuracy: 0.0376 - val_loss: 4.0272 - val_accuracy: 0.0654\n",
      "Epoch 92/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.3261 - accuracy: 0.0392 - val_loss: 4.0229 - val_accuracy: 0.0748\n",
      "Epoch 93/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.3210 - accuracy: 0.0380 - val_loss: 4.0187 - val_accuracy: 0.0748\n",
      "Epoch 94/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.3024 - accuracy: 0.0419 - val_loss: 4.0144 - val_accuracy: 0.0748\n",
      "Epoch 95/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.2879 - accuracy: 0.0403 - val_loss: 4.0101 - val_accuracy: 0.0748\n",
      "Epoch 96/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.2937 - accuracy: 0.0423 - val_loss: 4.0057 - val_accuracy: 0.0748\n",
      "Epoch 97/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.2821 - accuracy: 0.0450 - val_loss: 4.0015 - val_accuracy: 0.0748\n",
      "Epoch 98/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.2982 - accuracy: 0.0376 - val_loss: 3.9972 - val_accuracy: 0.0748\n",
      "Epoch 99/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.2908 - accuracy: 0.0376 - val_loss: 3.9930 - val_accuracy: 0.0748\n",
      "Epoch 100/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.2854 - accuracy: 0.0450 - val_loss: 3.9888 - val_accuracy: 0.0748\n",
      "Epoch 101/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.2599 - accuracy: 0.0478 - val_loss: 3.9845 - val_accuracy: 0.0748\n",
      "Epoch 102/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.2859 - accuracy: 0.0411 - val_loss: 3.9803 - val_accuracy: 0.0748\n",
      "Epoch 103/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 4.2730 - accuracy: 0.0497 - val_loss: 3.9761 - val_accuracy: 0.0748\n",
      "Epoch 104/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.2629 - accuracy: 0.0443 - val_loss: 3.9720 - val_accuracy: 0.0748\n",
      "Epoch 105/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.2562 - accuracy: 0.0458 - val_loss: 3.9677 - val_accuracy: 0.0748\n",
      "Epoch 106/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.2458 - accuracy: 0.0521 - val_loss: 3.9634 - val_accuracy: 0.0748\n",
      "Epoch 107/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.2659 - accuracy: 0.0505 - val_loss: 3.9593 - val_accuracy: 0.0748\n",
      "Epoch 108/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.2396 - accuracy: 0.0509 - val_loss: 3.9551 - val_accuracy: 0.0748\n",
      "Epoch 109/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.2383 - accuracy: 0.0525 - val_loss: 3.9509 - val_accuracy: 0.0748\n",
      "Epoch 110/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.2264 - accuracy: 0.0556 - val_loss: 3.9467 - val_accuracy: 0.0748\n",
      "Epoch 111/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.2339 - accuracy: 0.0568 - val_loss: 3.9425 - val_accuracy: 0.0748\n",
      "Epoch 112/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.2332 - accuracy: 0.0584 - val_loss: 3.9383 - val_accuracy: 0.0748\n",
      "Epoch 113/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.2164 - accuracy: 0.0576 - val_loss: 3.9341 - val_accuracy: 0.0748\n",
      "Epoch 114/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.2247 - accuracy: 0.0529 - val_loss: 3.9299 - val_accuracy: 0.0748\n",
      "Epoch 115/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.2177 - accuracy: 0.0584 - val_loss: 3.9257 - val_accuracy: 0.0841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.2005 - accuracy: 0.0627 - val_loss: 3.9215 - val_accuracy: 0.0841\n",
      "Epoch 117/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.2259 - accuracy: 0.0591 - val_loss: 3.9174 - val_accuracy: 0.0841\n",
      "Epoch 118/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.2226 - accuracy: 0.0595 - val_loss: 3.9134 - val_accuracy: 0.0841\n",
      "Epoch 119/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.2091 - accuracy: 0.0595 - val_loss: 3.9092 - val_accuracy: 0.0841\n",
      "Epoch 120/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.1962 - accuracy: 0.0646 - val_loss: 3.9051 - val_accuracy: 0.0841\n",
      "Epoch 121/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.2031 - accuracy: 0.0678 - val_loss: 3.9010 - val_accuracy: 0.0935\n",
      "Epoch 122/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.1773 - accuracy: 0.0693 - val_loss: 3.8968 - val_accuracy: 0.0935\n",
      "Epoch 123/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.1977 - accuracy: 0.0682 - val_loss: 3.8927 - val_accuracy: 0.0935\n",
      "Epoch 124/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.1812 - accuracy: 0.0678 - val_loss: 3.8886 - val_accuracy: 0.0935\n",
      "Epoch 125/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.1488 - accuracy: 0.0736 - val_loss: 3.8844 - val_accuracy: 0.0935\n",
      "Epoch 126/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.1858 - accuracy: 0.0725 - val_loss: 3.8804 - val_accuracy: 0.0935\n",
      "Epoch 127/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.1669 - accuracy: 0.0689 - val_loss: 3.8763 - val_accuracy: 0.0935\n",
      "Epoch 128/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.1589 - accuracy: 0.0701 - val_loss: 3.8721 - val_accuracy: 0.0935\n",
      "Epoch 129/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.1415 - accuracy: 0.0760 - val_loss: 3.8680 - val_accuracy: 0.0935\n",
      "Epoch 130/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.1514 - accuracy: 0.0713 - val_loss: 3.8638 - val_accuracy: 0.0935\n",
      "Epoch 131/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.1570 - accuracy: 0.0756 - val_loss: 3.8597 - val_accuracy: 0.1028\n",
      "Epoch 132/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.1356 - accuracy: 0.0807 - val_loss: 3.8556 - val_accuracy: 0.1028\n",
      "Epoch 133/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.1433 - accuracy: 0.0748 - val_loss: 3.8516 - val_accuracy: 0.1028\n",
      "Epoch 134/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.1214 - accuracy: 0.0799 - val_loss: 3.8474 - val_accuracy: 0.1028\n",
      "Epoch 135/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.1002 - accuracy: 0.0795 - val_loss: 3.8433 - val_accuracy: 0.1028\n",
      "Epoch 136/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.1123 - accuracy: 0.0862 - val_loss: 3.8392 - val_accuracy: 0.1028\n",
      "Epoch 137/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.1135 - accuracy: 0.0850 - val_loss: 3.8351 - val_accuracy: 0.1028\n",
      "Epoch 138/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.1155 - accuracy: 0.0830 - val_loss: 3.8310 - val_accuracy: 0.1028\n",
      "Epoch 139/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.0914 - accuracy: 0.0866 - val_loss: 3.8268 - val_accuracy: 0.1028\n",
      "Epoch 140/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 4.1199 - accuracy: 0.0870 - val_loss: 3.8228 - val_accuracy: 0.1028\n",
      "Epoch 141/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.0946 - accuracy: 0.0815 - val_loss: 3.8187 - val_accuracy: 0.1308\n",
      "Epoch 142/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.0695 - accuracy: 0.0905 - val_loss: 3.8145 - val_accuracy: 0.1308\n",
      "Epoch 143/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.0888 - accuracy: 0.0905 - val_loss: 3.8105 - val_accuracy: 0.1308\n",
      "Epoch 144/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.1006 - accuracy: 0.0846 - val_loss: 3.8064 - val_accuracy: 0.1308\n",
      "Epoch 145/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.0858 - accuracy: 0.0897 - val_loss: 3.8024 - val_accuracy: 0.1308\n",
      "Epoch 146/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.0838 - accuracy: 0.0873 - val_loss: 3.7984 - val_accuracy: 0.1308\n",
      "Epoch 147/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.0772 - accuracy: 0.0928 - val_loss: 3.7944 - val_accuracy: 0.1308\n",
      "Epoch 148/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.0683 - accuracy: 0.0975 - val_loss: 3.7903 - val_accuracy: 0.1308\n",
      "Epoch 149/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.0242 - accuracy: 0.1011 - val_loss: 3.7862 - val_accuracy: 0.1308\n",
      "Epoch 150/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.0412 - accuracy: 0.0999 - val_loss: 3.7821 - val_accuracy: 0.1308\n",
      "Epoch 151/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.0696 - accuracy: 0.0956 - val_loss: 3.7781 - val_accuracy: 0.1308\n",
      "Epoch 152/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.0527 - accuracy: 0.0999 - val_loss: 3.7741 - val_accuracy: 0.1308\n",
      "Epoch 153/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.0304 - accuracy: 0.1022 - val_loss: 3.7700 - val_accuracy: 0.1308\n",
      "Epoch 154/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.0753 - accuracy: 0.0960 - val_loss: 3.7660 - val_accuracy: 0.1402\n",
      "Epoch 155/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.0535 - accuracy: 0.0995 - val_loss: 3.7621 - val_accuracy: 0.1495\n",
      "Epoch 156/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.0447 - accuracy: 0.1014 - val_loss: 3.7581 - val_accuracy: 0.1495\n",
      "Epoch 157/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.0173 - accuracy: 0.1085 - val_loss: 3.7542 - val_accuracy: 0.1495\n",
      "Epoch 158/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.0473 - accuracy: 0.1046 - val_loss: 3.7503 - val_accuracy: 0.1495\n",
      "Epoch 159/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.0092 - accuracy: 0.1022 - val_loss: 3.7462 - val_accuracy: 0.1495\n",
      "Epoch 160/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.0404 - accuracy: 0.1011 - val_loss: 3.7423 - val_accuracy: 0.1495\n",
      "Epoch 161/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.0140 - accuracy: 0.1069 - val_loss: 3.7383 - val_accuracy: 0.1495\n",
      "Epoch 162/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.0255 - accuracy: 0.1152 - val_loss: 3.7344 - val_accuracy: 0.1495\n",
      "Epoch 163/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 3.9896 - accuracy: 0.1148 - val_loss: 3.7304 - val_accuracy: 0.1589\n",
      "Epoch 164/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.9831 - accuracy: 0.1191 - val_loss: 3.7264 - val_accuracy: 0.1682\n",
      "Epoch 165/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 3.9868 - accuracy: 0.1171 - val_loss: 3.7224 - val_accuracy: 0.1682\n",
      "Epoch 166/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 3.9865 - accuracy: 0.1199 - val_loss: 3.7185 - val_accuracy: 0.1682\n",
      "Epoch 167/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 3.9657 - accuracy: 0.1277 - val_loss: 3.7145 - val_accuracy: 0.1682\n",
      "Epoch 168/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 3.9785 - accuracy: 0.1199 - val_loss: 3.7105 - val_accuracy: 0.1682\n",
      "Epoch 169/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 3.9842 - accuracy: 0.1214 - val_loss: 3.7066 - val_accuracy: 0.1682\n",
      "Epoch 170/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 3.9717 - accuracy: 0.1312 - val_loss: 3.7027 - val_accuracy: 0.1682\n",
      "Epoch 171/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 3.9476 - accuracy: 0.1285 - val_loss: 3.6987 - val_accuracy: 0.1682\n",
      "Epoch 172/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 3.9571 - accuracy: 0.1300 - val_loss: 3.6948 - val_accuracy: 0.1682\n",
      "Epoch 173/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 3ms/step - loss: 3.9579 - accuracy: 0.1261 - val_loss: 3.6909 - val_accuracy: 0.1682\n",
      "Epoch 174/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 3.9726 - accuracy: 0.1285 - val_loss: 3.6870 - val_accuracy: 0.1682\n",
      "Epoch 175/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 3.9174 - accuracy: 0.1347 - val_loss: 3.6830 - val_accuracy: 0.1682\n",
      "Epoch 176/200\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 3.9419 - accuracy: 0.1328 - val_loss: 3.6791 - val_accuracy: 0.1682\n",
      "Epoch 177/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 3.9347 - accuracy: 0.1332 - val_loss: 3.6752 - val_accuracy: 0.1682\n",
      "Epoch 178/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 3.9610 - accuracy: 0.1289 - val_loss: 3.6714 - val_accuracy: 0.1682\n",
      "Epoch 179/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 3.9553 - accuracy: 0.1308 - val_loss: 3.6676 - val_accuracy: 0.1682\n",
      "Epoch 180/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 3.9431 - accuracy: 0.1308 - val_loss: 3.6638 - val_accuracy: 0.1682\n",
      "Epoch 181/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.9388 - accuracy: 0.1324 - val_loss: 3.6599 - val_accuracy: 0.1776\n",
      "Epoch 182/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.9479 - accuracy: 0.1363 - val_loss: 3.6562 - val_accuracy: 0.1776\n",
      "Epoch 183/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.9430 - accuracy: 0.1320 - val_loss: 3.6524 - val_accuracy: 0.1776\n",
      "Epoch 184/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.9261 - accuracy: 0.1383 - val_loss: 3.6485 - val_accuracy: 0.1776\n",
      "Epoch 185/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.9116 - accuracy: 0.1422 - val_loss: 3.6447 - val_accuracy: 0.1776\n",
      "Epoch 186/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.9162 - accuracy: 0.1363 - val_loss: 3.6409 - val_accuracy: 0.1776\n",
      "Epoch 187/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.8969 - accuracy: 0.1500 - val_loss: 3.6371 - val_accuracy: 0.1776\n",
      "Epoch 188/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.9292 - accuracy: 0.1355 - val_loss: 3.6334 - val_accuracy: 0.1776\n",
      "Epoch 189/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.9067 - accuracy: 0.1461 - val_loss: 3.6295 - val_accuracy: 0.1869\n",
      "Epoch 190/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.9285 - accuracy: 0.1371 - val_loss: 3.6259 - val_accuracy: 0.1869\n",
      "Epoch 191/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.9106 - accuracy: 0.1414 - val_loss: 3.6222 - val_accuracy: 0.1869\n",
      "Epoch 192/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.8958 - accuracy: 0.1477 - val_loss: 3.6184 - val_accuracy: 0.1869\n",
      "Epoch 193/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.8768 - accuracy: 0.1492 - val_loss: 3.6146 - val_accuracy: 0.1869\n",
      "Epoch 194/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.8845 - accuracy: 0.1547 - val_loss: 3.6108 - val_accuracy: 0.1963\n",
      "Epoch 195/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.8989 - accuracy: 0.1473 - val_loss: 3.6071 - val_accuracy: 0.2056\n",
      "Epoch 196/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.9045 - accuracy: 0.1481 - val_loss: 3.6034 - val_accuracy: 0.2056\n",
      "Epoch 197/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.8613 - accuracy: 0.1575 - val_loss: 3.5996 - val_accuracy: 0.2056\n",
      "Epoch 198/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.8952 - accuracy: 0.1528 - val_loss: 3.5959 - val_accuracy: 0.2056\n",
      "Epoch 199/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.8671 - accuracy: 0.1590 - val_loss: 3.5921 - val_accuracy: 0.2056\n",
      "Epoch 200/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.8617 - accuracy: 0.1594 - val_loss: 3.5883 - val_accuracy: 0.2056\n",
      "0.20560747385025024 {'loss': 3.861748456954956, 'accuracy': 0.15942029654979706, 'val_loss': 3.5883193016052246, 'val_accuracy': 0.20560747385025024}\n",
      "Model: \"model_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_21 (InputLayer)        [(None, 29)]              0         \n",
      "_________________________________________________________________\n",
      "flatten_20 (Flatten)         (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 41)                1230      \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 75)                3150      \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 75)                0         \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 75)                0         \n",
      "=================================================================\n",
      "Total params: 4,380\n",
      "Trainable params: 4,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.2283 - accuracy: 0.0020 - val_loss: 4.6355 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.2265 - accuracy: 0.0024 - val_loss: 4.6293 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.2080 - accuracy: 0.0016 - val_loss: 4.6229 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.1975 - accuracy: 0.0016 - val_loss: 4.6167 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.1936 - accuracy: 0.0027 - val_loss: 4.6102 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.1651 - accuracy: 0.0020 - val_loss: 4.6036 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.1529 - accuracy: 0.0020 - val_loss: 4.5970 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.1335 - accuracy: 0.0027 - val_loss: 4.5901 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.1243 - accuracy: 0.0035 - val_loss: 4.5834 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.1413 - accuracy: 0.0031 - val_loss: 4.5770 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.1248 - accuracy: 0.0027 - val_loss: 4.5705 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.1144 - accuracy: 0.0035 - val_loss: 4.5640 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.1039 - accuracy: 0.0039 - val_loss: 4.5576 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.0669 - accuracy: 0.0024 - val_loss: 4.5505 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.0779 - accuracy: 0.0031 - val_loss: 4.5438 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.0621 - accuracy: 0.0031 - val_loss: 4.5373 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.0646 - accuracy: 0.0039 - val_loss: 4.5307 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.0349 - accuracy: 0.0043 - val_loss: 4.5237 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.0202 - accuracy: 0.0078 - val_loss: 4.5171 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.0272 - accuracy: 0.0043 - val_loss: 4.5106 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.9941 - accuracy: 0.0043 - val_loss: 4.5038 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.9944 - accuracy: 0.0047 - val_loss: 4.4969 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.9925 - accuracy: 0.0055 - val_loss: 4.4902 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.9959 - accuracy: 0.0067 - val_loss: 4.4835 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.9773 - accuracy: 0.0051 - val_loss: 4.4768 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.9659 - accuracy: 0.0047 - val_loss: 4.4701 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.9400 - accuracy: 0.0071 - val_loss: 4.4633 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.9420 - accuracy: 0.0039 - val_loss: 4.4565 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.9412 - accuracy: 0.0067 - val_loss: 4.4499 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.9247 - accuracy: 0.0039 - val_loss: 4.4434 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.9041 - accuracy: 0.0059 - val_loss: 4.4366 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.8940 - accuracy: 0.0082 - val_loss: 4.4299 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.8803 - accuracy: 0.0055 - val_loss: 4.4232 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.8897 - accuracy: 0.0051 - val_loss: 4.4167 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.8767 - accuracy: 0.0071 - val_loss: 4.4100 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.8518 - accuracy: 0.0067 - val_loss: 4.4031 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.8288 - accuracy: 0.0098 - val_loss: 4.3959 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.8543 - accuracy: 0.0078 - val_loss: 4.3892 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.8253 - accuracy: 0.0094 - val_loss: 4.3821 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.8132 - accuracy: 0.0114 - val_loss: 4.3753 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.8232 - accuracy: 0.0141 - val_loss: 4.3686 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.8121 - accuracy: 0.0086 - val_loss: 4.3617 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.7798 - accuracy: 0.0114 - val_loss: 4.3550 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.7808 - accuracy: 0.0121 - val_loss: 4.3482 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.7595 - accuracy: 0.0121 - val_loss: 4.3414 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.7900 - accuracy: 0.0098 - val_loss: 4.3344 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.7576 - accuracy: 0.0102 - val_loss: 4.3274 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.7506 - accuracy: 0.0153 - val_loss: 4.3208 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.7209 - accuracy: 0.0129 - val_loss: 4.3138 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.7219 - accuracy: 0.0153 - val_loss: 4.3070 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.7142 - accuracy: 0.0153 - val_loss: 4.3004 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.6843 - accuracy: 0.0176 - val_loss: 4.2933 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.6933 - accuracy: 0.0157 - val_loss: 4.2864 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.6799 - accuracy: 0.0137 - val_loss: 4.2796 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.6586 - accuracy: 0.0172 - val_loss: 4.2727 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.6655 - accuracy: 0.0145 - val_loss: 4.2658 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.6529 - accuracy: 0.0188 - val_loss: 4.2590 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.6397 - accuracy: 0.0172 - val_loss: 4.2523 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.6350 - accuracy: 0.0184 - val_loss: 4.2456 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.6398 - accuracy: 0.0180 - val_loss: 4.2390 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.5977 - accuracy: 0.0235 - val_loss: 4.2321 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.6329 - accuracy: 0.0208 - val_loss: 4.2256 - val_accuracy: 0.0093\n",
      "Epoch 63/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.5784 - accuracy: 0.0286 - val_loss: 4.2189 - val_accuracy: 0.0093\n",
      "Epoch 64/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.6149 - accuracy: 0.0215 - val_loss: 4.2124 - val_accuracy: 0.0093\n",
      "Epoch 65/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.5786 - accuracy: 0.0223 - val_loss: 4.2056 - val_accuracy: 0.0093\n",
      "Epoch 66/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.5719 - accuracy: 0.0321 - val_loss: 4.1991 - val_accuracy: 0.0093\n",
      "Epoch 67/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.5730 - accuracy: 0.0204 - val_loss: 4.1925 - val_accuracy: 0.0093\n",
      "Epoch 68/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.5400 - accuracy: 0.0329 - val_loss: 4.1860 - val_accuracy: 0.0093\n",
      "Epoch 69/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.5498 - accuracy: 0.0227 - val_loss: 4.1793 - val_accuracy: 0.0093\n",
      "Epoch 70/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.5341 - accuracy: 0.0286 - val_loss: 4.1724 - val_accuracy: 0.0093\n",
      "Epoch 71/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.5171 - accuracy: 0.0313 - val_loss: 4.1657 - val_accuracy: 0.0093\n",
      "Epoch 72/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.4860 - accuracy: 0.0345 - val_loss: 4.1587 - val_accuracy: 0.0093\n",
      "Epoch 73/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.5032 - accuracy: 0.0290 - val_loss: 4.1517 - val_accuracy: 0.0093\n",
      "Epoch 74/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.4916 - accuracy: 0.0286 - val_loss: 4.1449 - val_accuracy: 0.0093\n",
      "Epoch 75/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.4950 - accuracy: 0.0337 - val_loss: 4.1383 - val_accuracy: 0.0093\n",
      "Epoch 76/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.4798 - accuracy: 0.0317 - val_loss: 4.1316 - val_accuracy: 0.0093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.4664 - accuracy: 0.0368 - val_loss: 4.1246 - val_accuracy: 0.0093\n",
      "Epoch 78/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.4317 - accuracy: 0.0447 - val_loss: 4.1177 - val_accuracy: 0.0093\n",
      "Epoch 79/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.4164 - accuracy: 0.0392 - val_loss: 4.1104 - val_accuracy: 0.0093\n",
      "Epoch 80/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.4351 - accuracy: 0.0356 - val_loss: 4.1034 - val_accuracy: 0.0187\n",
      "Epoch 81/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.4259 - accuracy: 0.0474 - val_loss: 4.0969 - val_accuracy: 0.0187\n",
      "Epoch 82/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.4173 - accuracy: 0.0400 - val_loss: 4.0900 - val_accuracy: 0.0187\n",
      "Epoch 83/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.4331 - accuracy: 0.0435 - val_loss: 4.0833 - val_accuracy: 0.0280\n",
      "Epoch 84/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.3865 - accuracy: 0.0439 - val_loss: 4.0763 - val_accuracy: 0.0280\n",
      "Epoch 85/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.3739 - accuracy: 0.0439 - val_loss: 4.0692 - val_accuracy: 0.0374\n",
      "Epoch 86/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.3771 - accuracy: 0.0521 - val_loss: 4.0622 - val_accuracy: 0.0374\n",
      "Epoch 87/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.3888 - accuracy: 0.0517 - val_loss: 4.0555 - val_accuracy: 0.0374\n",
      "Epoch 88/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.3597 - accuracy: 0.0486 - val_loss: 4.0487 - val_accuracy: 0.0467\n",
      "Epoch 89/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.3612 - accuracy: 0.0556 - val_loss: 4.0419 - val_accuracy: 0.0467\n",
      "Epoch 90/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.3309 - accuracy: 0.0533 - val_loss: 4.0349 - val_accuracy: 0.0467\n",
      "Epoch 91/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.3462 - accuracy: 0.0584 - val_loss: 4.0285 - val_accuracy: 0.0467\n",
      "Epoch 92/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.3500 - accuracy: 0.0486 - val_loss: 4.0218 - val_accuracy: 0.0561\n",
      "Epoch 93/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.3384 - accuracy: 0.0529 - val_loss: 4.0151 - val_accuracy: 0.0561\n",
      "Epoch 94/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.3224 - accuracy: 0.0537 - val_loss: 4.0084 - val_accuracy: 0.0561\n",
      "Epoch 95/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.3353 - accuracy: 0.0501 - val_loss: 4.0017 - val_accuracy: 0.0561\n",
      "Epoch 96/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.2902 - accuracy: 0.0638 - val_loss: 3.9951 - val_accuracy: 0.0561\n",
      "Epoch 97/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.3009 - accuracy: 0.0662 - val_loss: 3.9887 - val_accuracy: 0.0561\n",
      "Epoch 98/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.2810 - accuracy: 0.0646 - val_loss: 3.9818 - val_accuracy: 0.0654\n",
      "Epoch 99/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.2587 - accuracy: 0.0646 - val_loss: 3.9749 - val_accuracy: 0.0654\n",
      "Epoch 100/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.2863 - accuracy: 0.0744 - val_loss: 3.9685 - val_accuracy: 0.0748\n",
      "Epoch 101/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.2622 - accuracy: 0.0713 - val_loss: 3.9618 - val_accuracy: 0.0748\n",
      "Epoch 102/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.2580 - accuracy: 0.0768 - val_loss: 3.9552 - val_accuracy: 0.0748\n",
      "Epoch 103/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.2543 - accuracy: 0.0666 - val_loss: 3.9487 - val_accuracy: 0.0748\n",
      "Epoch 104/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.2464 - accuracy: 0.0748 - val_loss: 3.9420 - val_accuracy: 0.0748\n",
      "Epoch 105/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.2301 - accuracy: 0.0826 - val_loss: 3.9356 - val_accuracy: 0.0748\n",
      "Epoch 106/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.2178 - accuracy: 0.0838 - val_loss: 3.9288 - val_accuracy: 0.0841\n",
      "Epoch 107/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.2354 - accuracy: 0.0795 - val_loss: 3.9225 - val_accuracy: 0.0841\n",
      "Epoch 108/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.2392 - accuracy: 0.0830 - val_loss: 3.9162 - val_accuracy: 0.0841\n",
      "Epoch 109/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.1664 - accuracy: 0.0917 - val_loss: 3.9094 - val_accuracy: 0.0841\n",
      "Epoch 110/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.1622 - accuracy: 0.0913 - val_loss: 3.9027 - val_accuracy: 0.1028\n",
      "Epoch 111/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.2087 - accuracy: 0.0905 - val_loss: 3.8962 - val_accuracy: 0.1121\n",
      "Epoch 112/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.1757 - accuracy: 0.0932 - val_loss: 3.8898 - val_accuracy: 0.1121\n",
      "Epoch 113/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.1682 - accuracy: 0.1014 - val_loss: 3.8834 - val_accuracy: 0.1308\n",
      "Epoch 114/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.1673 - accuracy: 0.1034 - val_loss: 3.8771 - val_accuracy: 0.1308\n",
      "Epoch 115/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.1778 - accuracy: 0.0956 - val_loss: 3.8708 - val_accuracy: 0.1495\n",
      "Epoch 116/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.1395 - accuracy: 0.1030 - val_loss: 3.8643 - val_accuracy: 0.1495\n",
      "Epoch 117/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.1250 - accuracy: 0.1132 - val_loss: 3.8580 - val_accuracy: 0.1495\n",
      "Epoch 118/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.1443 - accuracy: 0.1073 - val_loss: 3.8517 - val_accuracy: 0.1589\n",
      "Epoch 119/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.1337 - accuracy: 0.1120 - val_loss: 3.8456 - val_accuracy: 0.1776\n",
      "Epoch 120/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.1422 - accuracy: 0.1144 - val_loss: 3.8396 - val_accuracy: 0.1776\n",
      "Epoch 121/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.1423 - accuracy: 0.1144 - val_loss: 3.8335 - val_accuracy: 0.1963\n",
      "Epoch 122/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.1355 - accuracy: 0.1112 - val_loss: 3.8273 - val_accuracy: 0.2056\n",
      "Epoch 123/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.0846 - accuracy: 0.1273 - val_loss: 3.8211 - val_accuracy: 0.2056\n",
      "Epoch 124/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.0890 - accuracy: 0.1308 - val_loss: 3.8149 - val_accuracy: 0.2056\n",
      "Epoch 125/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.0993 - accuracy: 0.1206 - val_loss: 3.8087 - val_accuracy: 0.2056\n",
      "Epoch 126/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.1181 - accuracy: 0.1234 - val_loss: 3.8027 - val_accuracy: 0.2056\n",
      "Epoch 127/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.0814 - accuracy: 0.1261 - val_loss: 3.7966 - val_accuracy: 0.2056\n",
      "Epoch 128/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.0500 - accuracy: 0.1383 - val_loss: 3.7903 - val_accuracy: 0.2150\n",
      "Epoch 129/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.0644 - accuracy: 0.1375 - val_loss: 3.7843 - val_accuracy: 0.2150\n",
      "Epoch 130/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.0456 - accuracy: 0.1359 - val_loss: 3.7780 - val_accuracy: 0.2150\n",
      "Epoch 131/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.0377 - accuracy: 0.1438 - val_loss: 3.7718 - val_accuracy: 0.2150\n",
      "Epoch 132/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.0759 - accuracy: 0.1379 - val_loss: 3.7660 - val_accuracy: 0.2150\n",
      "Epoch 133/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 2ms/step - loss: 4.0362 - accuracy: 0.1410 - val_loss: 3.7600 - val_accuracy: 0.2243\n",
      "Epoch 134/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.0205 - accuracy: 0.1461 - val_loss: 3.7540 - val_accuracy: 0.2336\n",
      "Epoch 135/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.0058 - accuracy: 0.1492 - val_loss: 3.7479 - val_accuracy: 0.2336\n",
      "Epoch 136/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.0306 - accuracy: 0.1555 - val_loss: 3.7421 - val_accuracy: 0.2336\n",
      "Epoch 137/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.9444 - accuracy: 0.1720 - val_loss: 3.7358 - val_accuracy: 0.2430\n",
      "Epoch 138/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.9553 - accuracy: 0.1649 - val_loss: 3.7295 - val_accuracy: 0.2430\n",
      "Epoch 139/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.0248 - accuracy: 0.1532 - val_loss: 3.7239 - val_accuracy: 0.2430\n",
      "Epoch 140/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.9711 - accuracy: 0.1708 - val_loss: 3.7179 - val_accuracy: 0.2430\n",
      "Epoch 141/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.0168 - accuracy: 0.1559 - val_loss: 3.7123 - val_accuracy: 0.2430\n",
      "Epoch 142/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.9584 - accuracy: 0.1669 - val_loss: 3.7062 - val_accuracy: 0.2430\n",
      "Epoch 143/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.9734 - accuracy: 0.1614 - val_loss: 3.7005 - val_accuracy: 0.2523\n",
      "Epoch 144/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.9720 - accuracy: 0.1763 - val_loss: 3.6946 - val_accuracy: 0.2523\n",
      "Epoch 145/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.9367 - accuracy: 0.1735 - val_loss: 3.6886 - val_accuracy: 0.2710\n",
      "Epoch 146/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.9239 - accuracy: 0.1841 - val_loss: 3.6827 - val_accuracy: 0.2710\n",
      "Epoch 147/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.9568 - accuracy: 0.1696 - val_loss: 3.6769 - val_accuracy: 0.2710\n",
      "Epoch 148/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.9493 - accuracy: 0.1716 - val_loss: 3.6712 - val_accuracy: 0.2710\n",
      "Epoch 149/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.9500 - accuracy: 0.1802 - val_loss: 3.6655 - val_accuracy: 0.2804\n",
      "Epoch 150/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.9224 - accuracy: 0.1872 - val_loss: 3.6600 - val_accuracy: 0.2804\n",
      "Epoch 151/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.9230 - accuracy: 0.1849 - val_loss: 3.6545 - val_accuracy: 0.2804\n",
      "Epoch 152/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.8990 - accuracy: 0.1982 - val_loss: 3.6487 - val_accuracy: 0.2804\n",
      "Epoch 153/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.9276 - accuracy: 0.1810 - val_loss: 3.6432 - val_accuracy: 0.2804\n",
      "Epoch 154/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.9649 - accuracy: 0.1786 - val_loss: 3.6379 - val_accuracy: 0.2804\n",
      "Epoch 155/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.9032 - accuracy: 0.1951 - val_loss: 3.6323 - val_accuracy: 0.2804\n",
      "Epoch 156/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.8929 - accuracy: 0.1911 - val_loss: 3.6267 - val_accuracy: 0.2804\n",
      "Epoch 157/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.8525 - accuracy: 0.2060 - val_loss: 3.6211 - val_accuracy: 0.2804\n",
      "Epoch 158/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.9011 - accuracy: 0.1990 - val_loss: 3.6157 - val_accuracy: 0.2991\n",
      "Epoch 159/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.8869 - accuracy: 0.2080 - val_loss: 3.6102 - val_accuracy: 0.2991\n",
      "Epoch 160/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.8494 - accuracy: 0.2060 - val_loss: 3.6046 - val_accuracy: 0.3084\n",
      "Epoch 161/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.8630 - accuracy: 0.2009 - val_loss: 3.5991 - val_accuracy: 0.3178\n",
      "Epoch 162/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.8524 - accuracy: 0.2049 - val_loss: 3.5937 - val_accuracy: 0.3178\n",
      "Epoch 163/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.8604 - accuracy: 0.2127 - val_loss: 3.5884 - val_accuracy: 0.3271\n",
      "Epoch 164/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.8438 - accuracy: 0.2076 - val_loss: 3.5831 - val_accuracy: 0.3364\n",
      "Epoch 165/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.8710 - accuracy: 0.2107 - val_loss: 3.5780 - val_accuracy: 0.3364\n",
      "Epoch 166/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.8551 - accuracy: 0.2119 - val_loss: 3.5726 - val_accuracy: 0.3364\n",
      "Epoch 167/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.8132 - accuracy: 0.2221 - val_loss: 3.5674 - val_accuracy: 0.3551\n",
      "Epoch 168/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.7896 - accuracy: 0.2311 - val_loss: 3.5619 - val_accuracy: 0.3551\n",
      "Epoch 169/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.8092 - accuracy: 0.2299 - val_loss: 3.5567 - val_accuracy: 0.3738\n",
      "Epoch 170/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.8094 - accuracy: 0.2284 - val_loss: 3.5515 - val_accuracy: 0.4019\n",
      "Epoch 171/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.8366 - accuracy: 0.2178 - val_loss: 3.5465 - val_accuracy: 0.4019\n",
      "Epoch 172/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.8292 - accuracy: 0.2190 - val_loss: 3.5415 - val_accuracy: 0.4019\n",
      "Epoch 173/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.8388 - accuracy: 0.2190 - val_loss: 3.5365 - val_accuracy: 0.4019\n",
      "Epoch 174/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.7806 - accuracy: 0.2244 - val_loss: 3.5314 - val_accuracy: 0.4019\n",
      "Epoch 175/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.8083 - accuracy: 0.2229 - val_loss: 3.5266 - val_accuracy: 0.3925\n",
      "Epoch 176/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.7933 - accuracy: 0.2268 - val_loss: 3.5215 - val_accuracy: 0.3925\n",
      "Epoch 177/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.8377 - accuracy: 0.2170 - val_loss: 3.5169 - val_accuracy: 0.3925\n",
      "Epoch 178/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.7812 - accuracy: 0.2311 - val_loss: 3.5120 - val_accuracy: 0.4019\n",
      "Epoch 179/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.8019 - accuracy: 0.2260 - val_loss: 3.5073 - val_accuracy: 0.4019\n",
      "Epoch 180/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.7402 - accuracy: 0.2429 - val_loss: 3.5021 - val_accuracy: 0.4019\n",
      "Epoch 181/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.8038 - accuracy: 0.2319 - val_loss: 3.4974 - val_accuracy: 0.4112\n",
      "Epoch 182/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.7818 - accuracy: 0.2264 - val_loss: 3.4926 - val_accuracy: 0.4112\n",
      "Epoch 183/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.8108 - accuracy: 0.2264 - val_loss: 3.4882 - val_accuracy: 0.4112\n",
      "Epoch 184/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.7399 - accuracy: 0.2487 - val_loss: 3.4834 - val_accuracy: 0.4112\n",
      "Epoch 185/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.8042 - accuracy: 0.2299 - val_loss: 3.4789 - val_accuracy: 0.4206\n",
      "Epoch 186/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.8200 - accuracy: 0.2268 - val_loss: 3.4748 - val_accuracy: 0.4206\n",
      "Epoch 187/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.7637 - accuracy: 0.2370 - val_loss: 3.4702 - val_accuracy: 0.4206\n",
      "Epoch 188/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.7106 - accuracy: 0.2452 - val_loss: 3.4654 - val_accuracy: 0.4206\n",
      "Epoch 189/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 2ms/step - loss: 3.7388 - accuracy: 0.2452 - val_loss: 3.4607 - val_accuracy: 0.4206\n",
      "Epoch 190/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.7316 - accuracy: 0.2472 - val_loss: 3.4559 - val_accuracy: 0.4206\n",
      "Epoch 191/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.7428 - accuracy: 0.2483 - val_loss: 3.4516 - val_accuracy: 0.4206\n",
      "Epoch 192/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.7433 - accuracy: 0.2382 - val_loss: 3.4471 - val_accuracy: 0.4206\n",
      "Epoch 193/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.7221 - accuracy: 0.2495 - val_loss: 3.4429 - val_accuracy: 0.4206\n",
      "Epoch 194/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.7243 - accuracy: 0.2436 - val_loss: 3.4383 - val_accuracy: 0.4206\n",
      "Epoch 195/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.7455 - accuracy: 0.2452 - val_loss: 3.4341 - val_accuracy: 0.4206\n",
      "Epoch 196/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.7731 - accuracy: 0.2429 - val_loss: 3.4300 - val_accuracy: 0.4206\n",
      "Epoch 197/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.6840 - accuracy: 0.2617 - val_loss: 3.4255 - val_accuracy: 0.4206\n",
      "Epoch 198/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.7310 - accuracy: 0.2405 - val_loss: 3.4211 - val_accuracy: 0.4299\n",
      "Epoch 199/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.7027 - accuracy: 0.2530 - val_loss: 3.4168 - val_accuracy: 0.4393\n",
      "Epoch 200/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.7186 - accuracy: 0.2542 - val_loss: 3.4124 - val_accuracy: 0.4393\n",
      "0.4392523467540741 {'loss': 3.7185676097869873, 'accuracy': 0.2542107403278351, 'val_loss': 3.412414073944092, 'val_accuracy': 0.4392523467540741}\n",
      "Model: \"model_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_22 (InputLayer)        [(None, 29)]              0         \n",
      "_________________________________________________________________\n",
      "flatten_21 (Flatten)         (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 41)                1230      \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 75)                3150      \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 75)                0         \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 75)                0         \n",
      "=================================================================\n",
      "Total params: 4,380\n",
      "Trainable params: 4,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 5.3868 - accuracy: 0.0020 - val_loss: 4.6699 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.3892 - accuracy: 0.0016 - val_loss: 4.6663 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.3626 - accuracy: 0.0012 - val_loss: 4.6627 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.3861 - accuracy: 0.0020 - val_loss: 4.6592 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.3378 - accuracy: 0.0012 - val_loss: 4.6555 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.3311 - accuracy: 0.0027 - val_loss: 4.6519 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.3517 - accuracy: 0.0020 - val_loss: 4.6483 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.3460 - accuracy: 0.0012 - val_loss: 4.6448 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.3133 - accuracy: 0.0024 - val_loss: 4.6412 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.3166 - accuracy: 0.0024 - val_loss: 4.6377 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.3185 - accuracy: 0.0020 - val_loss: 4.6342 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.2987 - accuracy: 0.0031 - val_loss: 4.6305 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.3157 - accuracy: 0.0024 - val_loss: 4.6270 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.3064 - accuracy: 0.0027 - val_loss: 4.6235 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.2781 - accuracy: 0.0027 - val_loss: 4.6200 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.2915 - accuracy: 0.0055 - val_loss: 4.6166 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.2720 - accuracy: 0.0024 - val_loss: 4.6131 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.2848 - accuracy: 0.0020 - val_loss: 4.6097 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.2786 - accuracy: 0.0035 - val_loss: 4.6062 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.2708 - accuracy: 0.0027 - val_loss: 4.6028 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.2751 - accuracy: 0.0047 - val_loss: 4.5994 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.2285 - accuracy: 0.0031 - val_loss: 4.5959 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.2026 - accuracy: 0.0031 - val_loss: 4.5923 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.2221 - accuracy: 0.0039 - val_loss: 4.5889 - val_accuracy: 0.0093\n",
      "Epoch 25/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.2069 - accuracy: 0.0039 - val_loss: 4.5854 - val_accuracy: 0.0093\n",
      "Epoch 26/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.2077 - accuracy: 0.0043 - val_loss: 4.5819 - val_accuracy: 0.0093\n",
      "Epoch 27/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.2364 - accuracy: 0.0027 - val_loss: 4.5786 - val_accuracy: 0.0093\n",
      "Epoch 28/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.2131 - accuracy: 0.0043 - val_loss: 4.5752 - val_accuracy: 0.0093\n",
      "Epoch 29/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.1831 - accuracy: 0.0059 - val_loss: 4.5717 - val_accuracy: 0.0093\n",
      "Epoch 30/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.1805 - accuracy: 0.0055 - val_loss: 4.5681 - val_accuracy: 0.0093\n",
      "Epoch 31/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.1809 - accuracy: 0.0051 - val_loss: 4.5647 - val_accuracy: 0.0093\n",
      "Epoch 32/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.1781 - accuracy: 0.0039 - val_loss: 4.5614 - val_accuracy: 0.0093\n",
      "Epoch 33/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.1789 - accuracy: 0.0031 - val_loss: 4.5580 - val_accuracy: 0.0093\n",
      "Epoch 34/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.1628 - accuracy: 0.0059 - val_loss: 4.5546 - val_accuracy: 0.0093\n",
      "Epoch 35/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.1596 - accuracy: 0.0059 - val_loss: 4.5512 - val_accuracy: 0.0093\n",
      "Epoch 36/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.1560 - accuracy: 0.0047 - val_loss: 4.5478 - val_accuracy: 0.0093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.1596 - accuracy: 0.0051 - val_loss: 4.5444 - val_accuracy: 0.0093\n",
      "Epoch 38/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.1376 - accuracy: 0.0051 - val_loss: 4.5410 - val_accuracy: 0.0093\n",
      "Epoch 39/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.1307 - accuracy: 0.0051 - val_loss: 4.5377 - val_accuracy: 0.0093\n",
      "Epoch 40/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.1229 - accuracy: 0.0063 - val_loss: 4.5343 - val_accuracy: 0.0093\n",
      "Epoch 41/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.1219 - accuracy: 0.0059 - val_loss: 4.5310 - val_accuracy: 0.0093\n",
      "Epoch 42/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.1174 - accuracy: 0.0074 - val_loss: 4.5277 - val_accuracy: 0.0093\n",
      "Epoch 43/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.1099 - accuracy: 0.0047 - val_loss: 4.5244 - val_accuracy: 0.0093\n",
      "Epoch 44/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.1032 - accuracy: 0.0078 - val_loss: 4.5210 - val_accuracy: 0.0093\n",
      "Epoch 45/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.1018 - accuracy: 0.0071 - val_loss: 4.5177 - val_accuracy: 0.0093\n",
      "Epoch 46/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.0915 - accuracy: 0.0067 - val_loss: 4.5144 - val_accuracy: 0.0093\n",
      "Epoch 47/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.0981 - accuracy: 0.0059 - val_loss: 4.5111 - val_accuracy: 0.0093\n",
      "Epoch 48/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.0490 - accuracy: 0.0102 - val_loss: 4.5077 - val_accuracy: 0.0187\n",
      "Epoch 49/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.0810 - accuracy: 0.0063 - val_loss: 4.5043 - val_accuracy: 0.0187\n",
      "Epoch 50/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.0653 - accuracy: 0.0082 - val_loss: 4.5010 - val_accuracy: 0.0187\n",
      "Epoch 51/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.0830 - accuracy: 0.0078 - val_loss: 4.4978 - val_accuracy: 0.0187\n",
      "Epoch 52/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.0598 - accuracy: 0.0125 - val_loss: 4.4945 - val_accuracy: 0.0187\n",
      "Epoch 53/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.0424 - accuracy: 0.0059 - val_loss: 4.4912 - val_accuracy: 0.0187\n",
      "Epoch 54/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.0316 - accuracy: 0.0059 - val_loss: 4.4879 - val_accuracy: 0.0187\n",
      "Epoch 55/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.0349 - accuracy: 0.0121 - val_loss: 4.4845 - val_accuracy: 0.0187\n",
      "Epoch 56/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.0108 - accuracy: 0.0094 - val_loss: 4.4811 - val_accuracy: 0.0187\n",
      "Epoch 57/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.0364 - accuracy: 0.0094 - val_loss: 4.4779 - val_accuracy: 0.0187\n",
      "Epoch 58/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.0122 - accuracy: 0.0102 - val_loss: 4.4747 - val_accuracy: 0.0187\n",
      "Epoch 59/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.0059 - accuracy: 0.0114 - val_loss: 4.4714 - val_accuracy: 0.0187\n",
      "Epoch 60/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.0191 - accuracy: 0.0067 - val_loss: 4.4682 - val_accuracy: 0.0187\n",
      "Epoch 61/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.9933 - accuracy: 0.0090 - val_loss: 4.4649 - val_accuracy: 0.0187\n",
      "Epoch 62/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.9851 - accuracy: 0.0098 - val_loss: 4.4615 - val_accuracy: 0.0187\n",
      "Epoch 63/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.9633 - accuracy: 0.0157 - val_loss: 4.4583 - val_accuracy: 0.0187\n",
      "Epoch 64/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.9700 - accuracy: 0.0102 - val_loss: 4.4549 - val_accuracy: 0.0187\n",
      "Epoch 65/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.9866 - accuracy: 0.0118 - val_loss: 4.4517 - val_accuracy: 0.0187\n",
      "Epoch 66/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.9679 - accuracy: 0.0133 - val_loss: 4.4484 - val_accuracy: 0.0187\n",
      "Epoch 67/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.9700 - accuracy: 0.0090 - val_loss: 4.4453 - val_accuracy: 0.0187\n",
      "Epoch 68/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.9498 - accuracy: 0.0137 - val_loss: 4.4421 - val_accuracy: 0.0187\n",
      "Epoch 69/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.9201 - accuracy: 0.0141 - val_loss: 4.4387 - val_accuracy: 0.0187\n",
      "Epoch 70/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.9520 - accuracy: 0.0110 - val_loss: 4.4355 - val_accuracy: 0.0187\n",
      "Epoch 71/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.9303 - accuracy: 0.0106 - val_loss: 4.4323 - val_accuracy: 0.0187\n",
      "Epoch 72/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.9226 - accuracy: 0.0137 - val_loss: 4.4291 - val_accuracy: 0.0187\n",
      "Epoch 73/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.9353 - accuracy: 0.0137 - val_loss: 4.4259 - val_accuracy: 0.0187\n",
      "Epoch 74/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.8859 - accuracy: 0.0149 - val_loss: 4.4227 - val_accuracy: 0.0187\n",
      "Epoch 75/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.9159 - accuracy: 0.0133 - val_loss: 4.4195 - val_accuracy: 0.0187\n",
      "Epoch 76/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.8746 - accuracy: 0.0161 - val_loss: 4.4162 - val_accuracy: 0.0187\n",
      "Epoch 77/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.8922 - accuracy: 0.0153 - val_loss: 4.4131 - val_accuracy: 0.0187\n",
      "Epoch 78/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.9012 - accuracy: 0.0165 - val_loss: 4.4100 - val_accuracy: 0.0187\n",
      "Epoch 79/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.8648 - accuracy: 0.0184 - val_loss: 4.4067 - val_accuracy: 0.0187\n",
      "Epoch 80/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.8779 - accuracy: 0.0165 - val_loss: 4.4034 - val_accuracy: 0.0187\n",
      "Epoch 81/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.8907 - accuracy: 0.0133 - val_loss: 4.4003 - val_accuracy: 0.0187\n",
      "Epoch 82/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.8738 - accuracy: 0.0176 - val_loss: 4.3971 - val_accuracy: 0.0187\n",
      "Epoch 83/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.8499 - accuracy: 0.0196 - val_loss: 4.3939 - val_accuracy: 0.0187\n",
      "Epoch 84/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.8710 - accuracy: 0.0165 - val_loss: 4.3908 - val_accuracy: 0.0187\n",
      "Epoch 85/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.8513 - accuracy: 0.0168 - val_loss: 4.3877 - val_accuracy: 0.0187\n",
      "Epoch 86/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.8447 - accuracy: 0.0184 - val_loss: 4.3845 - val_accuracy: 0.0187\n",
      "Epoch 87/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.8498 - accuracy: 0.0141 - val_loss: 4.3814 - val_accuracy: 0.0187\n",
      "Epoch 88/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.8441 - accuracy: 0.0176 - val_loss: 4.3781 - val_accuracy: 0.0187\n",
      "Epoch 89/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.8318 - accuracy: 0.0180 - val_loss: 4.3750 - val_accuracy: 0.0187\n",
      "Epoch 90/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.8520 - accuracy: 0.0176 - val_loss: 4.3719 - val_accuracy: 0.0187\n",
      "Epoch 91/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.8073 - accuracy: 0.0204 - val_loss: 4.3687 - val_accuracy: 0.0187\n",
      "Epoch 92/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.8037 - accuracy: 0.0212 - val_loss: 4.3655 - val_accuracy: 0.0187\n",
      "Epoch 93/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.7987 - accuracy: 0.0212 - val_loss: 4.3623 - val_accuracy: 0.0187\n",
      "Epoch 94/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 2ms/step - loss: 4.7915 - accuracy: 0.0227 - val_loss: 4.3592 - val_accuracy: 0.0187\n",
      "Epoch 95/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.8053 - accuracy: 0.0255 - val_loss: 4.3561 - val_accuracy: 0.0187\n",
      "Epoch 96/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.7714 - accuracy: 0.0208 - val_loss: 4.3529 - val_accuracy: 0.0187\n",
      "Epoch 97/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.7852 - accuracy: 0.0231 - val_loss: 4.3499 - val_accuracy: 0.0187\n",
      "Epoch 98/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.8087 - accuracy: 0.0212 - val_loss: 4.3469 - val_accuracy: 0.0187\n",
      "Epoch 99/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 4.7723 - accuracy: 0.0247 - val_loss: 4.3438 - val_accuracy: 0.0187\n",
      "Epoch 100/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 4.7573 - accuracy: 0.0243 - val_loss: 4.3406 - val_accuracy: 0.0187\n",
      "Epoch 101/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.7831 - accuracy: 0.0239 - val_loss: 4.3376 - val_accuracy: 0.0187\n",
      "Epoch 102/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 4.7679 - accuracy: 0.0223 - val_loss: 4.3345 - val_accuracy: 0.0187\n",
      "Epoch 103/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.7722 - accuracy: 0.0247 - val_loss: 4.3315 - val_accuracy: 0.0187\n",
      "Epoch 104/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.7374 - accuracy: 0.0266 - val_loss: 4.3284 - val_accuracy: 0.0187\n",
      "Epoch 105/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.7384 - accuracy: 0.0270 - val_loss: 4.3252 - val_accuracy: 0.0187\n",
      "Epoch 106/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.7787 - accuracy: 0.0235 - val_loss: 4.3222 - val_accuracy: 0.0187\n",
      "Epoch 107/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.7534 - accuracy: 0.0227 - val_loss: 4.3193 - val_accuracy: 0.0187\n",
      "Epoch 108/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.7213 - accuracy: 0.0282 - val_loss: 4.3162 - val_accuracy: 0.0187\n",
      "Epoch 109/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.7164 - accuracy: 0.0286 - val_loss: 4.3132 - val_accuracy: 0.0187\n",
      "Epoch 110/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.7418 - accuracy: 0.0266 - val_loss: 4.3101 - val_accuracy: 0.0187\n",
      "Epoch 111/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.7183 - accuracy: 0.0274 - val_loss: 4.3071 - val_accuracy: 0.0187\n",
      "Epoch 112/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.7018 - accuracy: 0.0282 - val_loss: 4.3041 - val_accuracy: 0.0187\n",
      "Epoch 113/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.7223 - accuracy: 0.0321 - val_loss: 4.3011 - val_accuracy: 0.0187\n",
      "Epoch 114/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.7162 - accuracy: 0.0282 - val_loss: 4.2981 - val_accuracy: 0.0187\n",
      "Epoch 115/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.6980 - accuracy: 0.0298 - val_loss: 4.2952 - val_accuracy: 0.0187\n",
      "Epoch 116/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.7037 - accuracy: 0.0309 - val_loss: 4.2922 - val_accuracy: 0.0187\n",
      "Epoch 117/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.6621 - accuracy: 0.0306 - val_loss: 4.2891 - val_accuracy: 0.0187\n",
      "Epoch 118/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.6635 - accuracy: 0.0345 - val_loss: 4.2860 - val_accuracy: 0.0187\n",
      "Epoch 119/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.6730 - accuracy: 0.0353 - val_loss: 4.2830 - val_accuracy: 0.0187\n",
      "Epoch 120/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.6517 - accuracy: 0.0333 - val_loss: 4.2799 - val_accuracy: 0.0187\n",
      "Epoch 121/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.6713 - accuracy: 0.0341 - val_loss: 4.2769 - val_accuracy: 0.0187\n",
      "Epoch 122/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.6664 - accuracy: 0.0353 - val_loss: 4.2739 - val_accuracy: 0.0187\n",
      "Epoch 123/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.6438 - accuracy: 0.0349 - val_loss: 4.2708 - val_accuracy: 0.0187\n",
      "Epoch 124/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.6458 - accuracy: 0.0364 - val_loss: 4.2678 - val_accuracy: 0.0280\n",
      "Epoch 125/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.6645 - accuracy: 0.0364 - val_loss: 4.2649 - val_accuracy: 0.0280\n",
      "Epoch 126/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.6414 - accuracy: 0.0403 - val_loss: 4.2618 - val_accuracy: 0.0280\n",
      "Epoch 127/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.6269 - accuracy: 0.0384 - val_loss: 4.2588 - val_accuracy: 0.0280\n",
      "Epoch 128/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.6492 - accuracy: 0.0364 - val_loss: 4.2560 - val_accuracy: 0.0280\n",
      "Epoch 129/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.6254 - accuracy: 0.0372 - val_loss: 4.2530 - val_accuracy: 0.0280\n",
      "Epoch 130/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.6372 - accuracy: 0.0392 - val_loss: 4.2501 - val_accuracy: 0.0280\n",
      "Epoch 131/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.5988 - accuracy: 0.0435 - val_loss: 4.2471 - val_accuracy: 0.0280\n",
      "Epoch 132/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.6248 - accuracy: 0.0403 - val_loss: 4.2441 - val_accuracy: 0.0280\n",
      "Epoch 133/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.6545 - accuracy: 0.0341 - val_loss: 4.2413 - val_accuracy: 0.0280\n",
      "Epoch 134/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.6154 - accuracy: 0.0360 - val_loss: 4.2384 - val_accuracy: 0.0280\n",
      "Epoch 135/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.6018 - accuracy: 0.0419 - val_loss: 4.2354 - val_accuracy: 0.0280\n",
      "Epoch 136/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.6138 - accuracy: 0.0384 - val_loss: 4.2326 - val_accuracy: 0.0280\n",
      "Epoch 137/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.6084 - accuracy: 0.0388 - val_loss: 4.2298 - val_accuracy: 0.0280\n",
      "Epoch 138/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.5722 - accuracy: 0.0439 - val_loss: 4.2268 - val_accuracy: 0.0280\n",
      "Epoch 139/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.5726 - accuracy: 0.0517 - val_loss: 4.2239 - val_accuracy: 0.0280\n",
      "Epoch 140/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.5653 - accuracy: 0.0450 - val_loss: 4.2209 - val_accuracy: 0.0280\n",
      "Epoch 141/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.5743 - accuracy: 0.0431 - val_loss: 4.2180 - val_accuracy: 0.0280\n",
      "Epoch 142/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.5815 - accuracy: 0.0400 - val_loss: 4.2151 - val_accuracy: 0.0280\n",
      "Epoch 143/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.5862 - accuracy: 0.0419 - val_loss: 4.2124 - val_accuracy: 0.0280\n",
      "Epoch 144/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 4.5651 - accuracy: 0.0478 - val_loss: 4.2096 - val_accuracy: 0.0280\n",
      "Epoch 145/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.5373 - accuracy: 0.0458 - val_loss: 4.2067 - val_accuracy: 0.0280\n",
      "Epoch 146/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.5763 - accuracy: 0.0419 - val_loss: 4.2039 - val_accuracy: 0.0280\n",
      "Epoch 147/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.5717 - accuracy: 0.0494 - val_loss: 4.2011 - val_accuracy: 0.0280\n",
      "Epoch 148/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.5607 - accuracy: 0.0443 - val_loss: 4.1983 - val_accuracy: 0.0280\n",
      "Epoch 149/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.5391 - accuracy: 0.0482 - val_loss: 4.1955 - val_accuracy: 0.0280\n",
      "Epoch 150/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.5400 - accuracy: 0.0529 - val_loss: 4.1926 - val_accuracy: 0.0280\n",
      "Epoch 151/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 3ms/step - loss: 4.5164 - accuracy: 0.0521 - val_loss: 4.1897 - val_accuracy: 0.0280\n",
      "Epoch 152/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.5199 - accuracy: 0.0517 - val_loss: 4.1868 - val_accuracy: 0.0280\n",
      "Epoch 153/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.5104 - accuracy: 0.0521 - val_loss: 4.1841 - val_accuracy: 0.0280\n",
      "Epoch 154/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.5246 - accuracy: 0.0505 - val_loss: 4.1813 - val_accuracy: 0.0280\n",
      "Epoch 155/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.5259 - accuracy: 0.0525 - val_loss: 4.1786 - val_accuracy: 0.0280\n",
      "Epoch 156/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.5157 - accuracy: 0.0529 - val_loss: 4.1758 - val_accuracy: 0.0280\n",
      "Epoch 157/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.5179 - accuracy: 0.0544 - val_loss: 4.1730 - val_accuracy: 0.0280\n",
      "Epoch 158/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.4870 - accuracy: 0.0556 - val_loss: 4.1701 - val_accuracy: 0.0280\n",
      "Epoch 159/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.4555 - accuracy: 0.0607 - val_loss: 4.1671 - val_accuracy: 0.0280\n",
      "Epoch 160/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.5021 - accuracy: 0.0478 - val_loss: 4.1643 - val_accuracy: 0.0280\n",
      "Epoch 161/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.5152 - accuracy: 0.0525 - val_loss: 4.1616 - val_accuracy: 0.0280\n",
      "Epoch 162/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.4950 - accuracy: 0.0556 - val_loss: 4.1589 - val_accuracy: 0.0280\n",
      "Epoch 163/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.4808 - accuracy: 0.0584 - val_loss: 4.1561 - val_accuracy: 0.0374\n",
      "Epoch 164/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.4396 - accuracy: 0.0556 - val_loss: 4.1532 - val_accuracy: 0.0374\n",
      "Epoch 165/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.4926 - accuracy: 0.0552 - val_loss: 4.1505 - val_accuracy: 0.0374\n",
      "Epoch 166/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.4524 - accuracy: 0.0572 - val_loss: 4.1477 - val_accuracy: 0.0374\n",
      "Epoch 167/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.4570 - accuracy: 0.0591 - val_loss: 4.1448 - val_accuracy: 0.0374\n",
      "Epoch 168/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.4704 - accuracy: 0.0544 - val_loss: 4.1421 - val_accuracy: 0.0374\n",
      "Epoch 169/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.4566 - accuracy: 0.0552 - val_loss: 4.1394 - val_accuracy: 0.0374\n",
      "Epoch 170/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.4636 - accuracy: 0.0548 - val_loss: 4.1367 - val_accuracy: 0.0374\n",
      "Epoch 171/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.4592 - accuracy: 0.0552 - val_loss: 4.1340 - val_accuracy: 0.0374\n",
      "Epoch 172/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.4255 - accuracy: 0.0627 - val_loss: 4.1312 - val_accuracy: 0.0374\n",
      "Epoch 173/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.4311 - accuracy: 0.0635 - val_loss: 4.1285 - val_accuracy: 0.0374\n",
      "Epoch 174/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.4441 - accuracy: 0.0615 - val_loss: 4.1257 - val_accuracy: 0.0374\n",
      "Epoch 175/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.4487 - accuracy: 0.0646 - val_loss: 4.1231 - val_accuracy: 0.0374\n",
      "Epoch 176/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.4154 - accuracy: 0.0662 - val_loss: 4.1203 - val_accuracy: 0.0374\n",
      "Epoch 177/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.4351 - accuracy: 0.0584 - val_loss: 4.1176 - val_accuracy: 0.0374\n",
      "Epoch 178/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.4283 - accuracy: 0.0611 - val_loss: 4.1149 - val_accuracy: 0.0374\n",
      "Epoch 179/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.4474 - accuracy: 0.0638 - val_loss: 4.1123 - val_accuracy: 0.0374\n",
      "Epoch 180/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.3939 - accuracy: 0.0682 - val_loss: 4.1095 - val_accuracy: 0.0374\n",
      "Epoch 181/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.4456 - accuracy: 0.0619 - val_loss: 4.1069 - val_accuracy: 0.0374\n",
      "Epoch 182/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.3926 - accuracy: 0.0638 - val_loss: 4.1042 - val_accuracy: 0.0374\n",
      "Epoch 183/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.4221 - accuracy: 0.0650 - val_loss: 4.1015 - val_accuracy: 0.0374\n",
      "Epoch 184/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.4011 - accuracy: 0.0670 - val_loss: 4.0989 - val_accuracy: 0.0467\n",
      "Epoch 185/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.3800 - accuracy: 0.0693 - val_loss: 4.0962 - val_accuracy: 0.0467\n",
      "Epoch 186/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.4064 - accuracy: 0.0697 - val_loss: 4.0934 - val_accuracy: 0.0467\n",
      "Epoch 187/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.3900 - accuracy: 0.0674 - val_loss: 4.0907 - val_accuracy: 0.0467\n",
      "Epoch 188/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.3608 - accuracy: 0.0779 - val_loss: 4.0880 - val_accuracy: 0.0467\n",
      "Epoch 189/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.4028 - accuracy: 0.0689 - val_loss: 4.0853 - val_accuracy: 0.0467\n",
      "Epoch 190/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.3545 - accuracy: 0.0795 - val_loss: 4.0826 - val_accuracy: 0.0467\n",
      "Epoch 191/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.3827 - accuracy: 0.0693 - val_loss: 4.0800 - val_accuracy: 0.0467\n",
      "Epoch 192/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.3739 - accuracy: 0.0760 - val_loss: 4.0774 - val_accuracy: 0.0467\n",
      "Epoch 193/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.3582 - accuracy: 0.0721 - val_loss: 4.0747 - val_accuracy: 0.0467\n",
      "Epoch 194/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 4.3169 - accuracy: 0.0823 - val_loss: 4.0718 - val_accuracy: 0.0467\n",
      "Epoch 195/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 4.3681 - accuracy: 0.0748 - val_loss: 4.0692 - val_accuracy: 0.0467\n",
      "Epoch 196/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 4.3445 - accuracy: 0.0776 - val_loss: 4.0667 - val_accuracy: 0.0467\n",
      "Epoch 197/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.3472 - accuracy: 0.0748 - val_loss: 4.0640 - val_accuracy: 0.0467\n",
      "Epoch 198/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.3588 - accuracy: 0.0705 - val_loss: 4.0615 - val_accuracy: 0.0467\n",
      "Epoch 199/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.3348 - accuracy: 0.0748 - val_loss: 4.0588 - val_accuracy: 0.0467\n",
      "Epoch 200/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 4.3560 - accuracy: 0.0791 - val_loss: 4.0563 - val_accuracy: 0.0467\n",
      "0.04672897234559059 {'loss': 4.355992794036865, 'accuracy': 0.07912260293960571, 'val_loss': 4.056273460388184, 'val_accuracy': 0.04672897234559059}\n",
      "Model: \"model_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_23 (InputLayer)        [(None, 29)]              0         \n",
      "_________________________________________________________________\n",
      "flatten_22 (Flatten)         (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 41)                1230      \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 75)                3150      \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 75)                0         \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 75)                0         \n",
      "=================================================================\n",
      "Total params: 4,380\n",
      "Trainable params: 4,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 7.0571 - accuracy: 0.0020 - val_loss: 4.7545 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/200\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 7.0515 - accuracy: 0.0031 - val_loss: 4.7493 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 7.0742 - accuracy: 7.8339e-04 - val_loss: 4.7443 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 6.9512 - accuracy: 0.0024 - val_loss: 4.7390 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 7.0069 - accuracy: 0.0031 - val_loss: 4.7337 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 6.9709 - accuracy: 0.0016 - val_loss: 4.7284 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 6.9456 - accuracy: 0.0016 - val_loss: 4.7234 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 6.9649 - accuracy: 0.0012 - val_loss: 4.7183 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 6.9376 - accuracy: 0.0016 - val_loss: 4.7130 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 6.8980 - accuracy: 0.0035 - val_loss: 4.7077 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 6.8976 - accuracy: 0.0024 - val_loss: 4.7026 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 6.8120 - accuracy: 0.0039 - val_loss: 4.6975 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 6.7930 - accuracy: 0.0031 - val_loss: 4.6925 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 6.8488 - accuracy: 0.0043 - val_loss: 4.6873 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 6.8695 - accuracy: 0.0027 - val_loss: 4.6823 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 6.7547 - accuracy: 0.0020 - val_loss: 4.6774 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 6.7680 - accuracy: 0.0016 - val_loss: 4.6724 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 6.7695 - accuracy: 0.0047 - val_loss: 4.6675 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 6.7396 - accuracy: 0.0039 - val_loss: 4.6626 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 6.6725 - accuracy: 0.0043 - val_loss: 4.6576 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 6.7013 - accuracy: 0.0027 - val_loss: 4.6527 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 6.6615 - accuracy: 0.0035 - val_loss: 4.6476 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/200\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 6.6258 - accuracy: 0.0035 - val_loss: 4.6428 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 6.6874 - accuracy: 0.0031 - val_loss: 4.6381 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 6.6422 - accuracy: 0.0043 - val_loss: 4.6331 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 6.5646 - accuracy: 0.0043 - val_loss: 4.6282 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 6.5975 - accuracy: 0.0063 - val_loss: 4.6234 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 6.5866 - accuracy: 0.0074 - val_loss: 4.6186 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 6.5432 - accuracy: 0.0020 - val_loss: 4.6139 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 6.4908 - accuracy: 0.0043 - val_loss: 4.6091 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 6.4646 - accuracy: 0.0031 - val_loss: 4.6041 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 6.4572 - accuracy: 0.0035 - val_loss: 4.5995 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 6.4648 - accuracy: 0.0043 - val_loss: 4.5947 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 6.4822 - accuracy: 0.0055 - val_loss: 4.5900 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 6.4899 - accuracy: 0.0063 - val_loss: 4.5853 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 6.4590 - accuracy: 0.0067 - val_loss: 4.5807 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 6.4262 - accuracy: 0.0035 - val_loss: 4.5759 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 6.4352 - accuracy: 0.0027 - val_loss: 4.5712 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 6.4019 - accuracy: 0.0047 - val_loss: 4.5665 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 6.3241 - accuracy: 0.0059 - val_loss: 4.5619 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 6.2971 - accuracy: 0.0051 - val_loss: 4.5573 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 6.3584 - accuracy: 0.0078 - val_loss: 4.5526 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 6.3248 - accuracy: 0.0086 - val_loss: 4.5479 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 6.2870 - accuracy: 0.0063 - val_loss: 4.5433 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 6.2662 - accuracy: 0.0063 - val_loss: 4.5386 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 6.2267 - accuracy: 0.0094 - val_loss: 4.5341 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 6.2186 - accuracy: 0.0082 - val_loss: 4.5296 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 6.2394 - accuracy: 0.0059 - val_loss: 4.5250 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 6.1540 - accuracy: 0.0098 - val_loss: 4.5204 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 6.1816 - accuracy: 0.0098 - val_loss: 4.5158 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 6.1533 - accuracy: 0.0082 - val_loss: 4.5113 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 6.1459 - accuracy: 0.0063 - val_loss: 4.5067 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 6.0768 - accuracy: 0.0121 - val_loss: 4.5022 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 6.1184 - accuracy: 0.0071 - val_loss: 4.4975 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 6.0880 - accuracy: 0.0067 - val_loss: 4.4929 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 2ms/step - loss: 6.0839 - accuracy: 0.0074 - val_loss: 4.4883 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 6.0441 - accuracy: 0.0078 - val_loss: 4.4836 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 6.0406 - accuracy: 0.0106 - val_loss: 4.4792 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 6.0395 - accuracy: 0.0063 - val_loss: 4.4745 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 6.0400 - accuracy: 0.0098 - val_loss: 4.4700 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 6.0001 - accuracy: 0.0090 - val_loss: 4.4655 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.9764 - accuracy: 0.0114 - val_loss: 4.4612 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 6.0007 - accuracy: 0.0094 - val_loss: 4.4568 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 6.0034 - accuracy: 0.0078 - val_loss: 4.4525 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.9664 - accuracy: 0.0129 - val_loss: 4.4481 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.9573 - accuracy: 0.0082 - val_loss: 4.4438 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.9274 - accuracy: 0.0090 - val_loss: 4.4394 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.9481 - accuracy: 0.0098 - val_loss: 4.4351 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.8532 - accuracy: 0.0102 - val_loss: 4.4307 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.8567 - accuracy: 0.0098 - val_loss: 4.4266 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.8329 - accuracy: 0.0137 - val_loss: 4.4222 - val_accuracy: 0.0093\n",
      "Epoch 72/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.8676 - accuracy: 0.0153 - val_loss: 4.4181 - val_accuracy: 0.0093\n",
      "Epoch 73/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.8306 - accuracy: 0.0121 - val_loss: 4.4139 - val_accuracy: 0.0093\n",
      "Epoch 74/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.7967 - accuracy: 0.0110 - val_loss: 4.4097 - val_accuracy: 0.0093\n",
      "Epoch 75/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 5.8149 - accuracy: 0.0121 - val_loss: 4.4056 - val_accuracy: 0.0093\n",
      "Epoch 76/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.7241 - accuracy: 0.0157 - val_loss: 4.4013 - val_accuracy: 0.0093\n",
      "Epoch 77/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.7658 - accuracy: 0.0141 - val_loss: 4.3970 - val_accuracy: 0.0093\n",
      "Epoch 78/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.7595 - accuracy: 0.0090 - val_loss: 4.3928 - val_accuracy: 0.0093\n",
      "Epoch 79/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.7568 - accuracy: 0.0125 - val_loss: 4.3886 - val_accuracy: 0.0093\n",
      "Epoch 80/200\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 5.7397 - accuracy: 0.0133 - val_loss: 4.3844 - val_accuracy: 0.0093\n",
      "Epoch 81/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.7156 - accuracy: 0.0129 - val_loss: 4.3803 - val_accuracy: 0.0093\n",
      "Epoch 82/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.6690 - accuracy: 0.0161 - val_loss: 4.3762 - val_accuracy: 0.0093\n",
      "Epoch 83/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.6757 - accuracy: 0.0153 - val_loss: 4.3719 - val_accuracy: 0.0093\n",
      "Epoch 84/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.6282 - accuracy: 0.0176 - val_loss: 4.3677 - val_accuracy: 0.0093\n",
      "Epoch 85/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.7080 - accuracy: 0.0141 - val_loss: 4.3636 - val_accuracy: 0.0093\n",
      "Epoch 86/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.5792 - accuracy: 0.0223 - val_loss: 4.3595 - val_accuracy: 0.0093\n",
      "Epoch 87/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.6143 - accuracy: 0.0192 - val_loss: 4.3552 - val_accuracy: 0.0093\n",
      "Epoch 88/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.6267 - accuracy: 0.0141 - val_loss: 4.3509 - val_accuracy: 0.0093\n",
      "Epoch 89/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.6257 - accuracy: 0.0176 - val_loss: 4.3468 - val_accuracy: 0.0093\n",
      "Epoch 90/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 5.5714 - accuracy: 0.0215 - val_loss: 4.3427 - val_accuracy: 0.0093\n",
      "Epoch 91/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.5795 - accuracy: 0.0137 - val_loss: 4.3388 - val_accuracy: 0.0093\n",
      "Epoch 92/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.6058 - accuracy: 0.0161 - val_loss: 4.3348 - val_accuracy: 0.0093\n",
      "Epoch 93/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.5747 - accuracy: 0.0180 - val_loss: 4.3309 - val_accuracy: 0.0093\n",
      "Epoch 94/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.4939 - accuracy: 0.0215 - val_loss: 4.3268 - val_accuracy: 0.0187\n",
      "Epoch 95/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.5416 - accuracy: 0.0161 - val_loss: 4.3229 - val_accuracy: 0.0187\n",
      "Epoch 96/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.4807 - accuracy: 0.0165 - val_loss: 4.3188 - val_accuracy: 0.0187\n",
      "Epoch 97/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.5288 - accuracy: 0.0192 - val_loss: 4.3148 - val_accuracy: 0.0187\n",
      "Epoch 98/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.5228 - accuracy: 0.0180 - val_loss: 4.3108 - val_accuracy: 0.0187\n",
      "Epoch 99/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.4758 - accuracy: 0.0192 - val_loss: 4.3068 - val_accuracy: 0.0187\n",
      "Epoch 100/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.4615 - accuracy: 0.0215 - val_loss: 4.3027 - val_accuracy: 0.0187\n",
      "Epoch 101/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.4155 - accuracy: 0.0196 - val_loss: 4.2988 - val_accuracy: 0.0187\n",
      "Epoch 102/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.4138 - accuracy: 0.0200 - val_loss: 4.2948 - val_accuracy: 0.0187\n",
      "Epoch 103/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.4138 - accuracy: 0.0208 - val_loss: 4.2908 - val_accuracy: 0.0187\n",
      "Epoch 104/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 5.4374 - accuracy: 0.0204 - val_loss: 4.2867 - val_accuracy: 0.0187\n",
      "Epoch 105/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 5.4059 - accuracy: 0.0251 - val_loss: 4.2828 - val_accuracy: 0.0187\n",
      "Epoch 106/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.3578 - accuracy: 0.0204 - val_loss: 4.2786 - val_accuracy: 0.0187\n",
      "Epoch 107/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 5.3827 - accuracy: 0.0200 - val_loss: 4.2745 - val_accuracy: 0.0187\n",
      "Epoch 108/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 5.3191 - accuracy: 0.0231 - val_loss: 4.2705 - val_accuracy: 0.0187\n",
      "Epoch 109/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 5.3170 - accuracy: 0.0204 - val_loss: 4.2665 - val_accuracy: 0.0187\n",
      "Epoch 110/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.3269 - accuracy: 0.0247 - val_loss: 4.2624 - val_accuracy: 0.0187\n",
      "Epoch 111/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.2961 - accuracy: 0.0290 - val_loss: 4.2585 - val_accuracy: 0.0187\n",
      "Epoch 112/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 2ms/step - loss: 5.2851 - accuracy: 0.0259 - val_loss: 4.2547 - val_accuracy: 0.0187\n",
      "Epoch 113/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.3671 - accuracy: 0.0212 - val_loss: 4.2510 - val_accuracy: 0.0280\n",
      "Epoch 114/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.2738 - accuracy: 0.0278 - val_loss: 4.2470 - val_accuracy: 0.0280\n",
      "Epoch 115/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.2336 - accuracy: 0.0286 - val_loss: 4.2431 - val_accuracy: 0.0280\n",
      "Epoch 116/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.2643 - accuracy: 0.0227 - val_loss: 4.2390 - val_accuracy: 0.0280\n",
      "Epoch 117/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.2508 - accuracy: 0.0321 - val_loss: 4.2349 - val_accuracy: 0.0280\n",
      "Epoch 118/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.2215 - accuracy: 0.0298 - val_loss: 4.2310 - val_accuracy: 0.0280\n",
      "Epoch 119/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.1897 - accuracy: 0.0306 - val_loss: 4.2270 - val_accuracy: 0.0280\n",
      "Epoch 120/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.2360 - accuracy: 0.0223 - val_loss: 4.2230 - val_accuracy: 0.0280\n",
      "Epoch 121/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.1904 - accuracy: 0.0349 - val_loss: 4.2190 - val_accuracy: 0.0280\n",
      "Epoch 122/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.1488 - accuracy: 0.0313 - val_loss: 4.2151 - val_accuracy: 0.0374\n",
      "Epoch 123/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.2089 - accuracy: 0.0306 - val_loss: 4.2112 - val_accuracy: 0.0374\n",
      "Epoch 124/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.1508 - accuracy: 0.0325 - val_loss: 4.2074 - val_accuracy: 0.0374\n",
      "Epoch 125/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.1764 - accuracy: 0.0282 - val_loss: 4.2034 - val_accuracy: 0.0374\n",
      "Epoch 126/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.1765 - accuracy: 0.0274 - val_loss: 4.1998 - val_accuracy: 0.0374\n",
      "Epoch 127/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.1378 - accuracy: 0.0360 - val_loss: 4.1961 - val_accuracy: 0.0374\n",
      "Epoch 128/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.1047 - accuracy: 0.0329 - val_loss: 4.1922 - val_accuracy: 0.0467\n",
      "Epoch 129/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.1400 - accuracy: 0.0360 - val_loss: 4.1885 - val_accuracy: 0.0467\n",
      "Epoch 130/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.0721 - accuracy: 0.0333 - val_loss: 4.1845 - val_accuracy: 0.0467\n",
      "Epoch 131/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.1223 - accuracy: 0.0290 - val_loss: 4.1808 - val_accuracy: 0.0467\n",
      "Epoch 132/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.0433 - accuracy: 0.0333 - val_loss: 4.1770 - val_accuracy: 0.0467\n",
      "Epoch 133/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.0915 - accuracy: 0.0337 - val_loss: 4.1735 - val_accuracy: 0.0467\n",
      "Epoch 134/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.0332 - accuracy: 0.0368 - val_loss: 4.1696 - val_accuracy: 0.0467\n",
      "Epoch 135/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.0501 - accuracy: 0.0353 - val_loss: 4.1659 - val_accuracy: 0.0467\n",
      "Epoch 136/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.0343 - accuracy: 0.0364 - val_loss: 4.1622 - val_accuracy: 0.0467\n",
      "Epoch 137/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.0294 - accuracy: 0.0411 - val_loss: 4.1587 - val_accuracy: 0.0467\n",
      "Epoch 138/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.0238 - accuracy: 0.0384 - val_loss: 4.1551 - val_accuracy: 0.0467\n",
      "Epoch 139/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.0119 - accuracy: 0.0341 - val_loss: 4.1515 - val_accuracy: 0.0467\n",
      "Epoch 140/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.9663 - accuracy: 0.0411 - val_loss: 4.1477 - val_accuracy: 0.0467\n",
      "Epoch 141/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.9304 - accuracy: 0.0462 - val_loss: 4.1438 - val_accuracy: 0.0467\n",
      "Epoch 142/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 5.0036 - accuracy: 0.0384 - val_loss: 4.1402 - val_accuracy: 0.0467\n",
      "Epoch 143/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.9603 - accuracy: 0.0450 - val_loss: 4.1365 - val_accuracy: 0.0467\n",
      "Epoch 144/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.9203 - accuracy: 0.0435 - val_loss: 4.1326 - val_accuracy: 0.0467\n",
      "Epoch 145/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.8842 - accuracy: 0.0494 - val_loss: 4.1285 - val_accuracy: 0.0467\n",
      "Epoch 146/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.9060 - accuracy: 0.0403 - val_loss: 4.1245 - val_accuracy: 0.0467\n",
      "Epoch 147/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.9111 - accuracy: 0.0482 - val_loss: 4.1203 - val_accuracy: 0.0467\n",
      "Epoch 148/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.9185 - accuracy: 0.0443 - val_loss: 4.1162 - val_accuracy: 0.0467\n",
      "Epoch 149/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.8703 - accuracy: 0.0497 - val_loss: 4.1121 - val_accuracy: 0.0467\n",
      "Epoch 150/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.9201 - accuracy: 0.0490 - val_loss: 4.1081 - val_accuracy: 0.0467\n",
      "Epoch 151/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.8714 - accuracy: 0.0482 - val_loss: 4.1039 - val_accuracy: 0.0467\n",
      "Epoch 152/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 4.8404 - accuracy: 0.0462 - val_loss: 4.0998 - val_accuracy: 0.0467\n",
      "Epoch 153/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 4.8344 - accuracy: 0.0517 - val_loss: 4.0954 - val_accuracy: 0.0467\n",
      "Epoch 154/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.8274 - accuracy: 0.0544 - val_loss: 4.0910 - val_accuracy: 0.0561\n",
      "Epoch 155/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.8289 - accuracy: 0.0521 - val_loss: 4.0870 - val_accuracy: 0.0561\n",
      "Epoch 156/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.8443 - accuracy: 0.0494 - val_loss: 4.0831 - val_accuracy: 0.0561\n",
      "Epoch 157/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.8410 - accuracy: 0.0517 - val_loss: 4.0792 - val_accuracy: 0.0561\n",
      "Epoch 158/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.8461 - accuracy: 0.0470 - val_loss: 4.0753 - val_accuracy: 0.0654\n",
      "Epoch 159/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.8035 - accuracy: 0.0486 - val_loss: 4.0712 - val_accuracy: 0.0654\n",
      "Epoch 160/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.7898 - accuracy: 0.0497 - val_loss: 4.0669 - val_accuracy: 0.0654\n",
      "Epoch 161/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.7851 - accuracy: 0.0564 - val_loss: 4.0627 - val_accuracy: 0.0654\n",
      "Epoch 162/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.8153 - accuracy: 0.0544 - val_loss: 4.0586 - val_accuracy: 0.0654\n",
      "Epoch 163/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.7806 - accuracy: 0.0552 - val_loss: 4.0544 - val_accuracy: 0.0654\n",
      "Epoch 164/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.7734 - accuracy: 0.0611 - val_loss: 4.0502 - val_accuracy: 0.0654\n",
      "Epoch 165/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.7166 - accuracy: 0.0591 - val_loss: 4.0460 - val_accuracy: 0.0654\n",
      "Epoch 166/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.7515 - accuracy: 0.0521 - val_loss: 4.0414 - val_accuracy: 0.0654\n",
      "Epoch 167/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.6819 - accuracy: 0.0693 - val_loss: 4.0369 - val_accuracy: 0.0748\n",
      "Epoch 168/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 3ms/step - loss: 4.7340 - accuracy: 0.0623 - val_loss: 4.0327 - val_accuracy: 0.0748\n",
      "Epoch 169/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.6852 - accuracy: 0.0552 - val_loss: 4.0284 - val_accuracy: 0.0748\n",
      "Epoch 170/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.7082 - accuracy: 0.0619 - val_loss: 4.0242 - val_accuracy: 0.0748\n",
      "Epoch 171/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.7143 - accuracy: 0.0595 - val_loss: 4.0199 - val_accuracy: 0.0748\n",
      "Epoch 172/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.6820 - accuracy: 0.0564 - val_loss: 4.0156 - val_accuracy: 0.0748\n",
      "Epoch 173/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.6773 - accuracy: 0.0627 - val_loss: 4.0110 - val_accuracy: 0.0748\n",
      "Epoch 174/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.6668 - accuracy: 0.0713 - val_loss: 4.0066 - val_accuracy: 0.0748\n",
      "Epoch 175/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 4.6996 - accuracy: 0.0607 - val_loss: 4.0025 - val_accuracy: 0.0748\n",
      "Epoch 176/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.6612 - accuracy: 0.0635 - val_loss: 3.9981 - val_accuracy: 0.0748\n",
      "Epoch 177/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.6462 - accuracy: 0.0658 - val_loss: 3.9936 - val_accuracy: 0.0748\n",
      "Epoch 178/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.6165 - accuracy: 0.0713 - val_loss: 3.9890 - val_accuracy: 0.0748\n",
      "Epoch 179/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.6519 - accuracy: 0.0650 - val_loss: 3.9848 - val_accuracy: 0.0748\n",
      "Epoch 180/200\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 4.5959 - accuracy: 0.0713 - val_loss: 3.9804 - val_accuracy: 0.0748\n",
      "Epoch 181/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 4.5697 - accuracy: 0.0674 - val_loss: 3.9757 - val_accuracy: 0.0935\n",
      "Epoch 182/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 4.5886 - accuracy: 0.0717 - val_loss: 3.9713 - val_accuracy: 0.1028\n",
      "Epoch 183/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.5665 - accuracy: 0.0721 - val_loss: 3.9670 - val_accuracy: 0.1028\n",
      "Epoch 184/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 4.5694 - accuracy: 0.0760 - val_loss: 3.9625 - val_accuracy: 0.1028\n",
      "Epoch 185/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.5844 - accuracy: 0.0744 - val_loss: 3.9578 - val_accuracy: 0.1028\n",
      "Epoch 186/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.5680 - accuracy: 0.0783 - val_loss: 3.9532 - val_accuracy: 0.1028\n",
      "Epoch 187/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 4.5569 - accuracy: 0.0736 - val_loss: 3.9488 - val_accuracy: 0.1028\n",
      "Epoch 188/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.5698 - accuracy: 0.0791 - val_loss: 3.9443 - val_accuracy: 0.1215\n",
      "Epoch 189/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.5606 - accuracy: 0.0768 - val_loss: 3.9399 - val_accuracy: 0.1215\n",
      "Epoch 190/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.5199 - accuracy: 0.0854 - val_loss: 3.9355 - val_accuracy: 0.1215\n",
      "Epoch 191/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 4.4755 - accuracy: 0.0877 - val_loss: 3.9307 - val_accuracy: 0.1215\n",
      "Epoch 192/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 4.5167 - accuracy: 0.0826 - val_loss: 3.9262 - val_accuracy: 0.1215\n",
      "Epoch 193/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.5028 - accuracy: 0.0807 - val_loss: 3.9219 - val_accuracy: 0.1215\n",
      "Epoch 194/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.4695 - accuracy: 0.0909 - val_loss: 3.9175 - val_accuracy: 0.1215\n",
      "Epoch 195/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.5387 - accuracy: 0.0721 - val_loss: 3.9133 - val_accuracy: 0.1215\n",
      "Epoch 196/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.4612 - accuracy: 0.0873 - val_loss: 3.9086 - val_accuracy: 0.1308\n",
      "Epoch 197/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.4596 - accuracy: 0.0873 - val_loss: 3.9039 - val_accuracy: 0.1308\n",
      "Epoch 198/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.4588 - accuracy: 0.0862 - val_loss: 3.8995 - val_accuracy: 0.1308\n",
      "Epoch 199/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.4587 - accuracy: 0.0846 - val_loss: 3.8949 - val_accuracy: 0.1402\n",
      "Epoch 200/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.4873 - accuracy: 0.0873 - val_loss: 3.8906 - val_accuracy: 0.1402\n",
      "0.14018692076206207 {'loss': 4.487292766571045, 'accuracy': 0.08734821528196335, 'val_loss': 3.8906023502349854, 'val_accuracy': 0.14018692076206207}\n",
      "Model: \"model_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_24 (InputLayer)        [(None, 29)]              0         \n",
      "_________________________________________________________________\n",
      "flatten_23 (Flatten)         (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 41)                1230      \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 75)                3150      \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 75)                0         \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 75)                0         \n",
      "=================================================================\n",
      "Total params: 4,380\n",
      "Trainable params: 4,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 6.2863 - accuracy: 0.0396 - val_loss: 4.1431 - val_accuracy: 0.0935\n",
      "Epoch 2/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 6.2696 - accuracy: 0.0443 - val_loss: 4.1403 - val_accuracy: 0.0935\n",
      "Epoch 3/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 6.3110 - accuracy: 0.0368 - val_loss: 4.1376 - val_accuracy: 0.0935\n",
      "Epoch 4/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 6.2615 - accuracy: 0.0482 - val_loss: 4.1348 - val_accuracy: 0.0935\n",
      "Epoch 5/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 6.2898 - accuracy: 0.0407 - val_loss: 4.1323 - val_accuracy: 0.0935\n",
      "Epoch 6/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 6.2117 - accuracy: 0.0447 - val_loss: 4.1296 - val_accuracy: 0.0935\n",
      "Epoch 7/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 6.1502 - accuracy: 0.0517 - val_loss: 4.1269 - val_accuracy: 0.0935\n",
      "Epoch 8/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 6.2391 - accuracy: 0.0439 - val_loss: 4.1243 - val_accuracy: 0.0935\n",
      "Epoch 9/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 6.1951 - accuracy: 0.0423 - val_loss: 4.1217 - val_accuracy: 0.0935\n",
      "Epoch 10/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 6.2317 - accuracy: 0.0470 - val_loss: 4.1190 - val_accuracy: 0.1121\n",
      "Epoch 11/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 6.1907 - accuracy: 0.0478 - val_loss: 4.1164 - val_accuracy: 0.1121\n",
      "Epoch 12/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 6.2164 - accuracy: 0.0435 - val_loss: 4.1138 - val_accuracy: 0.1121\n",
      "Epoch 13/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 6.1895 - accuracy: 0.0407 - val_loss: 4.1112 - val_accuracy: 0.1121\n",
      "Epoch 14/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 6.1191 - accuracy: 0.0564 - val_loss: 4.1086 - val_accuracy: 0.1121\n",
      "Epoch 15/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 6.1430 - accuracy: 0.0529 - val_loss: 4.1060 - val_accuracy: 0.1121\n",
      "Epoch 16/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 3ms/step - loss: 6.1709 - accuracy: 0.0494 - val_loss: 4.1034 - val_accuracy: 0.1121\n",
      "Epoch 17/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 6.1998 - accuracy: 0.0466 - val_loss: 4.1009 - val_accuracy: 0.1121\n",
      "Epoch 18/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 6.0673 - accuracy: 0.0529 - val_loss: 4.0984 - val_accuracy: 0.1121\n",
      "Epoch 19/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 6.0995 - accuracy: 0.0490 - val_loss: 4.0957 - val_accuracy: 0.1121\n",
      "Epoch 20/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 6.0337 - accuracy: 0.0588 - val_loss: 4.0930 - val_accuracy: 0.1121\n",
      "Epoch 21/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 6.1413 - accuracy: 0.0466 - val_loss: 4.0906 - val_accuracy: 0.1121\n",
      "Epoch 22/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 6.0656 - accuracy: 0.0517 - val_loss: 4.0880 - val_accuracy: 0.1121\n",
      "Epoch 23/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 6.0892 - accuracy: 0.0521 - val_loss: 4.0854 - val_accuracy: 0.1121\n",
      "Epoch 24/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 6.0202 - accuracy: 0.0513 - val_loss: 4.0828 - val_accuracy: 0.1121\n",
      "Epoch 25/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 6.0900 - accuracy: 0.0478 - val_loss: 4.0802 - val_accuracy: 0.1121\n",
      "Epoch 26/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 6.0719 - accuracy: 0.0529 - val_loss: 4.0777 - val_accuracy: 0.1121\n",
      "Epoch 27/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 6.0748 - accuracy: 0.0580 - val_loss: 4.0753 - val_accuracy: 0.1121\n",
      "Epoch 28/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 6.0077 - accuracy: 0.0525 - val_loss: 4.0727 - val_accuracy: 0.1121\n",
      "Epoch 29/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 5.9875 - accuracy: 0.0497 - val_loss: 4.0699 - val_accuracy: 0.1121\n",
      "Epoch 30/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 6.0676 - accuracy: 0.0439 - val_loss: 4.0675 - val_accuracy: 0.1121\n",
      "Epoch 31/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 6.0602 - accuracy: 0.0497 - val_loss: 4.0648 - val_accuracy: 0.1121\n",
      "Epoch 32/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.9513 - accuracy: 0.0525 - val_loss: 4.0621 - val_accuracy: 0.1121\n",
      "Epoch 33/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 6.0693 - accuracy: 0.0466 - val_loss: 4.0598 - val_accuracy: 0.1121\n",
      "Epoch 34/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 6.0541 - accuracy: 0.0497 - val_loss: 4.0573 - val_accuracy: 0.1121\n",
      "Epoch 35/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.9521 - accuracy: 0.0544 - val_loss: 4.0548 - val_accuracy: 0.1121\n",
      "Epoch 36/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 6.0102 - accuracy: 0.0497 - val_loss: 4.0523 - val_accuracy: 0.1121\n",
      "Epoch 37/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 6.0169 - accuracy: 0.0544 - val_loss: 4.0498 - val_accuracy: 0.1121\n",
      "Epoch 38/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.9304 - accuracy: 0.0537 - val_loss: 4.0472 - val_accuracy: 0.1121\n",
      "Epoch 39/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.9592 - accuracy: 0.0513 - val_loss: 4.0446 - val_accuracy: 0.1121\n",
      "Epoch 40/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.9319 - accuracy: 0.0544 - val_loss: 4.0422 - val_accuracy: 0.1121\n",
      "Epoch 41/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.9099 - accuracy: 0.0537 - val_loss: 4.0396 - val_accuracy: 0.1121\n",
      "Epoch 42/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.9167 - accuracy: 0.0521 - val_loss: 4.0371 - val_accuracy: 0.1121\n",
      "Epoch 43/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.8932 - accuracy: 0.0525 - val_loss: 4.0346 - val_accuracy: 0.1121\n",
      "Epoch 44/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 5.8912 - accuracy: 0.0537 - val_loss: 4.0320 - val_accuracy: 0.1121\n",
      "Epoch 45/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.8918 - accuracy: 0.0615 - val_loss: 4.0296 - val_accuracy: 0.1121\n",
      "Epoch 46/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.9094 - accuracy: 0.0548 - val_loss: 4.0272 - val_accuracy: 0.1121\n",
      "Epoch 47/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.8363 - accuracy: 0.0580 - val_loss: 4.0246 - val_accuracy: 0.1121\n",
      "Epoch 48/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.8309 - accuracy: 0.0599 - val_loss: 4.0221 - val_accuracy: 0.1121\n",
      "Epoch 49/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.8694 - accuracy: 0.0533 - val_loss: 4.0197 - val_accuracy: 0.1121\n",
      "Epoch 50/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.8858 - accuracy: 0.0513 - val_loss: 4.0173 - val_accuracy: 0.1121\n",
      "Epoch 51/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.8417 - accuracy: 0.0548 - val_loss: 4.0149 - val_accuracy: 0.1121\n",
      "Epoch 52/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.9008 - accuracy: 0.0560 - val_loss: 4.0127 - val_accuracy: 0.1121\n",
      "Epoch 53/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.8858 - accuracy: 0.0525 - val_loss: 4.0104 - val_accuracy: 0.1121\n",
      "Epoch 54/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.8707 - accuracy: 0.0572 - val_loss: 4.0080 - val_accuracy: 0.1121\n",
      "Epoch 55/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.7789 - accuracy: 0.0615 - val_loss: 4.0054 - val_accuracy: 0.1121\n",
      "Epoch 56/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.7631 - accuracy: 0.0607 - val_loss: 4.0028 - val_accuracy: 0.1121\n",
      "Epoch 57/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.7970 - accuracy: 0.0638 - val_loss: 4.0003 - val_accuracy: 0.1121\n",
      "Epoch 58/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.7707 - accuracy: 0.0607 - val_loss: 3.9978 - val_accuracy: 0.1215\n",
      "Epoch 59/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.7909 - accuracy: 0.0568 - val_loss: 3.9953 - val_accuracy: 0.1215\n",
      "Epoch 60/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 5.8017 - accuracy: 0.0638 - val_loss: 3.9930 - val_accuracy: 0.1308\n",
      "Epoch 61/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 5.8250 - accuracy: 0.0537 - val_loss: 3.9905 - val_accuracy: 0.1308\n",
      "Epoch 62/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.7482 - accuracy: 0.0615 - val_loss: 3.9882 - val_accuracy: 0.1308\n",
      "Epoch 63/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.7559 - accuracy: 0.0591 - val_loss: 3.9858 - val_accuracy: 0.1308\n",
      "Epoch 64/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.7467 - accuracy: 0.0552 - val_loss: 3.9834 - val_accuracy: 0.1308\n",
      "Epoch 65/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.7877 - accuracy: 0.0584 - val_loss: 3.9812 - val_accuracy: 0.1308\n",
      "Epoch 66/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.6577 - accuracy: 0.0615 - val_loss: 3.9787 - val_accuracy: 0.1308\n",
      "Epoch 67/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.6513 - accuracy: 0.0717 - val_loss: 3.9761 - val_accuracy: 0.1308\n",
      "Epoch 68/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.6929 - accuracy: 0.0658 - val_loss: 3.9737 - val_accuracy: 0.1402\n",
      "Epoch 69/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.7522 - accuracy: 0.0591 - val_loss: 3.9714 - val_accuracy: 0.1402\n",
      "Epoch 70/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.7014 - accuracy: 0.0599 - val_loss: 3.9690 - val_accuracy: 0.1402\n",
      "Epoch 71/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.7346 - accuracy: 0.0666 - val_loss: 3.9667 - val_accuracy: 0.1402\n",
      "Epoch 72/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.6984 - accuracy: 0.0646 - val_loss: 3.9643 - val_accuracy: 0.1402\n",
      "Epoch 73/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.6997 - accuracy: 0.0627 - val_loss: 3.9620 - val_accuracy: 0.1402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.6617 - accuracy: 0.0654 - val_loss: 3.9596 - val_accuracy: 0.1402\n",
      "Epoch 75/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.7045 - accuracy: 0.0619 - val_loss: 3.9573 - val_accuracy: 0.1308\n",
      "Epoch 76/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.6251 - accuracy: 0.0689 - val_loss: 3.9551 - val_accuracy: 0.1308\n",
      "Epoch 77/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.6435 - accuracy: 0.0580 - val_loss: 3.9527 - val_accuracy: 0.1308\n",
      "Epoch 78/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.6237 - accuracy: 0.0654 - val_loss: 3.9504 - val_accuracy: 0.1308\n",
      "Epoch 79/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.6655 - accuracy: 0.0638 - val_loss: 3.9481 - val_accuracy: 0.1308\n",
      "Epoch 80/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.6199 - accuracy: 0.0713 - val_loss: 3.9458 - val_accuracy: 0.1308\n",
      "Epoch 81/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 5.6493 - accuracy: 0.0627 - val_loss: 3.9435 - val_accuracy: 0.1308\n",
      "Epoch 82/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 5.5506 - accuracy: 0.0729 - val_loss: 3.9412 - val_accuracy: 0.1308\n",
      "Epoch 83/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.5693 - accuracy: 0.0693 - val_loss: 3.9387 - val_accuracy: 0.1308\n",
      "Epoch 84/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.6120 - accuracy: 0.0689 - val_loss: 3.9363 - val_accuracy: 0.1308\n",
      "Epoch 85/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.5793 - accuracy: 0.0689 - val_loss: 3.9341 - val_accuracy: 0.1308\n",
      "Epoch 86/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.6086 - accuracy: 0.0744 - val_loss: 3.9319 - val_accuracy: 0.1308\n",
      "Epoch 87/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 5.6362 - accuracy: 0.0666 - val_loss: 3.9298 - val_accuracy: 0.1308\n",
      "Epoch 88/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 5.5124 - accuracy: 0.0725 - val_loss: 3.9273 - val_accuracy: 0.1308\n",
      "Epoch 89/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.5408 - accuracy: 0.0693 - val_loss: 3.9250 - val_accuracy: 0.1308\n",
      "Epoch 90/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.5357 - accuracy: 0.0729 - val_loss: 3.9225 - val_accuracy: 0.1402\n",
      "Epoch 91/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 5.5893 - accuracy: 0.0685 - val_loss: 3.9205 - val_accuracy: 0.1402\n",
      "Epoch 92/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.4908 - accuracy: 0.0729 - val_loss: 3.9180 - val_accuracy: 0.1402\n",
      "Epoch 93/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.5685 - accuracy: 0.0666 - val_loss: 3.9158 - val_accuracy: 0.1402\n",
      "Epoch 94/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.4723 - accuracy: 0.0803 - val_loss: 3.9135 - val_accuracy: 0.1402\n",
      "Epoch 95/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.4823 - accuracy: 0.0674 - val_loss: 3.9111 - val_accuracy: 0.1402\n",
      "Epoch 96/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.4816 - accuracy: 0.0740 - val_loss: 3.9088 - val_accuracy: 0.1402\n",
      "Epoch 97/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.4843 - accuracy: 0.0799 - val_loss: 3.9064 - val_accuracy: 0.1402\n",
      "Epoch 98/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.4900 - accuracy: 0.0650 - val_loss: 3.9042 - val_accuracy: 0.1402\n",
      "Epoch 99/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.5166 - accuracy: 0.0658 - val_loss: 3.9020 - val_accuracy: 0.1402\n",
      "Epoch 100/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.5103 - accuracy: 0.0768 - val_loss: 3.9000 - val_accuracy: 0.1402\n",
      "Epoch 101/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.4079 - accuracy: 0.0717 - val_loss: 3.8977 - val_accuracy: 0.1402\n",
      "Epoch 102/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.4200 - accuracy: 0.0752 - val_loss: 3.8954 - val_accuracy: 0.1402\n",
      "Epoch 103/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.4263 - accuracy: 0.0725 - val_loss: 3.8929 - val_accuracy: 0.1402\n",
      "Epoch 104/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.4484 - accuracy: 0.0685 - val_loss: 3.8907 - val_accuracy: 0.1495\n",
      "Epoch 105/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.4242 - accuracy: 0.0764 - val_loss: 3.8884 - val_accuracy: 0.1495\n",
      "Epoch 106/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.4281 - accuracy: 0.0795 - val_loss: 3.8860 - val_accuracy: 0.1495\n",
      "Epoch 107/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.3937 - accuracy: 0.0760 - val_loss: 3.8838 - val_accuracy: 0.1495\n",
      "Epoch 108/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.3932 - accuracy: 0.0756 - val_loss: 3.8816 - val_accuracy: 0.1495\n",
      "Epoch 109/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.4238 - accuracy: 0.0736 - val_loss: 3.8795 - val_accuracy: 0.1495\n",
      "Epoch 110/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.4053 - accuracy: 0.0678 - val_loss: 3.8774 - val_accuracy: 0.1495\n",
      "Epoch 111/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.3838 - accuracy: 0.0721 - val_loss: 3.8752 - val_accuracy: 0.1495\n",
      "Epoch 112/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.4641 - accuracy: 0.0674 - val_loss: 3.8731 - val_accuracy: 0.1495\n",
      "Epoch 113/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.3955 - accuracy: 0.0823 - val_loss: 3.8710 - val_accuracy: 0.1495\n",
      "Epoch 114/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.3440 - accuracy: 0.0807 - val_loss: 3.8689 - val_accuracy: 0.1495\n",
      "Epoch 115/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.3847 - accuracy: 0.0779 - val_loss: 3.8668 - val_accuracy: 0.1495\n",
      "Epoch 116/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.3500 - accuracy: 0.0811 - val_loss: 3.8647 - val_accuracy: 0.1495\n",
      "Epoch 117/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.3794 - accuracy: 0.0779 - val_loss: 3.8626 - val_accuracy: 0.1495\n",
      "Epoch 118/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.3490 - accuracy: 0.0772 - val_loss: 3.8604 - val_accuracy: 0.1589\n",
      "Epoch 119/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.3088 - accuracy: 0.0819 - val_loss: 3.8584 - val_accuracy: 0.1589\n",
      "Epoch 120/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.3501 - accuracy: 0.0732 - val_loss: 3.8562 - val_accuracy: 0.1682\n",
      "Epoch 121/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.3902 - accuracy: 0.0717 - val_loss: 3.8542 - val_accuracy: 0.1682\n",
      "Epoch 122/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.3735 - accuracy: 0.0830 - val_loss: 3.8522 - val_accuracy: 0.1682\n",
      "Epoch 123/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.2655 - accuracy: 0.0870 - val_loss: 3.8500 - val_accuracy: 0.1682\n",
      "Epoch 124/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.2602 - accuracy: 0.0897 - val_loss: 3.8478 - val_accuracy: 0.1682\n",
      "Epoch 125/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.2504 - accuracy: 0.0815 - val_loss: 3.8455 - val_accuracy: 0.1776\n",
      "Epoch 126/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.3217 - accuracy: 0.0924 - val_loss: 3.8436 - val_accuracy: 0.1776\n",
      "Epoch 127/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.2903 - accuracy: 0.0834 - val_loss: 3.8414 - val_accuracy: 0.1776\n",
      "Epoch 128/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.3617 - accuracy: 0.0748 - val_loss: 3.8394 - val_accuracy: 0.1776\n",
      "Epoch 129/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.2628 - accuracy: 0.0779 - val_loss: 3.8372 - val_accuracy: 0.1776\n",
      "Epoch 130/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.2783 - accuracy: 0.0768 - val_loss: 3.8351 - val_accuracy: 0.1776\n",
      "Epoch 131/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 2ms/step - loss: 5.2906 - accuracy: 0.0842 - val_loss: 3.8332 - val_accuracy: 0.1776\n",
      "Epoch 132/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.2677 - accuracy: 0.0803 - val_loss: 3.8310 - val_accuracy: 0.1869\n",
      "Epoch 133/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.2363 - accuracy: 0.0756 - val_loss: 3.8288 - val_accuracy: 0.1869\n",
      "Epoch 134/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.2193 - accuracy: 0.0826 - val_loss: 3.8266 - val_accuracy: 0.1869\n",
      "Epoch 135/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.2764 - accuracy: 0.0838 - val_loss: 3.8245 - val_accuracy: 0.1869\n",
      "Epoch 136/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.2196 - accuracy: 0.0870 - val_loss: 3.8225 - val_accuracy: 0.1869\n",
      "Epoch 137/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.2275 - accuracy: 0.0858 - val_loss: 3.8205 - val_accuracy: 0.1869\n",
      "Epoch 138/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.1958 - accuracy: 0.0815 - val_loss: 3.8183 - val_accuracy: 0.1869\n",
      "Epoch 139/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.1922 - accuracy: 0.0940 - val_loss: 3.8163 - val_accuracy: 0.1869\n",
      "Epoch 140/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.1687 - accuracy: 0.0987 - val_loss: 3.8142 - val_accuracy: 0.1869\n",
      "Epoch 141/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.1886 - accuracy: 0.0913 - val_loss: 3.8120 - val_accuracy: 0.1869\n",
      "Epoch 142/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.1827 - accuracy: 0.0909 - val_loss: 3.8100 - val_accuracy: 0.1869\n",
      "Epoch 143/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.2640 - accuracy: 0.0803 - val_loss: 3.8081 - val_accuracy: 0.1869\n",
      "Epoch 144/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.2132 - accuracy: 0.0787 - val_loss: 3.8060 - val_accuracy: 0.1963\n",
      "Epoch 145/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.1430 - accuracy: 0.0909 - val_loss: 3.8038 - val_accuracy: 0.1963\n",
      "Epoch 146/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.1752 - accuracy: 0.0885 - val_loss: 3.8017 - val_accuracy: 0.1963\n",
      "Epoch 147/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.0955 - accuracy: 0.0936 - val_loss: 3.7996 - val_accuracy: 0.2056\n",
      "Epoch 148/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.1608 - accuracy: 0.0834 - val_loss: 3.7976 - val_accuracy: 0.2056\n",
      "Epoch 149/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.1869 - accuracy: 0.0846 - val_loss: 3.7955 - val_accuracy: 0.2056\n",
      "Epoch 150/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 5.2001 - accuracy: 0.0830 - val_loss: 3.7936 - val_accuracy: 0.2056\n",
      "Epoch 151/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.1604 - accuracy: 0.0850 - val_loss: 3.7915 - val_accuracy: 0.2056\n",
      "Epoch 152/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.1913 - accuracy: 0.0885 - val_loss: 3.7896 - val_accuracy: 0.2056\n",
      "Epoch 153/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.1572 - accuracy: 0.0897 - val_loss: 3.7877 - val_accuracy: 0.2056\n",
      "Epoch 154/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.1441 - accuracy: 0.0928 - val_loss: 3.7856 - val_accuracy: 0.2056\n",
      "Epoch 155/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.0705 - accuracy: 0.0987 - val_loss: 3.7834 - val_accuracy: 0.2243\n",
      "Epoch 156/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.0646 - accuracy: 0.0991 - val_loss: 3.7813 - val_accuracy: 0.2243\n",
      "Epoch 157/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.0428 - accuracy: 0.1014 - val_loss: 3.7792 - val_accuracy: 0.2243\n",
      "Epoch 158/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.0344 - accuracy: 0.0889 - val_loss: 3.7770 - val_accuracy: 0.2243\n",
      "Epoch 159/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.0944 - accuracy: 0.0920 - val_loss: 3.7751 - val_accuracy: 0.2243\n",
      "Epoch 160/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 5.0719 - accuracy: 0.0917 - val_loss: 3.7730 - val_accuracy: 0.2243\n",
      "Epoch 161/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 5.0312 - accuracy: 0.0967 - val_loss: 3.7709 - val_accuracy: 0.2243\n",
      "Epoch 162/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.0516 - accuracy: 0.1022 - val_loss: 3.7689 - val_accuracy: 0.2243\n",
      "Epoch 163/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.0284 - accuracy: 0.0979 - val_loss: 3.7668 - val_accuracy: 0.2243\n",
      "Epoch 164/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.0654 - accuracy: 0.0932 - val_loss: 3.7650 - val_accuracy: 0.2243\n",
      "Epoch 165/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.0492 - accuracy: 0.0956 - val_loss: 3.7631 - val_accuracy: 0.2243\n",
      "Epoch 166/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.0152 - accuracy: 0.0983 - val_loss: 3.7612 - val_accuracy: 0.2243\n",
      "Epoch 167/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.0056 - accuracy: 0.1026 - val_loss: 3.7592 - val_accuracy: 0.2150\n",
      "Epoch 168/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.0222 - accuracy: 0.1050 - val_loss: 3.7572 - val_accuracy: 0.2243\n",
      "Epoch 169/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.0661 - accuracy: 0.0920 - val_loss: 3.7554 - val_accuracy: 0.2243\n",
      "Epoch 170/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.0253 - accuracy: 0.0999 - val_loss: 3.7535 - val_accuracy: 0.2243\n",
      "Epoch 171/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.9571 - accuracy: 0.1061 - val_loss: 3.7514 - val_accuracy: 0.2243\n",
      "Epoch 172/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.0833 - accuracy: 0.0897 - val_loss: 3.7497 - val_accuracy: 0.2243\n",
      "Epoch 173/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.0211 - accuracy: 0.0909 - val_loss: 3.7478 - val_accuracy: 0.2243\n",
      "Epoch 174/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.9795 - accuracy: 0.0975 - val_loss: 3.7460 - val_accuracy: 0.2243\n",
      "Epoch 175/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5.0269 - accuracy: 0.1003 - val_loss: 3.7442 - val_accuracy: 0.2336\n",
      "Epoch 176/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.9825 - accuracy: 0.1030 - val_loss: 3.7422 - val_accuracy: 0.2336\n",
      "Epoch 177/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.9530 - accuracy: 0.0975 - val_loss: 3.7401 - val_accuracy: 0.2336\n",
      "Epoch 178/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.9129 - accuracy: 0.1105 - val_loss: 3.7381 - val_accuracy: 0.2336\n",
      "Epoch 179/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.9709 - accuracy: 0.1022 - val_loss: 3.7362 - val_accuracy: 0.2336\n",
      "Epoch 180/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.9581 - accuracy: 0.0936 - val_loss: 3.7342 - val_accuracy: 0.2336\n",
      "Epoch 181/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.8947 - accuracy: 0.1120 - val_loss: 3.7323 - val_accuracy: 0.2336\n",
      "Epoch 182/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.9161 - accuracy: 0.1069 - val_loss: 3.7304 - val_accuracy: 0.2336\n",
      "Epoch 183/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.9789 - accuracy: 0.1026 - val_loss: 3.7286 - val_accuracy: 0.2336\n",
      "Epoch 184/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.9572 - accuracy: 0.0913 - val_loss: 3.7268 - val_accuracy: 0.2336\n",
      "Epoch 185/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.9560 - accuracy: 0.0987 - val_loss: 3.7249 - val_accuracy: 0.2336\n",
      "Epoch 186/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.9426 - accuracy: 0.0987 - val_loss: 3.7232 - val_accuracy: 0.2336\n",
      "Epoch 187/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.8889 - accuracy: 0.1054 - val_loss: 3.7213 - val_accuracy: 0.2336\n",
      "Epoch 188/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 2ms/step - loss: 4.9273 - accuracy: 0.0987 - val_loss: 3.7195 - val_accuracy: 0.2336\n",
      "Epoch 189/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.9556 - accuracy: 0.0960 - val_loss: 3.7178 - val_accuracy: 0.2430\n",
      "Epoch 190/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.8742 - accuracy: 0.1046 - val_loss: 3.7159 - val_accuracy: 0.2523\n",
      "Epoch 191/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.8726 - accuracy: 0.1101 - val_loss: 3.7140 - val_accuracy: 0.2523\n",
      "Epoch 192/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.8676 - accuracy: 0.1093 - val_loss: 3.7121 - val_accuracy: 0.2523\n",
      "Epoch 193/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.9146 - accuracy: 0.1038 - val_loss: 3.7103 - val_accuracy: 0.2523\n",
      "Epoch 194/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.8553 - accuracy: 0.1058 - val_loss: 3.7084 - val_accuracy: 0.2523\n",
      "Epoch 195/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.8600 - accuracy: 0.1026 - val_loss: 3.7067 - val_accuracy: 0.2523\n",
      "Epoch 196/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.9173 - accuracy: 0.0971 - val_loss: 3.7049 - val_accuracy: 0.2523\n",
      "Epoch 197/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.8454 - accuracy: 0.1152 - val_loss: 3.7031 - val_accuracy: 0.2523\n",
      "Epoch 198/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.8516 - accuracy: 0.1097 - val_loss: 3.7013 - val_accuracy: 0.2523\n",
      "Epoch 199/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 4.8376 - accuracy: 0.1085 - val_loss: 3.6995 - val_accuracy: 0.2523\n",
      "Epoch 200/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.8684 - accuracy: 0.1042 - val_loss: 3.6978 - val_accuracy: 0.2523\n",
      "0.25233644247055054 {'loss': 4.868354320526123, 'accuracy': 0.10419114679098129, 'val_loss': 3.697763204574585, 'val_accuracy': 0.25233644247055054}\n",
      "Model: \"model_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_25 (InputLayer)        [(None, 29)]              0         \n",
      "_________________________________________________________________\n",
      "flatten_24 (Flatten)         (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 41)                1230      \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 10)                420       \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,870\n",
      "Trainable params: 1,870\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 3.0100 - accuracy: 3.9170e-04 - val_loss: 2.8604 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.9983 - accuracy: 3.9170e-04 - val_loss: 2.8506 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.9867 - accuracy: 3.9170e-04 - val_loss: 2.8410 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.9754 - accuracy: 3.9170e-04 - val_loss: 2.8316 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.9642 - accuracy: 3.9170e-04 - val_loss: 2.8223 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.9532 - accuracy: 3.9170e-04 - val_loss: 2.8132 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.9424 - accuracy: 3.9170e-04 - val_loss: 2.8041 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.9317 - accuracy: 3.9170e-04 - val_loss: 2.7951 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.9212 - accuracy: 3.9170e-04 - val_loss: 2.7863 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.9108 - accuracy: 7.8339e-04 - val_loss: 2.7776 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.9006 - accuracy: 7.8339e-04 - val_loss: 2.7689 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.8905 - accuracy: 7.8339e-04 - val_loss: 2.7605 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.8806 - accuracy: 7.8339e-04 - val_loss: 2.7522 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.8708 - accuracy: 7.8339e-04 - val_loss: 2.7440 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.8612 - accuracy: 7.8339e-04 - val_loss: 2.7360 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.8517 - accuracy: 7.8339e-04 - val_loss: 2.7280 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.8423 - accuracy: 0.0012 - val_loss: 2.7203 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.8330 - accuracy: 0.0012 - val_loss: 2.7126 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.8238 - accuracy: 0.0012 - val_loss: 2.7051 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.8148 - accuracy: 0.0012 - val_loss: 2.6978 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.8059 - accuracy: 0.0012 - val_loss: 2.6906 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.7971 - accuracy: 0.0020 - val_loss: 2.6835 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.7884 - accuracy: 0.0020 - val_loss: 2.6766 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.7799 - accuracy: 0.0024 - val_loss: 2.6697 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.7714 - accuracy: 0.0024 - val_loss: 2.6630 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.7631 - accuracy: 0.0024 - val_loss: 2.6563 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.7549 - accuracy: 0.0027 - val_loss: 2.6498 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.7469 - accuracy: 0.0027 - val_loss: 2.6434 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.7389 - accuracy: 0.0039 - val_loss: 2.6371 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.7311 - accuracy: 0.0043 - val_loss: 2.6309 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.7233 - accuracy: 0.0047 - val_loss: 2.6248 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.7157 - accuracy: 0.0047 - val_loss: 2.6188 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 2ms/step - loss: 2.7081 - accuracy: 0.0047 - val_loss: 2.6129 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.7007 - accuracy: 0.0047 - val_loss: 2.6071 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.6933 - accuracy: 0.0051 - val_loss: 2.6014 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.6861 - accuracy: 0.0055 - val_loss: 2.5958 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.6790 - accuracy: 0.0059 - val_loss: 2.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.6719 - accuracy: 0.0063 - val_loss: 2.5850 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.6650 - accuracy: 0.0063 - val_loss: 2.5798 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.6581 - accuracy: 0.0071 - val_loss: 2.5746 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.6512 - accuracy: 0.0078 - val_loss: 2.5693 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.6445 - accuracy: 0.0078 - val_loss: 2.5641 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.6378 - accuracy: 0.0082 - val_loss: 2.5591 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.6312 - accuracy: 0.0082 - val_loss: 2.5542 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.6247 - accuracy: 0.0090 - val_loss: 2.5494 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.6183 - accuracy: 0.0102 - val_loss: 2.5446 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.6120 - accuracy: 0.0106 - val_loss: 2.5400 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.6057 - accuracy: 0.0110 - val_loss: 2.5354 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.5995 - accuracy: 0.0133 - val_loss: 2.5308 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.5933 - accuracy: 0.0145 - val_loss: 2.5262 - val_accuracy: 0.0093\n",
      "Epoch 51/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.5872 - accuracy: 0.0145 - val_loss: 2.5215 - val_accuracy: 0.0093\n",
      "Epoch 52/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.5812 - accuracy: 0.0157 - val_loss: 2.5170 - val_accuracy: 0.0093\n",
      "Epoch 53/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 2.5753 - accuracy: 0.0165 - val_loss: 2.5124 - val_accuracy: 0.0093\n",
      "Epoch 54/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.5695 - accuracy: 0.0172 - val_loss: 2.5080 - val_accuracy: 0.0093\n",
      "Epoch 55/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.5638 - accuracy: 0.0184 - val_loss: 2.5037 - val_accuracy: 0.0093\n",
      "Epoch 56/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.5583 - accuracy: 0.0192 - val_loss: 2.4995 - val_accuracy: 0.0093\n",
      "Epoch 57/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.5528 - accuracy: 0.0200 - val_loss: 2.4955 - val_accuracy: 0.0093\n",
      "Epoch 58/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.5475 - accuracy: 0.0204 - val_loss: 2.4917 - val_accuracy: 0.0093\n",
      "Epoch 59/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.5421 - accuracy: 0.0212 - val_loss: 2.4879 - val_accuracy: 0.0093\n",
      "Epoch 60/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.5368 - accuracy: 0.0219 - val_loss: 2.4840 - val_accuracy: 0.0093\n",
      "Epoch 61/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.5316 - accuracy: 0.0235 - val_loss: 2.4801 - val_accuracy: 0.0187\n",
      "Epoch 62/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.5265 - accuracy: 0.0255 - val_loss: 2.4764 - val_accuracy: 0.0187\n",
      "Epoch 63/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.5216 - accuracy: 0.0262 - val_loss: 2.4725 - val_accuracy: 0.0187\n",
      "Epoch 64/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.5167 - accuracy: 0.0266 - val_loss: 2.4686 - val_accuracy: 0.0187\n",
      "Epoch 65/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.5118 - accuracy: 0.0278 - val_loss: 2.4647 - val_accuracy: 0.0187\n",
      "Epoch 66/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.5071 - accuracy: 0.0282 - val_loss: 2.4610 - val_accuracy: 0.0187\n",
      "Epoch 67/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.5024 - accuracy: 0.0286 - val_loss: 2.4573 - val_accuracy: 0.0187\n",
      "Epoch 68/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4977 - accuracy: 0.0294 - val_loss: 2.4535 - val_accuracy: 0.0187\n",
      "Epoch 69/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4932 - accuracy: 0.0317 - val_loss: 2.4499 - val_accuracy: 0.0187\n",
      "Epoch 70/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4887 - accuracy: 0.0337 - val_loss: 2.4462 - val_accuracy: 0.0280\n",
      "Epoch 71/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4843 - accuracy: 0.0356 - val_loss: 2.4426 - val_accuracy: 0.0280\n",
      "Epoch 72/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4800 - accuracy: 0.0376 - val_loss: 2.4391 - val_accuracy: 0.0374\n",
      "Epoch 73/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4758 - accuracy: 0.0403 - val_loss: 2.4356 - val_accuracy: 0.0374\n",
      "Epoch 74/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4716 - accuracy: 0.0411 - val_loss: 2.4323 - val_accuracy: 0.0374\n",
      "Epoch 75/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4675 - accuracy: 0.0423 - val_loss: 2.4290 - val_accuracy: 0.0374\n",
      "Epoch 76/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4635 - accuracy: 0.0435 - val_loss: 2.4258 - val_accuracy: 0.0374\n",
      "Epoch 77/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4596 - accuracy: 0.0454 - val_loss: 2.4227 - val_accuracy: 0.0374\n",
      "Epoch 78/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4556 - accuracy: 0.0462 - val_loss: 2.4196 - val_accuracy: 0.0374\n",
      "Epoch 79/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4517 - accuracy: 0.0486 - val_loss: 2.4167 - val_accuracy: 0.0374\n",
      "Epoch 80/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4479 - accuracy: 0.0494 - val_loss: 2.4138 - val_accuracy: 0.0467\n",
      "Epoch 81/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4441 - accuracy: 0.0497 - val_loss: 2.4110 - val_accuracy: 0.0467\n",
      "Epoch 82/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4404 - accuracy: 0.0497 - val_loss: 2.4082 - val_accuracy: 0.0467\n",
      "Epoch 83/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4366 - accuracy: 0.0513 - val_loss: 2.4055 - val_accuracy: 0.0467\n",
      "Epoch 84/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4330 - accuracy: 0.0529 - val_loss: 2.4028 - val_accuracy: 0.0467\n",
      "Epoch 85/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4294 - accuracy: 0.0544 - val_loss: 2.4003 - val_accuracy: 0.0467\n",
      "Epoch 86/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4258 - accuracy: 0.0568 - val_loss: 2.3979 - val_accuracy: 0.0467\n",
      "Epoch 87/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4224 - accuracy: 0.0588 - val_loss: 2.3954 - val_accuracy: 0.0467\n",
      "Epoch 88/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4189 - accuracy: 0.0595 - val_loss: 2.3928 - val_accuracy: 0.0467\n",
      "Epoch 89/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4155 - accuracy: 0.0611 - val_loss: 2.3902 - val_accuracy: 0.0467\n",
      "Epoch 90/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4121 - accuracy: 0.0611 - val_loss: 2.3877 - val_accuracy: 0.0467\n",
      "Epoch 91/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4087 - accuracy: 0.0615 - val_loss: 2.3853 - val_accuracy: 0.0561\n",
      "Epoch 92/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4054 - accuracy: 0.0627 - val_loss: 2.3830 - val_accuracy: 0.0561\n",
      "Epoch 93/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4021 - accuracy: 0.0646 - val_loss: 2.3807 - val_accuracy: 0.0561\n",
      "Epoch 94/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3988 - accuracy: 0.0662 - val_loss: 2.3784 - val_accuracy: 0.0561\n",
      "Epoch 95/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3956 - accuracy: 0.0685 - val_loss: 2.3763 - val_accuracy: 0.0561\n",
      "Epoch 96/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3925 - accuracy: 0.0705 - val_loss: 2.3742 - val_accuracy: 0.0654\n",
      "Epoch 97/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3894 - accuracy: 0.0740 - val_loss: 2.3720 - val_accuracy: 0.0654\n",
      "Epoch 98/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3863 - accuracy: 0.0744 - val_loss: 2.3698 - val_accuracy: 0.0654\n",
      "Epoch 99/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3832 - accuracy: 0.0752 - val_loss: 2.3677 - val_accuracy: 0.0654\n",
      "Epoch 100/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3802 - accuracy: 0.0768 - val_loss: 2.3655 - val_accuracy: 0.0654\n",
      "Epoch 101/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3773 - accuracy: 0.0791 - val_loss: 2.3632 - val_accuracy: 0.0654\n",
      "Epoch 102/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3744 - accuracy: 0.0819 - val_loss: 2.3609 - val_accuracy: 0.0654\n",
      "Epoch 103/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 2.3715 - accuracy: 0.0815 - val_loss: 2.3587 - val_accuracy: 0.0654\n",
      "Epoch 104/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3687 - accuracy: 0.0830 - val_loss: 2.3565 - val_accuracy: 0.0654\n",
      "Epoch 105/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3660 - accuracy: 0.0842 - val_loss: 2.3543 - val_accuracy: 0.0654\n",
      "Epoch 106/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3632 - accuracy: 0.0842 - val_loss: 2.3522 - val_accuracy: 0.0654\n",
      "Epoch 107/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3605 - accuracy: 0.0866 - val_loss: 2.3500 - val_accuracy: 0.0654\n",
      "Epoch 108/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3578 - accuracy: 0.0877 - val_loss: 2.3478 - val_accuracy: 0.0748\n",
      "Epoch 109/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3551 - accuracy: 0.0905 - val_loss: 2.3457 - val_accuracy: 0.0748\n",
      "Epoch 110/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3525 - accuracy: 0.0909 - val_loss: 2.3437 - val_accuracy: 0.0748\n",
      "Epoch 111/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3498 - accuracy: 0.0940 - val_loss: 2.3416 - val_accuracy: 0.0748\n",
      "Epoch 112/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3472 - accuracy: 0.0967 - val_loss: 2.3396 - val_accuracy: 0.0748\n",
      "Epoch 113/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3446 - accuracy: 0.1014 - val_loss: 2.3376 - val_accuracy: 0.0748\n",
      "Epoch 114/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3421 - accuracy: 0.1034 - val_loss: 2.3355 - val_accuracy: 0.0748\n",
      "Epoch 115/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3396 - accuracy: 0.1050 - val_loss: 2.3335 - val_accuracy: 0.0748\n",
      "Epoch 116/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3371 - accuracy: 0.1061 - val_loss: 2.3314 - val_accuracy: 0.1028\n",
      "Epoch 117/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3346 - accuracy: 0.1081 - val_loss: 2.3293 - val_accuracy: 0.1028\n",
      "Epoch 118/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3322 - accuracy: 0.1105 - val_loss: 2.3272 - val_accuracy: 0.1028\n",
      "Epoch 119/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3298 - accuracy: 0.1140 - val_loss: 2.3252 - val_accuracy: 0.1028\n",
      "Epoch 120/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3274 - accuracy: 0.1171 - val_loss: 2.3232 - val_accuracy: 0.1028\n",
      "Epoch 121/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3250 - accuracy: 0.1187 - val_loss: 2.3213 - val_accuracy: 0.1028\n",
      "Epoch 122/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3227 - accuracy: 0.1199 - val_loss: 2.3194 - val_accuracy: 0.1121\n",
      "Epoch 123/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3204 - accuracy: 0.1203 - val_loss: 2.3175 - val_accuracy: 0.1121\n",
      "Epoch 124/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3180 - accuracy: 0.1195 - val_loss: 2.3156 - val_accuracy: 0.1215\n",
      "Epoch 125/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3157 - accuracy: 0.1214 - val_loss: 2.3136 - val_accuracy: 0.1215\n",
      "Epoch 126/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3133 - accuracy: 0.1222 - val_loss: 2.3117 - val_accuracy: 0.1215\n",
      "Epoch 127/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3110 - accuracy: 0.1257 - val_loss: 2.3098 - val_accuracy: 0.1215\n",
      "Epoch 128/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3086 - accuracy: 0.1285 - val_loss: 2.3079 - val_accuracy: 0.1215\n",
      "Epoch 129/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3064 - accuracy: 0.1304 - val_loss: 2.3062 - val_accuracy: 0.1215\n",
      "Epoch 130/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3041 - accuracy: 0.1328 - val_loss: 2.3044 - val_accuracy: 0.1215\n",
      "Epoch 131/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3018 - accuracy: 0.1340 - val_loss: 2.3027 - val_accuracy: 0.1215\n",
      "Epoch 132/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2996 - accuracy: 0.1367 - val_loss: 2.3010 - val_accuracy: 0.1308\n",
      "Epoch 133/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2974 - accuracy: 0.1398 - val_loss: 2.2994 - val_accuracy: 0.1308\n",
      "Epoch 134/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2952 - accuracy: 0.1406 - val_loss: 2.2977 - val_accuracy: 0.1402\n",
      "Epoch 135/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2930 - accuracy: 0.1410 - val_loss: 2.2960 - val_accuracy: 0.1402\n",
      "Epoch 136/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2909 - accuracy: 0.1418 - val_loss: 2.2942 - val_accuracy: 0.1402\n",
      "Epoch 137/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2887 - accuracy: 0.1445 - val_loss: 2.2924 - val_accuracy: 0.1402\n",
      "Epoch 138/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2865 - accuracy: 0.1453 - val_loss: 2.2905 - val_accuracy: 0.1495\n",
      "Epoch 139/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2843 - accuracy: 0.1477 - val_loss: 2.2887 - val_accuracy: 0.1495\n",
      "Epoch 140/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2821 - accuracy: 0.1488 - val_loss: 2.2869 - val_accuracy: 0.1495\n",
      "Epoch 141/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2799 - accuracy: 0.1512 - val_loss: 2.2851 - val_accuracy: 0.1495\n",
      "Epoch 142/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2777 - accuracy: 0.1532 - val_loss: 2.2834 - val_accuracy: 0.1495\n",
      "Epoch 143/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2756 - accuracy: 0.1543 - val_loss: 2.2817 - val_accuracy: 0.1495\n",
      "Epoch 144/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2735 - accuracy: 0.1547 - val_loss: 2.2799 - val_accuracy: 0.1495\n",
      "Epoch 145/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2713 - accuracy: 0.1586 - val_loss: 2.2780 - val_accuracy: 0.1495\n",
      "Epoch 146/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2692 - accuracy: 0.1618 - val_loss: 2.2761 - val_accuracy: 0.1495\n",
      "Epoch 147/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2671 - accuracy: 0.1633 - val_loss: 2.2743 - val_accuracy: 0.1495\n",
      "Epoch 148/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2650 - accuracy: 0.1641 - val_loss: 2.2725 - val_accuracy: 0.1495\n",
      "Epoch 149/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2629 - accuracy: 0.1665 - val_loss: 2.2707 - val_accuracy: 0.1495\n",
      "Epoch 150/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2608 - accuracy: 0.1680 - val_loss: 2.2688 - val_accuracy: 0.1495\n",
      "Epoch 151/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2587 - accuracy: 0.1704 - val_loss: 2.2669 - val_accuracy: 0.1495\n",
      "Epoch 152/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2565 - accuracy: 0.1700 - val_loss: 2.2651 - val_accuracy: 0.1495\n",
      "Epoch 153/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2544 - accuracy: 0.1723 - val_loss: 2.2633 - val_accuracy: 0.1495\n",
      "Epoch 154/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2523 - accuracy: 0.1739 - val_loss: 2.2615 - val_accuracy: 0.1682\n",
      "Epoch 155/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2502 - accuracy: 0.1770 - val_loss: 2.2598 - val_accuracy: 0.1682\n",
      "Epoch 156/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2480 - accuracy: 0.1790 - val_loss: 2.2580 - val_accuracy: 0.1682\n",
      "Epoch 157/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2459 - accuracy: 0.1806 - val_loss: 2.2562 - val_accuracy: 0.1776\n",
      "Epoch 158/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2438 - accuracy: 0.1825 - val_loss: 2.2544 - val_accuracy: 0.1776\n",
      "Epoch 159/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2417 - accuracy: 0.1821 - val_loss: 2.2526 - val_accuracy: 0.1682\n",
      "Epoch 160/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2396 - accuracy: 0.1837 - val_loss: 2.2508 - val_accuracy: 0.1682\n",
      "Epoch 161/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2376 - accuracy: 0.1857 - val_loss: 2.2490 - val_accuracy: 0.1682\n",
      "Epoch 162/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2355 - accuracy: 0.1868 - val_loss: 2.2472 - val_accuracy: 0.1682\n",
      "Epoch 163/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2334 - accuracy: 0.1884 - val_loss: 2.2453 - val_accuracy: 0.1682\n",
      "Epoch 164/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2314 - accuracy: 0.1908 - val_loss: 2.2435 - val_accuracy: 0.1682\n",
      "Epoch 165/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2294 - accuracy: 0.1911 - val_loss: 2.2417 - val_accuracy: 0.1682\n",
      "Epoch 166/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2274 - accuracy: 0.1911 - val_loss: 2.2398 - val_accuracy: 0.1682\n",
      "Epoch 167/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2253 - accuracy: 0.1927 - val_loss: 2.2380 - val_accuracy: 0.1682\n",
      "Epoch 168/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2233 - accuracy: 0.1943 - val_loss: 2.2362 - val_accuracy: 0.1682\n",
      "Epoch 169/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2213 - accuracy: 0.1962 - val_loss: 2.2343 - val_accuracy: 0.1682\n",
      "Epoch 170/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2193 - accuracy: 0.1982 - val_loss: 2.2324 - val_accuracy: 0.1682\n",
      "Epoch 171/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2172 - accuracy: 0.1998 - val_loss: 2.2305 - val_accuracy: 0.1682\n",
      "Epoch 172/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2152 - accuracy: 0.2021 - val_loss: 2.2284 - val_accuracy: 0.1682\n",
      "Epoch 173/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2132 - accuracy: 0.2033 - val_loss: 2.2264 - val_accuracy: 0.1682\n",
      "Epoch 174/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2112 - accuracy: 0.2060 - val_loss: 2.2243 - val_accuracy: 0.1682\n",
      "Epoch 175/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2092 - accuracy: 0.2080 - val_loss: 2.2223 - val_accuracy: 0.1776\n",
      "Epoch 176/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2072 - accuracy: 0.2099 - val_loss: 2.2202 - val_accuracy: 0.1776\n",
      "Epoch 177/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2052 - accuracy: 0.2123 - val_loss: 2.2181 - val_accuracy: 0.1869\n",
      "Epoch 178/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2032 - accuracy: 0.2139 - val_loss: 2.2160 - val_accuracy: 0.2150\n",
      "Epoch 179/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2011 - accuracy: 0.2162 - val_loss: 2.2138 - val_accuracy: 0.2150\n",
      "Epoch 180/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1991 - accuracy: 0.2178 - val_loss: 2.2116 - val_accuracy: 0.2150\n",
      "Epoch 181/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1971 - accuracy: 0.2190 - val_loss: 2.2094 - val_accuracy: 0.2243\n",
      "Epoch 182/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1950 - accuracy: 0.2213 - val_loss: 2.2073 - val_accuracy: 0.2243\n",
      "Epoch 183/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1930 - accuracy: 0.2225 - val_loss: 2.2050 - val_accuracy: 0.2243\n",
      "Epoch 184/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 2.1909 - accuracy: 0.2225 - val_loss: 2.2028 - val_accuracy: 0.2243\n",
      "Epoch 185/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1888 - accuracy: 0.2233 - val_loss: 2.2005 - val_accuracy: 0.2243\n",
      "Epoch 186/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1867 - accuracy: 0.2241 - val_loss: 2.1983 - val_accuracy: 0.2243\n",
      "Epoch 187/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1847 - accuracy: 0.2252 - val_loss: 2.1960 - val_accuracy: 0.2243\n",
      "Epoch 188/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1826 - accuracy: 0.2280 - val_loss: 2.1938 - val_accuracy: 0.2243\n",
      "Epoch 189/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1805 - accuracy: 0.2284 - val_loss: 2.1915 - val_accuracy: 0.2243\n",
      "Epoch 190/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1784 - accuracy: 0.2299 - val_loss: 2.1893 - val_accuracy: 0.2243\n",
      "Epoch 191/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1763 - accuracy: 0.2307 - val_loss: 2.1870 - val_accuracy: 0.2243\n",
      "Epoch 192/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1741 - accuracy: 0.2323 - val_loss: 2.1848 - val_accuracy: 0.2243\n",
      "Epoch 193/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1720 - accuracy: 0.2327 - val_loss: 2.1826 - val_accuracy: 0.2243\n",
      "Epoch 194/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1699 - accuracy: 0.2338 - val_loss: 2.1804 - val_accuracy: 0.2336\n",
      "Epoch 195/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1678 - accuracy: 0.2358 - val_loss: 2.1783 - val_accuracy: 0.2243\n",
      "Epoch 196/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1657 - accuracy: 0.2401 - val_loss: 2.1761 - val_accuracy: 0.2150\n",
      "Epoch 197/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1636 - accuracy: 0.2421 - val_loss: 2.1740 - val_accuracy: 0.2243\n",
      "Epoch 198/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1615 - accuracy: 0.2444 - val_loss: 2.1719 - val_accuracy: 0.2243\n",
      "Epoch 199/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 2.1594 - accuracy: 0.2460 - val_loss: 2.1698 - val_accuracy: 0.2243\n",
      "Epoch 200/200\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 2.1572 - accuracy: 0.2464 - val_loss: 2.1677 - val_accuracy: 0.2243\n",
      "0.22429905831813812 {'loss': 2.157241106033325, 'accuracy': 0.24637681245803833, 'val_loss': 2.167663097381592, 'val_accuracy': 0.22429905831813812}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_26 (InputLayer)        [(None, 29)]              0         \n",
      "_________________________________________________________________\n",
      "flatten_25 (Flatten)         (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 41)                1230      \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 10)                420       \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,870\n",
      "Trainable params: 1,870\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 2.2885 - accuracy: 0.1629 - val_loss: 2.3283 - val_accuracy: 0.0374\n",
      "Epoch 2/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2868 - accuracy: 0.1637 - val_loss: 2.3265 - val_accuracy: 0.0467\n",
      "Epoch 3/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2851 - accuracy: 0.1649 - val_loss: 2.3246 - val_accuracy: 0.0467\n",
      "Epoch 4/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2834 - accuracy: 0.1649 - val_loss: 2.3227 - val_accuracy: 0.0467\n",
      "Epoch 5/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2816 - accuracy: 0.1641 - val_loss: 2.3208 - val_accuracy: 0.0467\n",
      "Epoch 6/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.2799 - accuracy: 0.1637 - val_loss: 2.3189 - val_accuracy: 0.0467\n",
      "Epoch 7/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2782 - accuracy: 0.1637 - val_loss: 2.3170 - val_accuracy: 0.0467\n",
      "Epoch 8/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.2764 - accuracy: 0.1641 - val_loss: 2.3150 - val_accuracy: 0.0467\n",
      "Epoch 9/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.2747 - accuracy: 0.1649 - val_loss: 2.3131 - val_accuracy: 0.0467\n",
      "Epoch 10/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.2729 - accuracy: 0.1669 - val_loss: 2.3112 - val_accuracy: 0.0561\n",
      "Epoch 11/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.2711 - accuracy: 0.1669 - val_loss: 2.3093 - val_accuracy: 0.0467\n",
      "Epoch 12/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.2694 - accuracy: 0.1673 - val_loss: 2.3074 - val_accuracy: 0.0561\n",
      "Epoch 13/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2676 - accuracy: 0.1684 - val_loss: 2.3055 - val_accuracy: 0.0561\n",
      "Epoch 14/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2659 - accuracy: 0.1680 - val_loss: 2.3036 - val_accuracy: 0.0561\n",
      "Epoch 15/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.2641 - accuracy: 0.1692 - val_loss: 2.3017 - val_accuracy: 0.0561\n",
      "Epoch 16/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.2624 - accuracy: 0.1692 - val_loss: 2.2998 - val_accuracy: 0.0654\n",
      "Epoch 17/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.2606 - accuracy: 0.1696 - val_loss: 2.2979 - val_accuracy: 0.0654\n",
      "Epoch 18/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.2588 - accuracy: 0.1696 - val_loss: 2.2961 - val_accuracy: 0.0654\n",
      "Epoch 19/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2571 - accuracy: 0.1704 - val_loss: 2.2942 - val_accuracy: 0.0654\n",
      "Epoch 20/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2553 - accuracy: 0.1716 - val_loss: 2.2924 - val_accuracy: 0.0654\n",
      "Epoch 21/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2536 - accuracy: 0.1720 - val_loss: 2.2904 - val_accuracy: 0.0654\n",
      "Epoch 22/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.2518 - accuracy: 0.1723 - val_loss: 2.2885 - val_accuracy: 0.0654\n",
      "Epoch 23/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2501 - accuracy: 0.1723 - val_loss: 2.2867 - val_accuracy: 0.0654\n",
      "Epoch 24/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2483 - accuracy: 0.1720 - val_loss: 2.2847 - val_accuracy: 0.0654\n",
      "Epoch 25/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.2466 - accuracy: 0.1720 - val_loss: 2.2828 - val_accuracy: 0.0654\n",
      "Epoch 26/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 2.2448 - accuracy: 0.1712 - val_loss: 2.2808 - val_accuracy: 0.0654\n",
      "Epoch 27/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 2.2431 - accuracy: 0.1716 - val_loss: 2.2789 - val_accuracy: 0.0654\n",
      "Epoch 28/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 2.2413 - accuracy: 0.1716 - val_loss: 2.2769 - val_accuracy: 0.0654\n",
      "Epoch 29/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.2396 - accuracy: 0.1716 - val_loss: 2.2750 - val_accuracy: 0.0654\n",
      "Epoch 30/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2378 - accuracy: 0.1723 - val_loss: 2.2731 - val_accuracy: 0.0654\n",
      "Epoch 31/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 2.2361 - accuracy: 0.1735 - val_loss: 2.2711 - val_accuracy: 0.0654\n",
      "Epoch 32/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.2343 - accuracy: 0.1747 - val_loss: 2.2691 - val_accuracy: 0.0654\n",
      "Epoch 33/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2326 - accuracy: 0.1739 - val_loss: 2.2671 - val_accuracy: 0.0748\n",
      "Epoch 34/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.2308 - accuracy: 0.1755 - val_loss: 2.2651 - val_accuracy: 0.0748\n",
      "Epoch 35/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.2290 - accuracy: 0.1763 - val_loss: 2.2630 - val_accuracy: 0.0748\n",
      "Epoch 36/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.2273 - accuracy: 0.1774 - val_loss: 2.2610 - val_accuracy: 0.0748\n",
      "Epoch 37/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.2255 - accuracy: 0.1778 - val_loss: 2.2590 - val_accuracy: 0.0748\n",
      "Epoch 38/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.2237 - accuracy: 0.1794 - val_loss: 2.2569 - val_accuracy: 0.0748\n",
      "Epoch 39/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2219 - accuracy: 0.1794 - val_loss: 2.2549 - val_accuracy: 0.0748\n",
      "Epoch 40/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2202 - accuracy: 0.1790 - val_loss: 2.2529 - val_accuracy: 0.0748\n",
      "Epoch 41/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2184 - accuracy: 0.1790 - val_loss: 2.2508 - val_accuracy: 0.0841\n",
      "Epoch 42/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.2166 - accuracy: 0.1782 - val_loss: 2.2488 - val_accuracy: 0.0841\n",
      "Epoch 43/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.2149 - accuracy: 0.1790 - val_loss: 2.2467 - val_accuracy: 0.0841\n",
      "Epoch 44/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.2131 - accuracy: 0.1798 - val_loss: 2.2447 - val_accuracy: 0.0841\n",
      "Epoch 45/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2113 - accuracy: 0.1806 - val_loss: 2.2426 - val_accuracy: 0.0841\n",
      "Epoch 46/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.2096 - accuracy: 0.1814 - val_loss: 2.2405 - val_accuracy: 0.0841\n",
      "Epoch 47/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2078 - accuracy: 0.1817 - val_loss: 2.2383 - val_accuracy: 0.0841\n",
      "Epoch 48/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2061 - accuracy: 0.1821 - val_loss: 2.2361 - val_accuracy: 0.0841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2043 - accuracy: 0.1817 - val_loss: 2.2339 - val_accuracy: 0.0841\n",
      "Epoch 50/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.2026 - accuracy: 0.1837 - val_loss: 2.2318 - val_accuracy: 0.0841\n",
      "Epoch 51/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.2008 - accuracy: 0.1837 - val_loss: 2.2296 - val_accuracy: 0.0841\n",
      "Epoch 52/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1990 - accuracy: 0.1841 - val_loss: 2.2275 - val_accuracy: 0.0841\n",
      "Epoch 53/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1973 - accuracy: 0.1845 - val_loss: 2.2254 - val_accuracy: 0.0841\n",
      "Epoch 54/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1955 - accuracy: 0.1841 - val_loss: 2.2233 - val_accuracy: 0.0841\n",
      "Epoch 55/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1937 - accuracy: 0.1853 - val_loss: 2.2211 - val_accuracy: 0.0841\n",
      "Epoch 56/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1920 - accuracy: 0.1857 - val_loss: 2.2190 - val_accuracy: 0.0841\n",
      "Epoch 57/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1902 - accuracy: 0.1868 - val_loss: 2.2168 - val_accuracy: 0.0748\n",
      "Epoch 58/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1884 - accuracy: 0.1872 - val_loss: 2.2147 - val_accuracy: 0.0748\n",
      "Epoch 59/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1866 - accuracy: 0.1876 - val_loss: 2.2126 - val_accuracy: 0.0748\n",
      "Epoch 60/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1849 - accuracy: 0.1888 - val_loss: 2.2104 - val_accuracy: 0.0748\n",
      "Epoch 61/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1831 - accuracy: 0.1896 - val_loss: 2.2083 - val_accuracy: 0.0748\n",
      "Epoch 62/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.1813 - accuracy: 0.1904 - val_loss: 2.2061 - val_accuracy: 0.0748\n",
      "Epoch 63/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1795 - accuracy: 0.1915 - val_loss: 2.2040 - val_accuracy: 0.0748\n",
      "Epoch 64/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1777 - accuracy: 0.1923 - val_loss: 2.2018 - val_accuracy: 0.0748\n",
      "Epoch 65/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1759 - accuracy: 0.1927 - val_loss: 2.1996 - val_accuracy: 0.0748\n",
      "Epoch 66/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1741 - accuracy: 0.1923 - val_loss: 2.1974 - val_accuracy: 0.0748\n",
      "Epoch 67/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1723 - accuracy: 0.1927 - val_loss: 2.1951 - val_accuracy: 0.0841\n",
      "Epoch 68/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1705 - accuracy: 0.1935 - val_loss: 2.1929 - val_accuracy: 0.0841\n",
      "Epoch 69/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1687 - accuracy: 0.1931 - val_loss: 2.1907 - val_accuracy: 0.0841\n",
      "Epoch 70/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1669 - accuracy: 0.1939 - val_loss: 2.1885 - val_accuracy: 0.0841\n",
      "Epoch 71/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1651 - accuracy: 0.1935 - val_loss: 2.1863 - val_accuracy: 0.0841\n",
      "Epoch 72/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.1633 - accuracy: 0.1943 - val_loss: 2.1840 - val_accuracy: 0.0841\n",
      "Epoch 73/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.1615 - accuracy: 0.1951 - val_loss: 2.1818 - val_accuracy: 0.0841\n",
      "Epoch 74/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.1597 - accuracy: 0.1955 - val_loss: 2.1796 - val_accuracy: 0.0841\n",
      "Epoch 75/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1579 - accuracy: 0.1962 - val_loss: 2.1773 - val_accuracy: 0.0841\n",
      "Epoch 76/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1560 - accuracy: 0.1966 - val_loss: 2.1751 - val_accuracy: 0.0841\n",
      "Epoch 77/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1542 - accuracy: 0.1978 - val_loss: 2.1729 - val_accuracy: 0.0841\n",
      "Epoch 78/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1524 - accuracy: 0.1970 - val_loss: 2.1707 - val_accuracy: 0.0841\n",
      "Epoch 79/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1506 - accuracy: 0.1978 - val_loss: 2.1685 - val_accuracy: 0.0841\n",
      "Epoch 80/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1487 - accuracy: 0.1990 - val_loss: 2.1663 - val_accuracy: 0.0935\n",
      "Epoch 81/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.1469 - accuracy: 0.1982 - val_loss: 2.1642 - val_accuracy: 0.0935\n",
      "Epoch 82/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1451 - accuracy: 0.1982 - val_loss: 2.1620 - val_accuracy: 0.1028\n",
      "Epoch 83/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.1433 - accuracy: 0.1990 - val_loss: 2.1598 - val_accuracy: 0.1028\n",
      "Epoch 84/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.1414 - accuracy: 0.1994 - val_loss: 2.1576 - val_accuracy: 0.1028\n",
      "Epoch 85/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1396 - accuracy: 0.2002 - val_loss: 2.1555 - val_accuracy: 0.1028\n",
      "Epoch 86/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1378 - accuracy: 0.2005 - val_loss: 2.1533 - val_accuracy: 0.1028\n",
      "Epoch 87/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1360 - accuracy: 0.2029 - val_loss: 2.1511 - val_accuracy: 0.1028\n",
      "Epoch 88/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.1342 - accuracy: 0.2041 - val_loss: 2.1490 - val_accuracy: 0.1028\n",
      "Epoch 89/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.1324 - accuracy: 0.2037 - val_loss: 2.1468 - val_accuracy: 0.1215\n",
      "Epoch 90/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.1305 - accuracy: 0.2037 - val_loss: 2.1446 - val_accuracy: 0.1308\n",
      "Epoch 91/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.1287 - accuracy: 0.2045 - val_loss: 2.1425 - val_accuracy: 0.1308\n",
      "Epoch 92/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.1268 - accuracy: 0.2049 - val_loss: 2.1403 - val_accuracy: 0.1308\n",
      "Epoch 93/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.1250 - accuracy: 0.2060 - val_loss: 2.1382 - val_accuracy: 0.1308\n",
      "Epoch 94/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.1231 - accuracy: 0.2076 - val_loss: 2.1360 - val_accuracy: 0.1308\n",
      "Epoch 95/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.1213 - accuracy: 0.2088 - val_loss: 2.1339 - val_accuracy: 0.1308\n",
      "Epoch 96/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.1194 - accuracy: 0.2092 - val_loss: 2.1317 - val_accuracy: 0.1308\n",
      "Epoch 97/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.1176 - accuracy: 0.2099 - val_loss: 2.1296 - val_accuracy: 0.1308\n",
      "Epoch 98/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.1157 - accuracy: 0.2107 - val_loss: 2.1274 - val_accuracy: 0.1308\n",
      "Epoch 99/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.1139 - accuracy: 0.2119 - val_loss: 2.1253 - val_accuracy: 0.1308\n",
      "Epoch 100/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1121 - accuracy: 0.2139 - val_loss: 2.1231 - val_accuracy: 0.1308\n",
      "Epoch 101/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.1102 - accuracy: 0.2139 - val_loss: 2.1210 - val_accuracy: 0.1308\n",
      "Epoch 102/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.1083 - accuracy: 0.2150 - val_loss: 2.1188 - val_accuracy: 0.1402\n",
      "Epoch 103/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.1065 - accuracy: 0.2154 - val_loss: 2.1166 - val_accuracy: 0.1402\n",
      "Epoch 104/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1046 - accuracy: 0.2158 - val_loss: 2.1145 - val_accuracy: 0.1402\n",
      "Epoch 105/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.1028 - accuracy: 0.2162 - val_loss: 2.1123 - val_accuracy: 0.1402\n",
      "Epoch 106/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 3ms/step - loss: 2.1009 - accuracy: 0.2162 - val_loss: 2.1101 - val_accuracy: 0.1402\n",
      "Epoch 107/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.0991 - accuracy: 0.2162 - val_loss: 2.1080 - val_accuracy: 0.1402\n",
      "Epoch 108/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0972 - accuracy: 0.2174 - val_loss: 2.1059 - val_accuracy: 0.1402\n",
      "Epoch 109/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.0953 - accuracy: 0.2178 - val_loss: 2.1037 - val_accuracy: 0.1402\n",
      "Epoch 110/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0934 - accuracy: 0.2186 - val_loss: 2.1015 - val_accuracy: 0.1402\n",
      "Epoch 111/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0915 - accuracy: 0.2186 - val_loss: 2.0995 - val_accuracy: 0.1402\n",
      "Epoch 112/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.0897 - accuracy: 0.2205 - val_loss: 2.0974 - val_accuracy: 0.1402\n",
      "Epoch 113/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.0878 - accuracy: 0.2221 - val_loss: 2.0953 - val_accuracy: 0.1495\n",
      "Epoch 114/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0859 - accuracy: 0.2233 - val_loss: 2.0932 - val_accuracy: 0.1495\n",
      "Epoch 115/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0841 - accuracy: 0.2237 - val_loss: 2.0911 - val_accuracy: 0.1495\n",
      "Epoch 116/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.0822 - accuracy: 0.2237 - val_loss: 2.0890 - val_accuracy: 0.1589\n",
      "Epoch 117/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0803 - accuracy: 0.2229 - val_loss: 2.0869 - val_accuracy: 0.1589\n",
      "Epoch 118/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.0785 - accuracy: 0.2233 - val_loss: 2.0848 - val_accuracy: 0.1589\n",
      "Epoch 119/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.0766 - accuracy: 0.2241 - val_loss: 2.0827 - val_accuracy: 0.1589\n",
      "Epoch 120/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.0748 - accuracy: 0.2248 - val_loss: 2.0806 - val_accuracy: 0.1589\n",
      "Epoch 121/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.0730 - accuracy: 0.2268 - val_loss: 2.0786 - val_accuracy: 0.1589\n",
      "Epoch 122/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0711 - accuracy: 0.2280 - val_loss: 2.0766 - val_accuracy: 0.1589\n",
      "Epoch 123/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0693 - accuracy: 0.2284 - val_loss: 2.0745 - val_accuracy: 0.1682\n",
      "Epoch 124/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0674 - accuracy: 0.2284 - val_loss: 2.0724 - val_accuracy: 0.1682\n",
      "Epoch 125/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0656 - accuracy: 0.2288 - val_loss: 2.0703 - val_accuracy: 0.1682\n",
      "Epoch 126/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0638 - accuracy: 0.2295 - val_loss: 2.0683 - val_accuracy: 0.1682\n",
      "Epoch 127/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0619 - accuracy: 0.2295 - val_loss: 2.0662 - val_accuracy: 0.1776\n",
      "Epoch 128/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0601 - accuracy: 0.2303 - val_loss: 2.0642 - val_accuracy: 0.1776\n",
      "Epoch 129/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0583 - accuracy: 0.2303 - val_loss: 2.0621 - val_accuracy: 0.1869\n",
      "Epoch 130/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0564 - accuracy: 0.2307 - val_loss: 2.0601 - val_accuracy: 0.1869\n",
      "Epoch 131/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0546 - accuracy: 0.2311 - val_loss: 2.0581 - val_accuracy: 0.1869\n",
      "Epoch 132/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0527 - accuracy: 0.2327 - val_loss: 2.0560 - val_accuracy: 0.1869\n",
      "Epoch 133/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0509 - accuracy: 0.2338 - val_loss: 2.0540 - val_accuracy: 0.1869\n",
      "Epoch 134/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0490 - accuracy: 0.2342 - val_loss: 2.0520 - val_accuracy: 0.1869\n",
      "Epoch 135/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0472 - accuracy: 0.2350 - val_loss: 2.0500 - val_accuracy: 0.1869\n",
      "Epoch 136/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0454 - accuracy: 0.2362 - val_loss: 2.0480 - val_accuracy: 0.1869\n",
      "Epoch 137/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0435 - accuracy: 0.2374 - val_loss: 2.0460 - val_accuracy: 0.1869\n",
      "Epoch 138/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0417 - accuracy: 0.2382 - val_loss: 2.0440 - val_accuracy: 0.1869\n",
      "Epoch 139/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0398 - accuracy: 0.2389 - val_loss: 2.0420 - val_accuracy: 0.1963\n",
      "Epoch 140/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0380 - accuracy: 0.2389 - val_loss: 2.0401 - val_accuracy: 0.1963\n",
      "Epoch 141/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0362 - accuracy: 0.2393 - val_loss: 2.0382 - val_accuracy: 0.1963\n",
      "Epoch 142/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0344 - accuracy: 0.2405 - val_loss: 2.0362 - val_accuracy: 0.1963\n",
      "Epoch 143/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0325 - accuracy: 0.2409 - val_loss: 2.0343 - val_accuracy: 0.1963\n",
      "Epoch 144/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0307 - accuracy: 0.2409 - val_loss: 2.0323 - val_accuracy: 0.1963\n",
      "Epoch 145/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0289 - accuracy: 0.2417 - val_loss: 2.0304 - val_accuracy: 0.1963\n",
      "Epoch 146/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0271 - accuracy: 0.2436 - val_loss: 2.0284 - val_accuracy: 0.2056\n",
      "Epoch 147/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0253 - accuracy: 0.2452 - val_loss: 2.0265 - val_accuracy: 0.1963\n",
      "Epoch 148/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0235 - accuracy: 0.2472 - val_loss: 2.0246 - val_accuracy: 0.1963\n",
      "Epoch 149/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0217 - accuracy: 0.2483 - val_loss: 2.0228 - val_accuracy: 0.1963\n",
      "Epoch 150/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0199 - accuracy: 0.2487 - val_loss: 2.0209 - val_accuracy: 0.1963\n",
      "Epoch 151/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0181 - accuracy: 0.2499 - val_loss: 2.0189 - val_accuracy: 0.1963\n",
      "Epoch 152/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0162 - accuracy: 0.2499 - val_loss: 2.0170 - val_accuracy: 0.1963\n",
      "Epoch 153/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0144 - accuracy: 0.2491 - val_loss: 2.0151 - val_accuracy: 0.1963\n",
      "Epoch 154/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0126 - accuracy: 0.2499 - val_loss: 2.0132 - val_accuracy: 0.1963\n",
      "Epoch 155/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0108 - accuracy: 0.2495 - val_loss: 2.0113 - val_accuracy: 0.1963\n",
      "Epoch 156/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0090 - accuracy: 0.2495 - val_loss: 2.0094 - val_accuracy: 0.1963\n",
      "Epoch 157/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0072 - accuracy: 0.2491 - val_loss: 2.0075 - val_accuracy: 0.1963\n",
      "Epoch 158/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0054 - accuracy: 0.2495 - val_loss: 2.0056 - val_accuracy: 0.1963\n",
      "Epoch 159/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0036 - accuracy: 0.2503 - val_loss: 2.0038 - val_accuracy: 0.1963\n",
      "Epoch 160/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0018 - accuracy: 0.2507 - val_loss: 2.0019 - val_accuracy: 0.2056\n",
      "Epoch 161/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0000 - accuracy: 0.2511 - val_loss: 2.0001 - val_accuracy: 0.2056\n",
      "Epoch 162/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9982 - accuracy: 0.2519 - val_loss: 1.9982 - val_accuracy: 0.2056\n",
      "Epoch 163/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9964 - accuracy: 0.2523 - val_loss: 1.9964 - val_accuracy: 0.2056\n",
      "Epoch 164/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9945 - accuracy: 0.2534 - val_loss: 1.9945 - val_accuracy: 0.2056\n",
      "Epoch 165/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9927 - accuracy: 0.2534 - val_loss: 1.9926 - val_accuracy: 0.2056\n",
      "Epoch 166/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.9909 - accuracy: 0.2542 - val_loss: 1.9907 - val_accuracy: 0.2056\n",
      "Epoch 167/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9890 - accuracy: 0.2554 - val_loss: 1.9888 - val_accuracy: 0.2056\n",
      "Epoch 168/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9872 - accuracy: 0.2562 - val_loss: 1.9869 - val_accuracy: 0.2056\n",
      "Epoch 169/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9854 - accuracy: 0.2593 - val_loss: 1.9850 - val_accuracy: 0.2056\n",
      "Epoch 170/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 1.9835 - accuracy: 0.2609 - val_loss: 1.9831 - val_accuracy: 0.2056\n",
      "Epoch 171/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.9817 - accuracy: 0.2624 - val_loss: 1.9812 - val_accuracy: 0.2056\n",
      "Epoch 172/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9799 - accuracy: 0.2636 - val_loss: 1.9792 - val_accuracy: 0.2150\n",
      "Epoch 173/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9780 - accuracy: 0.2656 - val_loss: 1.9772 - val_accuracy: 0.2150\n",
      "Epoch 174/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9762 - accuracy: 0.2652 - val_loss: 1.9752 - val_accuracy: 0.2243\n",
      "Epoch 175/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9743 - accuracy: 0.2656 - val_loss: 1.9733 - val_accuracy: 0.2336\n",
      "Epoch 176/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.9725 - accuracy: 0.2660 - val_loss: 1.9713 - val_accuracy: 0.2336\n",
      "Epoch 177/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9707 - accuracy: 0.2664 - val_loss: 1.9693 - val_accuracy: 0.2336\n",
      "Epoch 178/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9689 - accuracy: 0.2671 - val_loss: 1.9673 - val_accuracy: 0.2336\n",
      "Epoch 179/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9671 - accuracy: 0.2679 - val_loss: 1.9654 - val_accuracy: 0.2336\n",
      "Epoch 180/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9653 - accuracy: 0.2695 - val_loss: 1.9635 - val_accuracy: 0.2336\n",
      "Epoch 181/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.9635 - accuracy: 0.2707 - val_loss: 1.9615 - val_accuracy: 0.2336\n",
      "Epoch 182/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.9617 - accuracy: 0.2711 - val_loss: 1.9596 - val_accuracy: 0.2336\n",
      "Epoch 183/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.9599 - accuracy: 0.2718 - val_loss: 1.9576 - val_accuracy: 0.2336\n",
      "Epoch 184/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9581 - accuracy: 0.2722 - val_loss: 1.9557 - val_accuracy: 0.2336\n",
      "Epoch 185/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9563 - accuracy: 0.2726 - val_loss: 1.9538 - val_accuracy: 0.2336\n",
      "Epoch 186/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.9545 - accuracy: 0.2730 - val_loss: 1.9518 - val_accuracy: 0.2336\n",
      "Epoch 187/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9527 - accuracy: 0.2734 - val_loss: 1.9499 - val_accuracy: 0.2336\n",
      "Epoch 188/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.9509 - accuracy: 0.2738 - val_loss: 1.9480 - val_accuracy: 0.2336\n",
      "Epoch 189/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.9491 - accuracy: 0.2754 - val_loss: 1.9462 - val_accuracy: 0.2336\n",
      "Epoch 190/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9473 - accuracy: 0.2758 - val_loss: 1.9442 - val_accuracy: 0.2430\n",
      "Epoch 191/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9455 - accuracy: 0.2769 - val_loss: 1.9423 - val_accuracy: 0.2523\n",
      "Epoch 192/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9437 - accuracy: 0.2781 - val_loss: 1.9404 - val_accuracy: 0.2523\n",
      "Epoch 193/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9419 - accuracy: 0.2793 - val_loss: 1.9385 - val_accuracy: 0.2523\n",
      "Epoch 194/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9401 - accuracy: 0.2793 - val_loss: 1.9366 - val_accuracy: 0.2523\n",
      "Epoch 195/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9384 - accuracy: 0.2805 - val_loss: 1.9347 - val_accuracy: 0.2523\n",
      "Epoch 196/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9366 - accuracy: 0.2805 - val_loss: 1.9329 - val_accuracy: 0.2523\n",
      "Epoch 197/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9348 - accuracy: 0.2812 - val_loss: 1.9310 - val_accuracy: 0.2523\n",
      "Epoch 198/200\n",
      "80/80 [==============================] - ETA: 0s - loss: 1.9294 - accuracy: 0.29 - 0s 2ms/step - loss: 1.9331 - accuracy: 0.2816 - val_loss: 1.9291 - val_accuracy: 0.2523\n",
      "Epoch 199/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9313 - accuracy: 0.2824 - val_loss: 1.9273 - val_accuracy: 0.2523\n",
      "Epoch 200/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.9295 - accuracy: 0.2836 - val_loss: 1.9254 - val_accuracy: 0.2523\n",
      "0.25233644247055054 {'loss': 1.9295059442520142, 'accuracy': 0.2835879325866699, 'val_loss': 1.9253970384597778, 'val_accuracy': 0.25233644247055054}\n",
      "Model: \"model_26\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_27 (InputLayer)        [(None, 29)]              0         \n",
      "_________________________________________________________________\n",
      "flatten_26 (Flatten)         (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 41)                1230      \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 10)                420       \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,870\n",
      "Trainable params: 1,870\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 2.5278 - accuracy: 0.0631 - val_loss: 2.5094 - val_accuracy: 0.0561\n",
      "Epoch 2/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.5372 - accuracy: 0.0595 - val_loss: 2.5061 - val_accuracy: 0.0561\n",
      "Epoch 3/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.5231 - accuracy: 0.0588 - val_loss: 2.5030 - val_accuracy: 0.0561\n",
      "Epoch 4/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.5272 - accuracy: 0.0635 - val_loss: 2.4999 - val_accuracy: 0.0561\n",
      "Epoch 5/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.5139 - accuracy: 0.0646 - val_loss: 2.4967 - val_accuracy: 0.0561\n",
      "Epoch 6/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.5229 - accuracy: 0.0654 - val_loss: 2.4935 - val_accuracy: 0.0561\n",
      "Epoch 7/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.5151 - accuracy: 0.0662 - val_loss: 2.4902 - val_accuracy: 0.0561\n",
      "Epoch 8/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.5011 - accuracy: 0.0631 - val_loss: 2.4869 - val_accuracy: 0.0561\n",
      "Epoch 9/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 2ms/step - loss: 2.5094 - accuracy: 0.0662 - val_loss: 2.4835 - val_accuracy: 0.0561\n",
      "Epoch 10/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4882 - accuracy: 0.0693 - val_loss: 2.4801 - val_accuracy: 0.0561\n",
      "Epoch 11/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4972 - accuracy: 0.0689 - val_loss: 2.4766 - val_accuracy: 0.0561\n",
      "Epoch 12/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4845 - accuracy: 0.0721 - val_loss: 2.4730 - val_accuracy: 0.0561\n",
      "Epoch 13/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4735 - accuracy: 0.0760 - val_loss: 2.4697 - val_accuracy: 0.0561\n",
      "Epoch 14/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4785 - accuracy: 0.0776 - val_loss: 2.4662 - val_accuracy: 0.0561\n",
      "Epoch 15/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4880 - accuracy: 0.0689 - val_loss: 2.4629 - val_accuracy: 0.0561\n",
      "Epoch 16/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4735 - accuracy: 0.0756 - val_loss: 2.4595 - val_accuracy: 0.0654\n",
      "Epoch 17/200\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 2.4814 - accuracy: 0.0713 - val_loss: 2.4561 - val_accuracy: 0.0654\n",
      "Epoch 18/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4705 - accuracy: 0.0819 - val_loss: 2.4528 - val_accuracy: 0.0654\n",
      "Epoch 19/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 2.4732 - accuracy: 0.0815 - val_loss: 2.4493 - val_accuracy: 0.0654\n",
      "Epoch 20/200\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 2.4613 - accuracy: 0.0811 - val_loss: 2.4459 - val_accuracy: 0.0654\n",
      "Epoch 21/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 2.4580 - accuracy: 0.0846 - val_loss: 2.4423 - val_accuracy: 0.0654\n",
      "Epoch 22/200\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 2.4438 - accuracy: 0.0870 - val_loss: 2.4390 - val_accuracy: 0.0654\n",
      "Epoch 23/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 2.4435 - accuracy: 0.0858 - val_loss: 2.4353 - val_accuracy: 0.0654\n",
      "Epoch 24/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4325 - accuracy: 0.0901 - val_loss: 2.4316 - val_accuracy: 0.0654\n",
      "Epoch 25/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4382 - accuracy: 0.0928 - val_loss: 2.4281 - val_accuracy: 0.0654\n",
      "Epoch 26/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4292 - accuracy: 0.0964 - val_loss: 2.4245 - val_accuracy: 0.0748\n",
      "Epoch 27/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4481 - accuracy: 0.0823 - val_loss: 2.4209 - val_accuracy: 0.0748\n",
      "Epoch 28/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 2.4284 - accuracy: 0.0991 - val_loss: 2.4173 - val_accuracy: 0.0748\n",
      "Epoch 29/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4259 - accuracy: 0.0967 - val_loss: 2.4137 - val_accuracy: 0.0841\n",
      "Epoch 30/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4223 - accuracy: 0.0991 - val_loss: 2.4103 - val_accuracy: 0.0841\n",
      "Epoch 31/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4122 - accuracy: 0.1022 - val_loss: 2.4066 - val_accuracy: 0.0841\n",
      "Epoch 32/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4158 - accuracy: 0.1022 - val_loss: 2.4031 - val_accuracy: 0.0841\n",
      "Epoch 33/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4148 - accuracy: 0.1061 - val_loss: 2.3997 - val_accuracy: 0.0841\n",
      "Epoch 34/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4171 - accuracy: 0.0983 - val_loss: 2.3964 - val_accuracy: 0.0935\n",
      "Epoch 35/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3988 - accuracy: 0.1065 - val_loss: 2.3930 - val_accuracy: 0.0935\n",
      "Epoch 36/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3958 - accuracy: 0.1112 - val_loss: 2.3896 - val_accuracy: 0.0935\n",
      "Epoch 37/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3948 - accuracy: 0.1050 - val_loss: 2.3862 - val_accuracy: 0.1028\n",
      "Epoch 38/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3973 - accuracy: 0.1120 - val_loss: 2.3830 - val_accuracy: 0.1028\n",
      "Epoch 39/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3917 - accuracy: 0.1097 - val_loss: 2.3798 - val_accuracy: 0.1028\n",
      "Epoch 40/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4065 - accuracy: 0.1120 - val_loss: 2.3766 - val_accuracy: 0.1028\n",
      "Epoch 41/200\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 2.3798 - accuracy: 0.1175 - val_loss: 2.3733 - val_accuracy: 0.1028\n",
      "Epoch 42/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3921 - accuracy: 0.1179 - val_loss: 2.3699 - val_accuracy: 0.1028\n",
      "Epoch 43/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3833 - accuracy: 0.1159 - val_loss: 2.3665 - val_accuracy: 0.1028\n",
      "Epoch 44/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3776 - accuracy: 0.1187 - val_loss: 2.3632 - val_accuracy: 0.1028\n",
      "Epoch 45/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 2.3717 - accuracy: 0.1277 - val_loss: 2.3600 - val_accuracy: 0.1028\n",
      "Epoch 46/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 2.3557 - accuracy: 0.1285 - val_loss: 2.3568 - val_accuracy: 0.1028\n",
      "Epoch 47/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3660 - accuracy: 0.1293 - val_loss: 2.3534 - val_accuracy: 0.1028\n",
      "Epoch 48/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3639 - accuracy: 0.1297 - val_loss: 2.3500 - val_accuracy: 0.1028\n",
      "Epoch 49/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3490 - accuracy: 0.1340 - val_loss: 2.3465 - val_accuracy: 0.1028\n",
      "Epoch 50/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3498 - accuracy: 0.1344 - val_loss: 2.3431 - val_accuracy: 0.1121\n",
      "Epoch 51/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3493 - accuracy: 0.1394 - val_loss: 2.3396 - val_accuracy: 0.1121\n",
      "Epoch 52/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3390 - accuracy: 0.1445 - val_loss: 2.3359 - val_accuracy: 0.1121\n",
      "Epoch 53/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3522 - accuracy: 0.1355 - val_loss: 2.3324 - val_accuracy: 0.1121\n",
      "Epoch 54/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3440 - accuracy: 0.1453 - val_loss: 2.3287 - val_accuracy: 0.1215\n",
      "Epoch 55/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3313 - accuracy: 0.1469 - val_loss: 2.3251 - val_accuracy: 0.1215\n",
      "Epoch 56/200\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 2.3346 - accuracy: 0.1465 - val_loss: 2.3215 - val_accuracy: 0.1215\n",
      "Epoch 57/200\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 2.3320 - accuracy: 0.1512 - val_loss: 2.3179 - val_accuracy: 0.1215\n",
      "Epoch 58/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 2.3215 - accuracy: 0.1598 - val_loss: 2.3143 - val_accuracy: 0.1215\n",
      "Epoch 59/200\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 2.3130 - accuracy: 0.1500 - val_loss: 2.3108 - val_accuracy: 0.1215\n",
      "Epoch 60/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3191 - accuracy: 0.1594 - val_loss: 2.3074 - val_accuracy: 0.1215\n",
      "Epoch 61/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3235 - accuracy: 0.1524 - val_loss: 2.3040 - val_accuracy: 0.1215\n",
      "Epoch 62/200\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 2.3013 - accuracy: 0.1661 - val_loss: 2.3006 - val_accuracy: 0.1215\n",
      "Epoch 63/200\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 2.3154 - accuracy: 0.1559 - val_loss: 2.2974 - val_accuracy: 0.1215\n",
      "Epoch 64/200\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 2.3177 - accuracy: 0.1543 - val_loss: 2.2940 - val_accuracy: 0.1215\n",
      "Epoch 65/200\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 2.3084 - accuracy: 0.1673 - val_loss: 2.2906 - val_accuracy: 0.1308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/200\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 2.3106 - accuracy: 0.1633 - val_loss: 2.2874 - val_accuracy: 0.1308\n",
      "Epoch 67/200\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 2.3217 - accuracy: 0.1586 - val_loss: 2.2841 - val_accuracy: 0.1308\n",
      "Epoch 68/200\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 2.3047 - accuracy: 0.1590 - val_loss: 2.2808 - val_accuracy: 0.1308\n",
      "Epoch 69/200\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 2.2935 - accuracy: 0.1727 - val_loss: 2.2776 - val_accuracy: 0.1308\n",
      "Epoch 70/200\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 2.2865 - accuracy: 0.1712 - val_loss: 2.2744 - val_accuracy: 0.1308\n",
      "Epoch 71/200\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 2.2829 - accuracy: 0.1833 - val_loss: 2.2709 - val_accuracy: 0.1495\n",
      "Epoch 72/200\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 2.2887 - accuracy: 0.1770 - val_loss: 2.2677 - val_accuracy: 0.1589\n",
      "Epoch 73/200\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 2.2799 - accuracy: 0.1837 - val_loss: 2.2645 - val_accuracy: 0.1589\n",
      "Epoch 74/200\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 2.2741 - accuracy: 0.1857 - val_loss: 2.2612 - val_accuracy: 0.1589\n",
      "Epoch 75/200\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 2.2545 - accuracy: 0.1939 - val_loss: 2.2579 - val_accuracy: 0.1589\n",
      "Epoch 76/200\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 2.2828 - accuracy: 0.1755 - val_loss: 2.2547 - val_accuracy: 0.1589\n",
      "Epoch 77/200\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 2.2657 - accuracy: 0.1915 - val_loss: 2.2515 - val_accuracy: 0.1589\n",
      "Epoch 78/200\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 2.2691 - accuracy: 0.1814 - val_loss: 2.2483 - val_accuracy: 0.1589\n",
      "Epoch 79/200\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 2.2524 - accuracy: 0.1947 - val_loss: 2.2451 - val_accuracy: 0.1589\n",
      "Epoch 80/200\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 2.2655 - accuracy: 0.1935 - val_loss: 2.2419 - val_accuracy: 0.1589\n",
      "Epoch 81/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2531 - accuracy: 0.1966 - val_loss: 2.2387 - val_accuracy: 0.1589\n",
      "Epoch 82/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 2.2566 - accuracy: 0.1943 - val_loss: 2.2356 - val_accuracy: 0.1682\n",
      "Epoch 83/200\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 2.2556 - accuracy: 0.1958 - val_loss: 2.2325 - val_accuracy: 0.1682\n",
      "Epoch 84/200\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 2.2448 - accuracy: 0.2064 - val_loss: 2.2294 - val_accuracy: 0.1682\n",
      "Epoch 85/200\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 2.2509 - accuracy: 0.2025 - val_loss: 2.2264 - val_accuracy: 0.1682\n",
      "Epoch 86/200\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 2.2476 - accuracy: 0.2009 - val_loss: 2.2233 - val_accuracy: 0.1776\n",
      "Epoch 87/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 2.2450 - accuracy: 0.1962 - val_loss: 2.2203 - val_accuracy: 0.1776\n",
      "Epoch 88/200\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 2.2409 - accuracy: 0.1998 - val_loss: 2.2174 - val_accuracy: 0.1776\n",
      "Epoch 89/200\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 2.2323 - accuracy: 0.2049 - val_loss: 2.2142 - val_accuracy: 0.1776\n",
      "Epoch 90/200\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 2.2269 - accuracy: 0.2111 - val_loss: 2.2111 - val_accuracy: 0.1776\n",
      "Epoch 91/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2384 - accuracy: 0.2064 - val_loss: 2.2081 - val_accuracy: 0.1776\n",
      "Epoch 92/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2438 - accuracy: 0.2049 - val_loss: 2.2052 - val_accuracy: 0.1776\n",
      "Epoch 93/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2344 - accuracy: 0.2088 - val_loss: 2.2021 - val_accuracy: 0.1776\n",
      "Epoch 94/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2220 - accuracy: 0.2150 - val_loss: 2.1987 - val_accuracy: 0.1776\n",
      "Epoch 95/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 2.2202 - accuracy: 0.2213 - val_loss: 2.1953 - val_accuracy: 0.1776\n",
      "Epoch 96/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1910 - accuracy: 0.2280 - val_loss: 2.1919 - val_accuracy: 0.1869\n",
      "Epoch 97/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2165 - accuracy: 0.2182 - val_loss: 2.1888 - val_accuracy: 0.1869\n",
      "Epoch 98/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2035 - accuracy: 0.2201 - val_loss: 2.1855 - val_accuracy: 0.1869\n",
      "Epoch 99/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1971 - accuracy: 0.2307 - val_loss: 2.1823 - val_accuracy: 0.1869\n",
      "Epoch 100/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2045 - accuracy: 0.2237 - val_loss: 2.1790 - val_accuracy: 0.1869\n",
      "Epoch 101/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1912 - accuracy: 0.2374 - val_loss: 2.1755 - val_accuracy: 0.1869\n",
      "Epoch 102/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1981 - accuracy: 0.2252 - val_loss: 2.1721 - val_accuracy: 0.1869\n",
      "Epoch 103/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1879 - accuracy: 0.2393 - val_loss: 2.1687 - val_accuracy: 0.1963\n",
      "Epoch 104/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1893 - accuracy: 0.2327 - val_loss: 2.1652 - val_accuracy: 0.1963\n",
      "Epoch 105/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1833 - accuracy: 0.2421 - val_loss: 2.1616 - val_accuracy: 0.1963\n",
      "Epoch 106/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1829 - accuracy: 0.2299 - val_loss: 2.1582 - val_accuracy: 0.1963\n",
      "Epoch 107/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1882 - accuracy: 0.2331 - val_loss: 2.1548 - val_accuracy: 0.2056\n",
      "Epoch 108/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1817 - accuracy: 0.2436 - val_loss: 2.1515 - val_accuracy: 0.2056\n",
      "Epoch 109/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1819 - accuracy: 0.2354 - val_loss: 2.1481 - val_accuracy: 0.1963\n",
      "Epoch 110/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1676 - accuracy: 0.2483 - val_loss: 2.1446 - val_accuracy: 0.1963\n",
      "Epoch 111/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1719 - accuracy: 0.2378 - val_loss: 2.1413 - val_accuracy: 0.1963\n",
      "Epoch 112/200\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 2.1679 - accuracy: 0.2421 - val_loss: 2.1380 - val_accuracy: 0.2150\n",
      "Epoch 113/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1838 - accuracy: 0.2327 - val_loss: 2.1348 - val_accuracy: 0.2150\n",
      "Epoch 114/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1636 - accuracy: 0.2483 - val_loss: 2.1315 - val_accuracy: 0.2150\n",
      "Epoch 115/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1574 - accuracy: 0.2511 - val_loss: 2.1282 - val_accuracy: 0.2150\n",
      "Epoch 116/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1638 - accuracy: 0.2432 - val_loss: 2.1249 - val_accuracy: 0.2150\n",
      "Epoch 117/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1563 - accuracy: 0.2483 - val_loss: 2.1219 - val_accuracy: 0.2150\n",
      "Epoch 118/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1517 - accuracy: 0.2542 - val_loss: 2.1187 - val_accuracy: 0.2243\n",
      "Epoch 119/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1565 - accuracy: 0.2491 - val_loss: 2.1157 - val_accuracy: 0.2243\n",
      "Epoch 120/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1453 - accuracy: 0.2554 - val_loss: 2.1126 - val_accuracy: 0.2243\n",
      "Epoch 121/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1490 - accuracy: 0.2570 - val_loss: 2.1096 - val_accuracy: 0.2336\n",
      "Epoch 122/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1483 - accuracy: 0.2499 - val_loss: 2.1064 - val_accuracy: 0.2523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1394 - accuracy: 0.2656 - val_loss: 2.1033 - val_accuracy: 0.2523\n",
      "Epoch 124/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1267 - accuracy: 0.2781 - val_loss: 2.1000 - val_accuracy: 0.2617\n",
      "Epoch 125/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1337 - accuracy: 0.2664 - val_loss: 2.0966 - val_accuracy: 0.2710\n",
      "Epoch 126/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1446 - accuracy: 0.2542 - val_loss: 2.0935 - val_accuracy: 0.2710\n",
      "Epoch 127/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1349 - accuracy: 0.2691 - val_loss: 2.0903 - val_accuracy: 0.2710\n",
      "Epoch 128/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1157 - accuracy: 0.2742 - val_loss: 2.0869 - val_accuracy: 0.2804\n",
      "Epoch 129/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1329 - accuracy: 0.2687 - val_loss: 2.0839 - val_accuracy: 0.2897\n",
      "Epoch 130/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1222 - accuracy: 0.2683 - val_loss: 2.0807 - val_accuracy: 0.2897\n",
      "Epoch 131/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1339 - accuracy: 0.2609 - val_loss: 2.0777 - val_accuracy: 0.2991\n",
      "Epoch 132/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1171 - accuracy: 0.2648 - val_loss: 2.0745 - val_accuracy: 0.2991\n",
      "Epoch 133/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1056 - accuracy: 0.2711 - val_loss: 2.0713 - val_accuracy: 0.2991\n",
      "Epoch 134/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1031 - accuracy: 0.2738 - val_loss: 2.0680 - val_accuracy: 0.2991\n",
      "Epoch 135/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1048 - accuracy: 0.2730 - val_loss: 2.0647 - val_accuracy: 0.2991\n",
      "Epoch 136/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1391 - accuracy: 0.2624 - val_loss: 2.0620 - val_accuracy: 0.2991\n",
      "Epoch 137/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1233 - accuracy: 0.2667 - val_loss: 2.0589 - val_accuracy: 0.2991\n",
      "Epoch 138/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1067 - accuracy: 0.2859 - val_loss: 2.0557 - val_accuracy: 0.2991\n",
      "Epoch 139/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1124 - accuracy: 0.2746 - val_loss: 2.0527 - val_accuracy: 0.3084\n",
      "Epoch 140/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1023 - accuracy: 0.2808 - val_loss: 2.0497 - val_accuracy: 0.2991\n",
      "Epoch 141/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0882 - accuracy: 0.2840 - val_loss: 2.0465 - val_accuracy: 0.2991\n",
      "Epoch 142/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0949 - accuracy: 0.2875 - val_loss: 2.0436 - val_accuracy: 0.2991\n",
      "Epoch 143/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0627 - accuracy: 0.2965 - val_loss: 2.0403 - val_accuracy: 0.3084\n",
      "Epoch 144/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0813 - accuracy: 0.2989 - val_loss: 2.0372 - val_accuracy: 0.3178\n",
      "Epoch 145/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0782 - accuracy: 0.2942 - val_loss: 2.0341 - val_accuracy: 0.3178\n",
      "Epoch 146/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0882 - accuracy: 0.2871 - val_loss: 2.0312 - val_accuracy: 0.3271\n",
      "Epoch 147/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0821 - accuracy: 0.2949 - val_loss: 2.0283 - val_accuracy: 0.3271\n",
      "Epoch 148/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0809 - accuracy: 0.2934 - val_loss: 2.0253 - val_accuracy: 0.3271\n",
      "Epoch 149/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0703 - accuracy: 0.2855 - val_loss: 2.0222 - val_accuracy: 0.3271\n",
      "Epoch 150/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0745 - accuracy: 0.2836 - val_loss: 2.0193 - val_accuracy: 0.3271\n",
      "Epoch 151/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0626 - accuracy: 0.2957 - val_loss: 2.0164 - val_accuracy: 0.3178\n",
      "Epoch 152/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0809 - accuracy: 0.2879 - val_loss: 2.0136 - val_accuracy: 0.3178\n",
      "Epoch 153/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0803 - accuracy: 0.2981 - val_loss: 2.0109 - val_accuracy: 0.3178\n",
      "Epoch 154/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0859 - accuracy: 0.3067 - val_loss: 2.0081 - val_accuracy: 0.3271\n",
      "Epoch 155/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0660 - accuracy: 0.3016 - val_loss: 2.0053 - val_accuracy: 0.3271\n",
      "Epoch 156/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0890 - accuracy: 0.2946 - val_loss: 2.0029 - val_accuracy: 0.3271\n",
      "Epoch 157/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0820 - accuracy: 0.3016 - val_loss: 2.0002 - val_accuracy: 0.3364\n",
      "Epoch 158/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0714 - accuracy: 0.2969 - val_loss: 1.9976 - val_accuracy: 0.3364\n",
      "Epoch 159/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0505 - accuracy: 0.3184 - val_loss: 1.9948 - val_accuracy: 0.3364\n",
      "Epoch 160/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0484 - accuracy: 0.3212 - val_loss: 1.9920 - val_accuracy: 0.3458\n",
      "Epoch 161/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0611 - accuracy: 0.3028 - val_loss: 1.9894 - val_accuracy: 0.3645\n",
      "Epoch 162/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0335 - accuracy: 0.3251 - val_loss: 1.9865 - val_accuracy: 0.3738\n",
      "Epoch 163/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0483 - accuracy: 0.3141 - val_loss: 1.9838 - val_accuracy: 0.3738\n",
      "Epoch 164/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0107 - accuracy: 0.3302 - val_loss: 1.9809 - val_accuracy: 0.3832\n",
      "Epoch 165/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0259 - accuracy: 0.3373 - val_loss: 1.9783 - val_accuracy: 0.3832\n",
      "Epoch 166/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0298 - accuracy: 0.3267 - val_loss: 1.9756 - val_accuracy: 0.3832\n",
      "Epoch 167/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0343 - accuracy: 0.3294 - val_loss: 1.9730 - val_accuracy: 0.3832\n",
      "Epoch 168/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0478 - accuracy: 0.3212 - val_loss: 1.9706 - val_accuracy: 0.3832\n",
      "Epoch 169/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0356 - accuracy: 0.3204 - val_loss: 1.9682 - val_accuracy: 0.3832\n",
      "Epoch 170/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0367 - accuracy: 0.3298 - val_loss: 1.9657 - val_accuracy: 0.3832\n",
      "Epoch 171/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0377 - accuracy: 0.3231 - val_loss: 1.9632 - val_accuracy: 0.3832\n",
      "Epoch 172/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0071 - accuracy: 0.3443 - val_loss: 1.9604 - val_accuracy: 0.3832\n",
      "Epoch 173/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0286 - accuracy: 0.3447 - val_loss: 1.9577 - val_accuracy: 0.3925\n",
      "Epoch 174/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0253 - accuracy: 0.3373 - val_loss: 1.9552 - val_accuracy: 0.3925\n",
      "Epoch 175/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0144 - accuracy: 0.3329 - val_loss: 1.9526 - val_accuracy: 0.3925\n",
      "Epoch 176/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0165 - accuracy: 0.3380 - val_loss: 1.9501 - val_accuracy: 0.4019\n",
      "Epoch 177/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0124 - accuracy: 0.3365 - val_loss: 1.9474 - val_accuracy: 0.4019\n",
      "Epoch 178/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0107 - accuracy: 0.3478 - val_loss: 1.9446 - val_accuracy: 0.4019\n",
      "Epoch 179/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0181 - accuracy: 0.3404 - val_loss: 1.9418 - val_accuracy: 0.4019\n",
      "Epoch 180/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0228 - accuracy: 0.3404 - val_loss: 1.9393 - val_accuracy: 0.4019\n",
      "Epoch 181/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0024 - accuracy: 0.3427 - val_loss: 1.9365 - val_accuracy: 0.4019\n",
      "Epoch 182/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0069 - accuracy: 0.3431 - val_loss: 1.9340 - val_accuracy: 0.4019\n",
      "Epoch 183/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.9915 - accuracy: 0.3643 - val_loss: 1.9312 - val_accuracy: 0.4206\n",
      "Epoch 184/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.9861 - accuracy: 0.3553 - val_loss: 1.9283 - val_accuracy: 0.4206\n",
      "Epoch 185/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0021 - accuracy: 0.3455 - val_loss: 1.9254 - val_accuracy: 0.4206\n",
      "Epoch 186/200\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 2.0070 - accuracy: 0.3439 - val_loss: 1.9225 - val_accuracy: 0.4299\n",
      "Epoch 187/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 2.0119 - accuracy: 0.3388 - val_loss: 1.9197 - val_accuracy: 0.4393\n",
      "Epoch 188/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.0098 - accuracy: 0.3435 - val_loss: 1.9170 - val_accuracy: 0.4486\n",
      "Epoch 189/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.9738 - accuracy: 0.3655 - val_loss: 1.9139 - val_accuracy: 0.4673\n",
      "Epoch 190/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.9929 - accuracy: 0.3510 - val_loss: 1.9111 - val_accuracy: 0.4673\n",
      "Epoch 191/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.9957 - accuracy: 0.3608 - val_loss: 1.9083 - val_accuracy: 0.4673\n",
      "Epoch 192/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.9822 - accuracy: 0.3600 - val_loss: 1.9055 - val_accuracy: 0.4673\n",
      "Epoch 193/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.9516 - accuracy: 0.3799 - val_loss: 1.9025 - val_accuracy: 0.4673\n",
      "Epoch 194/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.9739 - accuracy: 0.3631 - val_loss: 1.8997 - val_accuracy: 0.4860\n",
      "Epoch 195/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.9790 - accuracy: 0.3678 - val_loss: 1.8970 - val_accuracy: 0.4860\n",
      "Epoch 196/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.9956 - accuracy: 0.3553 - val_loss: 1.8944 - val_accuracy: 0.4860\n",
      "Epoch 197/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.9799 - accuracy: 0.3666 - val_loss: 1.8918 - val_accuracy: 0.4860\n",
      "Epoch 198/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.9651 - accuracy: 0.3651 - val_loss: 1.8890 - val_accuracy: 0.4766\n",
      "Epoch 199/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.9807 - accuracy: 0.3600 - val_loss: 1.8862 - val_accuracy: 0.4766\n",
      "Epoch 200/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.9850 - accuracy: 0.3549 - val_loss: 1.8836 - val_accuracy: 0.4766\n",
      "0.47663551568984985 {'loss': 1.9849711656570435, 'accuracy': 0.3548766076564789, 'val_loss': 1.8836334943771362, 'val_accuracy': 0.47663551568984985}\n",
      "Model: \"model_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_28 (InputLayer)        [(None, 29)]              0         \n",
      "_________________________________________________________________\n",
      "flatten_27 (Flatten)         (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 41)                1230      \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 10)                420       \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,870\n",
      "Trainable params: 1,870\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 2.6020 - accuracy: 0.0505 - val_loss: 2.5197 - val_accuracy: 0.0561\n",
      "Epoch 2/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5931 - accuracy: 0.0513 - val_loss: 2.5175 - val_accuracy: 0.0561\n",
      "Epoch 3/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5945 - accuracy: 0.0482 - val_loss: 2.5153 - val_accuracy: 0.0561\n",
      "Epoch 4/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5800 - accuracy: 0.0490 - val_loss: 2.5131 - val_accuracy: 0.0561\n",
      "Epoch 5/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5870 - accuracy: 0.0450 - val_loss: 2.5108 - val_accuracy: 0.0561\n",
      "Epoch 6/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5868 - accuracy: 0.0568 - val_loss: 2.5085 - val_accuracy: 0.0561\n",
      "Epoch 7/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5866 - accuracy: 0.0462 - val_loss: 2.5063 - val_accuracy: 0.0561\n",
      "Epoch 8/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5770 - accuracy: 0.0486 - val_loss: 2.5042 - val_accuracy: 0.0561\n",
      "Epoch 9/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5744 - accuracy: 0.0501 - val_loss: 2.5020 - val_accuracy: 0.0561\n",
      "Epoch 10/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5673 - accuracy: 0.0544 - val_loss: 2.4999 - val_accuracy: 0.0561\n",
      "Epoch 11/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5637 - accuracy: 0.0588 - val_loss: 2.4977 - val_accuracy: 0.0561\n",
      "Epoch 12/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5686 - accuracy: 0.0525 - val_loss: 2.4956 - val_accuracy: 0.0561\n",
      "Epoch 13/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5558 - accuracy: 0.0595 - val_loss: 2.4935 - val_accuracy: 0.0561\n",
      "Epoch 14/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5634 - accuracy: 0.0580 - val_loss: 2.4914 - val_accuracy: 0.0561\n",
      "Epoch 15/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5595 - accuracy: 0.0564 - val_loss: 2.4892 - val_accuracy: 0.0561\n",
      "Epoch 16/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5470 - accuracy: 0.0568 - val_loss: 2.4872 - val_accuracy: 0.0561\n",
      "Epoch 17/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5481 - accuracy: 0.0631 - val_loss: 2.4851 - val_accuracy: 0.0561\n",
      "Epoch 18/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5520 - accuracy: 0.0580 - val_loss: 2.4830 - val_accuracy: 0.0561\n",
      "Epoch 19/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5470 - accuracy: 0.0603 - val_loss: 2.4809 - val_accuracy: 0.0561\n",
      "Epoch 20/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5437 - accuracy: 0.0607 - val_loss: 2.4789 - val_accuracy: 0.0561\n",
      "Epoch 21/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5429 - accuracy: 0.0560 - val_loss: 2.4770 - val_accuracy: 0.0654\n",
      "Epoch 22/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5325 - accuracy: 0.0638 - val_loss: 2.4750 - val_accuracy: 0.0654\n",
      "Epoch 23/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.5375 - accuracy: 0.0603 - val_loss: 2.4729 - val_accuracy: 0.0654\n",
      "Epoch 24/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.5345 - accuracy: 0.0603 - val_loss: 2.4710 - val_accuracy: 0.0654\n",
      "Epoch 25/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 3ms/step - loss: 2.5268 - accuracy: 0.0654 - val_loss: 2.4690 - val_accuracy: 0.0654\n",
      "Epoch 26/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.5206 - accuracy: 0.0642 - val_loss: 2.4671 - val_accuracy: 0.0654\n",
      "Epoch 27/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.5268 - accuracy: 0.0662 - val_loss: 2.4651 - val_accuracy: 0.0654\n",
      "Epoch 28/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.5226 - accuracy: 0.0674 - val_loss: 2.4632 - val_accuracy: 0.0654\n",
      "Epoch 29/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5165 - accuracy: 0.0603 - val_loss: 2.4613 - val_accuracy: 0.0654\n",
      "Epoch 30/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 2.5189 - accuracy: 0.0619 - val_loss: 2.4594 - val_accuracy: 0.0654\n",
      "Epoch 31/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5190 - accuracy: 0.0666 - val_loss: 2.4574 - val_accuracy: 0.0654\n",
      "Epoch 32/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.5199 - accuracy: 0.0674 - val_loss: 2.4554 - val_accuracy: 0.0654\n",
      "Epoch 33/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.5100 - accuracy: 0.0713 - val_loss: 2.4535 - val_accuracy: 0.0654\n",
      "Epoch 34/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5089 - accuracy: 0.0666 - val_loss: 2.4516 - val_accuracy: 0.0748\n",
      "Epoch 35/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5068 - accuracy: 0.0627 - val_loss: 2.4496 - val_accuracy: 0.0748\n",
      "Epoch 36/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5106 - accuracy: 0.0619 - val_loss: 2.4478 - val_accuracy: 0.0748\n",
      "Epoch 37/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4912 - accuracy: 0.0709 - val_loss: 2.4459 - val_accuracy: 0.0748\n",
      "Epoch 38/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4913 - accuracy: 0.0705 - val_loss: 2.4441 - val_accuracy: 0.0748\n",
      "Epoch 39/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4907 - accuracy: 0.0807 - val_loss: 2.4422 - val_accuracy: 0.0748\n",
      "Epoch 40/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4943 - accuracy: 0.0642 - val_loss: 2.4403 - val_accuracy: 0.0748\n",
      "Epoch 41/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4948 - accuracy: 0.0725 - val_loss: 2.4385 - val_accuracy: 0.0748\n",
      "Epoch 42/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4893 - accuracy: 0.0764 - val_loss: 2.4367 - val_accuracy: 0.0748\n",
      "Epoch 43/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.4883 - accuracy: 0.0736 - val_loss: 2.4348 - val_accuracy: 0.0748\n",
      "Epoch 44/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4854 - accuracy: 0.0756 - val_loss: 2.4330 - val_accuracy: 0.0748\n",
      "Epoch 45/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.4831 - accuracy: 0.0729 - val_loss: 2.4312 - val_accuracy: 0.0748\n",
      "Epoch 46/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.4795 - accuracy: 0.0807 - val_loss: 2.4294 - val_accuracy: 0.0748\n",
      "Epoch 47/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4737 - accuracy: 0.0791 - val_loss: 2.4276 - val_accuracy: 0.0748\n",
      "Epoch 48/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4743 - accuracy: 0.0787 - val_loss: 2.4258 - val_accuracy: 0.0841\n",
      "Epoch 49/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4778 - accuracy: 0.0756 - val_loss: 2.4240 - val_accuracy: 0.0841\n",
      "Epoch 50/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4781 - accuracy: 0.0740 - val_loss: 2.4223 - val_accuracy: 0.0841\n",
      "Epoch 51/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4672 - accuracy: 0.0807 - val_loss: 2.4206 - val_accuracy: 0.0841\n",
      "Epoch 52/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4661 - accuracy: 0.0799 - val_loss: 2.4189 - val_accuracy: 0.0841\n",
      "Epoch 53/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4715 - accuracy: 0.0823 - val_loss: 2.4171 - val_accuracy: 0.0841\n",
      "Epoch 54/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4687 - accuracy: 0.0823 - val_loss: 2.4154 - val_accuracy: 0.0935\n",
      "Epoch 55/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4523 - accuracy: 0.0901 - val_loss: 2.4137 - val_accuracy: 0.0935\n",
      "Epoch 56/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.4542 - accuracy: 0.0893 - val_loss: 2.4121 - val_accuracy: 0.0935\n",
      "Epoch 57/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4558 - accuracy: 0.0838 - val_loss: 2.4104 - val_accuracy: 0.0935\n",
      "Epoch 58/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4498 - accuracy: 0.0842 - val_loss: 2.4088 - val_accuracy: 0.0935\n",
      "Epoch 59/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4539 - accuracy: 0.0854 - val_loss: 2.4071 - val_accuracy: 0.0935\n",
      "Epoch 60/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4593 - accuracy: 0.0811 - val_loss: 2.4054 - val_accuracy: 0.0935\n",
      "Epoch 61/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4589 - accuracy: 0.0823 - val_loss: 2.4038 - val_accuracy: 0.1028\n",
      "Epoch 62/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4530 - accuracy: 0.0866 - val_loss: 2.4021 - val_accuracy: 0.1028\n",
      "Epoch 63/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4459 - accuracy: 0.0920 - val_loss: 2.4004 - val_accuracy: 0.1028\n",
      "Epoch 64/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4502 - accuracy: 0.0862 - val_loss: 2.3987 - val_accuracy: 0.1028\n",
      "Epoch 65/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4490 - accuracy: 0.0893 - val_loss: 2.3971 - val_accuracy: 0.1028\n",
      "Epoch 66/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4435 - accuracy: 0.0913 - val_loss: 2.3954 - val_accuracy: 0.1028\n",
      "Epoch 67/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.4354 - accuracy: 0.0873 - val_loss: 2.3938 - val_accuracy: 0.1028\n",
      "Epoch 68/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4267 - accuracy: 0.0928 - val_loss: 2.3922 - val_accuracy: 0.1028\n",
      "Epoch 69/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4328 - accuracy: 0.0936 - val_loss: 2.3905 - val_accuracy: 0.1028\n",
      "Epoch 70/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4363 - accuracy: 0.0897 - val_loss: 2.3889 - val_accuracy: 0.1028\n",
      "Epoch 71/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4327 - accuracy: 0.0897 - val_loss: 2.3874 - val_accuracy: 0.1028\n",
      "Epoch 72/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4278 - accuracy: 0.0893 - val_loss: 2.3858 - val_accuracy: 0.1121\n",
      "Epoch 73/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4221 - accuracy: 0.0967 - val_loss: 2.3842 - val_accuracy: 0.1121\n",
      "Epoch 74/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4265 - accuracy: 0.0920 - val_loss: 2.3827 - val_accuracy: 0.1121\n",
      "Epoch 75/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4292 - accuracy: 0.0920 - val_loss: 2.3812 - val_accuracy: 0.1121\n",
      "Epoch 76/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4252 - accuracy: 0.0928 - val_loss: 2.3796 - val_accuracy: 0.1121\n",
      "Epoch 77/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4177 - accuracy: 0.1073 - val_loss: 2.3781 - val_accuracy: 0.1215\n",
      "Epoch 78/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4282 - accuracy: 0.0920 - val_loss: 2.3765 - val_accuracy: 0.1215\n",
      "Epoch 79/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4137 - accuracy: 0.0936 - val_loss: 2.3750 - val_accuracy: 0.1308\n",
      "Epoch 80/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4140 - accuracy: 0.1042 - val_loss: 2.3735 - val_accuracy: 0.1308\n",
      "Epoch 81/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4162 - accuracy: 0.1093 - val_loss: 2.3719 - val_accuracy: 0.1308\n",
      "Epoch 82/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4070 - accuracy: 0.0995 - val_loss: 2.3703 - val_accuracy: 0.1308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4100 - accuracy: 0.1014 - val_loss: 2.3688 - val_accuracy: 0.1402\n",
      "Epoch 84/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4090 - accuracy: 0.1058 - val_loss: 2.3673 - val_accuracy: 0.1402\n",
      "Epoch 85/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4005 - accuracy: 0.1101 - val_loss: 2.3658 - val_accuracy: 0.1402\n",
      "Epoch 86/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4114 - accuracy: 0.1065 - val_loss: 2.3642 - val_accuracy: 0.1402\n",
      "Epoch 87/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3995 - accuracy: 0.1101 - val_loss: 2.3627 - val_accuracy: 0.1402\n",
      "Epoch 88/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3991 - accuracy: 0.0987 - val_loss: 2.3612 - val_accuracy: 0.1495\n",
      "Epoch 89/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4046 - accuracy: 0.1108 - val_loss: 2.3596 - val_accuracy: 0.1495\n",
      "Epoch 90/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3979 - accuracy: 0.1097 - val_loss: 2.3581 - val_accuracy: 0.1495\n",
      "Epoch 91/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3906 - accuracy: 0.1195 - val_loss: 2.3565 - val_accuracy: 0.1495\n",
      "Epoch 92/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3944 - accuracy: 0.1089 - val_loss: 2.3550 - val_accuracy: 0.1589\n",
      "Epoch 93/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4013 - accuracy: 0.1101 - val_loss: 2.3534 - val_accuracy: 0.1589\n",
      "Epoch 94/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3897 - accuracy: 0.1077 - val_loss: 2.3520 - val_accuracy: 0.1589\n",
      "Epoch 95/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3910 - accuracy: 0.1152 - val_loss: 2.3505 - val_accuracy: 0.1589\n",
      "Epoch 96/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3955 - accuracy: 0.1065 - val_loss: 2.3492 - val_accuracy: 0.1589\n",
      "Epoch 97/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3909 - accuracy: 0.1116 - val_loss: 2.3477 - val_accuracy: 0.1589\n",
      "Epoch 98/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3849 - accuracy: 0.1116 - val_loss: 2.3462 - val_accuracy: 0.1589\n",
      "Epoch 99/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3757 - accuracy: 0.1179 - val_loss: 2.3448 - val_accuracy: 0.1589\n",
      "Epoch 100/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3822 - accuracy: 0.1175 - val_loss: 2.3434 - val_accuracy: 0.1589\n",
      "Epoch 101/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.3831 - accuracy: 0.1089 - val_loss: 2.3420 - val_accuracy: 0.1589\n",
      "Epoch 102/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.3892 - accuracy: 0.1116 - val_loss: 2.3406 - val_accuracy: 0.1589\n",
      "Epoch 103/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3828 - accuracy: 0.1242 - val_loss: 2.3392 - val_accuracy: 0.1589\n",
      "Epoch 104/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3845 - accuracy: 0.1140 - val_loss: 2.3378 - val_accuracy: 0.1589\n",
      "Epoch 105/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3773 - accuracy: 0.1183 - val_loss: 2.3364 - val_accuracy: 0.1589\n",
      "Epoch 106/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 2.3744 - accuracy: 0.1175 - val_loss: 2.3350 - val_accuracy: 0.1589\n",
      "Epoch 107/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.3738 - accuracy: 0.1124 - val_loss: 2.3336 - val_accuracy: 0.1589\n",
      "Epoch 108/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3672 - accuracy: 0.1273 - val_loss: 2.3322 - val_accuracy: 0.1589\n",
      "Epoch 109/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3737 - accuracy: 0.1234 - val_loss: 2.3309 - val_accuracy: 0.1589\n",
      "Epoch 110/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3680 - accuracy: 0.1234 - val_loss: 2.3295 - val_accuracy: 0.1589\n",
      "Epoch 111/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.3682 - accuracy: 0.1257 - val_loss: 2.3281 - val_accuracy: 0.1589\n",
      "Epoch 112/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3711 - accuracy: 0.1093 - val_loss: 2.3268 - val_accuracy: 0.1589\n",
      "Epoch 113/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.3641 - accuracy: 0.1171 - val_loss: 2.3255 - val_accuracy: 0.1589\n",
      "Epoch 114/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.3601 - accuracy: 0.1320 - val_loss: 2.3241 - val_accuracy: 0.1589\n",
      "Epoch 115/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3664 - accuracy: 0.1175 - val_loss: 2.3228 - val_accuracy: 0.1589\n",
      "Epoch 116/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3546 - accuracy: 0.1265 - val_loss: 2.3215 - val_accuracy: 0.1589\n",
      "Epoch 117/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3608 - accuracy: 0.1203 - val_loss: 2.3202 - val_accuracy: 0.1589\n",
      "Epoch 118/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3539 - accuracy: 0.1246 - val_loss: 2.3189 - val_accuracy: 0.1589\n",
      "Epoch 119/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3479 - accuracy: 0.1242 - val_loss: 2.3175 - val_accuracy: 0.1589\n",
      "Epoch 120/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3559 - accuracy: 0.1226 - val_loss: 2.3162 - val_accuracy: 0.1495\n",
      "Epoch 121/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3518 - accuracy: 0.1297 - val_loss: 2.3149 - val_accuracy: 0.1495\n",
      "Epoch 122/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3473 - accuracy: 0.1336 - val_loss: 2.3137 - val_accuracy: 0.1495\n",
      "Epoch 123/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3425 - accuracy: 0.1328 - val_loss: 2.3124 - val_accuracy: 0.1495\n",
      "Epoch 124/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3409 - accuracy: 0.1312 - val_loss: 2.3111 - val_accuracy: 0.1495\n",
      "Epoch 125/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3490 - accuracy: 0.1355 - val_loss: 2.3098 - val_accuracy: 0.1589\n",
      "Epoch 126/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3449 - accuracy: 0.1332 - val_loss: 2.3086 - val_accuracy: 0.1589\n",
      "Epoch 127/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3392 - accuracy: 0.1297 - val_loss: 2.3073 - val_accuracy: 0.1589\n",
      "Epoch 128/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3416 - accuracy: 0.1297 - val_loss: 2.3060 - val_accuracy: 0.1589\n",
      "Epoch 129/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3438 - accuracy: 0.1383 - val_loss: 2.3046 - val_accuracy: 0.1495\n",
      "Epoch 130/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3388 - accuracy: 0.1438 - val_loss: 2.3034 - val_accuracy: 0.1495\n",
      "Epoch 131/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3386 - accuracy: 0.1367 - val_loss: 2.3021 - val_accuracy: 0.1495\n",
      "Epoch 132/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3338 - accuracy: 0.1422 - val_loss: 2.3007 - val_accuracy: 0.1495\n",
      "Epoch 133/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3361 - accuracy: 0.1277 - val_loss: 2.2994 - val_accuracy: 0.1495\n",
      "Epoch 134/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3389 - accuracy: 0.1344 - val_loss: 2.2981 - val_accuracy: 0.1495\n",
      "Epoch 135/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3358 - accuracy: 0.1504 - val_loss: 2.2969 - val_accuracy: 0.1495\n",
      "Epoch 136/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3346 - accuracy: 0.1430 - val_loss: 2.2956 - val_accuracy: 0.1495\n",
      "Epoch 137/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3383 - accuracy: 0.1297 - val_loss: 2.2943 - val_accuracy: 0.1589\n",
      "Epoch 138/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3349 - accuracy: 0.1461 - val_loss: 2.2930 - val_accuracy: 0.1589\n",
      "Epoch 139/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3273 - accuracy: 0.1367 - val_loss: 2.2918 - val_accuracy: 0.1589\n",
      "Epoch 140/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3258 - accuracy: 0.1379 - val_loss: 2.2906 - val_accuracy: 0.1589\n",
      "Epoch 141/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3282 - accuracy: 0.1438 - val_loss: 2.2894 - val_accuracy: 0.1589\n",
      "Epoch 142/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3348 - accuracy: 0.1261 - val_loss: 2.2882 - val_accuracy: 0.1589\n",
      "Epoch 143/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3157 - accuracy: 0.1473 - val_loss: 2.2869 - val_accuracy: 0.1589\n",
      "Epoch 144/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3192 - accuracy: 0.1383 - val_loss: 2.2857 - val_accuracy: 0.1682\n",
      "Epoch 145/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3149 - accuracy: 0.1488 - val_loss: 2.2845 - val_accuracy: 0.1682\n",
      "Epoch 146/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3206 - accuracy: 0.1414 - val_loss: 2.2834 - val_accuracy: 0.1682\n",
      "Epoch 147/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3169 - accuracy: 0.1453 - val_loss: 2.2821 - val_accuracy: 0.1682\n",
      "Epoch 148/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3118 - accuracy: 0.1430 - val_loss: 2.2809 - val_accuracy: 0.1682\n",
      "Epoch 149/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3209 - accuracy: 0.1485 - val_loss: 2.2797 - val_accuracy: 0.1682\n",
      "Epoch 150/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3177 - accuracy: 0.1391 - val_loss: 2.2786 - val_accuracy: 0.1682\n",
      "Epoch 151/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3176 - accuracy: 0.1387 - val_loss: 2.2774 - val_accuracy: 0.1682\n",
      "Epoch 152/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3104 - accuracy: 0.1477 - val_loss: 2.2762 - val_accuracy: 0.1682\n",
      "Epoch 153/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3088 - accuracy: 0.1485 - val_loss: 2.2750 - val_accuracy: 0.1682\n",
      "Epoch 154/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3127 - accuracy: 0.1430 - val_loss: 2.2738 - val_accuracy: 0.1682\n",
      "Epoch 155/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.3156 - accuracy: 0.1457 - val_loss: 2.2727 - val_accuracy: 0.1682\n",
      "Epoch 156/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3130 - accuracy: 0.1391 - val_loss: 2.2715 - val_accuracy: 0.1682\n",
      "Epoch 157/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3127 - accuracy: 0.1477 - val_loss: 2.2704 - val_accuracy: 0.1682\n",
      "Epoch 158/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.2967 - accuracy: 0.1602 - val_loss: 2.2692 - val_accuracy: 0.1682\n",
      "Epoch 159/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.3104 - accuracy: 0.1418 - val_loss: 2.2681 - val_accuracy: 0.1682\n",
      "Epoch 160/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3018 - accuracy: 0.1485 - val_loss: 2.2670 - val_accuracy: 0.1682\n",
      "Epoch 161/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.3012 - accuracy: 0.1461 - val_loss: 2.2659 - val_accuracy: 0.1682\n",
      "Epoch 162/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.3048 - accuracy: 0.1524 - val_loss: 2.2647 - val_accuracy: 0.1682\n",
      "Epoch 163/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2962 - accuracy: 0.1547 - val_loss: 2.2636 - val_accuracy: 0.1682\n",
      "Epoch 164/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2963 - accuracy: 0.1626 - val_loss: 2.2625 - val_accuracy: 0.1682\n",
      "Epoch 165/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2976 - accuracy: 0.1516 - val_loss: 2.2614 - val_accuracy: 0.1682\n",
      "Epoch 166/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2927 - accuracy: 0.1606 - val_loss: 2.2604 - val_accuracy: 0.1682\n",
      "Epoch 167/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2969 - accuracy: 0.1532 - val_loss: 2.2593 - val_accuracy: 0.1682\n",
      "Epoch 168/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2912 - accuracy: 0.1622 - val_loss: 2.2583 - val_accuracy: 0.1682\n",
      "Epoch 169/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2989 - accuracy: 0.1680 - val_loss: 2.2572 - val_accuracy: 0.1682\n",
      "Epoch 170/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2939 - accuracy: 0.1477 - val_loss: 2.2561 - val_accuracy: 0.1682\n",
      "Epoch 171/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2964 - accuracy: 0.1528 - val_loss: 2.2551 - val_accuracy: 0.1682\n",
      "Epoch 172/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2944 - accuracy: 0.1590 - val_loss: 2.2540 - val_accuracy: 0.1682\n",
      "Epoch 173/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2932 - accuracy: 0.1618 - val_loss: 2.2529 - val_accuracy: 0.1776\n",
      "Epoch 174/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2839 - accuracy: 0.1606 - val_loss: 2.2519 - val_accuracy: 0.1776\n",
      "Epoch 175/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2913 - accuracy: 0.1653 - val_loss: 2.2509 - val_accuracy: 0.1776\n",
      "Epoch 176/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2822 - accuracy: 0.1563 - val_loss: 2.2499 - val_accuracy: 0.1776\n",
      "Epoch 177/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2825 - accuracy: 0.1657 - val_loss: 2.2488 - val_accuracy: 0.1776\n",
      "Epoch 178/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2926 - accuracy: 0.1551 - val_loss: 2.2479 - val_accuracy: 0.1776\n",
      "Epoch 179/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2790 - accuracy: 0.1602 - val_loss: 2.2468 - val_accuracy: 0.1776\n",
      "Epoch 180/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2801 - accuracy: 0.1688 - val_loss: 2.2458 - val_accuracy: 0.1869\n",
      "Epoch 181/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.2792 - accuracy: 0.1586 - val_loss: 2.2448 - val_accuracy: 0.1869\n",
      "Epoch 182/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.2835 - accuracy: 0.1586 - val_loss: 2.2438 - val_accuracy: 0.1869\n",
      "Epoch 183/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2867 - accuracy: 0.1676 - val_loss: 2.2428 - val_accuracy: 0.1869\n",
      "Epoch 184/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2770 - accuracy: 0.1712 - val_loss: 2.2419 - val_accuracy: 0.1869\n",
      "Epoch 185/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.2745 - accuracy: 0.1676 - val_loss: 2.2408 - val_accuracy: 0.1869\n",
      "Epoch 186/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2764 - accuracy: 0.1723 - val_loss: 2.2399 - val_accuracy: 0.1869\n",
      "Epoch 187/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2728 - accuracy: 0.1720 - val_loss: 2.2389 - val_accuracy: 0.1869\n",
      "Epoch 188/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2776 - accuracy: 0.1704 - val_loss: 2.2379 - val_accuracy: 0.1869\n",
      "Epoch 189/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2766 - accuracy: 0.1692 - val_loss: 2.2370 - val_accuracy: 0.1869\n",
      "Epoch 190/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2725 - accuracy: 0.1751 - val_loss: 2.2360 - val_accuracy: 0.1869\n",
      "Epoch 191/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.2776 - accuracy: 0.1598 - val_loss: 2.2350 - val_accuracy: 0.1869\n",
      "Epoch 192/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2704 - accuracy: 0.1731 - val_loss: 2.2340 - val_accuracy: 0.1869\n",
      "Epoch 193/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2706 - accuracy: 0.1763 - val_loss: 2.2331 - val_accuracy: 0.1869\n",
      "Epoch 194/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2745 - accuracy: 0.1696 - val_loss: 2.2320 - val_accuracy: 0.1869\n",
      "Epoch 195/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2696 - accuracy: 0.1700 - val_loss: 2.2311 - val_accuracy: 0.1869\n",
      "Epoch 196/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2689 - accuracy: 0.1727 - val_loss: 2.2301 - val_accuracy: 0.1869\n",
      "Epoch 197/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2616 - accuracy: 0.1767 - val_loss: 2.2292 - val_accuracy: 0.1869\n",
      "Epoch 198/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2651 - accuracy: 0.1841 - val_loss: 2.2283 - val_accuracy: 0.1869\n",
      "Epoch 199/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2592 - accuracy: 0.1892 - val_loss: 2.2273 - val_accuracy: 0.1869\n",
      "Epoch 200/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2654 - accuracy: 0.1731 - val_loss: 2.2264 - val_accuracy: 0.1869\n",
      "0.18691588938236237 {'loss': 2.2654006481170654, 'accuracy': 0.17312964797019958, 'val_loss': 2.2263681888580322, 'val_accuracy': 0.18691588938236237}\n",
      "Model: \"model_28\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_29 (InputLayer)        [(None, 29)]              0         \n",
      "_________________________________________________________________\n",
      "flatten_28 (Flatten)         (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 41)                1230      \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 10)                420       \n",
      "_________________________________________________________________\n",
      "dense_82 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,870\n",
      "Trainable params: 1,870\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 2.4064 - accuracy: 0.0403 - val_loss: 2.3767 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4019 - accuracy: 0.0423 - val_loss: 2.3752 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4008 - accuracy: 0.0419 - val_loss: 2.3738 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4002 - accuracy: 0.0501 - val_loss: 2.3723 - val_accuracy: 0.0093\n",
      "Epoch 5/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3974 - accuracy: 0.0486 - val_loss: 2.3707 - val_accuracy: 0.0187\n",
      "Epoch 6/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3922 - accuracy: 0.0533 - val_loss: 2.3692 - val_accuracy: 0.0187\n",
      "Epoch 7/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3916 - accuracy: 0.0486 - val_loss: 2.3678 - val_accuracy: 0.0187\n",
      "Epoch 8/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3853 - accuracy: 0.0552 - val_loss: 2.3663 - val_accuracy: 0.0093\n",
      "Epoch 9/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3871 - accuracy: 0.0544 - val_loss: 2.3648 - val_accuracy: 0.0093\n",
      "Epoch 10/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3922 - accuracy: 0.0501 - val_loss: 2.3634 - val_accuracy: 0.0093\n",
      "Epoch 11/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3908 - accuracy: 0.0494 - val_loss: 2.3620 - val_accuracy: 0.0093\n",
      "Epoch 12/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3751 - accuracy: 0.0646 - val_loss: 2.3605 - val_accuracy: 0.0093\n",
      "Epoch 13/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3850 - accuracy: 0.0568 - val_loss: 2.3591 - val_accuracy: 0.0093\n",
      "Epoch 14/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3781 - accuracy: 0.0588 - val_loss: 2.3577 - val_accuracy: 0.0187\n",
      "Epoch 15/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3844 - accuracy: 0.0517 - val_loss: 2.3564 - val_accuracy: 0.0187\n",
      "Epoch 16/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3826 - accuracy: 0.0490 - val_loss: 2.3550 - val_accuracy: 0.0280\n",
      "Epoch 17/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3707 - accuracy: 0.0611 - val_loss: 2.3536 - val_accuracy: 0.0280\n",
      "Epoch 18/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3680 - accuracy: 0.0572 - val_loss: 2.3523 - val_accuracy: 0.0374\n",
      "Epoch 19/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3661 - accuracy: 0.0642 - val_loss: 2.3510 - val_accuracy: 0.0374\n",
      "Epoch 20/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3742 - accuracy: 0.0666 - val_loss: 2.3497 - val_accuracy: 0.0374\n",
      "Epoch 21/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3752 - accuracy: 0.0646 - val_loss: 2.3485 - val_accuracy: 0.0374\n",
      "Epoch 22/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3690 - accuracy: 0.0662 - val_loss: 2.3472 - val_accuracy: 0.0374\n",
      "Epoch 23/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3657 - accuracy: 0.0623 - val_loss: 2.3458 - val_accuracy: 0.0374\n",
      "Epoch 24/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3676 - accuracy: 0.0631 - val_loss: 2.3445 - val_accuracy: 0.0280\n",
      "Epoch 25/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3613 - accuracy: 0.0729 - val_loss: 2.3432 - val_accuracy: 0.0280\n",
      "Epoch 26/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3642 - accuracy: 0.0642 - val_loss: 2.3420 - val_accuracy: 0.0280\n",
      "Epoch 27/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3631 - accuracy: 0.0748 - val_loss: 2.3407 - val_accuracy: 0.0374\n",
      "Epoch 28/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3603 - accuracy: 0.0799 - val_loss: 2.3394 - val_accuracy: 0.0374\n",
      "Epoch 29/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3601 - accuracy: 0.0689 - val_loss: 2.3382 - val_accuracy: 0.0374\n",
      "Epoch 30/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3613 - accuracy: 0.0674 - val_loss: 2.3371 - val_accuracy: 0.0374\n",
      "Epoch 31/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3572 - accuracy: 0.0674 - val_loss: 2.3359 - val_accuracy: 0.0374\n",
      "Epoch 32/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3533 - accuracy: 0.0772 - val_loss: 2.3347 - val_accuracy: 0.0374\n",
      "Epoch 33/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3519 - accuracy: 0.0858 - val_loss: 2.3336 - val_accuracy: 0.0374\n",
      "Epoch 34/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3577 - accuracy: 0.0748 - val_loss: 2.3324 - val_accuracy: 0.0374\n",
      "Epoch 35/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3465 - accuracy: 0.0846 - val_loss: 2.3311 - val_accuracy: 0.0374\n",
      "Epoch 36/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3533 - accuracy: 0.0807 - val_loss: 2.3299 - val_accuracy: 0.0374\n",
      "Epoch 37/200\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 2.3511 - accuracy: 0.0834 - val_loss: 2.3287 - val_accuracy: 0.0374\n",
      "Epoch 38/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 2.3448 - accuracy: 0.0807 - val_loss: 2.3275 - val_accuracy: 0.0374\n",
      "Epoch 39/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3446 - accuracy: 0.0885 - val_loss: 2.3262 - val_accuracy: 0.0374\n",
      "Epoch 40/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 2.3423 - accuracy: 0.0858 - val_loss: 2.3249 - val_accuracy: 0.0467\n",
      "Epoch 41/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3399 - accuracy: 0.0846 - val_loss: 2.3235 - val_accuracy: 0.0561\n",
      "Epoch 42/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3390 - accuracy: 0.0901 - val_loss: 2.3220 - val_accuracy: 0.0561\n",
      "Epoch 43/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3426 - accuracy: 0.0830 - val_loss: 2.3206 - val_accuracy: 0.0561\n",
      "Epoch 44/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3357 - accuracy: 0.0830 - val_loss: 2.3192 - val_accuracy: 0.0561\n",
      "Epoch 45/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3359 - accuracy: 0.0838 - val_loss: 2.3177 - val_accuracy: 0.0561\n",
      "Epoch 46/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3390 - accuracy: 0.0893 - val_loss: 2.3163 - val_accuracy: 0.0561\n",
      "Epoch 47/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3320 - accuracy: 0.0944 - val_loss: 2.3150 - val_accuracy: 0.0561\n",
      "Epoch 48/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3326 - accuracy: 0.0885 - val_loss: 2.3137 - val_accuracy: 0.0561\n",
      "Epoch 49/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 2.3357 - accuracy: 0.0858 - val_loss: 2.3124 - val_accuracy: 0.0561\n",
      "Epoch 50/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3317 - accuracy: 0.0917 - val_loss: 2.3112 - val_accuracy: 0.0561\n",
      "Epoch 51/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3318 - accuracy: 0.0901 - val_loss: 2.3098 - val_accuracy: 0.0467\n",
      "Epoch 52/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3248 - accuracy: 0.0987 - val_loss: 2.3085 - val_accuracy: 0.0561\n",
      "Epoch 53/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3237 - accuracy: 0.0960 - val_loss: 2.3073 - val_accuracy: 0.0561\n",
      "Epoch 54/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3254 - accuracy: 0.1026 - val_loss: 2.3061 - val_accuracy: 0.0561\n",
      "Epoch 55/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3221 - accuracy: 0.1042 - val_loss: 2.3050 - val_accuracy: 0.0561\n",
      "Epoch 56/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3226 - accuracy: 0.1050 - val_loss: 2.3037 - val_accuracy: 0.0561\n",
      "Epoch 57/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3152 - accuracy: 0.1128 - val_loss: 2.3024 - val_accuracy: 0.0561\n",
      "Epoch 58/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3196 - accuracy: 0.1081 - val_loss: 2.3012 - val_accuracy: 0.0561\n",
      "Epoch 59/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3186 - accuracy: 0.0964 - val_loss: 2.2998 - val_accuracy: 0.0841\n",
      "Epoch 60/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3198 - accuracy: 0.1046 - val_loss: 2.2987 - val_accuracy: 0.0748\n",
      "Epoch 61/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3177 - accuracy: 0.1030 - val_loss: 2.2974 - val_accuracy: 0.0748\n",
      "Epoch 62/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3113 - accuracy: 0.1124 - val_loss: 2.2961 - val_accuracy: 0.0748\n",
      "Epoch 63/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3118 - accuracy: 0.1163 - val_loss: 2.2948 - val_accuracy: 0.0748\n",
      "Epoch 64/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3215 - accuracy: 0.0987 - val_loss: 2.2937 - val_accuracy: 0.0748\n",
      "Epoch 65/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 2.3125 - accuracy: 0.1046 - val_loss: 2.2925 - val_accuracy: 0.0748\n",
      "Epoch 66/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3114 - accuracy: 0.1089 - val_loss: 2.2912 - val_accuracy: 0.0748\n",
      "Epoch 67/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3079 - accuracy: 0.1238 - val_loss: 2.2899 - val_accuracy: 0.0748\n",
      "Epoch 68/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3026 - accuracy: 0.1167 - val_loss: 2.2886 - val_accuracy: 0.0748\n",
      "Epoch 69/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3043 - accuracy: 0.1167 - val_loss: 2.2873 - val_accuracy: 0.0748\n",
      "Epoch 70/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 2.3100 - accuracy: 0.1144 - val_loss: 2.2860 - val_accuracy: 0.0748\n",
      "Epoch 71/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3060 - accuracy: 0.1144 - val_loss: 2.2847 - val_accuracy: 0.0748\n",
      "Epoch 72/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2936 - accuracy: 0.1144 - val_loss: 2.2834 - val_accuracy: 0.0748\n",
      "Epoch 73/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2979 - accuracy: 0.1230 - val_loss: 2.2821 - val_accuracy: 0.0841\n",
      "Epoch 74/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3034 - accuracy: 0.1167 - val_loss: 2.2809 - val_accuracy: 0.0841\n",
      "Epoch 75/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2965 - accuracy: 0.1269 - val_loss: 2.2796 - val_accuracy: 0.0841\n",
      "Epoch 76/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2979 - accuracy: 0.1308 - val_loss: 2.2783 - val_accuracy: 0.0935\n",
      "Epoch 77/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2923 - accuracy: 0.1234 - val_loss: 2.2771 - val_accuracy: 0.0935\n",
      "Epoch 78/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3032 - accuracy: 0.1191 - val_loss: 2.2760 - val_accuracy: 0.1028\n",
      "Epoch 79/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2948 - accuracy: 0.1250 - val_loss: 2.2748 - val_accuracy: 0.1215\n",
      "Epoch 80/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2899 - accuracy: 0.1293 - val_loss: 2.2737 - val_accuracy: 0.1215\n",
      "Epoch 81/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2981 - accuracy: 0.1218 - val_loss: 2.2725 - val_accuracy: 0.1215\n",
      "Epoch 82/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2941 - accuracy: 0.1250 - val_loss: 2.2713 - val_accuracy: 0.1215\n",
      "Epoch 83/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2932 - accuracy: 0.1293 - val_loss: 2.2701 - val_accuracy: 0.1215\n",
      "Epoch 84/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2902 - accuracy: 0.1289 - val_loss: 2.2690 - val_accuracy: 0.1215\n",
      "Epoch 85/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2846 - accuracy: 0.1410 - val_loss: 2.2677 - val_accuracy: 0.1215\n",
      "Epoch 86/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2869 - accuracy: 0.1312 - val_loss: 2.2666 - val_accuracy: 0.1215\n",
      "Epoch 87/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2873 - accuracy: 0.1363 - val_loss: 2.2654 - val_accuracy: 0.1215\n",
      "Epoch 88/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2895 - accuracy: 0.1398 - val_loss: 2.2642 - val_accuracy: 0.1215\n",
      "Epoch 89/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2873 - accuracy: 0.1340 - val_loss: 2.2631 - val_accuracy: 0.1215\n",
      "Epoch 90/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2889 - accuracy: 0.1414 - val_loss: 2.2619 - val_accuracy: 0.1308\n",
      "Epoch 91/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2731 - accuracy: 0.1512 - val_loss: 2.2606 - val_accuracy: 0.1308\n",
      "Epoch 92/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2786 - accuracy: 0.1441 - val_loss: 2.2595 - val_accuracy: 0.1308\n",
      "Epoch 93/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2800 - accuracy: 0.1461 - val_loss: 2.2584 - val_accuracy: 0.1308\n",
      "Epoch 94/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2703 - accuracy: 0.1391 - val_loss: 2.2571 - val_accuracy: 0.1308\n",
      "Epoch 95/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2683 - accuracy: 0.1512 - val_loss: 2.2559 - val_accuracy: 0.1308\n",
      "Epoch 96/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2636 - accuracy: 0.1579 - val_loss: 2.2546 - val_accuracy: 0.1402\n",
      "Epoch 97/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2715 - accuracy: 0.1391 - val_loss: 2.2535 - val_accuracy: 0.1402\n",
      "Epoch 98/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2727 - accuracy: 0.1547 - val_loss: 2.2524 - val_accuracy: 0.1402\n",
      "Epoch 99/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2662 - accuracy: 0.1645 - val_loss: 2.2510 - val_accuracy: 0.1402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2725 - accuracy: 0.1504 - val_loss: 2.2499 - val_accuracy: 0.1402\n",
      "Epoch 101/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2721 - accuracy: 0.1520 - val_loss: 2.2487 - val_accuracy: 0.1402\n",
      "Epoch 102/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2744 - accuracy: 0.1653 - val_loss: 2.2476 - val_accuracy: 0.1402\n",
      "Epoch 103/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2665 - accuracy: 0.1614 - val_loss: 2.2465 - val_accuracy: 0.1402\n",
      "Epoch 104/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2651 - accuracy: 0.1579 - val_loss: 2.2453 - val_accuracy: 0.1402\n",
      "Epoch 105/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2561 - accuracy: 0.1559 - val_loss: 2.2441 - val_accuracy: 0.1402\n",
      "Epoch 106/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2617 - accuracy: 0.1684 - val_loss: 2.2429 - val_accuracy: 0.1402\n",
      "Epoch 107/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2578 - accuracy: 0.1649 - val_loss: 2.2418 - val_accuracy: 0.1402\n",
      "Epoch 108/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2663 - accuracy: 0.1649 - val_loss: 2.2407 - val_accuracy: 0.1402\n",
      "Epoch 109/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2540 - accuracy: 0.1622 - val_loss: 2.2395 - val_accuracy: 0.1402\n",
      "Epoch 110/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2655 - accuracy: 0.1618 - val_loss: 2.2384 - val_accuracy: 0.1402\n",
      "Epoch 111/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2633 - accuracy: 0.1696 - val_loss: 2.2373 - val_accuracy: 0.1402\n",
      "Epoch 112/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2633 - accuracy: 0.1688 - val_loss: 2.2361 - val_accuracy: 0.1402\n",
      "Epoch 113/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2548 - accuracy: 0.1692 - val_loss: 2.2350 - val_accuracy: 0.1402\n",
      "Epoch 114/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2596 - accuracy: 0.1700 - val_loss: 2.2339 - val_accuracy: 0.1495\n",
      "Epoch 115/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2521 - accuracy: 0.1770 - val_loss: 2.2326 - val_accuracy: 0.1495\n",
      "Epoch 116/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2557 - accuracy: 0.1727 - val_loss: 2.2315 - val_accuracy: 0.1589\n",
      "Epoch 117/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2511 - accuracy: 0.1770 - val_loss: 2.2304 - val_accuracy: 0.1589\n",
      "Epoch 118/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2566 - accuracy: 0.1767 - val_loss: 2.2293 - val_accuracy: 0.1589\n",
      "Epoch 119/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2507 - accuracy: 0.1731 - val_loss: 2.2280 - val_accuracy: 0.1589\n",
      "Epoch 120/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2522 - accuracy: 0.1798 - val_loss: 2.2269 - val_accuracy: 0.1589\n",
      "Epoch 121/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2448 - accuracy: 0.1935 - val_loss: 2.2256 - val_accuracy: 0.1589\n",
      "Epoch 122/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2555 - accuracy: 0.1712 - val_loss: 2.2245 - val_accuracy: 0.1682\n",
      "Epoch 123/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2559 - accuracy: 0.1704 - val_loss: 2.2234 - val_accuracy: 0.1776\n",
      "Epoch 124/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2422 - accuracy: 0.1876 - val_loss: 2.2222 - val_accuracy: 0.1963\n",
      "Epoch 125/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2424 - accuracy: 0.1876 - val_loss: 2.2210 - val_accuracy: 0.1963\n",
      "Epoch 126/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2480 - accuracy: 0.1861 - val_loss: 2.2198 - val_accuracy: 0.1963\n",
      "Epoch 127/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2411 - accuracy: 0.1904 - val_loss: 2.2186 - val_accuracy: 0.1963\n",
      "Epoch 128/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2358 - accuracy: 0.2080 - val_loss: 2.2173 - val_accuracy: 0.1963\n",
      "Epoch 129/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2337 - accuracy: 0.2029 - val_loss: 2.2161 - val_accuracy: 0.1963\n",
      "Epoch 130/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2345 - accuracy: 0.2080 - val_loss: 2.2149 - val_accuracy: 0.1963\n",
      "Epoch 131/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2284 - accuracy: 0.1998 - val_loss: 2.2136 - val_accuracy: 0.2056\n",
      "Epoch 132/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2305 - accuracy: 0.2064 - val_loss: 2.2124 - val_accuracy: 0.2056\n",
      "Epoch 133/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2432 - accuracy: 0.1911 - val_loss: 2.2113 - val_accuracy: 0.2056\n",
      "Epoch 134/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2395 - accuracy: 0.1939 - val_loss: 2.2102 - val_accuracy: 0.2056\n",
      "Epoch 135/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2371 - accuracy: 0.1943 - val_loss: 2.2089 - val_accuracy: 0.2150\n",
      "Epoch 136/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2421 - accuracy: 0.1962 - val_loss: 2.2077 - val_accuracy: 0.2056\n",
      "Epoch 137/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2344 - accuracy: 0.1908 - val_loss: 2.2065 - val_accuracy: 0.2056\n",
      "Epoch 138/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2381 - accuracy: 0.2045 - val_loss: 2.2053 - val_accuracy: 0.2056\n",
      "Epoch 139/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2270 - accuracy: 0.2111 - val_loss: 2.2040 - val_accuracy: 0.2150\n",
      "Epoch 140/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2353 - accuracy: 0.2111 - val_loss: 2.2028 - val_accuracy: 0.2150\n",
      "Epoch 141/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2244 - accuracy: 0.2131 - val_loss: 2.2015 - val_accuracy: 0.2150\n",
      "Epoch 142/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2175 - accuracy: 0.2143 - val_loss: 2.2002 - val_accuracy: 0.2150\n",
      "Epoch 143/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2193 - accuracy: 0.2205 - val_loss: 2.1989 - val_accuracy: 0.2150\n",
      "Epoch 144/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2211 - accuracy: 0.2174 - val_loss: 2.1976 - val_accuracy: 0.2150\n",
      "Epoch 145/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2278 - accuracy: 0.2127 - val_loss: 2.1964 - val_accuracy: 0.2150\n",
      "Epoch 146/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2284 - accuracy: 0.2107 - val_loss: 2.1953 - val_accuracy: 0.2150\n",
      "Epoch 147/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2187 - accuracy: 0.2201 - val_loss: 2.1939 - val_accuracy: 0.2150\n",
      "Epoch 148/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2206 - accuracy: 0.2150 - val_loss: 2.1928 - val_accuracy: 0.2243\n",
      "Epoch 149/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2146 - accuracy: 0.2150 - val_loss: 2.1915 - val_accuracy: 0.2243\n",
      "Epoch 150/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2164 - accuracy: 0.2178 - val_loss: 2.1903 - val_accuracy: 0.2243\n",
      "Epoch 151/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2169 - accuracy: 0.2099 - val_loss: 2.1890 - val_accuracy: 0.2243\n",
      "Epoch 152/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2183 - accuracy: 0.2205 - val_loss: 2.1878 - val_accuracy: 0.2243\n",
      "Epoch 153/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2313 - accuracy: 0.2096 - val_loss: 2.1867 - val_accuracy: 0.2243\n",
      "Epoch 154/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2117 - accuracy: 0.2256 - val_loss: 2.1856 - val_accuracy: 0.2243\n",
      "Epoch 155/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2115 - accuracy: 0.2280 - val_loss: 2.1844 - val_accuracy: 0.2336\n",
      "Epoch 156/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2149 - accuracy: 0.2209 - val_loss: 2.1832 - val_accuracy: 0.2336\n",
      "Epoch 157/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2087 - accuracy: 0.2213 - val_loss: 2.1820 - val_accuracy: 0.2336\n",
      "Epoch 158/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2138 - accuracy: 0.2213 - val_loss: 2.1809 - val_accuracy: 0.2336\n",
      "Epoch 159/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2075 - accuracy: 0.2291 - val_loss: 2.1798 - val_accuracy: 0.2336\n",
      "Epoch 160/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2077 - accuracy: 0.2307 - val_loss: 2.1786 - val_accuracy: 0.2336\n",
      "Epoch 161/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2099 - accuracy: 0.2295 - val_loss: 2.1774 - val_accuracy: 0.2430\n",
      "Epoch 162/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2082 - accuracy: 0.2405 - val_loss: 2.1762 - val_accuracy: 0.2430\n",
      "Epoch 163/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2060 - accuracy: 0.2299 - val_loss: 2.1751 - val_accuracy: 0.2430\n",
      "Epoch 164/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1986 - accuracy: 0.2401 - val_loss: 2.1739 - val_accuracy: 0.2430\n",
      "Epoch 165/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2063 - accuracy: 0.2315 - val_loss: 2.1727 - val_accuracy: 0.2523\n",
      "Epoch 166/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2076 - accuracy: 0.2338 - val_loss: 2.1716 - val_accuracy: 0.2523\n",
      "Epoch 167/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2127 - accuracy: 0.2311 - val_loss: 2.1705 - val_accuracy: 0.2617\n",
      "Epoch 168/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2090 - accuracy: 0.2338 - val_loss: 2.1695 - val_accuracy: 0.2617\n",
      "Epoch 169/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2052 - accuracy: 0.2362 - val_loss: 2.1684 - val_accuracy: 0.2617\n",
      "Epoch 170/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1929 - accuracy: 0.2483 - val_loss: 2.1672 - val_accuracy: 0.2617\n",
      "Epoch 171/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1976 - accuracy: 0.2362 - val_loss: 2.1661 - val_accuracy: 0.2804\n",
      "Epoch 172/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2129 - accuracy: 0.2331 - val_loss: 2.1651 - val_accuracy: 0.2804\n",
      "Epoch 173/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1918 - accuracy: 0.2421 - val_loss: 2.1639 - val_accuracy: 0.2804\n",
      "Epoch 174/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1935 - accuracy: 0.2491 - val_loss: 2.1627 - val_accuracy: 0.2804\n",
      "Epoch 175/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1979 - accuracy: 0.2370 - val_loss: 2.1617 - val_accuracy: 0.2804\n",
      "Epoch 176/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1918 - accuracy: 0.2378 - val_loss: 2.1606 - val_accuracy: 0.2804\n",
      "Epoch 177/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2078 - accuracy: 0.2346 - val_loss: 2.1595 - val_accuracy: 0.2804\n",
      "Epoch 178/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1957 - accuracy: 0.2487 - val_loss: 2.1584 - val_accuracy: 0.2897\n",
      "Epoch 179/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1902 - accuracy: 0.2511 - val_loss: 2.1572 - val_accuracy: 0.2897\n",
      "Epoch 180/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 2.1873 - accuracy: 0.2432 - val_loss: 2.1560 - val_accuracy: 0.2991\n",
      "Epoch 181/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1831 - accuracy: 0.2628 - val_loss: 2.1548 - val_accuracy: 0.2991\n",
      "Epoch 182/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1948 - accuracy: 0.2378 - val_loss: 2.1537 - val_accuracy: 0.2991\n",
      "Epoch 183/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1866 - accuracy: 0.2456 - val_loss: 2.1525 - val_accuracy: 0.3084\n",
      "Epoch 184/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1907 - accuracy: 0.2472 - val_loss: 2.1514 - val_accuracy: 0.3084\n",
      "Epoch 185/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2165 - accuracy: 0.2276 - val_loss: 2.1504 - val_accuracy: 0.3084\n",
      "Epoch 186/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1829 - accuracy: 0.2499 - val_loss: 2.1492 - val_accuracy: 0.3084\n",
      "Epoch 187/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1892 - accuracy: 0.2523 - val_loss: 2.1481 - val_accuracy: 0.3084\n",
      "Epoch 188/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2038 - accuracy: 0.2295 - val_loss: 2.1471 - val_accuracy: 0.3084\n",
      "Epoch 189/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1883 - accuracy: 0.2389 - val_loss: 2.1460 - val_accuracy: 0.3084\n",
      "Epoch 190/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1750 - accuracy: 0.2624 - val_loss: 2.1448 - val_accuracy: 0.3084\n",
      "Epoch 191/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1757 - accuracy: 0.2558 - val_loss: 2.1437 - val_accuracy: 0.3084\n",
      "Epoch 192/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1746 - accuracy: 0.2523 - val_loss: 2.1425 - val_accuracy: 0.3084\n",
      "Epoch 193/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1873 - accuracy: 0.2573 - val_loss: 2.1414 - val_accuracy: 0.3271\n",
      "Epoch 194/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1677 - accuracy: 0.2652 - val_loss: 2.1401 - val_accuracy: 0.3271\n",
      "Epoch 195/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1710 - accuracy: 0.2534 - val_loss: 2.1389 - val_accuracy: 0.3271\n",
      "Epoch 196/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1799 - accuracy: 0.2542 - val_loss: 2.1377 - val_accuracy: 0.3364\n",
      "Epoch 197/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1734 - accuracy: 0.2617 - val_loss: 2.1365 - val_accuracy: 0.3364\n",
      "Epoch 198/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1913 - accuracy: 0.2425 - val_loss: 2.1355 - val_accuracy: 0.3364\n",
      "Epoch 199/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1825 - accuracy: 0.2577 - val_loss: 2.1344 - val_accuracy: 0.3271\n",
      "Epoch 200/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.1735 - accuracy: 0.2550 - val_loss: 2.1332 - val_accuracy: 0.3271\n",
      "0.32710281014442444 {'loss': 2.173461437225342, 'accuracy': 0.25499412417411804, 'val_loss': 2.133169651031494, 'val_accuracy': 0.32710281014442444}\n",
      "Model: \"model_29\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_30 (InputLayer)        [(None, 29)]              0         \n",
      "_________________________________________________________________\n",
      "flatten_29 (Flatten)         (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_84 (Dense)             (None, 41)                1230      \n",
      "_________________________________________________________________\n",
      "dense_85 (Dense)             (None, 10)                420       \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,870\n",
      "Trainable params: 1,870\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.8363 - accuracy: 0.0478 - val_loss: 2.6030 - val_accuracy: 0.0093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.8373 - accuracy: 0.0450 - val_loss: 2.5997 - val_accuracy: 0.0093\n",
      "Epoch 3/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.8351 - accuracy: 0.0525 - val_loss: 2.5964 - val_accuracy: 0.0093\n",
      "Epoch 4/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.8358 - accuracy: 0.0478 - val_loss: 2.5932 - val_accuracy: 0.0093\n",
      "Epoch 5/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.8401 - accuracy: 0.0415 - val_loss: 2.5900 - val_accuracy: 0.0093\n",
      "Epoch 6/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.8391 - accuracy: 0.0431 - val_loss: 2.5868 - val_accuracy: 0.0093\n",
      "Epoch 7/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.8069 - accuracy: 0.0470 - val_loss: 2.5837 - val_accuracy: 0.0093\n",
      "Epoch 8/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.8170 - accuracy: 0.0513 - val_loss: 2.5806 - val_accuracy: 0.0093\n",
      "Epoch 9/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.8253 - accuracy: 0.0400 - val_loss: 2.5775 - val_accuracy: 0.0093\n",
      "Epoch 10/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.7938 - accuracy: 0.0494 - val_loss: 2.5742 - val_accuracy: 0.0093\n",
      "Epoch 11/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.7707 - accuracy: 0.0505 - val_loss: 2.5711 - val_accuracy: 0.0093\n",
      "Epoch 12/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.7854 - accuracy: 0.0462 - val_loss: 2.5680 - val_accuracy: 0.0093\n",
      "Epoch 13/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.7784 - accuracy: 0.0490 - val_loss: 2.5648 - val_accuracy: 0.0093\n",
      "Epoch 14/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.7783 - accuracy: 0.0529 - val_loss: 2.5617 - val_accuracy: 0.0093\n",
      "Epoch 15/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.7709 - accuracy: 0.0521 - val_loss: 2.5586 - val_accuracy: 0.0093\n",
      "Epoch 16/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.7674 - accuracy: 0.0466 - val_loss: 2.5556 - val_accuracy: 0.0093\n",
      "Epoch 17/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.7501 - accuracy: 0.0580 - val_loss: 2.5527 - val_accuracy: 0.0093\n",
      "Epoch 18/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.7660 - accuracy: 0.0486 - val_loss: 2.5498 - val_accuracy: 0.0093\n",
      "Epoch 19/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.7622 - accuracy: 0.0525 - val_loss: 2.5469 - val_accuracy: 0.0093\n",
      "Epoch 20/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.7608 - accuracy: 0.0560 - val_loss: 2.5441 - val_accuracy: 0.0093\n",
      "Epoch 21/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.7567 - accuracy: 0.0427 - val_loss: 2.5413 - val_accuracy: 0.0093\n",
      "Epoch 22/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.7226 - accuracy: 0.0584 - val_loss: 2.5385 - val_accuracy: 0.0093\n",
      "Epoch 23/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.7354 - accuracy: 0.0505 - val_loss: 2.5356 - val_accuracy: 0.0093\n",
      "Epoch 24/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.7292 - accuracy: 0.0544 - val_loss: 2.5328 - val_accuracy: 0.0093\n",
      "Epoch 25/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.7272 - accuracy: 0.0548 - val_loss: 2.5299 - val_accuracy: 0.0187\n",
      "Epoch 26/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.7161 - accuracy: 0.0576 - val_loss: 2.5270 - val_accuracy: 0.0187\n",
      "Epoch 27/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.7085 - accuracy: 0.0572 - val_loss: 2.5243 - val_accuracy: 0.0280\n",
      "Epoch 28/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.7108 - accuracy: 0.0560 - val_loss: 2.5216 - val_accuracy: 0.0280\n",
      "Epoch 29/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.7020 - accuracy: 0.0615 - val_loss: 2.5188 - val_accuracy: 0.0280\n",
      "Epoch 30/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.7055 - accuracy: 0.0560 - val_loss: 2.5161 - val_accuracy: 0.0280\n",
      "Epoch 31/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.6979 - accuracy: 0.0619 - val_loss: 2.5134 - val_accuracy: 0.0280\n",
      "Epoch 32/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.6732 - accuracy: 0.0619 - val_loss: 2.5107 - val_accuracy: 0.0280\n",
      "Epoch 33/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.6699 - accuracy: 0.0689 - val_loss: 2.5079 - val_accuracy: 0.0280\n",
      "Epoch 34/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.6542 - accuracy: 0.0666 - val_loss: 2.5053 - val_accuracy: 0.0280\n",
      "Epoch 35/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.6681 - accuracy: 0.0654 - val_loss: 2.5027 - val_accuracy: 0.0280\n",
      "Epoch 36/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.6706 - accuracy: 0.0732 - val_loss: 2.5000 - val_accuracy: 0.0280\n",
      "Epoch 37/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.6609 - accuracy: 0.0662 - val_loss: 2.4975 - val_accuracy: 0.0280\n",
      "Epoch 38/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.6971 - accuracy: 0.0560 - val_loss: 2.4949 - val_accuracy: 0.0280\n",
      "Epoch 39/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.6452 - accuracy: 0.0666 - val_loss: 2.4924 - val_accuracy: 0.0280\n",
      "Epoch 40/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.6606 - accuracy: 0.0635 - val_loss: 2.4899 - val_accuracy: 0.0280\n",
      "Epoch 41/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.6458 - accuracy: 0.0662 - val_loss: 2.4874 - val_accuracy: 0.0280\n",
      "Epoch 42/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.6378 - accuracy: 0.0619 - val_loss: 2.4849 - val_accuracy: 0.0280\n",
      "Epoch 43/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.6359 - accuracy: 0.0725 - val_loss: 2.4824 - val_accuracy: 0.0374\n",
      "Epoch 44/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.6272 - accuracy: 0.0678 - val_loss: 2.4800 - val_accuracy: 0.0374\n",
      "Epoch 45/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.6179 - accuracy: 0.0736 - val_loss: 2.4776 - val_accuracy: 0.0374\n",
      "Epoch 46/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.6247 - accuracy: 0.0697 - val_loss: 2.4752 - val_accuracy: 0.0374\n",
      "Epoch 47/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.6238 - accuracy: 0.0697 - val_loss: 2.4728 - val_accuracy: 0.0374\n",
      "Epoch 48/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.6243 - accuracy: 0.0642 - val_loss: 2.4706 - val_accuracy: 0.0374\n",
      "Epoch 49/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.6005 - accuracy: 0.0819 - val_loss: 2.4683 - val_accuracy: 0.0374\n",
      "Epoch 50/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.6049 - accuracy: 0.0658 - val_loss: 2.4660 - val_accuracy: 0.0374\n",
      "Epoch 51/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.6015 - accuracy: 0.0772 - val_loss: 2.4636 - val_accuracy: 0.0374\n",
      "Epoch 52/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.6116 - accuracy: 0.0685 - val_loss: 2.4613 - val_accuracy: 0.0374\n",
      "Epoch 53/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5881 - accuracy: 0.0764 - val_loss: 2.4590 - val_accuracy: 0.0374\n",
      "Epoch 54/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5998 - accuracy: 0.0744 - val_loss: 2.4568 - val_accuracy: 0.0374\n",
      "Epoch 55/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.6091 - accuracy: 0.0650 - val_loss: 2.4546 - val_accuracy: 0.0374\n",
      "Epoch 56/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5914 - accuracy: 0.0717 - val_loss: 2.4524 - val_accuracy: 0.0374\n",
      "Epoch 57/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5929 - accuracy: 0.0752 - val_loss: 2.4502 - val_accuracy: 0.0374\n",
      "Epoch 58/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5681 - accuracy: 0.0768 - val_loss: 2.4481 - val_accuracy: 0.0374\n",
      "Epoch 59/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.5872 - accuracy: 0.0705 - val_loss: 2.4459 - val_accuracy: 0.0467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5785 - accuracy: 0.0807 - val_loss: 2.4437 - val_accuracy: 0.0467\n",
      "Epoch 61/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5585 - accuracy: 0.0889 - val_loss: 2.4415 - val_accuracy: 0.0467\n",
      "Epoch 62/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5652 - accuracy: 0.0768 - val_loss: 2.4393 - val_accuracy: 0.0467\n",
      "Epoch 63/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5645 - accuracy: 0.0776 - val_loss: 2.4371 - val_accuracy: 0.0467\n",
      "Epoch 64/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5630 - accuracy: 0.0819 - val_loss: 2.4350 - val_accuracy: 0.0467\n",
      "Epoch 65/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5472 - accuracy: 0.0866 - val_loss: 2.4329 - val_accuracy: 0.0467\n",
      "Epoch 66/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5561 - accuracy: 0.0779 - val_loss: 2.4309 - val_accuracy: 0.0467\n",
      "Epoch 67/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5397 - accuracy: 0.0897 - val_loss: 2.4287 - val_accuracy: 0.0467\n",
      "Epoch 68/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5529 - accuracy: 0.0850 - val_loss: 2.4267 - val_accuracy: 0.0467\n",
      "Epoch 69/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5447 - accuracy: 0.0877 - val_loss: 2.4246 - val_accuracy: 0.0467\n",
      "Epoch 70/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5732 - accuracy: 0.0795 - val_loss: 2.4226 - val_accuracy: 0.0467\n",
      "Epoch 71/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5409 - accuracy: 0.0885 - val_loss: 2.4207 - val_accuracy: 0.0467\n",
      "Epoch 72/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5557 - accuracy: 0.0772 - val_loss: 2.4187 - val_accuracy: 0.0467\n",
      "Epoch 73/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5380 - accuracy: 0.0823 - val_loss: 2.4167 - val_accuracy: 0.0467\n",
      "Epoch 74/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5292 - accuracy: 0.0975 - val_loss: 2.4148 - val_accuracy: 0.0467\n",
      "Epoch 75/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5414 - accuracy: 0.0862 - val_loss: 2.4129 - val_accuracy: 0.0467\n",
      "Epoch 76/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5316 - accuracy: 0.0873 - val_loss: 2.4110 - val_accuracy: 0.0654\n",
      "Epoch 77/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5058 - accuracy: 0.0936 - val_loss: 2.4089 - val_accuracy: 0.0654\n",
      "Epoch 78/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5227 - accuracy: 0.0917 - val_loss: 2.4071 - val_accuracy: 0.0654\n",
      "Epoch 79/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5061 - accuracy: 0.0991 - val_loss: 2.4052 - val_accuracy: 0.0654\n",
      "Epoch 80/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5100 - accuracy: 0.0893 - val_loss: 2.4032 - val_accuracy: 0.0654\n",
      "Epoch 81/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5207 - accuracy: 0.0885 - val_loss: 2.4013 - val_accuracy: 0.0654\n",
      "Epoch 82/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5109 - accuracy: 0.0885 - val_loss: 2.3995 - val_accuracy: 0.0654\n",
      "Epoch 83/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5148 - accuracy: 0.0920 - val_loss: 2.3976 - val_accuracy: 0.0654\n",
      "Epoch 84/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5149 - accuracy: 0.0889 - val_loss: 2.3958 - val_accuracy: 0.0654\n",
      "Epoch 85/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5050 - accuracy: 0.0873 - val_loss: 2.3940 - val_accuracy: 0.0654\n",
      "Epoch 86/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5000 - accuracy: 0.0897 - val_loss: 2.3921 - val_accuracy: 0.0748\n",
      "Epoch 87/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4867 - accuracy: 0.0967 - val_loss: 2.3902 - val_accuracy: 0.0748\n",
      "Epoch 88/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4935 - accuracy: 0.1003 - val_loss: 2.3884 - val_accuracy: 0.0748\n",
      "Epoch 89/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4968 - accuracy: 0.0909 - val_loss: 2.3866 - val_accuracy: 0.0748\n",
      "Epoch 90/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4918 - accuracy: 0.0909 - val_loss: 2.3848 - val_accuracy: 0.0748\n",
      "Epoch 91/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4799 - accuracy: 0.0967 - val_loss: 2.3830 - val_accuracy: 0.0748\n",
      "Epoch 92/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4817 - accuracy: 0.0975 - val_loss: 2.3811 - val_accuracy: 0.0748\n",
      "Epoch 93/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4761 - accuracy: 0.0964 - val_loss: 2.3793 - val_accuracy: 0.0748\n",
      "Epoch 94/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4724 - accuracy: 0.1042 - val_loss: 2.3775 - val_accuracy: 0.0748\n",
      "Epoch 95/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4753 - accuracy: 0.0936 - val_loss: 2.3758 - val_accuracy: 0.0748\n",
      "Epoch 96/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4883 - accuracy: 0.0956 - val_loss: 2.3742 - val_accuracy: 0.0748\n",
      "Epoch 97/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.4581 - accuracy: 0.1089 - val_loss: 2.3724 - val_accuracy: 0.0748\n",
      "Epoch 98/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4443 - accuracy: 0.1120 - val_loss: 2.3707 - val_accuracy: 0.0748\n",
      "Epoch 99/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4632 - accuracy: 0.1003 - val_loss: 2.3690 - val_accuracy: 0.0748\n",
      "Epoch 100/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4569 - accuracy: 0.1089 - val_loss: 2.3674 - val_accuracy: 0.0748\n",
      "Epoch 101/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4423 - accuracy: 0.1167 - val_loss: 2.3657 - val_accuracy: 0.0748\n",
      "Epoch 102/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4594 - accuracy: 0.1061 - val_loss: 2.3642 - val_accuracy: 0.0748\n",
      "Epoch 103/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4752 - accuracy: 0.0956 - val_loss: 2.3626 - val_accuracy: 0.0748\n",
      "Epoch 104/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.4610 - accuracy: 0.1022 - val_loss: 2.3611 - val_accuracy: 0.0748\n",
      "Epoch 105/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4398 - accuracy: 0.1159 - val_loss: 2.3595 - val_accuracy: 0.0748\n",
      "Epoch 106/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4591 - accuracy: 0.1011 - val_loss: 2.3580 - val_accuracy: 0.0748\n",
      "Epoch 107/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4484 - accuracy: 0.1073 - val_loss: 2.3565 - val_accuracy: 0.0748\n",
      "Epoch 108/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.4614 - accuracy: 0.0983 - val_loss: 2.3551 - val_accuracy: 0.0748\n",
      "Epoch 109/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.4509 - accuracy: 0.0999 - val_loss: 2.3536 - val_accuracy: 0.0748\n",
      "Epoch 110/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4488 - accuracy: 0.1077 - val_loss: 2.3521 - val_accuracy: 0.0748\n",
      "Epoch 111/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4362 - accuracy: 0.1140 - val_loss: 2.3506 - val_accuracy: 0.0748\n",
      "Epoch 112/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4429 - accuracy: 0.1112 - val_loss: 2.3491 - val_accuracy: 0.0748\n",
      "Epoch 113/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4368 - accuracy: 0.1112 - val_loss: 2.3477 - val_accuracy: 0.0748\n",
      "Epoch 114/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.4336 - accuracy: 0.0995 - val_loss: 2.3463 - val_accuracy: 0.0748\n",
      "Epoch 115/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4399 - accuracy: 0.1054 - val_loss: 2.3448 - val_accuracy: 0.0841\n",
      "Epoch 116/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4399 - accuracy: 0.1054 - val_loss: 2.3433 - val_accuracy: 0.0841\n",
      "Epoch 117/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4281 - accuracy: 0.1128 - val_loss: 2.3420 - val_accuracy: 0.0841\n",
      "Epoch 118/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4274 - accuracy: 0.1097 - val_loss: 2.3406 - val_accuracy: 0.0841\n",
      "Epoch 119/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.4294 - accuracy: 0.1136 - val_loss: 2.3392 - val_accuracy: 0.0841\n",
      "Epoch 120/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.4210 - accuracy: 0.1061 - val_loss: 2.3377 - val_accuracy: 0.0841\n",
      "Epoch 121/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3986 - accuracy: 0.1269 - val_loss: 2.3362 - val_accuracy: 0.0841\n",
      "Epoch 122/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4033 - accuracy: 0.1261 - val_loss: 2.3347 - val_accuracy: 0.0841\n",
      "Epoch 123/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4061 - accuracy: 0.1285 - val_loss: 2.3333 - val_accuracy: 0.0841\n",
      "Epoch 124/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4068 - accuracy: 0.1214 - val_loss: 2.3319 - val_accuracy: 0.0841\n",
      "Epoch 125/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4022 - accuracy: 0.1148 - val_loss: 2.3304 - val_accuracy: 0.0841\n",
      "Epoch 126/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.4161 - accuracy: 0.1226 - val_loss: 2.3292 - val_accuracy: 0.0841\n",
      "Epoch 127/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4307 - accuracy: 0.1050 - val_loss: 2.3279 - val_accuracy: 0.0841\n",
      "Epoch 128/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4118 - accuracy: 0.1156 - val_loss: 2.3266 - val_accuracy: 0.0841\n",
      "Epoch 129/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.3986 - accuracy: 0.1253 - val_loss: 2.3253 - val_accuracy: 0.0841\n",
      "Epoch 130/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4050 - accuracy: 0.1187 - val_loss: 2.3241 - val_accuracy: 0.0841\n",
      "Epoch 131/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.4033 - accuracy: 0.1203 - val_loss: 2.3228 - val_accuracy: 0.0841\n",
      "Epoch 132/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4086 - accuracy: 0.1152 - val_loss: 2.3215 - val_accuracy: 0.0935\n",
      "Epoch 133/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3957 - accuracy: 0.1226 - val_loss: 2.3202 - val_accuracy: 0.0935\n",
      "Epoch 134/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3937 - accuracy: 0.1222 - val_loss: 2.3188 - val_accuracy: 0.1028\n",
      "Epoch 135/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3861 - accuracy: 0.1312 - val_loss: 2.3175 - val_accuracy: 0.1028\n",
      "Epoch 136/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3923 - accuracy: 0.1312 - val_loss: 2.3163 - val_accuracy: 0.1028\n",
      "Epoch 137/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3731 - accuracy: 0.1297 - val_loss: 2.3149 - val_accuracy: 0.1028\n",
      "Epoch 138/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4028 - accuracy: 0.1152 - val_loss: 2.3136 - val_accuracy: 0.1121\n",
      "Epoch 139/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3860 - accuracy: 0.1257 - val_loss: 2.3123 - val_accuracy: 0.1121\n",
      "Epoch 140/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3735 - accuracy: 0.1347 - val_loss: 2.3111 - val_accuracy: 0.1121\n",
      "Epoch 141/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3716 - accuracy: 0.1324 - val_loss: 2.3097 - val_accuracy: 0.1215\n",
      "Epoch 142/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3951 - accuracy: 0.1226 - val_loss: 2.3085 - val_accuracy: 0.1308\n",
      "Epoch 143/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.3826 - accuracy: 0.1297 - val_loss: 2.3073 - val_accuracy: 0.1308\n",
      "Epoch 144/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3880 - accuracy: 0.1253 - val_loss: 2.3061 - val_accuracy: 0.1308\n",
      "Epoch 145/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.3772 - accuracy: 0.1336 - val_loss: 2.3049 - val_accuracy: 0.1308\n",
      "Epoch 146/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3757 - accuracy: 0.1312 - val_loss: 2.3036 - val_accuracy: 0.1308\n",
      "Epoch 147/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3901 - accuracy: 0.1312 - val_loss: 2.3024 - val_accuracy: 0.1402\n",
      "Epoch 148/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3706 - accuracy: 0.1367 - val_loss: 2.3012 - val_accuracy: 0.1308\n",
      "Epoch 149/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3721 - accuracy: 0.1320 - val_loss: 2.3001 - val_accuracy: 0.1308\n",
      "Epoch 150/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.3626 - accuracy: 0.1347 - val_loss: 2.2989 - val_accuracy: 0.1308\n",
      "Epoch 151/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3479 - accuracy: 0.1406 - val_loss: 2.2976 - val_accuracy: 0.1308\n",
      "Epoch 152/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3810 - accuracy: 0.1324 - val_loss: 2.2965 - val_accuracy: 0.1308\n",
      "Epoch 153/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.3681 - accuracy: 0.1355 - val_loss: 2.2953 - val_accuracy: 0.1308\n",
      "Epoch 154/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.3641 - accuracy: 0.1355 - val_loss: 2.2941 - val_accuracy: 0.1308\n",
      "Epoch 155/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.3674 - accuracy: 0.1387 - val_loss: 2.2930 - val_accuracy: 0.1215\n",
      "Epoch 156/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.3508 - accuracy: 0.1457 - val_loss: 2.2917 - val_accuracy: 0.1215\n",
      "Epoch 157/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3644 - accuracy: 0.1328 - val_loss: 2.2906 - val_accuracy: 0.1215\n",
      "Epoch 158/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3560 - accuracy: 0.1387 - val_loss: 2.2895 - val_accuracy: 0.1215\n",
      "Epoch 159/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3710 - accuracy: 0.1332 - val_loss: 2.2884 - val_accuracy: 0.1215\n",
      "Epoch 160/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3599 - accuracy: 0.1340 - val_loss: 2.2872 - val_accuracy: 0.1215\n",
      "Epoch 161/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.3659 - accuracy: 0.1359 - val_loss: 2.2861 - val_accuracy: 0.1215\n",
      "Epoch 162/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3420 - accuracy: 0.1488 - val_loss: 2.2848 - val_accuracy: 0.1215\n",
      "Epoch 163/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3615 - accuracy: 0.1394 - val_loss: 2.2836 - val_accuracy: 0.1215\n",
      "Epoch 164/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.3552 - accuracy: 0.1461 - val_loss: 2.2823 - val_accuracy: 0.1215\n",
      "Epoch 165/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3480 - accuracy: 0.1406 - val_loss: 2.2812 - val_accuracy: 0.1215\n",
      "Epoch 166/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3408 - accuracy: 0.1449 - val_loss: 2.2800 - val_accuracy: 0.1215\n",
      "Epoch 167/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3334 - accuracy: 0.1465 - val_loss: 2.2788 - val_accuracy: 0.1215\n",
      "Epoch 168/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3450 - accuracy: 0.1496 - val_loss: 2.2776 - val_accuracy: 0.1215\n",
      "Epoch 169/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3354 - accuracy: 0.1547 - val_loss: 2.2764 - val_accuracy: 0.1215\n",
      "Epoch 170/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3390 - accuracy: 0.1508 - val_loss: 2.2751 - val_accuracy: 0.1215\n",
      "Epoch 171/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3372 - accuracy: 0.1555 - val_loss: 2.2738 - val_accuracy: 0.1308\n",
      "Epoch 172/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.3342 - accuracy: 0.1496 - val_loss: 2.2727 - val_accuracy: 0.1308\n",
      "Epoch 173/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3306 - accuracy: 0.1528 - val_loss: 2.2715 - val_accuracy: 0.1308\n",
      "Epoch 174/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3357 - accuracy: 0.1622 - val_loss: 2.2703 - val_accuracy: 0.1308\n",
      "Epoch 175/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.3275 - accuracy: 0.1481 - val_loss: 2.2692 - val_accuracy: 0.1308\n",
      "Epoch 176/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3180 - accuracy: 0.1559 - val_loss: 2.2680 - val_accuracy: 0.1308\n",
      "Epoch 177/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3355 - accuracy: 0.1571 - val_loss: 2.2669 - val_accuracy: 0.1308\n",
      "Epoch 178/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3256 - accuracy: 0.1563 - val_loss: 2.2657 - val_accuracy: 0.1402\n",
      "Epoch 179/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3343 - accuracy: 0.1571 - val_loss: 2.2646 - val_accuracy: 0.1402\n",
      "Epoch 180/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3254 - accuracy: 0.1637 - val_loss: 2.2635 - val_accuracy: 0.1402\n",
      "Epoch 181/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3175 - accuracy: 0.1637 - val_loss: 2.2624 - val_accuracy: 0.1402\n",
      "Epoch 182/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3235 - accuracy: 0.1579 - val_loss: 2.2612 - val_accuracy: 0.1402\n",
      "Epoch 183/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3166 - accuracy: 0.1653 - val_loss: 2.2602 - val_accuracy: 0.1402\n",
      "Epoch 184/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3230 - accuracy: 0.1606 - val_loss: 2.2591 - val_accuracy: 0.1589\n",
      "Epoch 185/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3295 - accuracy: 0.1508 - val_loss: 2.2580 - val_accuracy: 0.1589\n",
      "Epoch 186/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3344 - accuracy: 0.1532 - val_loss: 2.2570 - val_accuracy: 0.1589\n",
      "Epoch 187/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3200 - accuracy: 0.1602 - val_loss: 2.2558 - val_accuracy: 0.1589\n",
      "Epoch 188/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3213 - accuracy: 0.1575 - val_loss: 2.2547 - val_accuracy: 0.1589\n",
      "Epoch 189/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3008 - accuracy: 0.1653 - val_loss: 2.2537 - val_accuracy: 0.1589\n",
      "Epoch 190/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3130 - accuracy: 0.1684 - val_loss: 2.2525 - val_accuracy: 0.1776\n",
      "Epoch 191/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2977 - accuracy: 0.1704 - val_loss: 2.2514 - val_accuracy: 0.1776\n",
      "Epoch 192/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3087 - accuracy: 0.1637 - val_loss: 2.2502 - val_accuracy: 0.1776\n",
      "Epoch 193/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3041 - accuracy: 0.1712 - val_loss: 2.2490 - val_accuracy: 0.1776\n",
      "Epoch 194/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.2949 - accuracy: 0.1716 - val_loss: 2.2479 - val_accuracy: 0.1776\n",
      "Epoch 195/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3112 - accuracy: 0.1626 - val_loss: 2.2467 - val_accuracy: 0.1776\n",
      "Epoch 196/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3048 - accuracy: 0.1751 - val_loss: 2.2456 - val_accuracy: 0.1776\n",
      "Epoch 197/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2980 - accuracy: 0.1669 - val_loss: 2.2445 - val_accuracy: 0.1776\n",
      "Epoch 198/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2886 - accuracy: 0.1786 - val_loss: 2.2434 - val_accuracy: 0.1776\n",
      "Epoch 199/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2857 - accuracy: 0.1868 - val_loss: 2.2422 - val_accuracy: 0.1776\n",
      "Epoch 200/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.2874 - accuracy: 0.1755 - val_loss: 2.2410 - val_accuracy: 0.1776\n",
      "0.17757008969783783 {'loss': 2.2874386310577393, 'accuracy': 0.17547982931137085, 'val_loss': 2.240968942642212, 'val_accuracy': 0.17757008969783783}\n",
      "Model: \"model_30\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_31 (InputLayer)        [(None, 29)]              0         \n",
      "_________________________________________________________________\n",
      "flatten_30 (Flatten)         (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_88 (Dense)             (None, 41)                1230      \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 10)                420       \n",
      "_________________________________________________________________\n",
      "dense_90 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_91 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,870\n",
      "Trainable params: 1,870\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 2.9076 - accuracy: 0.1061 - val_loss: 2.5371 - val_accuracy: 0.0374\n",
      "Epoch 2/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.9170 - accuracy: 0.1042 - val_loss: 2.5329 - val_accuracy: 0.0374\n",
      "Epoch 3/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.9002 - accuracy: 0.1140 - val_loss: 2.5289 - val_accuracy: 0.0374\n",
      "Epoch 4/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.8372 - accuracy: 0.1018 - val_loss: 2.5252 - val_accuracy: 0.0374\n",
      "Epoch 5/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.8734 - accuracy: 0.1046 - val_loss: 2.5212 - val_accuracy: 0.0374\n",
      "Epoch 6/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.8639 - accuracy: 0.1007 - val_loss: 2.5173 - val_accuracy: 0.0374\n",
      "Epoch 7/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.8305 - accuracy: 0.1081 - val_loss: 2.5138 - val_accuracy: 0.0374\n",
      "Epoch 8/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.8560 - accuracy: 0.0948 - val_loss: 2.5101 - val_accuracy: 0.0467\n",
      "Epoch 9/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.8160 - accuracy: 0.1128 - val_loss: 2.5066 - val_accuracy: 0.0467\n",
      "Epoch 10/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.8136 - accuracy: 0.1011 - val_loss: 2.5032 - val_accuracy: 0.0561\n",
      "Epoch 11/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.7966 - accuracy: 0.1018 - val_loss: 2.4998 - val_accuracy: 0.0654\n",
      "Epoch 12/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.7753 - accuracy: 0.1152 - val_loss: 2.4967 - val_accuracy: 0.0654\n",
      "Epoch 13/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.7896 - accuracy: 0.1054 - val_loss: 2.4934 - val_accuracy: 0.0654\n",
      "Epoch 14/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.7918 - accuracy: 0.1022 - val_loss: 2.4902 - val_accuracy: 0.0654\n",
      "Epoch 15/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.7756 - accuracy: 0.1050 - val_loss: 2.4871 - val_accuracy: 0.0654\n",
      "Epoch 16/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.7497 - accuracy: 0.1069 - val_loss: 2.4841 - val_accuracy: 0.0654\n",
      "Epoch 17/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.7640 - accuracy: 0.1065 - val_loss: 2.4811 - val_accuracy: 0.0654\n",
      "Epoch 18/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.7334 - accuracy: 0.1108 - val_loss: 2.4782 - val_accuracy: 0.0654\n",
      "Epoch 19/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.7326 - accuracy: 0.1148 - val_loss: 2.4754 - val_accuracy: 0.0654\n",
      "Epoch 20/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 2ms/step - loss: 2.7134 - accuracy: 0.1120 - val_loss: 2.4726 - val_accuracy: 0.0654\n",
      "Epoch 21/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.7047 - accuracy: 0.1065 - val_loss: 2.4699 - val_accuracy: 0.0841\n",
      "Epoch 22/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.7104 - accuracy: 0.1046 - val_loss: 2.4671 - val_accuracy: 0.0841\n",
      "Epoch 23/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.7139 - accuracy: 0.1014 - val_loss: 2.4643 - val_accuracy: 0.0841\n",
      "Epoch 24/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.6638 - accuracy: 0.1152 - val_loss: 2.4618 - val_accuracy: 0.0841\n",
      "Epoch 25/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.6759 - accuracy: 0.1054 - val_loss: 2.4593 - val_accuracy: 0.0841\n",
      "Epoch 26/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.6700 - accuracy: 0.1018 - val_loss: 2.4567 - val_accuracy: 0.0841\n",
      "Epoch 27/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.6691 - accuracy: 0.1038 - val_loss: 2.4541 - val_accuracy: 0.0841\n",
      "Epoch 28/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.6755 - accuracy: 0.1152 - val_loss: 2.4515 - val_accuracy: 0.0841\n",
      "Epoch 29/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.6538 - accuracy: 0.1171 - val_loss: 2.4490 - val_accuracy: 0.0841\n",
      "Epoch 30/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.6410 - accuracy: 0.1152 - val_loss: 2.4465 - val_accuracy: 0.0841\n",
      "Epoch 31/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.6549 - accuracy: 0.1038 - val_loss: 2.4440 - val_accuracy: 0.0841\n",
      "Epoch 32/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.6226 - accuracy: 0.1093 - val_loss: 2.4416 - val_accuracy: 0.0841\n",
      "Epoch 33/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.6340 - accuracy: 0.1101 - val_loss: 2.4391 - val_accuracy: 0.0841\n",
      "Epoch 34/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.6147 - accuracy: 0.1152 - val_loss: 2.4368 - val_accuracy: 0.0841\n",
      "Epoch 35/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.6106 - accuracy: 0.1034 - val_loss: 2.4345 - val_accuracy: 0.0841\n",
      "Epoch 36/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.6194 - accuracy: 0.1163 - val_loss: 2.4322 - val_accuracy: 0.0935\n",
      "Epoch 37/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.5925 - accuracy: 0.1195 - val_loss: 2.4298 - val_accuracy: 0.0935\n",
      "Epoch 38/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.5973 - accuracy: 0.1124 - val_loss: 2.4275 - val_accuracy: 0.0935\n",
      "Epoch 39/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.5968 - accuracy: 0.1073 - val_loss: 2.4252 - val_accuracy: 0.0935\n",
      "Epoch 40/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.5876 - accuracy: 0.1120 - val_loss: 2.4230 - val_accuracy: 0.0935\n",
      "Epoch 41/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 2.5804 - accuracy: 0.1081 - val_loss: 2.4208 - val_accuracy: 0.0935\n",
      "Epoch 42/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.5741 - accuracy: 0.1167 - val_loss: 2.4187 - val_accuracy: 0.0935\n",
      "Epoch 43/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.5625 - accuracy: 0.1132 - val_loss: 2.4165 - val_accuracy: 0.0935\n",
      "Epoch 44/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.5574 - accuracy: 0.1167 - val_loss: 2.4144 - val_accuracy: 0.0935\n",
      "Epoch 45/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.5386 - accuracy: 0.1163 - val_loss: 2.4123 - val_accuracy: 0.0935\n",
      "Epoch 46/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.5411 - accuracy: 0.1124 - val_loss: 2.4103 - val_accuracy: 0.0935\n",
      "Epoch 47/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.5510 - accuracy: 0.1124 - val_loss: 2.4082 - val_accuracy: 0.0935\n",
      "Epoch 48/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.5280 - accuracy: 0.1140 - val_loss: 2.4063 - val_accuracy: 0.0935\n",
      "Epoch 49/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.5236 - accuracy: 0.1167 - val_loss: 2.4045 - val_accuracy: 0.0935\n",
      "Epoch 50/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.5432 - accuracy: 0.1116 - val_loss: 2.4025 - val_accuracy: 0.0935\n",
      "Epoch 51/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.5266 - accuracy: 0.1183 - val_loss: 2.4005 - val_accuracy: 0.0935\n",
      "Epoch 52/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 2.5211 - accuracy: 0.1156 - val_loss: 2.3987 - val_accuracy: 0.0935\n",
      "Epoch 53/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.5081 - accuracy: 0.1242 - val_loss: 2.3968 - val_accuracy: 0.0935\n",
      "Epoch 54/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4971 - accuracy: 0.1214 - val_loss: 2.3950 - val_accuracy: 0.0935\n",
      "Epoch 55/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.5007 - accuracy: 0.1144 - val_loss: 2.3933 - val_accuracy: 0.0935\n",
      "Epoch 56/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4931 - accuracy: 0.1281 - val_loss: 2.3914 - val_accuracy: 0.0935\n",
      "Epoch 57/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.5051 - accuracy: 0.1152 - val_loss: 2.3896 - val_accuracy: 0.0935\n",
      "Epoch 58/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4927 - accuracy: 0.1195 - val_loss: 2.3878 - val_accuracy: 0.0935\n",
      "Epoch 59/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4952 - accuracy: 0.1171 - val_loss: 2.3860 - val_accuracy: 0.0935\n",
      "Epoch 60/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4741 - accuracy: 0.1222 - val_loss: 2.3843 - val_accuracy: 0.0935\n",
      "Epoch 61/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4745 - accuracy: 0.1242 - val_loss: 2.3826 - val_accuracy: 0.1028\n",
      "Epoch 62/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4878 - accuracy: 0.1179 - val_loss: 2.3808 - val_accuracy: 0.1028\n",
      "Epoch 63/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4724 - accuracy: 0.1320 - val_loss: 2.3791 - val_accuracy: 0.1028\n",
      "Epoch 64/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4611 - accuracy: 0.1320 - val_loss: 2.3774 - val_accuracy: 0.1121\n",
      "Epoch 65/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4590 - accuracy: 0.1320 - val_loss: 2.3758 - val_accuracy: 0.1121\n",
      "Epoch 66/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4521 - accuracy: 0.1253 - val_loss: 2.3743 - val_accuracy: 0.1121\n",
      "Epoch 67/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4545 - accuracy: 0.1250 - val_loss: 2.3726 - val_accuracy: 0.1121\n",
      "Epoch 68/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4501 - accuracy: 0.1222 - val_loss: 2.3711 - val_accuracy: 0.1121\n",
      "Epoch 69/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4378 - accuracy: 0.1387 - val_loss: 2.3696 - val_accuracy: 0.1121\n",
      "Epoch 70/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4406 - accuracy: 0.1191 - val_loss: 2.3681 - val_accuracy: 0.1121\n",
      "Epoch 71/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4408 - accuracy: 0.1363 - val_loss: 2.3666 - val_accuracy: 0.1215\n",
      "Epoch 72/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4465 - accuracy: 0.1297 - val_loss: 2.3651 - val_accuracy: 0.1215\n",
      "Epoch 73/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4268 - accuracy: 0.1269 - val_loss: 2.3637 - val_accuracy: 0.1215\n",
      "Epoch 74/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4355 - accuracy: 0.1234 - val_loss: 2.3623 - val_accuracy: 0.1215\n",
      "Epoch 75/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4181 - accuracy: 0.1312 - val_loss: 2.3609 - val_accuracy: 0.1215\n",
      "Epoch 76/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4216 - accuracy: 0.1336 - val_loss: 2.3594 - val_accuracy: 0.1215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4170 - accuracy: 0.1304 - val_loss: 2.3580 - val_accuracy: 0.1215\n",
      "Epoch 78/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4193 - accuracy: 0.1273 - val_loss: 2.3566 - val_accuracy: 0.1308\n",
      "Epoch 79/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4140 - accuracy: 0.1316 - val_loss: 2.3554 - val_accuracy: 0.1308\n",
      "Epoch 80/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4067 - accuracy: 0.1371 - val_loss: 2.3541 - val_accuracy: 0.1402\n",
      "Epoch 81/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4126 - accuracy: 0.1355 - val_loss: 2.3529 - val_accuracy: 0.1402\n",
      "Epoch 82/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3892 - accuracy: 0.1434 - val_loss: 2.3515 - val_accuracy: 0.1402\n",
      "Epoch 83/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4090 - accuracy: 0.1324 - val_loss: 2.3503 - val_accuracy: 0.1495\n",
      "Epoch 84/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3929 - accuracy: 0.1375 - val_loss: 2.3491 - val_accuracy: 0.1495\n",
      "Epoch 85/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4039 - accuracy: 0.1398 - val_loss: 2.3478 - val_accuracy: 0.1589\n",
      "Epoch 86/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3875 - accuracy: 0.1422 - val_loss: 2.3466 - val_accuracy: 0.1589\n",
      "Epoch 87/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.4043 - accuracy: 0.1308 - val_loss: 2.3454 - val_accuracy: 0.1589\n",
      "Epoch 88/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3879 - accuracy: 0.1422 - val_loss: 2.3442 - val_accuracy: 0.1589\n",
      "Epoch 89/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3769 - accuracy: 0.1441 - val_loss: 2.3432 - val_accuracy: 0.1589\n",
      "Epoch 90/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3818 - accuracy: 0.1371 - val_loss: 2.3421 - val_accuracy: 0.1682\n",
      "Epoch 91/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3807 - accuracy: 0.1418 - val_loss: 2.3410 - val_accuracy: 0.1682\n",
      "Epoch 92/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3787 - accuracy: 0.1434 - val_loss: 2.3398 - val_accuracy: 0.1776\n",
      "Epoch 93/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3853 - accuracy: 0.1308 - val_loss: 2.3387 - val_accuracy: 0.1776\n",
      "Epoch 94/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3683 - accuracy: 0.1387 - val_loss: 2.3376 - val_accuracy: 0.1776\n",
      "Epoch 95/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3657 - accuracy: 0.1457 - val_loss: 2.3366 - val_accuracy: 0.1776\n",
      "Epoch 96/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3784 - accuracy: 0.1383 - val_loss: 2.3355 - val_accuracy: 0.1869\n",
      "Epoch 97/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3781 - accuracy: 0.1347 - val_loss: 2.3346 - val_accuracy: 0.1869\n",
      "Epoch 98/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3636 - accuracy: 0.1418 - val_loss: 2.3336 - val_accuracy: 0.1869\n",
      "Epoch 99/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3636 - accuracy: 0.1441 - val_loss: 2.3326 - val_accuracy: 0.1869\n",
      "Epoch 100/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3622 - accuracy: 0.1465 - val_loss: 2.3316 - val_accuracy: 0.1869\n",
      "Epoch 101/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3559 - accuracy: 0.1520 - val_loss: 2.3307 - val_accuracy: 0.1869\n",
      "Epoch 102/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3620 - accuracy: 0.1473 - val_loss: 2.3298 - val_accuracy: 0.1869\n",
      "Epoch 103/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3625 - accuracy: 0.1488 - val_loss: 2.3289 - val_accuracy: 0.1963\n",
      "Epoch 104/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3524 - accuracy: 0.1532 - val_loss: 2.3280 - val_accuracy: 0.1963\n",
      "Epoch 105/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3594 - accuracy: 0.1508 - val_loss: 2.3271 - val_accuracy: 0.1963\n",
      "Epoch 106/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3485 - accuracy: 0.1492 - val_loss: 2.3262 - val_accuracy: 0.1963\n",
      "Epoch 107/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3484 - accuracy: 0.1449 - val_loss: 2.3253 - val_accuracy: 0.2056\n",
      "Epoch 108/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3497 - accuracy: 0.1477 - val_loss: 2.3245 - val_accuracy: 0.2056\n",
      "Epoch 109/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3505 - accuracy: 0.1563 - val_loss: 2.3237 - val_accuracy: 0.2056\n",
      "Epoch 110/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3475 - accuracy: 0.1473 - val_loss: 2.3228 - val_accuracy: 0.2056\n",
      "Epoch 111/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3520 - accuracy: 0.1473 - val_loss: 2.3220 - val_accuracy: 0.2056\n",
      "Epoch 112/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3415 - accuracy: 0.1543 - val_loss: 2.3211 - val_accuracy: 0.2056\n",
      "Epoch 113/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3538 - accuracy: 0.1441 - val_loss: 2.3203 - val_accuracy: 0.2056\n",
      "Epoch 114/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3475 - accuracy: 0.1453 - val_loss: 2.3196 - val_accuracy: 0.1963\n",
      "Epoch 115/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3401 - accuracy: 0.1504 - val_loss: 2.3188 - val_accuracy: 0.1963\n",
      "Epoch 116/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3416 - accuracy: 0.1520 - val_loss: 2.3181 - val_accuracy: 0.1963\n",
      "Epoch 117/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3429 - accuracy: 0.1579 - val_loss: 2.3173 - val_accuracy: 0.1963\n",
      "Epoch 118/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3402 - accuracy: 0.1520 - val_loss: 2.3166 - val_accuracy: 0.1963\n",
      "Epoch 119/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3422 - accuracy: 0.1465 - val_loss: 2.3159 - val_accuracy: 0.1963\n",
      "Epoch 120/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3391 - accuracy: 0.1485 - val_loss: 2.3152 - val_accuracy: 0.1963\n",
      "Epoch 121/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3319 - accuracy: 0.1512 - val_loss: 2.3145 - val_accuracy: 0.1963\n",
      "Epoch 122/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3332 - accuracy: 0.1516 - val_loss: 2.3138 - val_accuracy: 0.1963\n",
      "Epoch 123/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3305 - accuracy: 0.1539 - val_loss: 2.3131 - val_accuracy: 0.1963\n",
      "Epoch 124/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3346 - accuracy: 0.1532 - val_loss: 2.3124 - val_accuracy: 0.1963\n",
      "Epoch 125/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3254 - accuracy: 0.1657 - val_loss: 2.3117 - val_accuracy: 0.2056\n",
      "Epoch 126/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3259 - accuracy: 0.1641 - val_loss: 2.3111 - val_accuracy: 0.2056\n",
      "Epoch 127/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3258 - accuracy: 0.1649 - val_loss: 2.3105 - val_accuracy: 0.2056\n",
      "Epoch 128/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3322 - accuracy: 0.1512 - val_loss: 2.3099 - val_accuracy: 0.2056\n",
      "Epoch 129/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3237 - accuracy: 0.1626 - val_loss: 2.3093 - val_accuracy: 0.2056\n",
      "Epoch 130/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3266 - accuracy: 0.1516 - val_loss: 2.3087 - val_accuracy: 0.1963\n",
      "Epoch 131/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3220 - accuracy: 0.1622 - val_loss: 2.3081 - val_accuracy: 0.2150\n",
      "Epoch 132/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3186 - accuracy: 0.1547 - val_loss: 2.3075 - val_accuracy: 0.2150\n",
      "Epoch 133/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3188 - accuracy: 0.1532 - val_loss: 2.3069 - val_accuracy: 0.2150\n",
      "Epoch 134/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3250 - accuracy: 0.1622 - val_loss: 2.3065 - val_accuracy: 0.2150\n",
      "Epoch 135/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3108 - accuracy: 0.1712 - val_loss: 2.3059 - val_accuracy: 0.2150\n",
      "Epoch 136/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3251 - accuracy: 0.1563 - val_loss: 2.3054 - val_accuracy: 0.2243\n",
      "Epoch 137/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3085 - accuracy: 0.1692 - val_loss: 2.3049 - val_accuracy: 0.2243\n",
      "Epoch 138/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3144 - accuracy: 0.1614 - val_loss: 2.3044 - val_accuracy: 0.2243\n",
      "Epoch 139/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3194 - accuracy: 0.1575 - val_loss: 2.3038 - val_accuracy: 0.2243\n",
      "Epoch 140/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3151 - accuracy: 0.1641 - val_loss: 2.3033 - val_accuracy: 0.2243\n",
      "Epoch 141/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3159 - accuracy: 0.1637 - val_loss: 2.3028 - val_accuracy: 0.2243\n",
      "Epoch 142/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3190 - accuracy: 0.1661 - val_loss: 2.3023 - val_accuracy: 0.2243\n",
      "Epoch 143/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3183 - accuracy: 0.1575 - val_loss: 2.3018 - val_accuracy: 0.2243\n",
      "Epoch 144/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3160 - accuracy: 0.1582 - val_loss: 2.3013 - val_accuracy: 0.2243\n",
      "Epoch 145/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3042 - accuracy: 0.1653 - val_loss: 2.3007 - val_accuracy: 0.2243\n",
      "Epoch 146/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3161 - accuracy: 0.1614 - val_loss: 2.3003 - val_accuracy: 0.2243\n",
      "Epoch 147/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3081 - accuracy: 0.1723 - val_loss: 2.2997 - val_accuracy: 0.2243\n",
      "Epoch 148/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3150 - accuracy: 0.1571 - val_loss: 2.2993 - val_accuracy: 0.2243\n",
      "Epoch 149/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3123 - accuracy: 0.1645 - val_loss: 2.2988 - val_accuracy: 0.2243\n",
      "Epoch 150/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3138 - accuracy: 0.1579 - val_loss: 2.2984 - val_accuracy: 0.2243\n",
      "Epoch 151/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3089 - accuracy: 0.1641 - val_loss: 2.2980 - val_accuracy: 0.2243\n",
      "Epoch 152/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3133 - accuracy: 0.1626 - val_loss: 2.2975 - val_accuracy: 0.2243\n",
      "Epoch 153/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3137 - accuracy: 0.1661 - val_loss: 2.2971 - val_accuracy: 0.2243\n",
      "Epoch 154/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3061 - accuracy: 0.1665 - val_loss: 2.2967 - val_accuracy: 0.2243\n",
      "Epoch 155/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3013 - accuracy: 0.1661 - val_loss: 2.2963 - val_accuracy: 0.2243\n",
      "Epoch 156/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3034 - accuracy: 0.1676 - val_loss: 2.2958 - val_accuracy: 0.2243\n",
      "Epoch 157/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3036 - accuracy: 0.1680 - val_loss: 2.2954 - val_accuracy: 0.2243\n",
      "Epoch 158/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3112 - accuracy: 0.1637 - val_loss: 2.2950 - val_accuracy: 0.2243\n",
      "Epoch 159/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3114 - accuracy: 0.1586 - val_loss: 2.2947 - val_accuracy: 0.2243\n",
      "Epoch 160/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2974 - accuracy: 0.1692 - val_loss: 2.2943 - val_accuracy: 0.2243\n",
      "Epoch 161/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3103 - accuracy: 0.1692 - val_loss: 2.2939 - val_accuracy: 0.2243\n",
      "Epoch 162/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3044 - accuracy: 0.1770 - val_loss: 2.2935 - val_accuracy: 0.2243\n",
      "Epoch 163/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3084 - accuracy: 0.1645 - val_loss: 2.2931 - val_accuracy: 0.2243\n",
      "Epoch 164/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2936 - accuracy: 0.1786 - val_loss: 2.2927 - val_accuracy: 0.2243\n",
      "Epoch 165/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2951 - accuracy: 0.1739 - val_loss: 2.2922 - val_accuracy: 0.2243\n",
      "Epoch 166/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3053 - accuracy: 0.1720 - val_loss: 2.2918 - val_accuracy: 0.2243\n",
      "Epoch 167/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2961 - accuracy: 0.1778 - val_loss: 2.2914 - val_accuracy: 0.2243\n",
      "Epoch 168/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2956 - accuracy: 0.1798 - val_loss: 2.2910 - val_accuracy: 0.2243\n",
      "Epoch 169/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3016 - accuracy: 0.1755 - val_loss: 2.2907 - val_accuracy: 0.2243\n",
      "Epoch 170/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2882 - accuracy: 0.1794 - val_loss: 2.2902 - val_accuracy: 0.2243\n",
      "Epoch 171/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3009 - accuracy: 0.1735 - val_loss: 2.2899 - val_accuracy: 0.2243\n",
      "Epoch 172/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3029 - accuracy: 0.1727 - val_loss: 2.2895 - val_accuracy: 0.2243\n",
      "Epoch 173/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3024 - accuracy: 0.1790 - val_loss: 2.2892 - val_accuracy: 0.2243\n",
      "Epoch 174/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2915 - accuracy: 0.1821 - val_loss: 2.2888 - val_accuracy: 0.2243\n",
      "Epoch 175/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2943 - accuracy: 0.1814 - val_loss: 2.2884 - val_accuracy: 0.2243\n",
      "Epoch 176/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2962 - accuracy: 0.1774 - val_loss: 2.2881 - val_accuracy: 0.2243\n",
      "Epoch 177/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2950 - accuracy: 0.1833 - val_loss: 2.2877 - val_accuracy: 0.2336\n",
      "Epoch 178/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2970 - accuracy: 0.1817 - val_loss: 2.2874 - val_accuracy: 0.2336\n",
      "Epoch 179/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2919 - accuracy: 0.1802 - val_loss: 2.2871 - val_accuracy: 0.2336\n",
      "Epoch 180/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3029 - accuracy: 0.1806 - val_loss: 2.2868 - val_accuracy: 0.2523\n",
      "Epoch 181/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3001 - accuracy: 0.1716 - val_loss: 2.2865 - val_accuracy: 0.2523\n",
      "Epoch 182/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3006 - accuracy: 0.1825 - val_loss: 2.2862 - val_accuracy: 0.2523\n",
      "Epoch 183/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2896 - accuracy: 0.1782 - val_loss: 2.2859 - val_accuracy: 0.2523\n",
      "Epoch 184/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2958 - accuracy: 0.1864 - val_loss: 2.2856 - val_accuracy: 0.2523\n",
      "Epoch 185/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2927 - accuracy: 0.1751 - val_loss: 2.2853 - val_accuracy: 0.2523\n",
      "Epoch 186/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2937 - accuracy: 0.1821 - val_loss: 2.2850 - val_accuracy: 0.2523\n",
      "Epoch 187/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2897 - accuracy: 0.1880 - val_loss: 2.2847 - val_accuracy: 0.2523\n",
      "Epoch 188/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2918 - accuracy: 0.1782 - val_loss: 2.2844 - val_accuracy: 0.2523\n",
      "Epoch 189/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2903 - accuracy: 0.1829 - val_loss: 2.2841 - val_accuracy: 0.2523\n",
      "Epoch 190/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2959 - accuracy: 0.1802 - val_loss: 2.2839 - val_accuracy: 0.2523\n",
      "Epoch 191/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2855 - accuracy: 0.1767 - val_loss: 2.2835 - val_accuracy: 0.2523\n",
      "Epoch 192/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2837 - accuracy: 0.1849 - val_loss: 2.2832 - val_accuracy: 0.2523\n",
      "Epoch 193/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3000 - accuracy: 0.1763 - val_loss: 2.2829 - val_accuracy: 0.2523\n",
      "Epoch 194/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2952 - accuracy: 0.1798 - val_loss: 2.2826 - val_accuracy: 0.2523\n",
      "Epoch 195/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2855 - accuracy: 0.1786 - val_loss: 2.2823 - val_accuracy: 0.2523\n",
      "Epoch 196/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2908 - accuracy: 0.1774 - val_loss: 2.2820 - val_accuracy: 0.2523\n",
      "Epoch 197/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2875 - accuracy: 0.1790 - val_loss: 2.2817 - val_accuracy: 0.2523\n",
      "Epoch 198/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2878 - accuracy: 0.1837 - val_loss: 2.2815 - val_accuracy: 0.2523\n",
      "Epoch 199/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2945 - accuracy: 0.1821 - val_loss: 2.2812 - val_accuracy: 0.2523\n",
      "Epoch 200/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2992 - accuracy: 0.1743 - val_loss: 2.2810 - val_accuracy: 0.2523\n",
      "0.25233644247055054 {'loss': 2.299208402633667, 'accuracy': 0.17430473864078522, 'val_loss': 2.2809770107269287, 'val_accuracy': 0.25233644247055054}\n",
      "Model: \"model_31\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_32 (InputLayer)        [(None, 29)]              0         \n",
      "_________________________________________________________________\n",
      "flatten_31 (Flatten)         (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 41)                1230      \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 10)                420       \n",
      "_________________________________________________________________\n",
      "dense_94 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_95 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,870\n",
      "Trainable params: 1,870\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 2.6392 - accuracy: 0.1504 - val_loss: 2.3781 - val_accuracy: 0.1963\n",
      "Epoch 2/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.6303 - accuracy: 0.1551 - val_loss: 2.3765 - val_accuracy: 0.1963\n",
      "Epoch 3/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.6092 - accuracy: 0.1614 - val_loss: 2.3749 - val_accuracy: 0.1963\n",
      "Epoch 4/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5830 - accuracy: 0.1665 - val_loss: 2.3732 - val_accuracy: 0.1963\n",
      "Epoch 5/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.6233 - accuracy: 0.1535 - val_loss: 2.3718 - val_accuracy: 0.1963\n",
      "Epoch 6/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5789 - accuracy: 0.1641 - val_loss: 2.3703 - val_accuracy: 0.2056\n",
      "Epoch 7/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5797 - accuracy: 0.1680 - val_loss: 2.3688 - val_accuracy: 0.2056\n",
      "Epoch 8/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.6252 - accuracy: 0.1598 - val_loss: 2.3672 - val_accuracy: 0.2056\n",
      "Epoch 9/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5738 - accuracy: 0.1751 - val_loss: 2.3656 - val_accuracy: 0.2150\n",
      "Epoch 10/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.6058 - accuracy: 0.1696 - val_loss: 2.3640 - val_accuracy: 0.2150\n",
      "Epoch 11/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5958 - accuracy: 0.1602 - val_loss: 2.3625 - val_accuracy: 0.2150\n",
      "Epoch 12/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5908 - accuracy: 0.1704 - val_loss: 2.3610 - val_accuracy: 0.2150\n",
      "Epoch 13/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5766 - accuracy: 0.1610 - val_loss: 2.3596 - val_accuracy: 0.2150\n",
      "Epoch 14/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5997 - accuracy: 0.1618 - val_loss: 2.3582 - val_accuracy: 0.2150\n",
      "Epoch 15/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5796 - accuracy: 0.1641 - val_loss: 2.3567 - val_accuracy: 0.2150\n",
      "Epoch 16/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5953 - accuracy: 0.1543 - val_loss: 2.3553 - val_accuracy: 0.2150\n",
      "Epoch 17/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5824 - accuracy: 0.1716 - val_loss: 2.3539 - val_accuracy: 0.2150\n",
      "Epoch 18/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5805 - accuracy: 0.1704 - val_loss: 2.3523 - val_accuracy: 0.2150\n",
      "Epoch 19/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5706 - accuracy: 0.1680 - val_loss: 2.3507 - val_accuracy: 0.2243\n",
      "Epoch 20/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5990 - accuracy: 0.1614 - val_loss: 2.3492 - val_accuracy: 0.2243\n",
      "Epoch 21/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5695 - accuracy: 0.1637 - val_loss: 2.3476 - val_accuracy: 0.2243\n",
      "Epoch 22/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5901 - accuracy: 0.1543 - val_loss: 2.3462 - val_accuracy: 0.2243\n",
      "Epoch 23/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5567 - accuracy: 0.1794 - val_loss: 2.3448 - val_accuracy: 0.2243\n",
      "Epoch 24/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5606 - accuracy: 0.1751 - val_loss: 2.3434 - val_accuracy: 0.2243\n",
      "Epoch 25/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5387 - accuracy: 0.1661 - val_loss: 2.3422 - val_accuracy: 0.2243\n",
      "Epoch 26/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5574 - accuracy: 0.1680 - val_loss: 2.3408 - val_accuracy: 0.2336\n",
      "Epoch 27/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5251 - accuracy: 0.1716 - val_loss: 2.3395 - val_accuracy: 0.2336\n",
      "Epoch 28/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5762 - accuracy: 0.1598 - val_loss: 2.3384 - val_accuracy: 0.2336\n",
      "Epoch 29/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5452 - accuracy: 0.1665 - val_loss: 2.3371 - val_accuracy: 0.2336\n",
      "Epoch 30/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5393 - accuracy: 0.1747 - val_loss: 2.3358 - val_accuracy: 0.2336\n",
      "Epoch 31/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5543 - accuracy: 0.1657 - val_loss: 2.3345 - val_accuracy: 0.2336\n",
      "Epoch 32/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5646 - accuracy: 0.1598 - val_loss: 2.3334 - val_accuracy: 0.2336\n",
      "Epoch 33/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5475 - accuracy: 0.1626 - val_loss: 2.3320 - val_accuracy: 0.2430\n",
      "Epoch 34/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5341 - accuracy: 0.1700 - val_loss: 2.3308 - val_accuracy: 0.2430\n",
      "Epoch 35/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5240 - accuracy: 0.1731 - val_loss: 2.3293 - val_accuracy: 0.2430\n",
      "Epoch 36/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5376 - accuracy: 0.1696 - val_loss: 2.3281 - val_accuracy: 0.2523\n",
      "Epoch 37/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5280 - accuracy: 0.1802 - val_loss: 2.3267 - val_accuracy: 0.2523\n",
      "Epoch 38/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5272 - accuracy: 0.1778 - val_loss: 2.3253 - val_accuracy: 0.2617\n",
      "Epoch 39/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5251 - accuracy: 0.1661 - val_loss: 2.3241 - val_accuracy: 0.2617\n",
      "Epoch 40/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5259 - accuracy: 0.1618 - val_loss: 2.3229 - val_accuracy: 0.2617\n",
      "Epoch 41/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5146 - accuracy: 0.1747 - val_loss: 2.3216 - val_accuracy: 0.2617\n",
      "Epoch 42/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5287 - accuracy: 0.1716 - val_loss: 2.3205 - val_accuracy: 0.2710\n",
      "Epoch 43/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5144 - accuracy: 0.1700 - val_loss: 2.3192 - val_accuracy: 0.2710\n",
      "Epoch 44/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5068 - accuracy: 0.1735 - val_loss: 2.3181 - val_accuracy: 0.2710\n",
      "Epoch 45/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5103 - accuracy: 0.1794 - val_loss: 2.3168 - val_accuracy: 0.2710\n",
      "Epoch 46/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4957 - accuracy: 0.1747 - val_loss: 2.3155 - val_accuracy: 0.2710\n",
      "Epoch 47/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5068 - accuracy: 0.1751 - val_loss: 2.3141 - val_accuracy: 0.2710\n",
      "Epoch 48/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5149 - accuracy: 0.1755 - val_loss: 2.3130 - val_accuracy: 0.2710\n",
      "Epoch 49/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5018 - accuracy: 0.1747 - val_loss: 2.3118 - val_accuracy: 0.2710\n",
      "Epoch 50/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4996 - accuracy: 0.1841 - val_loss: 2.3104 - val_accuracy: 0.2710\n",
      "Epoch 51/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4947 - accuracy: 0.1657 - val_loss: 2.3093 - val_accuracy: 0.2710\n",
      "Epoch 52/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4915 - accuracy: 0.1861 - val_loss: 2.3081 - val_accuracy: 0.2710\n",
      "Epoch 53/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5164 - accuracy: 0.1774 - val_loss: 2.3069 - val_accuracy: 0.2710\n",
      "Epoch 54/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4872 - accuracy: 0.1833 - val_loss: 2.3058 - val_accuracy: 0.2710\n",
      "Epoch 55/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4884 - accuracy: 0.1829 - val_loss: 2.3047 - val_accuracy: 0.2710\n",
      "Epoch 56/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5247 - accuracy: 0.1641 - val_loss: 2.3036 - val_accuracy: 0.2710\n",
      "Epoch 57/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4865 - accuracy: 0.1770 - val_loss: 2.3025 - val_accuracy: 0.2710\n",
      "Epoch 58/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4666 - accuracy: 0.1908 - val_loss: 2.3013 - val_accuracy: 0.2710\n",
      "Epoch 59/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4787 - accuracy: 0.1845 - val_loss: 2.3000 - val_accuracy: 0.2710\n",
      "Epoch 60/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4772 - accuracy: 0.1915 - val_loss: 2.2988 - val_accuracy: 0.2710\n",
      "Epoch 61/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4822 - accuracy: 0.1892 - val_loss: 2.2977 - val_accuracy: 0.2804\n",
      "Epoch 62/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4922 - accuracy: 0.1833 - val_loss: 2.2966 - val_accuracy: 0.2804\n",
      "Epoch 63/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4805 - accuracy: 0.1673 - val_loss: 2.2956 - val_accuracy: 0.2804\n",
      "Epoch 64/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4841 - accuracy: 0.1763 - val_loss: 2.2945 - val_accuracy: 0.2804\n",
      "Epoch 65/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4781 - accuracy: 0.1810 - val_loss: 2.2935 - val_accuracy: 0.2804\n",
      "Epoch 66/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4690 - accuracy: 0.1864 - val_loss: 2.2925 - val_accuracy: 0.2804\n",
      "Epoch 67/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4711 - accuracy: 0.1774 - val_loss: 2.2915 - val_accuracy: 0.2804\n",
      "Epoch 68/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4879 - accuracy: 0.1712 - val_loss: 2.2906 - val_accuracy: 0.2804\n",
      "Epoch 69/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4546 - accuracy: 0.1806 - val_loss: 2.2894 - val_accuracy: 0.2897\n",
      "Epoch 70/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4750 - accuracy: 0.1778 - val_loss: 2.2884 - val_accuracy: 0.2991\n",
      "Epoch 71/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4725 - accuracy: 0.1821 - val_loss: 2.2873 - val_accuracy: 0.2991\n",
      "Epoch 72/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4556 - accuracy: 0.1814 - val_loss: 2.2863 - val_accuracy: 0.2991\n",
      "Epoch 73/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4433 - accuracy: 0.1849 - val_loss: 2.2852 - val_accuracy: 0.2991\n",
      "Epoch 74/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4675 - accuracy: 0.1817 - val_loss: 2.2841 - val_accuracy: 0.2991\n",
      "Epoch 75/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4823 - accuracy: 0.1692 - val_loss: 2.2831 - val_accuracy: 0.2991\n",
      "Epoch 76/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4443 - accuracy: 0.1825 - val_loss: 2.2820 - val_accuracy: 0.2991\n",
      "Epoch 77/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4763 - accuracy: 0.1868 - val_loss: 2.2809 - val_accuracy: 0.2991\n",
      "Epoch 78/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4589 - accuracy: 0.1759 - val_loss: 2.2800 - val_accuracy: 0.2991\n",
      "Epoch 79/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4440 - accuracy: 0.1970 - val_loss: 2.2788 - val_accuracy: 0.2991\n",
      "Epoch 80/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4414 - accuracy: 0.1841 - val_loss: 2.2776 - val_accuracy: 0.2991\n",
      "Epoch 81/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4428 - accuracy: 0.1880 - val_loss: 2.2767 - val_accuracy: 0.2991\n",
      "Epoch 82/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4386 - accuracy: 0.1833 - val_loss: 2.2757 - val_accuracy: 0.2991\n",
      "Epoch 83/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4220 - accuracy: 0.1978 - val_loss: 2.2745 - val_accuracy: 0.2991\n",
      "Epoch 84/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4419 - accuracy: 0.1896 - val_loss: 2.2734 - val_accuracy: 0.2991\n",
      "Epoch 85/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4419 - accuracy: 0.1770 - val_loss: 2.2724 - val_accuracy: 0.2991\n",
      "Epoch 86/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4416 - accuracy: 0.1892 - val_loss: 2.2713 - val_accuracy: 0.2991\n",
      "Epoch 87/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.4342 - accuracy: 0.1861 - val_loss: 2.2703 - val_accuracy: 0.2991\n",
      "Epoch 88/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4358 - accuracy: 0.1743 - val_loss: 2.2694 - val_accuracy: 0.2991\n",
      "Epoch 89/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4249 - accuracy: 0.1935 - val_loss: 2.2683 - val_accuracy: 0.2991\n",
      "Epoch 90/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4328 - accuracy: 0.1958 - val_loss: 2.2673 - val_accuracy: 0.2991\n",
      "Epoch 91/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4201 - accuracy: 0.1915 - val_loss: 2.2664 - val_accuracy: 0.2991\n",
      "Epoch 92/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4463 - accuracy: 0.1853 - val_loss: 2.2654 - val_accuracy: 0.2991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4179 - accuracy: 0.1982 - val_loss: 2.2643 - val_accuracy: 0.2991\n",
      "Epoch 94/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4245 - accuracy: 0.1908 - val_loss: 2.2633 - val_accuracy: 0.2897\n",
      "Epoch 95/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4223 - accuracy: 0.1955 - val_loss: 2.2623 - val_accuracy: 0.2897\n",
      "Epoch 96/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4022 - accuracy: 0.1943 - val_loss: 2.2612 - val_accuracy: 0.2991\n",
      "Epoch 97/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4249 - accuracy: 0.1802 - val_loss: 2.2604 - val_accuracy: 0.2991\n",
      "Epoch 98/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4262 - accuracy: 0.1802 - val_loss: 2.2596 - val_accuracy: 0.2991\n",
      "Epoch 99/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4132 - accuracy: 0.1884 - val_loss: 2.2586 - val_accuracy: 0.2991\n",
      "Epoch 100/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4178 - accuracy: 0.1911 - val_loss: 2.2577 - val_accuracy: 0.2991\n",
      "Epoch 101/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4119 - accuracy: 0.1923 - val_loss: 2.2568 - val_accuracy: 0.2991\n",
      "Epoch 102/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4103 - accuracy: 0.1817 - val_loss: 2.2559 - val_accuracy: 0.2991\n",
      "Epoch 103/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4067 - accuracy: 0.1958 - val_loss: 2.2550 - val_accuracy: 0.2991\n",
      "Epoch 104/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3949 - accuracy: 0.1986 - val_loss: 2.2540 - val_accuracy: 0.2991\n",
      "Epoch 105/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3985 - accuracy: 0.2009 - val_loss: 2.2529 - val_accuracy: 0.2991\n",
      "Epoch 106/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4128 - accuracy: 0.1931 - val_loss: 2.2520 - val_accuracy: 0.2991\n",
      "Epoch 107/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3932 - accuracy: 0.1939 - val_loss: 2.2511 - val_accuracy: 0.2991\n",
      "Epoch 108/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4025 - accuracy: 0.1982 - val_loss: 2.2501 - val_accuracy: 0.2991\n",
      "Epoch 109/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3896 - accuracy: 0.1994 - val_loss: 2.2490 - val_accuracy: 0.2991\n",
      "Epoch 110/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4146 - accuracy: 0.1868 - val_loss: 2.2483 - val_accuracy: 0.2991\n",
      "Epoch 111/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3968 - accuracy: 0.1927 - val_loss: 2.2474 - val_accuracy: 0.2991\n",
      "Epoch 112/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3848 - accuracy: 0.2049 - val_loss: 2.2463 - val_accuracy: 0.2991\n",
      "Epoch 113/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3993 - accuracy: 0.1943 - val_loss: 2.2453 - val_accuracy: 0.2991\n",
      "Epoch 114/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3824 - accuracy: 0.1927 - val_loss: 2.2446 - val_accuracy: 0.2991\n",
      "Epoch 115/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.3916 - accuracy: 0.2033 - val_loss: 2.2437 - val_accuracy: 0.2991\n",
      "Epoch 116/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3841 - accuracy: 0.1888 - val_loss: 2.2428 - val_accuracy: 0.2991\n",
      "Epoch 117/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3918 - accuracy: 0.1931 - val_loss: 2.2420 - val_accuracy: 0.2991\n",
      "Epoch 118/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4001 - accuracy: 0.1931 - val_loss: 2.2411 - val_accuracy: 0.3084\n",
      "Epoch 119/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4017 - accuracy: 0.1884 - val_loss: 2.2404 - val_accuracy: 0.3084\n",
      "Epoch 120/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3888 - accuracy: 0.1911 - val_loss: 2.2397 - val_accuracy: 0.3084\n",
      "Epoch 121/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3785 - accuracy: 0.2029 - val_loss: 2.2388 - val_accuracy: 0.3084\n",
      "Epoch 122/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3840 - accuracy: 0.1900 - val_loss: 2.2380 - val_accuracy: 0.3084\n",
      "Epoch 123/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3812 - accuracy: 0.1978 - val_loss: 2.2371 - val_accuracy: 0.3084\n",
      "Epoch 124/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3821 - accuracy: 0.1923 - val_loss: 2.2363 - val_accuracy: 0.3084\n",
      "Epoch 125/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3979 - accuracy: 0.1919 - val_loss: 2.2356 - val_accuracy: 0.3084\n",
      "Epoch 126/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3833 - accuracy: 0.1868 - val_loss: 2.2351 - val_accuracy: 0.3084\n",
      "Epoch 127/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3809 - accuracy: 0.1892 - val_loss: 2.2344 - val_accuracy: 0.3084\n",
      "Epoch 128/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3900 - accuracy: 0.1864 - val_loss: 2.2336 - val_accuracy: 0.3084\n",
      "Epoch 129/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3835 - accuracy: 0.1857 - val_loss: 2.2328 - val_accuracy: 0.3084\n",
      "Epoch 130/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3862 - accuracy: 0.1892 - val_loss: 2.2320 - val_accuracy: 0.3084\n",
      "Epoch 131/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3748 - accuracy: 0.1880 - val_loss: 2.2313 - val_accuracy: 0.3084\n",
      "Epoch 132/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3562 - accuracy: 0.2029 - val_loss: 2.2303 - val_accuracy: 0.3084\n",
      "Epoch 133/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3981 - accuracy: 0.1872 - val_loss: 2.2297 - val_accuracy: 0.3084\n",
      "Epoch 134/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3767 - accuracy: 0.1947 - val_loss: 2.2289 - val_accuracy: 0.3084\n",
      "Epoch 135/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3723 - accuracy: 0.1939 - val_loss: 2.2282 - val_accuracy: 0.3084\n",
      "Epoch 136/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3506 - accuracy: 0.2115 - val_loss: 2.2274 - val_accuracy: 0.3084\n",
      "Epoch 137/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.3813 - accuracy: 0.1911 - val_loss: 2.2269 - val_accuracy: 0.3084\n",
      "Epoch 138/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 2.3710 - accuracy: 0.2005 - val_loss: 2.2263 - val_accuracy: 0.3084\n",
      "Epoch 139/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3707 - accuracy: 0.1970 - val_loss: 2.2256 - val_accuracy: 0.3084\n",
      "Epoch 140/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3619 - accuracy: 0.2009 - val_loss: 2.2249 - val_accuracy: 0.3084\n",
      "Epoch 141/200\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 2.3722 - accuracy: 0.1911 - val_loss: 2.2242 - val_accuracy: 0.3084\n",
      "Epoch 142/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 2.3794 - accuracy: 0.1955 - val_loss: 2.2235 - val_accuracy: 0.3178\n",
      "Epoch 143/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3637 - accuracy: 0.1943 - val_loss: 2.2228 - val_accuracy: 0.3178\n",
      "Epoch 144/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.3672 - accuracy: 0.1982 - val_loss: 2.2222 - val_accuracy: 0.3178\n",
      "Epoch 145/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.3736 - accuracy: 0.1868 - val_loss: 2.2216 - val_accuracy: 0.3178\n",
      "Epoch 146/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.3613 - accuracy: 0.1962 - val_loss: 2.2210 - val_accuracy: 0.3178\n",
      "Epoch 147/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3471 - accuracy: 0.2021 - val_loss: 2.2203 - val_accuracy: 0.3178\n",
      "Epoch 148/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.3627 - accuracy: 0.1951 - val_loss: 2.2196 - val_accuracy: 0.3178\n",
      "Epoch 149/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.3673 - accuracy: 0.1931 - val_loss: 2.2189 - val_accuracy: 0.3178\n",
      "Epoch 150/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3608 - accuracy: 0.1978 - val_loss: 2.2183 - val_accuracy: 0.3178\n",
      "Epoch 151/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.3340 - accuracy: 0.2080 - val_loss: 2.2176 - val_accuracy: 0.3178\n",
      "Epoch 152/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3620 - accuracy: 0.1986 - val_loss: 2.2170 - val_accuracy: 0.3178\n",
      "Epoch 153/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3639 - accuracy: 0.1927 - val_loss: 2.2165 - val_accuracy: 0.3178\n",
      "Epoch 154/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3513 - accuracy: 0.1880 - val_loss: 2.2159 - val_accuracy: 0.3178\n",
      "Epoch 155/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3456 - accuracy: 0.2013 - val_loss: 2.2153 - val_accuracy: 0.3178\n",
      "Epoch 156/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.3552 - accuracy: 0.1915 - val_loss: 2.2147 - val_accuracy: 0.3178\n",
      "Epoch 157/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.3403 - accuracy: 0.2096 - val_loss: 2.2141 - val_accuracy: 0.3178\n",
      "Epoch 158/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3632 - accuracy: 0.2002 - val_loss: 2.2134 - val_accuracy: 0.3178\n",
      "Epoch 159/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3319 - accuracy: 0.2076 - val_loss: 2.2127 - val_accuracy: 0.3178\n",
      "Epoch 160/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3388 - accuracy: 0.2049 - val_loss: 2.2120 - val_accuracy: 0.3178\n",
      "Epoch 161/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3493 - accuracy: 0.1974 - val_loss: 2.2114 - val_accuracy: 0.3178\n",
      "Epoch 162/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3526 - accuracy: 0.1947 - val_loss: 2.2107 - val_accuracy: 0.3178\n",
      "Epoch 163/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3367 - accuracy: 0.2041 - val_loss: 2.2101 - val_accuracy: 0.3178\n",
      "Epoch 164/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3570 - accuracy: 0.1896 - val_loss: 2.2095 - val_accuracy: 0.3178\n",
      "Epoch 165/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3464 - accuracy: 0.1892 - val_loss: 2.2090 - val_accuracy: 0.3178\n",
      "Epoch 166/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.3309 - accuracy: 0.2072 - val_loss: 2.2082 - val_accuracy: 0.3178\n",
      "Epoch 167/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3381 - accuracy: 0.1962 - val_loss: 2.2075 - val_accuracy: 0.3178\n",
      "Epoch 168/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 2.3222 - accuracy: 0.2099 - val_loss: 2.2069 - val_accuracy: 0.3178\n",
      "Epoch 169/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.3558 - accuracy: 0.1955 - val_loss: 2.2064 - val_accuracy: 0.3178\n",
      "Epoch 170/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3549 - accuracy: 0.1880 - val_loss: 2.2060 - val_accuracy: 0.3178\n",
      "Epoch 171/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3383 - accuracy: 0.1970 - val_loss: 2.2055 - val_accuracy: 0.3178\n",
      "Epoch 172/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3385 - accuracy: 0.2017 - val_loss: 2.2050 - val_accuracy: 0.3178\n",
      "Epoch 173/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3351 - accuracy: 0.2002 - val_loss: 2.2046 - val_accuracy: 0.3178\n",
      "Epoch 174/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3392 - accuracy: 0.1986 - val_loss: 2.2041 - val_accuracy: 0.3178\n",
      "Epoch 175/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.3217 - accuracy: 0.2049 - val_loss: 2.2033 - val_accuracy: 0.3178\n",
      "Epoch 176/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.3321 - accuracy: 0.2005 - val_loss: 2.2026 - val_accuracy: 0.3271\n",
      "Epoch 177/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.3325 - accuracy: 0.1986 - val_loss: 2.2020 - val_accuracy: 0.3271\n",
      "Epoch 178/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3394 - accuracy: 0.1966 - val_loss: 2.2016 - val_accuracy: 0.3271\n",
      "Epoch 179/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3367 - accuracy: 0.2017 - val_loss: 2.2011 - val_accuracy: 0.3271\n",
      "Epoch 180/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3289 - accuracy: 0.2029 - val_loss: 2.2005 - val_accuracy: 0.3271\n",
      "Epoch 181/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3460 - accuracy: 0.1986 - val_loss: 2.2002 - val_accuracy: 0.3271\n",
      "Epoch 182/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3073 - accuracy: 0.2107 - val_loss: 2.1995 - val_accuracy: 0.3271\n",
      "Epoch 183/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3356 - accuracy: 0.1955 - val_loss: 2.1990 - val_accuracy: 0.3271\n",
      "Epoch 184/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3177 - accuracy: 0.2076 - val_loss: 2.1984 - val_accuracy: 0.3271\n",
      "Epoch 185/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.3161 - accuracy: 0.2123 - val_loss: 2.1980 - val_accuracy: 0.3271\n",
      "Epoch 186/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.3405 - accuracy: 0.1861 - val_loss: 2.1975 - val_accuracy: 0.3364\n",
      "Epoch 187/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3245 - accuracy: 0.2068 - val_loss: 2.1970 - val_accuracy: 0.3364\n",
      "Epoch 188/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3169 - accuracy: 0.2088 - val_loss: 2.1964 - val_accuracy: 0.3364\n",
      "Epoch 189/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3270 - accuracy: 0.1986 - val_loss: 2.1958 - val_accuracy: 0.3364\n",
      "Epoch 190/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3271 - accuracy: 0.2041 - val_loss: 2.1954 - val_accuracy: 0.3364\n",
      "Epoch 191/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3353 - accuracy: 0.1872 - val_loss: 2.1949 - val_accuracy: 0.3364\n",
      "Epoch 192/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3358 - accuracy: 0.1849 - val_loss: 2.1946 - val_accuracy: 0.3364\n",
      "Epoch 193/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3084 - accuracy: 0.2135 - val_loss: 2.1938 - val_accuracy: 0.3364\n",
      "Epoch 194/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3155 - accuracy: 0.2049 - val_loss: 2.1933 - val_accuracy: 0.3364\n",
      "Epoch 195/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3234 - accuracy: 0.2033 - val_loss: 2.1928 - val_accuracy: 0.3364\n",
      "Epoch 196/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.3015 - accuracy: 0.2080 - val_loss: 2.1924 - val_accuracy: 0.3364\n",
      "Epoch 197/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3192 - accuracy: 0.1939 - val_loss: 2.1919 - val_accuracy: 0.3364\n",
      "Epoch 198/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3070 - accuracy: 0.2088 - val_loss: 2.1913 - val_accuracy: 0.3364\n",
      "Epoch 199/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3283 - accuracy: 0.2002 - val_loss: 2.1909 - val_accuracy: 0.3364\n",
      "Epoch 200/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3148 - accuracy: 0.2021 - val_loss: 2.1906 - val_accuracy: 0.3364\n",
      "0.336448609828949 {'loss': 2.314753532409668, 'accuracy': 0.20211516320705414, 'val_loss': 2.1905927658081055, 'val_accuracy': 0.336448609828949}\n"
     ]
    }
   ],
   "source": [
    "#hyperparam tuning\n",
    "#learning_rate\n",
    "# learning_rates = [1e-5,1e-6,1e-7]\n",
    "learning_rates = [1e-5,1e-6]\n",
    "#hidden_layers\n",
    "# hidden_layers = [[41,75],[41,10],[41,10,10,10]]\n",
    "hidden_layers = [[41,75],[41,10,10,10]]\n",
    "#dropout\n",
    "dropouts = [0,.3,.5,.7]\n",
    "# dropouts = [.3,.5]\n",
    "#batch_size\n",
    "# batch_sizes = [8,16,32,64]\n",
    "batch_sizes = [16,32]\n",
    "#result\n",
    "result = {}\n",
    "best_history = None\n",
    "best_val_accuracy = 0\n",
    "best_model = None\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for hl in hidden_layers:\n",
    "        hl_str = '-'.join(map(str, hl))+'-3'\n",
    "        for dp in dropouts:\n",
    "            for bs in batch_sizes:\n",
    "                history, model = fit_model(lr, hl, dp, bs)\n",
    "                tmp = {}\n",
    "                tmp['loss'] = history.history['loss'][-1]\n",
    "                tmp['accuracy'] = history.history['accuracy'][-1]\n",
    "                tmp['val_loss'] = history.history['val_loss'][-1]\n",
    "                tmp['val_accuracy'] = history.history['val_accuracy'][-1]\n",
    "    #             print(history)\n",
    "                result[(lr,hl_str,dp, bs)] = tmp\n",
    "                print(tmp['val_accuracy'], tmp)\n",
    "                if tmp['val_accuracy'] > best_val_accuracy:\n",
    "                    best_val_accuracy = tmp['val_accuracy']\n",
    "                    best_history = history\n",
    "                    best_model = model\n",
    "                \n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2020-06-14_18-15-46_hyper_param_result.npy'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "timestamp = datetime.now()\n",
    "timestamp = timestamp.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "timestamp + '_hyper_param_result.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(1e-05, '41-75-3', 0, 16): {'loss': 1.0177156925201416,\n",
       "  'accuracy': 0.5045045018196106,\n",
       "  'val_loss': 0.9678374528884888,\n",
       "  'val_accuracy': 0.5233644843101501},\n",
       " (1e-05, '41-75-3', 0, 32): {'loss': 1.0832277536392212,\n",
       "  'accuracy': 0.4868781864643097,\n",
       "  'val_loss': 1.0739868879318237,\n",
       "  'val_accuracy': 0.4953271150588989},\n",
       " (1e-05, '41-75-3', 0.3, 16): {'loss': 2.300823450088501,\n",
       "  'accuracy': 0.43830788135528564,\n",
       "  'val_loss': 1.6535708904266357,\n",
       "  'val_accuracy': 0.5420560836791992},\n",
       " (1e-05, '41-75-3', 0.3, 32): {'loss': 2.377525806427002,\n",
       "  'accuracy': 0.42969056963920593,\n",
       "  'val_loss': 1.7633767127990723,\n",
       "  'val_accuracy': 0.514018714427948},\n",
       " (1e-05, '41-75-3', 0.5, 16): {'loss': 3.3005502223968506,\n",
       "  'accuracy': 0.37837839126586914,\n",
       "  'val_loss': 2.8191776275634766,\n",
       "  'val_accuracy': 0.6168224215507507},\n",
       " (1e-05, '41-75-3', 0.5, 32): {'loss': 2.948958158493042,\n",
       "  'accuracy': 0.37681159377098083,\n",
       "  'val_loss': 2.3832387924194336,\n",
       "  'val_accuracy': 0.5420560836791992},\n",
       " (1e-05, '41-75-3', 0.7, 16): {'loss': 3.5411782264709473,\n",
       "  'accuracy': 0.35213473439216614,\n",
       "  'val_loss': 3.1992664337158203,\n",
       "  'val_accuracy': 0.5046728849411011},\n",
       " (1e-05, '41-75-3', 0.7, 32): {'loss': 3.6251943111419678,\n",
       "  'accuracy': 0.3266744911670685,\n",
       "  'val_loss': 3.298799514770508,\n",
       "  'val_accuracy': 0.5046728849411011},\n",
       " (1e-05, '41-10-10-10-3', 0, 16): {'loss': 1.5416814088821411,\n",
       "  'accuracy': 0.5037211179733276,\n",
       "  'val_loss': 1.463592529296875,\n",
       "  'val_accuracy': 0.5607476830482483},\n",
       " (1e-05, '41-10-10-10-3', 0, 32): {'loss': 1.9660307168960571,\n",
       "  'accuracy': 0.2984723746776581,\n",
       "  'val_loss': 1.9500761032104492,\n",
       "  'val_accuracy': 0.29906541109085083},\n",
       " (1e-05, '41-10-10-10-3', 0.3, 16): {'loss': 1.6450891494750977,\n",
       "  'accuracy': 0.4375244677066803,\n",
       "  'val_loss': 1.3364527225494385,\n",
       "  'val_accuracy': 0.5233644843101501},\n",
       " (1e-05, '41-10-10-10-3', 0.3, 32): {'loss': 1.9460257291793823,\n",
       "  'accuracy': 0.3725029230117798,\n",
       "  'val_loss': 1.8061615228652954,\n",
       "  'val_accuracy': 0.47663551568984985},\n",
       " (1e-05, '41-10-10-10-3', 0.5, 16): {'loss': 2.049022674560547,\n",
       "  'accuracy': 0.3689776659011841,\n",
       "  'val_loss': 1.8924561738967896,\n",
       "  'val_accuracy': 0.47663551568984985},\n",
       " (1e-05, '41-10-10-10-3', 0.5, 32): {'loss': 2.0919721126556396,\n",
       "  'accuracy': 0.3137485384941101,\n",
       "  'val_loss': 1.9597609043121338,\n",
       "  'val_accuracy': 0.47663551568984985},\n",
       " (1e-05, '41-10-10-10-3', 0.7, 16): {'loss': 2.2476909160614014,\n",
       "  'accuracy': 0.25303563475608826,\n",
       "  'val_loss': 2.218731641769409,\n",
       "  'val_accuracy': 0.22429905831813812},\n",
       " (1e-05, '41-10-10-10-3', 0.7, 32): {'loss': 2.0935239791870117,\n",
       "  'accuracy': 0.331374853849411,\n",
       "  'val_loss': 1.8868650197982788,\n",
       "  'val_accuracy': 0.5233644843101501},\n",
       " (1e-06, '41-75-3', 0, 16): {'loss': 2.785413980484009,\n",
       "  'accuracy': 0.32510772347450256,\n",
       "  'val_loss': 2.92917799949646,\n",
       "  'val_accuracy': 0.2710280418395996},\n",
       " (1e-06, '41-75-3', 0, 32): {'loss': 3.84824800491333,\n",
       "  'accuracy': 0.20877398550510406,\n",
       "  'val_loss': 3.952089309692383,\n",
       "  'val_accuracy': 0.20560747385025024},\n",
       " (1e-06, '41-75-3', 0.3, 16): {'loss': 2.8564412593841553,\n",
       "  'accuracy': 0.3478260934352875,\n",
       "  'val_loss': 2.5484273433685303,\n",
       "  'val_accuracy': 0.37383177876472473},\n",
       " (1e-06, '41-75-3', 0.3, 32): {'loss': 3.861748456954956,\n",
       "  'accuracy': 0.15942029654979706,\n",
       "  'val_loss': 3.5883193016052246,\n",
       "  'val_accuracy': 0.20560747385025024},\n",
       " (1e-06, '41-75-3', 0.5, 16): {'loss': 3.7185676097869873,\n",
       "  'accuracy': 0.2542107403278351,\n",
       "  'val_loss': 3.412414073944092,\n",
       "  'val_accuracy': 0.4392523467540741},\n",
       " (1e-06, '41-75-3', 0.5, 32): {'loss': 4.355992794036865,\n",
       "  'accuracy': 0.07912260293960571,\n",
       "  'val_loss': 4.056273460388184,\n",
       "  'val_accuracy': 0.04672897234559059},\n",
       " (1e-06, '41-75-3', 0.7, 16): {'loss': 4.487292766571045,\n",
       "  'accuracy': 0.08734821528196335,\n",
       "  'val_loss': 3.8906023502349854,\n",
       "  'val_accuracy': 0.14018692076206207},\n",
       " (1e-06, '41-75-3', 0.7, 32): {'loss': 4.868354320526123,\n",
       "  'accuracy': 0.10419114679098129,\n",
       "  'val_loss': 3.697763204574585,\n",
       "  'val_accuracy': 0.25233644247055054},\n",
       " (1e-06, '41-10-10-10-3', 0, 16): {'loss': 2.157241106033325,\n",
       "  'accuracy': 0.24637681245803833,\n",
       "  'val_loss': 2.167663097381592,\n",
       "  'val_accuracy': 0.22429905831813812},\n",
       " (1e-06, '41-10-10-10-3', 0, 32): {'loss': 1.9295059442520142,\n",
       "  'accuracy': 0.2835879325866699,\n",
       "  'val_loss': 1.9253970384597778,\n",
       "  'val_accuracy': 0.25233644247055054},\n",
       " (1e-06, '41-10-10-10-3', 0.3, 16): {'loss': 1.9849711656570435,\n",
       "  'accuracy': 0.3548766076564789,\n",
       "  'val_loss': 1.8836334943771362,\n",
       "  'val_accuracy': 0.47663551568984985},\n",
       " (1e-06, '41-10-10-10-3', 0.3, 32): {'loss': 2.2654006481170654,\n",
       "  'accuracy': 0.17312964797019958,\n",
       "  'val_loss': 2.2263681888580322,\n",
       "  'val_accuracy': 0.18691588938236237},\n",
       " (1e-06, '41-10-10-10-3', 0.5, 16): {'loss': 2.173461437225342,\n",
       "  'accuracy': 0.25499412417411804,\n",
       "  'val_loss': 2.133169651031494,\n",
       "  'val_accuracy': 0.32710281014442444},\n",
       " (1e-06, '41-10-10-10-3', 0.5, 32): {'loss': 2.2874386310577393,\n",
       "  'accuracy': 0.17547982931137085,\n",
       "  'val_loss': 2.240968942642212,\n",
       "  'val_accuracy': 0.17757008969783783},\n",
       " (1e-06, '41-10-10-10-3', 0.7, 16): {'loss': 2.299208402633667,\n",
       "  'accuracy': 0.17430473864078522,\n",
       "  'val_loss': 2.2809770107269287,\n",
       "  'val_accuracy': 0.25233644247055054},\n",
       " (1e-06, '41-10-10-10-3', 0.7, 32): {'loss': 2.314753532409668,\n",
       "  'accuracy': 0.20211516320705414,\n",
       "  'val_loss': 2.1905927658081055,\n",
       "  'val_accuracy': 0.336448609828949}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.save(timestamp + '_hyper_param_result.npy', result) \n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = best_model\n",
    "history = best_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='validation')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.plot(history.history['acc'], label='train')\n",
    "# plt.plot(history.history['val_acc'], label='validation')\n",
    "plt.plot(history.history['accuracy'], label='train')\n",
    "plt.plot(history.history['val_accuracy'], label='validation')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.5105263157894737\n"
     ]
    }
   ],
   "source": [
    "test_predictions = np.argmax(model.predict(X_test), axis=1)\n",
    "accuracy = (test_predictions == y_test.values).sum() / y_test.values.shape[0]\n",
    "print(\"Test set accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y train\n",
      "Unique train labels: [0 1 2]\n",
      "Away win count: 757\n",
      "Draw count: 686\n",
      "Away win count: 1217\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(\"Y train\")\n",
    "print(\"Unique train labels:\", np.unique(y_train.values))\n",
    "print(\"Away win count:\", (y_train==0).sum())\n",
    "print(\"Draw count:\", (y_train==1).sum())\n",
    "print(\"Away win count:\", (y_train==2).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Prediction\n",
      "Unique train labels: [0 2]\n",
      "Away win count: 757\n",
      "Draw count: 686\n",
      "Home win count: 1217\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Prediction\")\n",
    "train_predictions = np.argmax(model.predict(X_train), axis=1)\n",
    "print(\"Unique train labels:\", np.unique(train_predictions))\n",
    "print(\"Away win count:\", (y_train==0).sum())\n",
    "print(\"Draw count:\", (y_train==1).sum())\n",
    "print(\"Home win count:\", (y_train==2).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred home</th>\n",
       "      <th>pred draw</th>\n",
       "      <th>pred away</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true home</th>\n",
       "      <td>346</td>\n",
       "      <td>0</td>\n",
       "      <td>411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true draw</th>\n",
       "      <td>238</td>\n",
       "      <td>0</td>\n",
       "      <td>448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true away</th>\n",
       "      <td>211</td>\n",
       "      <td>0</td>\n",
       "      <td>1006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pred home  pred draw  pred away\n",
       "true home        346          0        411\n",
       "true draw        238          0        448\n",
       "true away        211          0       1006"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train\n",
    "df_conf_matrix = pd.DataFrame(confusion_matrix(y_train, train_predictions, labels=[0, 1, 2]), \n",
    "             index=['true home', 'true draw', 'true away'], columns=['pred home', 'pred draw', 'pred away'])\n",
    "print(\"Train Data\")\n",
    "df_conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred home</th>\n",
       "      <th>pred draw</th>\n",
       "      <th>pred away</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true home</th>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true draw</th>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true away</th>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pred home  pred draw  pred away\n",
       "true home         56          0         54\n",
       "true draw         26          0         71\n",
       "true away         35          0        138"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test\n",
    "df_conf_matrix = pd.DataFrame(confusion_matrix(y_test, test_predictions, labels=[0, 1, 2]), \n",
    "             index=['true home', 'true draw', 'true away'], columns=['pred home', 'pred draw', 'pred away'])\n",
    "print(\"Test Data\")\n",
    "df_conf_matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
