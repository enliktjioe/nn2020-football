{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# making all pandas columns visable with display command\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, Activation, Flatten, Dense, Dropout, LSTM\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(\"X_2d.npy\")\n",
    "y = np.load(\"y_2d.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 41-75-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 20, 32)]          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 640)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 41)                26281     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 75)                3150      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 75)                0         \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 75)                0         \n",
      "=================================================================\n",
      "Total params: 29,431\n",
      "Trainable params: 29,431\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# We first need to define the sequence of dependencies (the computational graph)\n",
    "x = Input(shape=(20,32))\n",
    "# h = Conv2D(32, (7, 7), strides=(2, 2))(x)\n",
    "# h = Activation('relu')(x)\n",
    "h = Flatten()(x)\n",
    "h = Dense(41)(h)\n",
    "h = Dense(75)(h)\n",
    "# h = Dense(40)(h)\n",
    "# h = Dense(40)(h)\n",
    "h = Dropout(0.3)(h)\n",
    "p = Activation('softmax')(h)\n",
    "\n",
    "# Now that we have defined how to find p from x, we can create a \n",
    "# model simply by saying what is input and what is output\n",
    "model = Model(inputs=x, outputs=p)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(lr=0.00001), metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2010 samples, validate on 84 samples\n",
      "Epoch 1/200\n",
      "2010/2010 [==============================] - 0s 238us/sample - loss: 901883.7586 - accuracy: 0.0000e+00 - val_loss: 661337.6161 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/200\n",
      "2010/2010 [==============================] - 0s 33us/sample - loss: 855082.5091 - accuracy: 0.0000e+00 - val_loss: 622786.7173 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/200\n",
      "2010/2010 [==============================] - 0s 31us/sample - loss: 809311.2088 - accuracy: 0.0000e+00 - val_loss: 584618.5357 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/200\n",
      "2010/2010 [==============================] - 0s 29us/sample - loss: 764758.1901 - accuracy: 0.0000e+00 - val_loss: 546596.6488 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/200\n",
      "2010/2010 [==============================] - 0s 32us/sample - loss: 714363.1907 - accuracy: 0.0000e+00 - val_loss: 509213.0565 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/200\n",
      "2010/2010 [==============================] - 0s 31us/sample - loss: 672611.5201 - accuracy: 0.0000e+00 - val_loss: 473941.9539 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/200\n",
      "2010/2010 [==============================] - 0s 34us/sample - loss: 627680.4415 - accuracy: 0.0000e+00 - val_loss: 439238.9301 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/200\n",
      "2010/2010 [==============================] - 0s 35us/sample - loss: 582659.0131 - accuracy: 0.0000e+00 - val_loss: 405254.9598 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/200\n",
      "2010/2010 [==============================] - 0s 34us/sample - loss: 548934.8717 - accuracy: 0.0000e+00 - val_loss: 375760.9256 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/200\n",
      "2010/2010 [==============================] - 0s 33us/sample - loss: 510337.8504 - accuracy: 0.0000e+00 - val_loss: 349133.5506 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/200\n",
      "2010/2010 [==============================] - 0s 31us/sample - loss: 485478.5708 - accuracy: 0.0000e+00 - val_loss: 324066.4137 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/200\n",
      "2010/2010 [==============================] - 0s 32us/sample - loss: 453614.4835 - accuracy: 0.0000e+00 - val_loss: 299796.8661 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/200\n",
      "2010/2010 [==============================] - 0s 32us/sample - loss: 423500.3567 - accuracy: 0.0000e+00 - val_loss: 275791.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/200\n",
      "2010/2010 [==============================] - 0s 38us/sample - loss: 395926.1678 - accuracy: 0.0000e+00 - val_loss: 252015.9888 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/200\n",
      "2010/2010 [==============================] - 0s 34us/sample - loss: 368804.3792 - accuracy: 0.0000e+00 - val_loss: 228476.7210 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/200\n",
      "2010/2010 [==============================] - 0s 31us/sample - loss: 334879.6566 - accuracy: 0.0000e+00 - val_loss: 204707.5781 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/200\n",
      "2010/2010 [==============================] - 0s 33us/sample - loss: 310517.5981 - accuracy: 0.1313 - val_loss: 189361.0499 - val_accuracy: 0.3690\n",
      "Epoch 18/200\n",
      "2010/2010 [==============================] - 0s 35us/sample - loss: 293455.0288 - accuracy: 0.1910 - val_loss: 179873.4092 - val_accuracy: 0.3214\n",
      "Epoch 19/200\n",
      "2010/2010 [==============================] - 0s 37us/sample - loss: 283460.5402 - accuracy: 0.1955 - val_loss: 170885.6458 - val_accuracy: 0.2976\n",
      "Epoch 20/200\n",
      "2010/2010 [==============================] - 0s 35us/sample - loss: 268633.6909 - accuracy: 0.2005 - val_loss: 161813.0045 - val_accuracy: 0.2857\n",
      "Epoch 21/200\n",
      "2010/2010 [==============================] - 0s 37us/sample - loss: 257539.0611 - accuracy: 0.2075 - val_loss: 152733.2545 - val_accuracy: 0.2857\n",
      "Epoch 22/200\n",
      "2010/2010 [==============================] - 0s 32us/sample - loss: 238151.6433 - accuracy: 0.2025 - val_loss: 143928.5818 - val_accuracy: 0.3333\n",
      "Epoch 23/200\n",
      "2010/2010 [==============================] - 0s 32us/sample - loss: 232405.4699 - accuracy: 0.1990 - val_loss: 135262.8341 - val_accuracy: 0.3214\n",
      "Epoch 24/200\n",
      "2010/2010 [==============================] - 0s 30us/sample - loss: 219261.7294 - accuracy: 0.1960 - val_loss: 126395.8876 - val_accuracy: 0.3214\n",
      "Epoch 25/200\n",
      "2010/2010 [==============================] - 0s 32us/sample - loss: 205899.1123 - accuracy: 0.1960 - val_loss: 117825.3869 - val_accuracy: 0.3214\n",
      "Epoch 26/200\n",
      "2010/2010 [==============================] - 0s 33us/sample - loss: 190733.3271 - accuracy: 0.1990 - val_loss: 109377.0000 - val_accuracy: 0.2738\n",
      "Epoch 27/200\n",
      "2010/2010 [==============================] - 0s 32us/sample - loss: 178264.6865 - accuracy: 0.2020 - val_loss: 100953.0227 - val_accuracy: 0.2738\n",
      "Epoch 28/200\n",
      "2010/2010 [==============================] - 0s 33us/sample - loss: 166514.7560 - accuracy: 0.2020 - val_loss: 92319.2150 - val_accuracy: 0.2857\n",
      "Epoch 29/200\n",
      "2010/2010 [==============================] - 0s 38us/sample - loss: 152848.4886 - accuracy: 0.2045 - val_loss: 83836.0926 - val_accuracy: 0.3333\n",
      "Epoch 30/200\n",
      "2010/2010 [==============================] - 0s 41us/sample - loss: 138082.9869 - accuracy: 0.2060 - val_loss: 75488.3832 - val_accuracy: 0.3214\n",
      "Epoch 31/200\n",
      "2010/2010 [==============================] - 0s 35us/sample - loss: 127362.2278 - accuracy: 0.2149 - val_loss: 67117.9702 - val_accuracy: 0.2857\n",
      "Epoch 32/200\n",
      "2010/2010 [==============================] - 0s 36us/sample - loss: 118859.6905 - accuracy: 0.1891 - val_loss: 58996.5060 - val_accuracy: 0.2976\n",
      "Epoch 33/200\n",
      "2010/2010 [==============================] - 0s 32us/sample - loss: 105574.1208 - accuracy: 0.2030 - val_loss: 50934.4734 - val_accuracy: 0.3333\n",
      "Epoch 34/200\n",
      "2010/2010 [==============================] - 0s 35us/sample - loss: 94544.2192 - accuracy: 0.2060 - val_loss: 42873.3142 - val_accuracy: 0.2619\n",
      "Epoch 35/200\n",
      "2010/2010 [==============================] - 0s 33us/sample - loss: 80788.3895 - accuracy: 0.2104 - val_loss: 34862.1115 - val_accuracy: 0.3214\n",
      "Epoch 36/200\n",
      "2010/2010 [==============================] - 0s 33us/sample - loss: 71771.9397 - accuracy: 0.2030 - val_loss: 27116.3849 - val_accuracy: 0.2976\n",
      "Epoch 37/200\n",
      "2010/2010 [==============================] - 0s 33us/sample - loss: 59861.8863 - accuracy: 0.1980 - val_loss: 19534.1469 - val_accuracy: 0.3095\n",
      "Epoch 38/200\n",
      "2010/2010 [==============================] - 0s 35us/sample - loss: 50897.1139 - accuracy: 0.2055 - val_loss: 12272.7434 - val_accuracy: 0.2857\n",
      "Epoch 39/200\n",
      "2010/2010 [==============================] - 0s 35us/sample - loss: 40422.4424 - accuracy: 0.2363 - val_loss: 7303.2934 - val_accuracy: 0.3095\n",
      "Epoch 40/200\n",
      "2010/2010 [==============================] - 0s 35us/sample - loss: 38076.2714 - accuracy: 0.2393 - val_loss: 5122.6628 - val_accuracy: 0.3214\n",
      "Epoch 41/200\n",
      "2010/2010 [==============================] - 0s 33us/sample - loss: 35973.2282 - accuracy: 0.2512 - val_loss: 4909.6324 - val_accuracy: 0.3452\n",
      "Epoch 42/200\n",
      "2010/2010 [==============================] - 0s 29us/sample - loss: 34169.9695 - accuracy: 0.2612 - val_loss: 4732.6426 - val_accuracy: 0.3333\n",
      "Epoch 43/200\n",
      "2010/2010 [==============================] - 0s 30us/sample - loss: 35813.3311 - accuracy: 0.2493 - val_loss: 4664.3525 - val_accuracy: 0.3452\n",
      "Epoch 44/200\n",
      "2010/2010 [==============================] - 0s 33us/sample - loss: 33613.3314 - accuracy: 0.2542 - val_loss: 4546.7757 - val_accuracy: 0.3452\n",
      "Epoch 45/200\n",
      "2010/2010 [==============================] - 0s 37us/sample - loss: 30000.8257 - accuracy: 0.2652 - val_loss: 4394.8190 - val_accuracy: 0.3571\n",
      "Epoch 46/200\n",
      "2010/2010 [==============================] - 0s 32us/sample - loss: 31352.1439 - accuracy: 0.2473 - val_loss: 4349.5968 - val_accuracy: 0.3214\n",
      "Epoch 47/200\n",
      "2010/2010 [==============================] - 0s 31us/sample - loss: 28767.4985 - accuracy: 0.2597 - val_loss: 4272.8798 - val_accuracy: 0.3333\n",
      "Epoch 48/200\n",
      "2010/2010 [==============================] - 0s 33us/sample - loss: 27414.6971 - accuracy: 0.2522 - val_loss: 4223.8954 - val_accuracy: 0.3333\n",
      "Epoch 49/200\n",
      "2010/2010 [==============================] - 0s 30us/sample - loss: 28175.1040 - accuracy: 0.2363 - val_loss: 4199.5043 - val_accuracy: 0.3333\n",
      "Epoch 50/200\n",
      "2010/2010 [==============================] - 0s 31us/sample - loss: 26443.6585 - accuracy: 0.2672 - val_loss: 4110.9993 - val_accuracy: 0.3452\n",
      "Epoch 51/200\n",
      "2010/2010 [==============================] - 0s 32us/sample - loss: 25509.8775 - accuracy: 0.2597 - val_loss: 4029.6976 - val_accuracy: 0.3333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/200\n",
      "2010/2010 [==============================] - 0s 31us/sample - loss: 24275.2507 - accuracy: 0.2433 - val_loss: 4281.8164 - val_accuracy: 0.2500\n",
      "Epoch 53/200\n",
      "2010/2010 [==============================] - 0s 32us/sample - loss: 22998.6944 - accuracy: 0.2423 - val_loss: 3933.2622 - val_accuracy: 0.2738\n",
      "Epoch 54/200\n",
      "2010/2010 [==============================] - 0s 33us/sample - loss: 21845.3967 - accuracy: 0.2572 - val_loss: 3906.3402 - val_accuracy: 0.2976\n",
      "Epoch 55/200\n",
      "2010/2010 [==============================] - 0s 31us/sample - loss: 20996.7544 - accuracy: 0.2577 - val_loss: 3819.1771 - val_accuracy: 0.3095\n",
      "Epoch 56/200\n",
      "2010/2010 [==============================] - 0s 32us/sample - loss: 20610.4995 - accuracy: 0.2632 - val_loss: 3808.1704 - val_accuracy: 0.2738\n",
      "Epoch 57/200\n",
      "2010/2010 [==============================] - 0s 32us/sample - loss: 19345.2751 - accuracy: 0.2512 - val_loss: 3781.1878 - val_accuracy: 0.2619\n",
      "Epoch 58/200\n",
      "2010/2010 [==============================] - 0s 31us/sample - loss: 19391.8773 - accuracy: 0.2517 - val_loss: 3829.2383 - val_accuracy: 0.2500\n",
      "Epoch 59/200\n",
      "2010/2010 [==============================] - 0s 35us/sample - loss: 18608.5133 - accuracy: 0.2532 - val_loss: 3905.3874 - val_accuracy: 0.1667\n",
      "Epoch 60/200\n",
      "2010/2010 [==============================] - 0s 36us/sample - loss: 17531.5534 - accuracy: 0.2532 - val_loss: 3723.5763 - val_accuracy: 0.2857\n",
      "Epoch 61/200\n",
      "2010/2010 [==============================] - 0s 41us/sample - loss: 16198.9370 - accuracy: 0.2622 - val_loss: 3698.4406 - val_accuracy: 0.2857\n",
      "Epoch 62/200\n",
      "2010/2010 [==============================] - 0s 35us/sample - loss: 16275.7128 - accuracy: 0.2622 - val_loss: 3714.7466 - val_accuracy: 0.2500\n",
      "Epoch 63/200\n",
      "2010/2010 [==============================] - 0s 37us/sample - loss: 14931.8886 - accuracy: 0.2687 - val_loss: 3715.2945 - val_accuracy: 0.2262\n",
      "Epoch 64/200\n",
      "2010/2010 [==============================] - 0s 36us/sample - loss: 14752.1018 - accuracy: 0.2453 - val_loss: 3654.1159 - val_accuracy: 0.2619\n",
      "Epoch 65/200\n",
      "2010/2010 [==============================] - 0s 32us/sample - loss: 13596.8468 - accuracy: 0.2517 - val_loss: 3659.8582 - val_accuracy: 0.2619\n",
      "Epoch 66/200\n",
      "2010/2010 [==============================] - 0s 31us/sample - loss: 13378.5757 - accuracy: 0.2662 - val_loss: 3719.6852 - val_accuracy: 0.2738\n",
      "Epoch 67/200\n",
      "2010/2010 [==============================] - 0s 30us/sample - loss: 12419.3248 - accuracy: 0.2532 - val_loss: 3719.8669 - val_accuracy: 0.3571\n",
      "Epoch 68/200\n",
      "2010/2010 [==============================] - 0s 31us/sample - loss: 11581.4772 - accuracy: 0.2751 - val_loss: 3694.0706 - val_accuracy: 0.2857\n",
      "Epoch 69/200\n",
      "2010/2010 [==============================] - 0s 32us/sample - loss: 11168.3436 - accuracy: 0.2701 - val_loss: 3757.2041 - val_accuracy: 0.3452\n",
      "Epoch 70/200\n",
      "2010/2010 [==============================] - 0s 33us/sample - loss: 10454.0001 - accuracy: 0.2791 - val_loss: 3753.4897 - val_accuracy: 0.1548\n",
      "Epoch 71/200\n",
      "2010/2010 [==============================] - 0s 34us/sample - loss: 9740.0791 - accuracy: 0.2711 - val_loss: 3758.1466 - val_accuracy: 0.2143\n",
      "Epoch 72/200\n",
      "2010/2010 [==============================] - 0s 32us/sample - loss: 9284.2972 - accuracy: 0.2672 - val_loss: 3705.6555 - val_accuracy: 0.3095\n",
      "Epoch 73/200\n",
      "2010/2010 [==============================] - 0s 32us/sample - loss: 8668.5470 - accuracy: 0.2667 - val_loss: 3890.7715 - val_accuracy: 0.3333\n",
      "Epoch 74/200\n",
      "2010/2010 [==============================] - 0s 36us/sample - loss: 7746.1577 - accuracy: 0.2736 - val_loss: 3738.1375 - val_accuracy: 0.2857\n",
      "Epoch 75/200\n",
      "2010/2010 [==============================] - 0s 32us/sample - loss: 7350.5760 - accuracy: 0.2891 - val_loss: 3681.5398 - val_accuracy: 0.2738\n",
      "Epoch 76/200\n",
      "2010/2010 [==============================] - 0s 37us/sample - loss: 6793.3771 - accuracy: 0.2836 - val_loss: 3542.4085 - val_accuracy: 0.4048\n",
      "Epoch 77/200\n",
      "2010/2010 [==============================] - 0s 33us/sample - loss: 6432.8286 - accuracy: 0.3060 - val_loss: 3502.8161 - val_accuracy: 0.1905\n",
      "Epoch 78/200\n",
      "2010/2010 [==============================] - 0s 32us/sample - loss: 6033.8994 - accuracy: 0.2816 - val_loss: 3354.8597 - val_accuracy: 0.1667\n",
      "Epoch 79/200\n",
      "2010/2010 [==============================] - 0s 31us/sample - loss: 5713.2070 - accuracy: 0.2960 - val_loss: 3136.9506 - val_accuracy: 0.3929\n",
      "Epoch 80/200\n",
      "2010/2010 [==============================] - 0s 32us/sample - loss: 5600.3044 - accuracy: 0.3005 - val_loss: 3014.1819 - val_accuracy: 0.4524\n",
      "Epoch 81/200\n",
      "2010/2010 [==============================] - 0s 31us/sample - loss: 5471.4812 - accuracy: 0.3010 - val_loss: 2989.5867 - val_accuracy: 0.4167\n",
      "Epoch 82/200\n",
      "2010/2010 [==============================] - 0s 32us/sample - loss: 5025.1905 - accuracy: 0.2970 - val_loss: 2839.4296 - val_accuracy: 0.4286\n",
      "Epoch 83/200\n",
      "2010/2010 [==============================] - 0s 32us/sample - loss: 5014.5303 - accuracy: 0.3080 - val_loss: 2796.3162 - val_accuracy: 0.4286\n",
      "Epoch 84/200\n",
      "2010/2010 [==============================] - 0s 32us/sample - loss: 4970.4086 - accuracy: 0.2935 - val_loss: 2735.4861 - val_accuracy: 0.4048\n",
      "Epoch 85/200\n",
      "2010/2010 [==============================] - 0s 32us/sample - loss: 4708.6025 - accuracy: 0.3000 - val_loss: 2595.0042 - val_accuracy: 0.4048\n",
      "Epoch 86/200\n",
      "2010/2010 [==============================] - 0s 32us/sample - loss: 4532.9467 - accuracy: 0.3294 - val_loss: 2522.8620 - val_accuracy: 0.3095\n",
      "Epoch 87/200\n",
      "2010/2010 [==============================] - 0s 32us/sample - loss: 4366.3824 - accuracy: 0.3294 - val_loss: 2463.2358 - val_accuracy: 0.3452\n",
      "Epoch 88/200\n",
      "2010/2010 [==============================] - 0s 31us/sample - loss: 4258.0058 - accuracy: 0.3224 - val_loss: 2428.2251 - val_accuracy: 0.4286\n",
      "Epoch 89/200\n",
      "2010/2010 [==============================] - 0s 31us/sample - loss: 4414.3632 - accuracy: 0.3249 - val_loss: 2353.6477 - val_accuracy: 0.3214\n",
      "Epoch 90/200\n",
      "2010/2010 [==============================] - 0s 33us/sample - loss: 4542.4556 - accuracy: 0.3294 - val_loss: 2305.5358 - val_accuracy: 0.3452\n",
      "Epoch 91/200\n",
      "2010/2010 [==============================] - 0s 33us/sample - loss: 4290.2484 - accuracy: 0.3353 - val_loss: 2277.4909 - val_accuracy: 0.3214\n",
      "Epoch 92/200\n",
      "2010/2010 [==============================] - 0s 36us/sample - loss: 4373.1871 - accuracy: 0.3095 - val_loss: 2244.7104 - val_accuracy: 0.3810\n",
      "Epoch 93/200\n",
      "2010/2010 [==============================] - 0s 35us/sample - loss: 4324.8880 - accuracy: 0.3194 - val_loss: 2197.0364 - val_accuracy: 0.3095\n",
      "Epoch 94/200\n",
      "2010/2010 [==============================] - 0s 35us/sample - loss: 4114.7117 - accuracy: 0.3139 - val_loss: 2197.6291 - val_accuracy: 0.4643\n",
      "Epoch 95/200\n",
      "2010/2010 [==============================] - 0s 39us/sample - loss: 4142.6842 - accuracy: 0.3114 - val_loss: 2219.9183 - val_accuracy: 0.3929\n",
      "Epoch 96/200\n",
      "2010/2010 [==============================] - 0s 37us/sample - loss: 3932.3352 - accuracy: 0.3139 - val_loss: 2157.5250 - val_accuracy: 0.3810\n",
      "Epoch 97/200\n",
      "2010/2010 [==============================] - 0s 39us/sample - loss: 4077.6598 - accuracy: 0.3159 - val_loss: 2144.3398 - val_accuracy: 0.3571\n",
      "Epoch 98/200\n",
      "2010/2010 [==============================] - 0s 40us/sample - loss: 4141.1825 - accuracy: 0.3254 - val_loss: 2106.2543 - val_accuracy: 0.3333\n",
      "Epoch 99/200\n",
      "2010/2010 [==============================] - 0s 37us/sample - loss: 3993.2946 - accuracy: 0.3284 - val_loss: 2211.4931 - val_accuracy: 0.4286\n",
      "Epoch 100/200\n",
      "2010/2010 [==============================] - 0s 36us/sample - loss: 3972.2558 - accuracy: 0.3179 - val_loss: 2092.3489 - val_accuracy: 0.3214\n",
      "Epoch 101/200\n",
      "2010/2010 [==============================] - 0s 39us/sample - loss: 3860.8586 - accuracy: 0.3179 - val_loss: 2200.9165 - val_accuracy: 0.3095\n",
      "Epoch 102/200\n",
      "2010/2010 [==============================] - 0s 39us/sample - loss: 3953.7227 - accuracy: 0.3104 - val_loss: 2071.2427 - val_accuracy: 0.3214\n",
      "Epoch 103/200\n",
      "2010/2010 [==============================] - 0s 38us/sample - loss: 4212.1452 - accuracy: 0.3303 - val_loss: 2054.4820 - val_accuracy: 0.2976\n",
      "Epoch 104/200\n",
      "2010/2010 [==============================] - 0s 37us/sample - loss: 3777.5051 - accuracy: 0.3249 - val_loss: 2111.6755 - val_accuracy: 0.2262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105/200\n",
      "2010/2010 [==============================] - 0s 42us/sample - loss: 3938.4277 - accuracy: 0.3204 - val_loss: 2032.9836 - val_accuracy: 0.4167\n",
      "Epoch 106/200\n",
      "2010/2010 [==============================] - 0s 46us/sample - loss: 4015.8877 - accuracy: 0.3333 - val_loss: 1993.8284 - val_accuracy: 0.4286\n",
      "Epoch 107/200\n",
      "2010/2010 [==============================] - 0s 40us/sample - loss: 3886.0114 - accuracy: 0.3244 - val_loss: 2006.7693 - val_accuracy: 0.4167\n",
      "Epoch 108/200\n",
      "2010/2010 [==============================] - 0s 40us/sample - loss: 3881.7126 - accuracy: 0.3184 - val_loss: 2057.4808 - val_accuracy: 0.4405\n",
      "Epoch 109/200\n",
      "2010/2010 [==============================] - 0s 34us/sample - loss: 3768.1803 - accuracy: 0.3254 - val_loss: 2017.0686 - val_accuracy: 0.3452\n",
      "Epoch 110/200\n",
      "2010/2010 [==============================] - 0s 34us/sample - loss: 3962.1318 - accuracy: 0.3075 - val_loss: 2009.6238 - val_accuracy: 0.2976\n",
      "Epoch 111/200\n",
      "2010/2010 [==============================] - 0s 35us/sample - loss: 3823.9310 - accuracy: 0.3244 - val_loss: 1983.1958 - val_accuracy: 0.3929\n",
      "Epoch 112/200\n",
      "2010/2010 [==============================] - 0s 33us/sample - loss: 3576.9616 - accuracy: 0.3224 - val_loss: 2017.9262 - val_accuracy: 0.4286\n",
      "Epoch 113/200\n",
      "2010/2010 [==============================] - 0s 33us/sample - loss: 3783.2019 - accuracy: 0.3254 - val_loss: 1982.1693 - val_accuracy: 0.4405\n",
      "Epoch 114/200\n",
      "2010/2010 [==============================] - 0s 33us/sample - loss: 3881.4434 - accuracy: 0.3313 - val_loss: 1943.5424 - val_accuracy: 0.2976\n",
      "Epoch 115/200\n",
      "2010/2010 [==============================] - 0s 32us/sample - loss: 3807.1560 - accuracy: 0.3154 - val_loss: 1967.9526 - val_accuracy: 0.3333\n",
      "Epoch 116/200\n",
      "2010/2010 [==============================] - 0s 31us/sample - loss: 3900.5699 - accuracy: 0.3199 - val_loss: 1906.5833 - val_accuracy: 0.2738\n",
      "Epoch 117/200\n",
      "2010/2010 [==============================] - 0s 32us/sample - loss: 3803.5890 - accuracy: 0.3254 - val_loss: 1891.6643 - val_accuracy: 0.3452\n",
      "Epoch 118/200\n",
      "2010/2010 [==============================] - 0s 32us/sample - loss: 3623.9095 - accuracy: 0.3134 - val_loss: 1875.2393 - val_accuracy: 0.3452\n",
      "Epoch 119/200\n",
      "2010/2010 [==============================] - 0s 34us/sample - loss: 3479.3695 - accuracy: 0.3219 - val_loss: 1916.7202 - val_accuracy: 0.4643\n",
      "Epoch 120/200\n",
      "2010/2010 [==============================] - 0s 34us/sample - loss: 3724.9304 - accuracy: 0.3199 - val_loss: 1853.7339 - val_accuracy: 0.3929\n",
      "Epoch 121/200\n",
      "2010/2010 [==============================] - 0s 37us/sample - loss: 3435.0510 - accuracy: 0.3274 - val_loss: 1879.5633 - val_accuracy: 0.4524\n",
      "Epoch 122/200\n",
      "2010/2010 [==============================] - 0s 33us/sample - loss: 3748.9858 - accuracy: 0.3169 - val_loss: 1990.3288 - val_accuracy: 0.3571\n",
      "Epoch 123/200\n",
      "2010/2010 [==============================] - 0s 31us/sample - loss: 3656.2936 - accuracy: 0.3318 - val_loss: 1835.2758 - val_accuracy: 0.3690\n",
      "Epoch 124/200\n",
      "2010/2010 [==============================] - 0s 31us/sample - loss: 3245.1288 - accuracy: 0.3443 - val_loss: 1793.6522 - val_accuracy: 0.3690\n",
      "Epoch 125/200\n",
      "2010/2010 [==============================] - 0s 32us/sample - loss: 3591.8888 - accuracy: 0.3214 - val_loss: 1794.2052 - val_accuracy: 0.4286\n",
      "Epoch 126/200\n",
      "2010/2010 [==============================] - 0s 32us/sample - loss: 3568.1401 - accuracy: 0.3373 - val_loss: 1982.7154 - val_accuracy: 0.2738\n",
      "Epoch 127/200\n",
      "2010/2010 [==============================] - 0s 32us/sample - loss: 3437.9323 - accuracy: 0.3144 - val_loss: 1762.0684 - val_accuracy: 0.4048\n",
      "Epoch 128/200\n",
      "2010/2010 [==============================] - 0s 30us/sample - loss: 3483.3332 - accuracy: 0.3269 - val_loss: 1756.6777 - val_accuracy: 0.3333\n",
      "Epoch 129/200\n",
      "2010/2010 [==============================] - 0s 32us/sample - loss: 3466.6900 - accuracy: 0.3109 - val_loss: 1744.1266 - val_accuracy: 0.4048\n",
      "Epoch 130/200\n",
      "2010/2010 [==============================] - 0s 32us/sample - loss: 3570.6544 - accuracy: 0.3279 - val_loss: 1919.6607 - val_accuracy: 0.4405\n",
      "Epoch 131/200\n",
      "2010/2010 [==============================] - 0s 32us/sample - loss: 3594.2625 - accuracy: 0.3264 - val_loss: 1770.7501 - val_accuracy: 0.4405\n",
      "Epoch 132/200\n",
      "2010/2010 [==============================] - 0s 32us/sample - loss: 3415.0503 - accuracy: 0.3328 - val_loss: 1745.6714 - val_accuracy: 0.4524\n",
      "Epoch 133/200\n",
      "2010/2010 [==============================] - 0s 32us/sample - loss: 3427.7755 - accuracy: 0.3159 - val_loss: 1730.6491 - val_accuracy: 0.4643\n",
      "Epoch 134/200\n",
      "2010/2010 [==============================] - 0s 32us/sample - loss: 3340.4074 - accuracy: 0.3328 - val_loss: 1688.5376 - val_accuracy: 0.4167\n",
      "Epoch 135/200\n",
      "2010/2010 [==============================] - 0s 34us/sample - loss: 3480.1424 - accuracy: 0.3303 - val_loss: 1680.1109 - val_accuracy: 0.3452\n",
      "Epoch 136/200\n",
      "2010/2010 [==============================] - 0s 34us/sample - loss: 3383.7246 - accuracy: 0.3109 - val_loss: 1763.1441 - val_accuracy: 0.2738\n",
      "Epoch 137/200\n",
      "2010/2010 [==============================] - 0s 38us/sample - loss: 3365.3424 - accuracy: 0.3239 - val_loss: 1653.8893 - val_accuracy: 0.4405\n",
      "Epoch 138/200\n",
      "2010/2010 [==============================] - 0s 33us/sample - loss: 3615.9305 - accuracy: 0.3100 - val_loss: 1686.4524 - val_accuracy: 0.3452\n",
      "Epoch 139/200\n",
      "2010/2010 [==============================] - 0s 31us/sample - loss: 3294.8259 - accuracy: 0.3284 - val_loss: 1630.0317 - val_accuracy: 0.3571\n",
      "Epoch 140/200\n",
      "2010/2010 [==============================] - 0s 32us/sample - loss: 3198.5728 - accuracy: 0.3383 - val_loss: 1658.9800 - val_accuracy: 0.3095\n",
      "Epoch 141/200\n",
      "2010/2010 [==============================] - 0s 31us/sample - loss: 3263.5871 - accuracy: 0.3373 - val_loss: 1710.2407 - val_accuracy: 0.2738\n",
      "Epoch 142/200\n",
      "2010/2010 [==============================] - 0s 32us/sample - loss: 3312.7701 - accuracy: 0.3279 - val_loss: 1593.3197 - val_accuracy: 0.3571\n",
      "Epoch 143/200\n",
      "2010/2010 [==============================] - 0s 31us/sample - loss: 3425.5977 - accuracy: 0.3189 - val_loss: 1582.5551 - val_accuracy: 0.3333\n",
      "Epoch 144/200\n",
      "2010/2010 [==============================] - 0s 32us/sample - loss: 3166.4572 - accuracy: 0.3149 - val_loss: 1580.0910 - val_accuracy: 0.3571\n",
      "Epoch 145/200\n",
      "2010/2010 [==============================] - 0s 32us/sample - loss: 3283.7723 - accuracy: 0.3468 - val_loss: 1579.0843 - val_accuracy: 0.3214\n",
      "Epoch 146/200\n",
      "2010/2010 [==============================] - 0s 33us/sample - loss: 3563.4335 - accuracy: 0.3289 - val_loss: 1565.5443 - val_accuracy: 0.4286\n",
      "Epoch 147/200\n",
      "2010/2010 [==============================] - 0s 33us/sample - loss: 3327.7104 - accuracy: 0.3323 - val_loss: 1628.5334 - val_accuracy: 0.4286\n",
      "Epoch 148/200\n",
      "2010/2010 [==============================] - 0s 32us/sample - loss: 3349.9793 - accuracy: 0.3338 - val_loss: 1537.6909 - val_accuracy: 0.4167\n",
      "Epoch 149/200\n",
      "2010/2010 [==============================] - 0s 31us/sample - loss: 3508.1589 - accuracy: 0.3219 - val_loss: 1547.5035 - val_accuracy: 0.4762\n",
      "Epoch 150/200\n",
      "2010/2010 [==============================] - 0s 33us/sample - loss: 3248.7657 - accuracy: 0.3184 - val_loss: 1573.8045 - val_accuracy: 0.4643\n",
      "Epoch 151/200\n",
      "2010/2010 [==============================] - 0s 33us/sample - loss: 3226.9791 - accuracy: 0.3289 - val_loss: 1509.6949 - val_accuracy: 0.3929\n",
      "Epoch 152/200\n",
      "2010/2010 [==============================] - 0s 33us/sample - loss: 3265.5493 - accuracy: 0.3239 - val_loss: 1498.8774 - val_accuracy: 0.4286\n",
      "Epoch 153/200\n",
      "2010/2010 [==============================] - 0s 37us/sample - loss: 3104.8363 - accuracy: 0.3179 - val_loss: 1601.7153 - val_accuracy: 0.2976\n",
      "Epoch 154/200\n",
      "2010/2010 [==============================] - 0s 31us/sample - loss: 3155.2472 - accuracy: 0.3448 - val_loss: 1512.4421 - val_accuracy: 0.3214\n",
      "Epoch 155/200\n",
      "2010/2010 [==============================] - 0s 33us/sample - loss: 3284.7295 - accuracy: 0.3164 - val_loss: 1491.0036 - val_accuracy: 0.4286\n",
      "Epoch 156/200\n",
      "2010/2010 [==============================] - 0s 32us/sample - loss: 3163.8780 - accuracy: 0.3378 - val_loss: 1616.3637 - val_accuracy: 0.2262\n",
      "Epoch 157/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010/2010 [==============================] - 0s 32us/sample - loss: 3172.4748 - accuracy: 0.3388 - val_loss: 1470.2195 - val_accuracy: 0.4762\n",
      "Epoch 158/200\n",
      "2010/2010 [==============================] - 0s 32us/sample - loss: 3337.0338 - accuracy: 0.3318 - val_loss: 1490.4058 - val_accuracy: 0.4524\n",
      "Epoch 159/200\n",
      "2010/2010 [==============================] - 0s 32us/sample - loss: 3284.1668 - accuracy: 0.3259 - val_loss: 1447.4248 - val_accuracy: 0.4048\n",
      "Epoch 160/200\n",
      "2010/2010 [==============================] - 0s 31us/sample - loss: 3083.0495 - accuracy: 0.3373 - val_loss: 1491.2640 - val_accuracy: 0.4643\n",
      "Epoch 161/200\n",
      "2010/2010 [==============================] - 0s 33us/sample - loss: 3138.2043 - accuracy: 0.3338 - val_loss: 1441.4579 - val_accuracy: 0.4643\n",
      "Epoch 162/200\n",
      "2010/2010 [==============================] - 0s 32us/sample - loss: 2924.2715 - accuracy: 0.3174 - val_loss: 1447.9412 - val_accuracy: 0.3929\n",
      "Epoch 163/200\n",
      "2010/2010 [==============================] - 0s 32us/sample - loss: 3262.2698 - accuracy: 0.3313 - val_loss: 1430.4418 - val_accuracy: 0.2976\n",
      "Epoch 164/200\n",
      "2010/2010 [==============================] - 0s 34us/sample - loss: 3048.4251 - accuracy: 0.3164 - val_loss: 1404.9479 - val_accuracy: 0.4405\n",
      "Epoch 165/200\n",
      "2010/2010 [==============================] - 0s 33us/sample - loss: 3159.5966 - accuracy: 0.3289 - val_loss: 1456.8229 - val_accuracy: 0.4405\n",
      "Epoch 166/200\n",
      "2010/2010 [==============================] - 0s 35us/sample - loss: 2999.2211 - accuracy: 0.3303 - val_loss: 1456.4896 - val_accuracy: 0.3690\n",
      "Epoch 167/200\n",
      "2010/2010 [==============================] - 0s 32us/sample - loss: 3316.1996 - accuracy: 0.3348 - val_loss: 1445.7337 - val_accuracy: 0.4524\n",
      "Epoch 168/200\n",
      "2010/2010 [==============================] - 0s 35us/sample - loss: 3042.9612 - accuracy: 0.3224 - val_loss: 1355.5446 - val_accuracy: 0.3810\n",
      "Epoch 169/200\n",
      "2010/2010 [==============================] - 0s 36us/sample - loss: 3172.4276 - accuracy: 0.3184 - val_loss: 1515.2773 - val_accuracy: 0.4643\n",
      "Epoch 170/200\n",
      "2010/2010 [==============================] - 0s 32us/sample - loss: 3210.7776 - accuracy: 0.3343 - val_loss: 1339.6988 - val_accuracy: 0.3452\n",
      "Epoch 171/200\n",
      "2010/2010 [==============================] - 0s 32us/sample - loss: 3082.0559 - accuracy: 0.3473 - val_loss: 1394.8880 - val_accuracy: 0.3571\n",
      "Epoch 172/200\n",
      "2010/2010 [==============================] - 0s 32us/sample - loss: 3467.4901 - accuracy: 0.3169 - val_loss: 1323.6568 - val_accuracy: 0.4048\n",
      "Epoch 173/200\n",
      "2010/2010 [==============================] - 0s 32us/sample - loss: 3143.8187 - accuracy: 0.3119 - val_loss: 1328.9231 - val_accuracy: 0.4286\n",
      "Epoch 174/200\n",
      "2010/2010 [==============================] - 0s 32us/sample - loss: 3249.9523 - accuracy: 0.3224 - val_loss: 1300.2906 - val_accuracy: 0.3452\n",
      "Epoch 175/200\n",
      "2010/2010 [==============================] - 0s 32us/sample - loss: 3274.6467 - accuracy: 0.3378 - val_loss: 1306.9263 - val_accuracy: 0.4286\n",
      "Epoch 176/200\n",
      "2010/2010 [==============================] - 0s 33us/sample - loss: 3194.6006 - accuracy: 0.3428 - val_loss: 1352.7166 - val_accuracy: 0.4524\n",
      "Epoch 177/200\n",
      "2010/2010 [==============================] - 0s 32us/sample - loss: 2890.2001 - accuracy: 0.3100 - val_loss: 1296.4663 - val_accuracy: 0.4286\n",
      "Epoch 178/200\n",
      "2010/2010 [==============================] - 0s 33us/sample - loss: 2965.8760 - accuracy: 0.3393 - val_loss: 1326.1344 - val_accuracy: 0.3929\n",
      "Epoch 179/200\n",
      "2010/2010 [==============================] - 0s 32us/sample - loss: 3023.5273 - accuracy: 0.3279 - val_loss: 1279.9674 - val_accuracy: 0.3333\n",
      "Epoch 180/200\n",
      "2010/2010 [==============================] - 0s 33us/sample - loss: 3040.0401 - accuracy: 0.3308 - val_loss: 1290.8982 - val_accuracy: 0.4643\n",
      "Epoch 181/200\n",
      "2010/2010 [==============================] - 0s 35us/sample - loss: 3155.8771 - accuracy: 0.3234 - val_loss: 1444.2346 - val_accuracy: 0.4643\n",
      "Epoch 182/200\n",
      "2010/2010 [==============================] - 0s 33us/sample - loss: 3328.3978 - accuracy: 0.3403 - val_loss: 1336.5719 - val_accuracy: 0.2500\n",
      "Epoch 183/200\n",
      "2010/2010 [==============================] - 0s 32us/sample - loss: 2975.5275 - accuracy: 0.3289 - val_loss: 1385.9605 - val_accuracy: 0.3690\n",
      "Epoch 184/200\n",
      "2010/2010 [==============================] - 0s 41us/sample - loss: 3353.8394 - accuracy: 0.3294 - val_loss: 1275.0149 - val_accuracy: 0.3095\n",
      "Epoch 185/200\n",
      "2010/2010 [==============================] - 0s 38us/sample - loss: 2951.5217 - accuracy: 0.3308 - val_loss: 1292.3841 - val_accuracy: 0.4524\n",
      "Epoch 186/200\n",
      "2010/2010 [==============================] - 0s 37us/sample - loss: 3034.7496 - accuracy: 0.3274 - val_loss: 1304.7495 - val_accuracy: 0.3095\n",
      "Epoch 187/200\n",
      "2010/2010 [==============================] - 0s 32us/sample - loss: 3052.2301 - accuracy: 0.3498 - val_loss: 1396.1980 - val_accuracy: 0.2262\n",
      "Epoch 188/200\n",
      "2010/2010 [==============================] - 0s 31us/sample - loss: 3257.7883 - accuracy: 0.3318 - val_loss: 1221.8047 - val_accuracy: 0.3452\n",
      "Epoch 189/200\n",
      "2010/2010 [==============================] - 0s 33us/sample - loss: 3083.1822 - accuracy: 0.3333 - val_loss: 1221.8167 - val_accuracy: 0.3214\n",
      "Epoch 190/200\n",
      "2010/2010 [==============================] - 0s 32us/sample - loss: 3136.1929 - accuracy: 0.3259 - val_loss: 1229.4006 - val_accuracy: 0.3452\n",
      "Epoch 191/200\n",
      "2010/2010 [==============================] - 0s 32us/sample - loss: 3050.5605 - accuracy: 0.3254 - val_loss: 1198.8551 - val_accuracy: 0.3333\n",
      "Epoch 192/200\n",
      "2010/2010 [==============================] - 0s 32us/sample - loss: 2994.9406 - accuracy: 0.3289 - val_loss: 1190.1742 - val_accuracy: 0.4286\n",
      "Epoch 193/200\n",
      "2010/2010 [==============================] - 0s 31us/sample - loss: 3145.6865 - accuracy: 0.3229 - val_loss: 1319.2523 - val_accuracy: 0.4643\n",
      "Epoch 194/200\n",
      "2010/2010 [==============================] - 0s 32us/sample - loss: 3060.0722 - accuracy: 0.3343 - val_loss: 1178.2980 - val_accuracy: 0.3810\n",
      "Epoch 195/200\n",
      "2010/2010 [==============================] - 0s 33us/sample - loss: 3064.5432 - accuracy: 0.3249 - val_loss: 1193.5257 - val_accuracy: 0.4286\n",
      "Epoch 196/200\n",
      "2010/2010 [==============================] - 0s 33us/sample - loss: 2991.8875 - accuracy: 0.3403 - val_loss: 1301.0961 - val_accuracy: 0.2500\n",
      "Epoch 197/200\n",
      "2010/2010 [==============================] - 0s 31us/sample - loss: 2983.8482 - accuracy: 0.3408 - val_loss: 1235.9433 - val_accuracy: 0.4048\n",
      "Epoch 198/200\n",
      "2010/2010 [==============================] - 0s 32us/sample - loss: 3119.7107 - accuracy: 0.3219 - val_loss: 1169.5692 - val_accuracy: 0.3333\n",
      "Epoch 199/200\n",
      "2010/2010 [==============================] - 0s 32us/sample - loss: 3130.7748 - accuracy: 0.3234 - val_loss: 1270.0308 - val_accuracy: 0.3690\n",
      "Epoch 200/200\n",
      "2010/2010 [==============================] - 0s 38us/sample - loss: 2949.8687 - accuracy: 0.3244 - val_loss: 1176.6117 - val_accuracy: 0.4286\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=64, epochs=200, validation_split=0.04)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM  8-41-75-75-75-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 20, 32)]          0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 8)                 1312      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 41)                369       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 75)                3150      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 75)                5700      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 75)                5700      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 75)                0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 75)                0         \n",
      "=================================================================\n",
      "Total params: 16,231\n",
      "Trainable params: 16,231\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# We first need to define the sequence of dependencies (the computational graph)\n",
    "x = Input(shape=(20,32))\n",
    "# h = Conv2D(32, (7, 7), strides=(2, 2))(x)\n",
    "# h = Activation('relu')(x)\n",
    "# h = Flatten()(x)\n",
    "h = LSTM(8)(x)\n",
    "h = Dense(41)(h)\n",
    "h = Dense(75)(h)\n",
    "h = Dense(75)(h)\n",
    "h = Dense(75)(h)\n",
    "# h = Dense(40)(h)\n",
    "# h = Dense(40)(h)\n",
    "h = Dropout(0.3)(h)\n",
    "p = Activation('softmax')(h)\n",
    "\n",
    "# Now that we have defined how to find p from x, we can create a \n",
    "# model simply by saying what is input and what is output\n",
    "model = Model(inputs=x, outputs=p)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(lr=0.00001), metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2010 samples, validate on 84 samples\n",
      "Epoch 1/200\n",
      "2010/2010 [==============================] - 2s 1ms/sample - loss: 4.1659 - accuracy: 9.9502e-04 - val_loss: 4.1466 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/200\n",
      "2010/2010 [==============================] - 0s 120us/sample - loss: 4.1340 - accuracy: 4.9751e-04 - val_loss: 4.1129 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/200\n",
      "2010/2010 [==============================] - 0s 118us/sample - loss: 4.0997 - accuracy: 0.0184 - val_loss: 4.0785 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/200\n",
      "2010/2010 [==============================] - 0s 123us/sample - loss: 4.0650 - accuracy: 0.0557 - val_loss: 4.0439 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/200\n",
      "2010/2010 [==============================] - 0s 126us/sample - loss: 4.0375 - accuracy: 0.0746 - val_loss: 4.0088 - val_accuracy: 0.2024\n",
      "Epoch 6/200\n",
      "2010/2010 [==============================] - 0s 130us/sample - loss: 3.9978 - accuracy: 0.2627 - val_loss: 3.9729 - val_accuracy: 0.4643\n",
      "Epoch 7/200\n",
      "2010/2010 [==============================] - 0s 122us/sample - loss: 3.9571 - accuracy: 0.3706 - val_loss: 3.9359 - val_accuracy: 0.4643\n",
      "Epoch 8/200\n",
      "2010/2010 [==============================] - 0s 125us/sample - loss: 3.9195 - accuracy: 0.3836 - val_loss: 3.8981 - val_accuracy: 0.4643\n",
      "Epoch 9/200\n",
      "2010/2010 [==============================] - 0s 126us/sample - loss: 3.8939 - accuracy: 0.3756 - val_loss: 3.8599 - val_accuracy: 0.4643\n",
      "Epoch 10/200\n",
      "2010/2010 [==============================] - 0s 126us/sample - loss: 3.8394 - accuracy: 0.4025 - val_loss: 3.8203 - val_accuracy: 0.4643\n",
      "Epoch 11/200\n",
      "2010/2010 [==============================] - 0s 128us/sample - loss: 3.8196 - accuracy: 0.3940 - val_loss: 3.7804 - val_accuracy: 0.4643\n",
      "Epoch 12/200\n",
      "2010/2010 [==============================] - 0s 126us/sample - loss: 3.7741 - accuracy: 0.3856 - val_loss: 3.7395 - val_accuracy: 0.4643\n",
      "Epoch 13/200\n",
      "2010/2010 [==============================] - 0s 124us/sample - loss: 3.7280 - accuracy: 0.3980 - val_loss: 3.6969 - val_accuracy: 0.4643\n",
      "Epoch 14/200\n",
      "2010/2010 [==============================] - 0s 127us/sample - loss: 3.6959 - accuracy: 0.3806 - val_loss: 3.6536 - val_accuracy: 0.4643\n",
      "Epoch 15/200\n",
      "2010/2010 [==============================] - 0s 132us/sample - loss: 3.6607 - accuracy: 0.3886 - val_loss: 3.6093 - val_accuracy: 0.4643\n",
      "Epoch 16/200\n",
      "2010/2010 [==============================] - 0s 124us/sample - loss: 3.6160 - accuracy: 0.3861 - val_loss: 3.5635 - val_accuracy: 0.4643\n",
      "Epoch 17/200\n",
      "2010/2010 [==============================] - 0s 126us/sample - loss: 3.5620 - accuracy: 0.3940 - val_loss: 3.5164 - val_accuracy: 0.4643\n",
      "Epoch 18/200\n",
      "2010/2010 [==============================] - 0s 137us/sample - loss: 3.5264 - accuracy: 0.3836 - val_loss: 3.4678 - val_accuracy: 0.4643\n",
      "Epoch 19/200\n",
      "2010/2010 [==============================] - 0s 132us/sample - loss: 3.4787 - accuracy: 0.3866 - val_loss: 3.4186 - val_accuracy: 0.4643\n",
      "Epoch 20/200\n",
      "2010/2010 [==============================] - 0s 132us/sample - loss: 3.4246 - accuracy: 0.3960 - val_loss: 3.3679 - val_accuracy: 0.4643\n",
      "Epoch 21/200\n",
      "2010/2010 [==============================] - 0s 131us/sample - loss: 3.3886 - accuracy: 0.3866 - val_loss: 3.3159 - val_accuracy: 0.4643\n",
      "Epoch 22/200\n",
      "2010/2010 [==============================] - 0s 137us/sample - loss: 3.3016 - accuracy: 0.4129 - val_loss: 3.2613 - val_accuracy: 0.4643\n",
      "Epoch 23/200\n",
      "2010/2010 [==============================] - 0s 139us/sample - loss: 3.2684 - accuracy: 0.3950 - val_loss: 3.2063 - val_accuracy: 0.4643\n",
      "Epoch 24/200\n",
      "2010/2010 [==============================] - 0s 130us/sample - loss: 3.2670 - accuracy: 0.3766 - val_loss: 3.1513 - val_accuracy: 0.4643\n",
      "Epoch 25/200\n",
      "2010/2010 [==============================] - 0s 126us/sample - loss: 3.1770 - accuracy: 0.3930 - val_loss: 3.0950 - val_accuracy: 0.4643\n",
      "Epoch 26/200\n",
      "2010/2010 [==============================] - 0s 130us/sample - loss: 3.1411 - accuracy: 0.3920 - val_loss: 3.0382 - val_accuracy: 0.4643\n",
      "Epoch 27/200\n",
      "2010/2010 [==============================] - 0s 138us/sample - loss: 3.0731 - accuracy: 0.3896 - val_loss: 2.9802 - val_accuracy: 0.4643\n",
      "Epoch 28/200\n",
      "2010/2010 [==============================] - 0s 125us/sample - loss: 3.0551 - accuracy: 0.3851 - val_loss: 2.9224 - val_accuracy: 0.4643\n",
      "Epoch 29/200\n",
      "2010/2010 [==============================] - 0s 127us/sample - loss: 2.9876 - accuracy: 0.3935 - val_loss: 2.8636 - val_accuracy: 0.4643\n",
      "Epoch 30/200\n",
      "2010/2010 [==============================] - 0s 140us/sample - loss: 2.9400 - accuracy: 0.3940 - val_loss: 2.8055 - val_accuracy: 0.4643\n",
      "Epoch 31/200\n",
      "2010/2010 [==============================] - 0s 129us/sample - loss: 2.8406 - accuracy: 0.4154 - val_loss: 2.7451 - val_accuracy: 0.4643\n",
      "Epoch 32/200\n",
      "2010/2010 [==============================] - 0s 124us/sample - loss: 2.8186 - accuracy: 0.3955 - val_loss: 2.6848 - val_accuracy: 0.4643\n",
      "Epoch 33/200\n",
      "2010/2010 [==============================] - 0s 127us/sample - loss: 2.8038 - accuracy: 0.3876 - val_loss: 2.6273 - val_accuracy: 0.4643\n",
      "Epoch 34/200\n",
      "2010/2010 [==============================] - 0s 125us/sample - loss: 2.7658 - accuracy: 0.3871 - val_loss: 2.5704 - val_accuracy: 0.4643\n",
      "Epoch 35/200\n",
      "2010/2010 [==============================] - 0s 129us/sample - loss: 2.6878 - accuracy: 0.3915 - val_loss: 2.5135 - val_accuracy: 0.4643\n",
      "Epoch 36/200\n",
      "2010/2010 [==============================] - 0s 125us/sample - loss: 2.6471 - accuracy: 0.4020 - val_loss: 2.4572 - val_accuracy: 0.4643\n",
      "Epoch 37/200\n",
      "2010/2010 [==============================] - 0s 126us/sample - loss: 2.5768 - accuracy: 0.4040 - val_loss: 2.4023 - val_accuracy: 0.4643\n",
      "Epoch 38/200\n",
      "2010/2010 [==============================] - 0s 128us/sample - loss: 2.6062 - accuracy: 0.3821 - val_loss: 2.3499 - val_accuracy: 0.4643\n",
      "Epoch 39/200\n",
      "2010/2010 [==============================] - 0s 132us/sample - loss: 2.5464 - accuracy: 0.3866 - val_loss: 2.2987 - val_accuracy: 0.4643\n",
      "Epoch 40/200\n",
      "2010/2010 [==============================] - 0s 124us/sample - loss: 2.4916 - accuracy: 0.4035 - val_loss: 2.2495 - val_accuracy: 0.4643\n",
      "Epoch 41/200\n",
      "2010/2010 [==============================] - 0s 126us/sample - loss: 2.4709 - accuracy: 0.3891 - val_loss: 2.2023 - val_accuracy: 0.4643\n",
      "Epoch 42/200\n",
      "2010/2010 [==============================] - 0s 126us/sample - loss: 2.4104 - accuracy: 0.3955 - val_loss: 2.1558 - val_accuracy: 0.4643\n",
      "Epoch 43/200\n",
      "2010/2010 [==============================] - 0s 133us/sample - loss: 2.4612 - accuracy: 0.3896 - val_loss: 2.1140 - val_accuracy: 0.4643\n",
      "Epoch 44/200\n",
      "2010/2010 [==============================] - 0s 124us/sample - loss: 2.4223 - accuracy: 0.3891 - val_loss: 2.0738 - val_accuracy: 0.4643\n",
      "Epoch 45/200\n",
      "2010/2010 [==============================] - 0s 127us/sample - loss: 2.3584 - accuracy: 0.3970 - val_loss: 2.0352 - val_accuracy: 0.4643\n",
      "Epoch 46/200\n",
      "2010/2010 [==============================] - 0s 128us/sample - loss: 2.3715 - accuracy: 0.3871 - val_loss: 1.9989 - val_accuracy: 0.4643\n",
      "Epoch 47/200\n",
      "2010/2010 [==============================] - 0s 134us/sample - loss: 2.3702 - accuracy: 0.3866 - val_loss: 1.9657 - val_accuracy: 0.4643\n",
      "Epoch 48/200\n",
      "2010/2010 [==============================] - 0s 125us/sample - loss: 2.2757 - accuracy: 0.3955 - val_loss: 1.9324 - val_accuracy: 0.4643\n",
      "Epoch 49/200\n",
      "2010/2010 [==============================] - 0s 126us/sample - loss: 2.3125 - accuracy: 0.4000 - val_loss: 1.9019 - val_accuracy: 0.4643\n",
      "Epoch 50/200\n",
      "2010/2010 [==============================] - 0s 123us/sample - loss: 2.3357 - accuracy: 0.3851 - val_loss: 1.8751 - val_accuracy: 0.4643\n",
      "Epoch 51/200\n",
      "2010/2010 [==============================] - 0s 139us/sample - loss: 2.2381 - accuracy: 0.4085 - val_loss: 1.8480 - val_accuracy: 0.4643\n",
      "Epoch 52/200\n",
      "2010/2010 [==============================] - 0s 124us/sample - loss: 2.3021 - accuracy: 0.3945 - val_loss: 1.8236 - val_accuracy: 0.4643\n",
      "Epoch 53/200\n",
      "2010/2010 [==============================] - 0s 130us/sample - loss: 2.2187 - accuracy: 0.4005 - val_loss: 1.7989 - val_accuracy: 0.4643\n",
      "Epoch 54/200\n",
      "2010/2010 [==============================] - 0s 127us/sample - loss: 2.2848 - accuracy: 0.3831 - val_loss: 1.7796 - val_accuracy: 0.4643\n",
      "Epoch 55/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010/2010 [==============================] - 0s 141us/sample - loss: 2.2430 - accuracy: 0.3945 - val_loss: 1.7601 - val_accuracy: 0.4643\n",
      "Epoch 56/200\n",
      "2010/2010 [==============================] - ETA: 0s - loss: 2.1974 - accuracy: 0.39 - 0s 129us/sample - loss: 2.1906 - accuracy: 0.3985 - val_loss: 1.7411 - val_accuracy: 0.4643\n",
      "Epoch 57/200\n",
      "2010/2010 [==============================] - 0s 129us/sample - loss: 2.2053 - accuracy: 0.3925 - val_loss: 1.7215 - val_accuracy: 0.4643\n",
      "Epoch 58/200\n",
      "2010/2010 [==============================] - 0s 126us/sample - loss: 2.2040 - accuracy: 0.3940 - val_loss: 1.7052 - val_accuracy: 0.4643\n",
      "Epoch 59/200\n",
      "2010/2010 [==============================] - 0s 131us/sample - loss: 2.2472 - accuracy: 0.3940 - val_loss: 1.6896 - val_accuracy: 0.4643\n",
      "Epoch 60/200\n",
      "2010/2010 [==============================] - 0s 135us/sample - loss: 2.1883 - accuracy: 0.3975 - val_loss: 1.6759 - val_accuracy: 0.4643\n",
      "Epoch 61/200\n",
      "2010/2010 [==============================] - 0s 127us/sample - loss: 2.2287 - accuracy: 0.3950 - val_loss: 1.6637 - val_accuracy: 0.4643\n",
      "Epoch 62/200\n",
      "2010/2010 [==============================] - 0s 129us/sample - loss: 2.1103 - accuracy: 0.4055 - val_loss: 1.6494 - val_accuracy: 0.4643\n",
      "Epoch 63/200\n",
      "2010/2010 [==============================] - 0s 130us/sample - loss: 2.1466 - accuracy: 0.4040 - val_loss: 1.6360 - val_accuracy: 0.4643\n",
      "Epoch 64/200\n",
      "2010/2010 [==============================] - 0s 126us/sample - loss: 2.1968 - accuracy: 0.3920 - val_loss: 1.6278 - val_accuracy: 0.4643\n",
      "Epoch 65/200\n",
      "2010/2010 [==============================] - 0s 124us/sample - loss: 2.1761 - accuracy: 0.3945 - val_loss: 1.6167 - val_accuracy: 0.4643\n",
      "Epoch 66/200\n",
      "2010/2010 [==============================] - 0s 128us/sample - loss: 2.1174 - accuracy: 0.4075 - val_loss: 1.6060 - val_accuracy: 0.4643\n",
      "Epoch 67/200\n",
      "2010/2010 [==============================] - 0s 132us/sample - loss: 2.1890 - accuracy: 0.3905 - val_loss: 1.5968 - val_accuracy: 0.4643\n",
      "Epoch 68/200\n",
      "2010/2010 [==============================] - 0s 124us/sample - loss: 2.1239 - accuracy: 0.4080 - val_loss: 1.5880 - val_accuracy: 0.4643\n",
      "Epoch 69/200\n",
      "2010/2010 [==============================] - 0s 129us/sample - loss: 2.2209 - accuracy: 0.3900 - val_loss: 1.5833 - val_accuracy: 0.4643\n",
      "Epoch 70/200\n",
      "2010/2010 [==============================] - 0s 137us/sample - loss: 2.1302 - accuracy: 0.3891 - val_loss: 1.5765 - val_accuracy: 0.4643\n",
      "Epoch 71/200\n",
      "2010/2010 [==============================] - 0s 138us/sample - loss: 2.1069 - accuracy: 0.4050 - val_loss: 1.5682 - val_accuracy: 0.4643\n",
      "Epoch 72/200\n",
      "2010/2010 [==============================] - 0s 130us/sample - loss: 2.1551 - accuracy: 0.4020 - val_loss: 1.5596 - val_accuracy: 0.4643\n",
      "Epoch 73/200\n",
      "2010/2010 [==============================] - 0s 126us/sample - loss: 2.1662 - accuracy: 0.3891 - val_loss: 1.5552 - val_accuracy: 0.4643\n",
      "Epoch 74/200\n",
      "2010/2010 [==============================] - 0s 132us/sample - loss: 2.1257 - accuracy: 0.4050 - val_loss: 1.5491 - val_accuracy: 0.4643\n",
      "Epoch 75/200\n",
      "2010/2010 [==============================] - 0s 137us/sample - loss: 2.2025 - accuracy: 0.3955 - val_loss: 1.5461 - val_accuracy: 0.4643\n",
      "Epoch 76/200\n",
      "2010/2010 [==============================] - 0s 129us/sample - loss: 2.1910 - accuracy: 0.3896 - val_loss: 1.5434 - val_accuracy: 0.4643\n",
      "Epoch 77/200\n",
      "2010/2010 [==============================] - 0s 132us/sample - loss: 2.1375 - accuracy: 0.3990 - val_loss: 1.5387 - val_accuracy: 0.4643\n",
      "Epoch 78/200\n",
      "2010/2010 [==============================] - 0s 125us/sample - loss: 2.1127 - accuracy: 0.4075 - val_loss: 1.5345 - val_accuracy: 0.4643\n",
      "Epoch 79/200\n",
      "2010/2010 [==============================] - 0s 134us/sample - loss: 2.1358 - accuracy: 0.3905 - val_loss: 1.5289 - val_accuracy: 0.4643\n",
      "Epoch 80/200\n",
      "2010/2010 [==============================] - 0s 136us/sample - loss: 2.0793 - accuracy: 0.4025 - val_loss: 1.5238 - val_accuracy: 0.4643\n",
      "Epoch 81/200\n",
      "2010/2010 [==============================] - 0s 132us/sample - loss: 2.1372 - accuracy: 0.3930 - val_loss: 1.5204 - val_accuracy: 0.4643\n",
      "Epoch 82/200\n",
      "2010/2010 [==============================] - 0s 127us/sample - loss: 2.1486 - accuracy: 0.4020 - val_loss: 1.5168 - val_accuracy: 0.4643\n",
      "Epoch 83/200\n",
      "2010/2010 [==============================] - 0s 139us/sample - loss: 2.0977 - accuracy: 0.4050 - val_loss: 1.5122 - val_accuracy: 0.4643\n",
      "Epoch 84/200\n",
      "2010/2010 [==============================] - 0s 127us/sample - loss: 2.1887 - accuracy: 0.4085 - val_loss: 1.5101 - val_accuracy: 0.4643\n",
      "Epoch 85/200\n",
      "2010/2010 [==============================] - 0s 132us/sample - loss: 2.1720 - accuracy: 0.3945 - val_loss: 1.5084 - val_accuracy: 0.4643\n",
      "Epoch 86/200\n",
      "2010/2010 [==============================] - 0s 128us/sample - loss: 2.0430 - accuracy: 0.4199 - val_loss: 1.5014 - val_accuracy: 0.4643\n",
      "Epoch 87/200\n",
      "2010/2010 [==============================] - 0s 137us/sample - loss: 2.1979 - accuracy: 0.3900 - val_loss: 1.5004 - val_accuracy: 0.4643\n",
      "Epoch 88/200\n",
      "2010/2010 [==============================] - 0s 131us/sample - loss: 2.0928 - accuracy: 0.4169 - val_loss: 1.4964 - val_accuracy: 0.4643\n",
      "Epoch 89/200\n",
      "2010/2010 [==============================] - 0s 131us/sample - loss: 2.0800 - accuracy: 0.4179 - val_loss: 1.4929 - val_accuracy: 0.4643\n",
      "Epoch 90/200\n",
      "2010/2010 [==============================] - 0s 131us/sample - loss: 2.1412 - accuracy: 0.4119 - val_loss: 1.4907 - val_accuracy: 0.4643\n",
      "Epoch 91/200\n",
      "2010/2010 [==============================] - 0s 136us/sample - loss: 2.2265 - accuracy: 0.4000 - val_loss: 1.4899 - val_accuracy: 0.4643\n",
      "Epoch 92/200\n",
      "2010/2010 [==============================] - 0s 132us/sample - loss: 2.0877 - accuracy: 0.4174 - val_loss: 1.4881 - val_accuracy: 0.4643\n",
      "Epoch 93/200\n",
      "2010/2010 [==============================] - 0s 132us/sample - loss: 2.1488 - accuracy: 0.3985 - val_loss: 1.4856 - val_accuracy: 0.4643\n",
      "Epoch 94/200\n",
      "2010/2010 [==============================] - 0s 127us/sample - loss: 2.1022 - accuracy: 0.4124 - val_loss: 1.4830 - val_accuracy: 0.4643\n",
      "Epoch 95/200\n",
      "2010/2010 [==============================] - 0s 144us/sample - loss: 2.1231 - accuracy: 0.4149 - val_loss: 1.4800 - val_accuracy: 0.4643\n",
      "Epoch 96/200\n",
      "2010/2010 [==============================] - 0s 135us/sample - loss: 2.0915 - accuracy: 0.4114 - val_loss: 1.4762 - val_accuracy: 0.4643\n",
      "Epoch 97/200\n",
      "2010/2010 [==============================] - 0s 130us/sample - loss: 2.1151 - accuracy: 0.4030 - val_loss: 1.4745 - val_accuracy: 0.4643\n",
      "Epoch 98/200\n",
      "2010/2010 [==============================] - 0s 130us/sample - loss: 2.0793 - accuracy: 0.4109 - val_loss: 1.4713 - val_accuracy: 0.4643\n",
      "Epoch 99/200\n",
      "2010/2010 [==============================] - 0s 136us/sample - loss: 2.0622 - accuracy: 0.4045 - val_loss: 1.4665 - val_accuracy: 0.4643\n",
      "Epoch 100/200\n",
      "2010/2010 [==============================] - 0s 129us/sample - loss: 2.0697 - accuracy: 0.4100 - val_loss: 1.4614 - val_accuracy: 0.4643\n",
      "Epoch 101/200\n",
      "2010/2010 [==============================] - 0s 133us/sample - loss: 2.1249 - accuracy: 0.4005 - val_loss: 1.4602 - val_accuracy: 0.4643\n",
      "Epoch 102/200\n",
      "2010/2010 [==============================] - 0s 126us/sample - loss: 2.0841 - accuracy: 0.3940 - val_loss: 1.4580 - val_accuracy: 0.4643\n",
      "Epoch 103/200\n",
      "2010/2010 [==============================] - 0s 141us/sample - loss: 2.0532 - accuracy: 0.4303 - val_loss: 1.4541 - val_accuracy: 0.4643\n",
      "Epoch 104/200\n",
      "2010/2010 [==============================] - 0s 129us/sample - loss: 2.1351 - accuracy: 0.3955 - val_loss: 1.4531 - val_accuracy: 0.4643\n",
      "Epoch 105/200\n",
      "2010/2010 [==============================] - 0s 124us/sample - loss: 2.2073 - accuracy: 0.3905 - val_loss: 1.4546 - val_accuracy: 0.4643\n",
      "Epoch 106/200\n",
      "2010/2010 [==============================] - 0s 126us/sample - loss: 2.0698 - accuracy: 0.4129 - val_loss: 1.4528 - val_accuracy: 0.4643\n",
      "Epoch 107/200\n",
      "2010/2010 [==============================] - 0s 141us/sample - loss: 2.0931 - accuracy: 0.4149 - val_loss: 1.4486 - val_accuracy: 0.4643\n",
      "Epoch 108/200\n",
      "2010/2010 [==============================] - 0s 129us/sample - loss: 2.0845 - accuracy: 0.4199 - val_loss: 1.4456 - val_accuracy: 0.4643\n",
      "Epoch 109/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010/2010 [==============================] - 0s 125us/sample - loss: 2.1275 - accuracy: 0.4035 - val_loss: 1.4423 - val_accuracy: 0.4643\n",
      "Epoch 110/200\n",
      "2010/2010 [==============================] - 0s 124us/sample - loss: 2.1108 - accuracy: 0.3985 - val_loss: 1.4398 - val_accuracy: 0.4643\n",
      "Epoch 111/200\n",
      "2010/2010 [==============================] - 0s 141us/sample - loss: 2.1220 - accuracy: 0.3985 - val_loss: 1.4384 - val_accuracy: 0.4643\n",
      "Epoch 112/200\n",
      "2010/2010 [==============================] - 0s 124us/sample - loss: 2.1325 - accuracy: 0.4005 - val_loss: 1.4387 - val_accuracy: 0.4643\n",
      "Epoch 113/200\n",
      "2010/2010 [==============================] - 0s 133us/sample - loss: 2.1192 - accuracy: 0.3910 - val_loss: 1.4373 - val_accuracy: 0.4643\n",
      "Epoch 114/200\n",
      "2010/2010 [==============================] - 0s 129us/sample - loss: 2.0814 - accuracy: 0.3975 - val_loss: 1.4352 - val_accuracy: 0.4643\n",
      "Epoch 115/200\n",
      "2010/2010 [==============================] - 0s 135us/sample - loss: 2.0950 - accuracy: 0.4104 - val_loss: 1.4318 - val_accuracy: 0.4643\n",
      "Epoch 116/200\n",
      "2010/2010 [==============================] - 0s 127us/sample - loss: 2.0476 - accuracy: 0.4169 - val_loss: 1.4266 - val_accuracy: 0.4643\n",
      "Epoch 117/200\n",
      "2010/2010 [==============================] - 0s 131us/sample - loss: 2.0954 - accuracy: 0.3955 - val_loss: 1.4243 - val_accuracy: 0.4643\n",
      "Epoch 118/200\n",
      "2010/2010 [==============================] - 0s 133us/sample - loss: 2.0582 - accuracy: 0.4149 - val_loss: 1.4194 - val_accuracy: 0.4643\n",
      "Epoch 119/200\n",
      "2010/2010 [==============================] - 0s 141us/sample - loss: 2.0753 - accuracy: 0.3950 - val_loss: 1.4145 - val_accuracy: 0.4643\n",
      "Epoch 120/200\n",
      "2010/2010 [==============================] - 0s 128us/sample - loss: 2.0324 - accuracy: 0.4239 - val_loss: 1.4111 - val_accuracy: 0.4643\n",
      "Epoch 121/200\n",
      "2010/2010 [==============================] - 0s 126us/sample - loss: 2.0839 - accuracy: 0.4164 - val_loss: 1.4089 - val_accuracy: 0.4643\n",
      "Epoch 122/200\n",
      "2010/2010 [==============================] - 0s 132us/sample - loss: 2.0716 - accuracy: 0.4050 - val_loss: 1.4076 - val_accuracy: 0.4643\n",
      "Epoch 123/200\n",
      "2010/2010 [==============================] - 0s 136us/sample - loss: 2.0867 - accuracy: 0.3975 - val_loss: 1.4048 - val_accuracy: 0.4643\n",
      "Epoch 124/200\n",
      "2010/2010 [==============================] - 0s 130us/sample - loss: 2.0536 - accuracy: 0.4124 - val_loss: 1.4020 - val_accuracy: 0.4643\n",
      "Epoch 125/200\n",
      "2010/2010 [==============================] - 0s 132us/sample - loss: 2.1001 - accuracy: 0.4075 - val_loss: 1.4016 - val_accuracy: 0.4643\n",
      "Epoch 126/200\n",
      "2010/2010 [==============================] - 0s 129us/sample - loss: 2.1251 - accuracy: 0.3950 - val_loss: 1.4004 - val_accuracy: 0.4643\n",
      "Epoch 127/200\n",
      "2010/2010 [==============================] - 0s 141us/sample - loss: 2.1166 - accuracy: 0.3955 - val_loss: 1.3995 - val_accuracy: 0.4643\n",
      "Epoch 128/200\n",
      "2010/2010 [==============================] - 0s 125us/sample - loss: 2.0612 - accuracy: 0.3995 - val_loss: 1.3971 - val_accuracy: 0.4643\n",
      "Epoch 129/200\n",
      "2010/2010 [==============================] - 0s 125us/sample - loss: 2.0783 - accuracy: 0.4030 - val_loss: 1.3953 - val_accuracy: 0.4643\n",
      "Epoch 130/200\n",
      "2010/2010 [==============================] - 0s 128us/sample - loss: 2.0666 - accuracy: 0.4030 - val_loss: 1.3919 - val_accuracy: 0.4643\n",
      "Epoch 131/200\n",
      "2010/2010 [==============================] - 0s 134us/sample - loss: 2.0437 - accuracy: 0.4080 - val_loss: 1.3869 - val_accuracy: 0.4643\n",
      "Epoch 132/200\n",
      "2010/2010 [==============================] - 0s 127us/sample - loss: 2.0791 - accuracy: 0.4085 - val_loss: 1.3841 - val_accuracy: 0.4643\n",
      "Epoch 133/200\n",
      "2010/2010 [==============================] - 0s 137us/sample - loss: 2.0855 - accuracy: 0.4005 - val_loss: 1.3825 - val_accuracy: 0.4643\n",
      "Epoch 134/200\n",
      "2010/2010 [==============================] - 0s 132us/sample - loss: 2.0161 - accuracy: 0.4174 - val_loss: 1.3780 - val_accuracy: 0.4643\n",
      "Epoch 135/200\n",
      "2010/2010 [==============================] - 0s 142us/sample - loss: 2.0291 - accuracy: 0.4164 - val_loss: 1.3719 - val_accuracy: 0.4643\n",
      "Epoch 136/200\n",
      "2010/2010 [==============================] - 0s 132us/sample - loss: 2.0286 - accuracy: 0.4085 - val_loss: 1.3686 - val_accuracy: 0.4643\n",
      "Epoch 137/200\n",
      "2010/2010 [==============================] - 0s 133us/sample - loss: 2.0977 - accuracy: 0.3965 - val_loss: 1.3668 - val_accuracy: 0.4643\n",
      "Epoch 138/200\n",
      "2010/2010 [==============================] - 0s 130us/sample - loss: 2.0603 - accuracy: 0.4020 - val_loss: 1.3648 - val_accuracy: 0.4643\n",
      "Epoch 139/200\n",
      "2010/2010 [==============================] - 0s 140us/sample - loss: 2.0663 - accuracy: 0.4010 - val_loss: 1.3624 - val_accuracy: 0.4643\n",
      "Epoch 140/200\n",
      "2010/2010 [==============================] - 0s 130us/sample - loss: 2.1009 - accuracy: 0.4085 - val_loss: 1.3613 - val_accuracy: 0.4643\n",
      "Epoch 141/200\n",
      "2010/2010 [==============================] - 0s 133us/sample - loss: 2.0468 - accuracy: 0.4109 - val_loss: 1.3591 - val_accuracy: 0.4643\n",
      "Epoch 142/200\n",
      "2010/2010 [==============================] - 0s 135us/sample - loss: 2.0746 - accuracy: 0.3975 - val_loss: 1.3590 - val_accuracy: 0.4643\n",
      "Epoch 143/200\n",
      "2010/2010 [==============================] - 0s 132us/sample - loss: 2.0311 - accuracy: 0.4095 - val_loss: 1.3554 - val_accuracy: 0.4643\n",
      "Epoch 144/200\n",
      "2010/2010 [==============================] - 0s 130us/sample - loss: 2.0597 - accuracy: 0.3940 - val_loss: 1.3521 - val_accuracy: 0.4643\n",
      "Epoch 145/200\n",
      "2010/2010 [==============================] - 0s 134us/sample - loss: 2.1344 - accuracy: 0.3930 - val_loss: 1.3534 - val_accuracy: 0.4643\n",
      "Epoch 146/200\n",
      "2010/2010 [==============================] - 0s 135us/sample - loss: 2.0567 - accuracy: 0.4005 - val_loss: 1.3514 - val_accuracy: 0.4643\n",
      "Epoch 147/200\n",
      "2010/2010 [==============================] - 0s 137us/sample - loss: 2.0048 - accuracy: 0.4104 - val_loss: 1.3449 - val_accuracy: 0.4643\n",
      "Epoch 148/200\n",
      "2010/2010 [==============================] - 0s 133us/sample - loss: 2.0357 - accuracy: 0.4144 - val_loss: 1.3393 - val_accuracy: 0.4643\n",
      "Epoch 149/200\n",
      "2010/2010 [==============================] - 0s 131us/sample - loss: 2.0969 - accuracy: 0.3881 - val_loss: 1.3404 - val_accuracy: 0.4643\n",
      "Epoch 150/200\n",
      "2010/2010 [==============================] - 0s 135us/sample - loss: 1.9714 - accuracy: 0.4085 - val_loss: 1.3342 - val_accuracy: 0.4643\n",
      "Epoch 151/200\n",
      "2010/2010 [==============================] - 0s 140us/sample - loss: 2.0516 - accuracy: 0.3960 - val_loss: 1.3315 - val_accuracy: 0.4643\n",
      "Epoch 152/200\n",
      "2010/2010 [==============================] - 0s 135us/sample - loss: 2.0807 - accuracy: 0.4055 - val_loss: 1.3308 - val_accuracy: 0.4643\n",
      "Epoch 153/200\n",
      "2010/2010 [==============================] - 0s 134us/sample - loss: 2.0008 - accuracy: 0.4095 - val_loss: 1.3278 - val_accuracy: 0.4643\n",
      "Epoch 154/200\n",
      "2010/2010 [==============================] - 0s 138us/sample - loss: 2.0337 - accuracy: 0.4075 - val_loss: 1.3254 - val_accuracy: 0.4643\n",
      "Epoch 155/200\n",
      "2010/2010 [==============================] - 0s 138us/sample - loss: 2.0358 - accuracy: 0.3950 - val_loss: 1.3224 - val_accuracy: 0.4643\n",
      "Epoch 156/200\n",
      "2010/2010 [==============================] - 0s 131us/sample - loss: 2.0344 - accuracy: 0.4075 - val_loss: 1.3205 - val_accuracy: 0.4643\n",
      "Epoch 157/200\n",
      "2010/2010 [==============================] - 0s 135us/sample - loss: 2.0636 - accuracy: 0.3940 - val_loss: 1.3189 - val_accuracy: 0.4643\n",
      "Epoch 158/200\n",
      "2010/2010 [==============================] - 0s 132us/sample - loss: 2.0560 - accuracy: 0.4040 - val_loss: 1.3198 - val_accuracy: 0.4643\n",
      "Epoch 159/200\n",
      "2010/2010 [==============================] - 0s 136us/sample - loss: 2.0081 - accuracy: 0.4015 - val_loss: 1.3153 - val_accuracy: 0.4643\n",
      "Epoch 160/200\n",
      "2010/2010 [==============================] - 0s 133us/sample - loss: 2.0198 - accuracy: 0.4139 - val_loss: 1.3111 - val_accuracy: 0.4643\n",
      "Epoch 161/200\n",
      "2010/2010 [==============================] - 0s 135us/sample - loss: 2.0491 - accuracy: 0.4010 - val_loss: 1.3081 - val_accuracy: 0.4643\n",
      "Epoch 162/200\n",
      "2010/2010 [==============================] - 0s 133us/sample - loss: 2.0566 - accuracy: 0.4085 - val_loss: 1.3067 - val_accuracy: 0.4643\n",
      "Epoch 163/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010/2010 [==============================] - 0s 135us/sample - loss: 2.0336 - accuracy: 0.4060 - val_loss: 1.3043 - val_accuracy: 0.4643\n",
      "Epoch 164/200\n",
      "2010/2010 [==============================] - 0s 134us/sample - loss: 2.0397 - accuracy: 0.3900 - val_loss: 1.3022 - val_accuracy: 0.4643\n",
      "Epoch 165/200\n",
      "2010/2010 [==============================] - 0s 136us/sample - loss: 1.9900 - accuracy: 0.4095 - val_loss: 1.2989 - val_accuracy: 0.4643\n",
      "Epoch 166/200\n",
      "2010/2010 [==============================] - 0s 134us/sample - loss: 2.0762 - accuracy: 0.4005 - val_loss: 1.2990 - val_accuracy: 0.4643\n",
      "Epoch 167/200\n",
      "2010/2010 [==============================] - 0s 130us/sample - loss: 2.0358 - accuracy: 0.3955 - val_loss: 1.2963 - val_accuracy: 0.4643\n",
      "Epoch 168/200\n",
      "2010/2010 [==============================] - 0s 133us/sample - loss: 2.0256 - accuracy: 0.3990 - val_loss: 1.2945 - val_accuracy: 0.4643\n",
      "Epoch 169/200\n",
      "2010/2010 [==============================] - 0s 133us/sample - loss: 2.0296 - accuracy: 0.4179 - val_loss: 1.2906 - val_accuracy: 0.4643\n",
      "Epoch 170/200\n",
      "2010/2010 [==============================] - 0s 140us/sample - loss: 2.0109 - accuracy: 0.4144 - val_loss: 1.2873 - val_accuracy: 0.4643\n",
      "Epoch 171/200\n",
      "2010/2010 [==============================] - 0s 130us/sample - loss: 2.0072 - accuracy: 0.4164 - val_loss: 1.2841 - val_accuracy: 0.4643\n",
      "Epoch 172/200\n",
      "2010/2010 [==============================] - 0s 131us/sample - loss: 1.9951 - accuracy: 0.4060 - val_loss: 1.2819 - val_accuracy: 0.4643\n",
      "Epoch 173/200\n",
      "2010/2010 [==============================] - 0s 135us/sample - loss: 1.9977 - accuracy: 0.4144 - val_loss: 1.2772 - val_accuracy: 0.4643\n",
      "Epoch 174/200\n",
      "2010/2010 [==============================] - 0s 138us/sample - loss: 2.0222 - accuracy: 0.4075 - val_loss: 1.2748 - val_accuracy: 0.4643\n",
      "Epoch 175/200\n",
      "2010/2010 [==============================] - 0s 136us/sample - loss: 2.0666 - accuracy: 0.4005 - val_loss: 1.2754 - val_accuracy: 0.4643\n",
      "Epoch 176/200\n",
      "2010/2010 [==============================] - 0s 137us/sample - loss: 1.9974 - accuracy: 0.4114 - val_loss: 1.2729 - val_accuracy: 0.4643\n",
      "Epoch 177/200\n",
      "2010/2010 [==============================] - 0s 133us/sample - loss: 2.0493 - accuracy: 0.4035 - val_loss: 1.2723 - val_accuracy: 0.4643\n",
      "Epoch 178/200\n",
      "2010/2010 [==============================] - 0s 142us/sample - loss: 2.0085 - accuracy: 0.4050 - val_loss: 1.2698 - val_accuracy: 0.4643\n",
      "Epoch 179/200\n",
      "2010/2010 [==============================] - 0s 130us/sample - loss: 2.0509 - accuracy: 0.3995 - val_loss: 1.2684 - val_accuracy: 0.4643\n",
      "Epoch 180/200\n",
      "2010/2010 [==============================] - 0s 131us/sample - loss: 2.0533 - accuracy: 0.4010 - val_loss: 1.2683 - val_accuracy: 0.4643\n",
      "Epoch 181/200\n",
      "2010/2010 [==============================] - 0s 127us/sample - loss: 2.0460 - accuracy: 0.3866 - val_loss: 1.2665 - val_accuracy: 0.4643\n",
      "Epoch 182/200\n",
      "2010/2010 [==============================] - 0s 137us/sample - loss: 2.0144 - accuracy: 0.4080 - val_loss: 1.2649 - val_accuracy: 0.4643\n",
      "Epoch 183/200\n",
      "2010/2010 [==============================] - 0s 134us/sample - loss: 1.9843 - accuracy: 0.4109 - val_loss: 1.2606 - val_accuracy: 0.4643\n",
      "Epoch 184/200\n",
      "2010/2010 [==============================] - 0s 140us/sample - loss: 2.0679 - accuracy: 0.3950 - val_loss: 1.2601 - val_accuracy: 0.4643\n",
      "Epoch 185/200\n",
      "2010/2010 [==============================] - 0s 129us/sample - loss: 2.0121 - accuracy: 0.4124 - val_loss: 1.2579 - val_accuracy: 0.4643\n",
      "Epoch 186/200\n",
      "2010/2010 [==============================] - 0s 136us/sample - loss: 2.0062 - accuracy: 0.4124 - val_loss: 1.2553 - val_accuracy: 0.4643\n",
      "Epoch 187/200\n",
      "2010/2010 [==============================] - 0s 129us/sample - loss: 2.0158 - accuracy: 0.3970 - val_loss: 1.2530 - val_accuracy: 0.4643\n",
      "Epoch 188/200\n",
      "2010/2010 [==============================] - 0s 130us/sample - loss: 1.9918 - accuracy: 0.4129 - val_loss: 1.2510 - val_accuracy: 0.4643\n",
      "Epoch 189/200\n",
      "2010/2010 [==============================] - 0s 128us/sample - loss: 2.0447 - accuracy: 0.3900 - val_loss: 1.2502 - val_accuracy: 0.4643\n",
      "Epoch 190/200\n",
      "2010/2010 [==============================] - 0s 166us/sample - loss: 1.9771 - accuracy: 0.4219 - val_loss: 1.2459 - val_accuracy: 0.4643\n",
      "Epoch 191/200\n",
      "2010/2010 [==============================] - 0s 157us/sample - loss: 2.0199 - accuracy: 0.4075 - val_loss: 1.2444 - val_accuracy: 0.4643\n",
      "Epoch 192/200\n",
      "2010/2010 [==============================] - 0s 143us/sample - loss: 2.0244 - accuracy: 0.4154 - val_loss: 1.2427 - val_accuracy: 0.4643\n",
      "Epoch 193/200\n",
      "2010/2010 [==============================] - 0s 156us/sample - loss: 2.0211 - accuracy: 0.3980 - val_loss: 1.2390 - val_accuracy: 0.4643\n",
      "Epoch 194/200\n",
      "2010/2010 [==============================] - 0s 138us/sample - loss: 2.0309 - accuracy: 0.4020 - val_loss: 1.2371 - val_accuracy: 0.4643\n",
      "Epoch 195/200\n",
      "2010/2010 [==============================] - 0s 142us/sample - loss: 1.9962 - accuracy: 0.4154 - val_loss: 1.2372 - val_accuracy: 0.4643\n",
      "Epoch 196/200\n",
      "2010/2010 [==============================] - 0s 148us/sample - loss: 2.0056 - accuracy: 0.4139 - val_loss: 1.2367 - val_accuracy: 0.4643\n",
      "Epoch 197/200\n",
      "2010/2010 [==============================] - 0s 143us/sample - loss: 2.0382 - accuracy: 0.3955 - val_loss: 1.2363 - val_accuracy: 0.4643\n",
      "Epoch 198/200\n",
      "2010/2010 [==============================] - 0s 142us/sample - loss: 2.0093 - accuracy: 0.4109 - val_loss: 1.2338 - val_accuracy: 0.4643\n",
      "Epoch 199/200\n",
      "2010/2010 [==============================] - 0s 138us/sample - loss: 2.0011 - accuracy: 0.3945 - val_loss: 1.2321 - val_accuracy: 0.4643\n",
      "Epoch 200/200\n",
      "2010/2010 [==============================] - 0s 137us/sample - loss: 2.0040 - accuracy: 0.4085 - val_loss: 1.2294 - val_accuracy: 0.4643\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=64, epochs=200, validation_split=0.04)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
