{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## La Liga Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# making all pandas columns visable with display command\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, Activation, Flatten, Dense, Dropout, LSTM\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv(\"datasets/laliga_data_train_onehot.csv\")\n",
    "test=pd.read_csv(\"datasets/laliga_data_test_onehot.csv\")\n",
    "# print(train.head())\n",
    "# print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2660, 29)\n",
      "(2660,)\n"
     ]
    }
   ],
   "source": [
    "X_train = train.drop(columns = ['FTR'])\n",
    "y_train = train['FTR']\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(380, 29)\n",
      "(380,)\n"
     ]
    }
   ],
   "source": [
    "X_test = test.drop(columns = ['FTR'])\n",
    "y_test = test['FTR']\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = X_train.shape[1]\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 41-75-3\n",
    "# We first need to define the sequence of dependencies (the computational graph)\n",
    "# x = Input(shape=(20,32))\n",
    "def fit_model(learning_rate, hidden_layer, dropout, batch_size):\n",
    "    x = Input(shape=(columns,))\n",
    "    # h = Conv2D(32, (7, 7), strides=(2, 2))(x)\n",
    "    # h = Activation('relu')(x)\n",
    "    h = Flatten()(x)\n",
    "    for i in hidden_layer:\n",
    "        h = Dense(i, activation = 'relu')(h)\n",
    "    # for i in range(10):\n",
    "    #     h = Dense(75)(h)\n",
    "    h = Dropout(dropout)(h)\n",
    "    p = Activation('softmax')(h)\n",
    "\n",
    "    # Now that we have defined how to find p from x, we can create a \n",
    "    # model simply by saying what is input and what is output\n",
    "    model = Model(inputs=x, outputs=p)\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(lr=learning_rate), metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    \n",
    "    history = model.fit(X_train, y_train, batch_size=batch_size, epochs=200, validation_split=0.04)\n",
    "    return history,model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 29)]              0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 41)                1230      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 75)                3150      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 228       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 4,608\n",
      "Trainable params: 4,608\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2553 samples, validate on 107 samples\n",
      "Epoch 1/200\n",
      "2553/2553 [==============================] - 1s 404us/sample - loss: 1.1358 - accuracy: 0.3510 - val_loss: 1.1094 - val_accuracy: 0.3178\n",
      "Epoch 2/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.1014 - accuracy: 0.3972 - val_loss: 1.0749 - val_accuracy: 0.3738\n",
      "Epoch 3/200\n",
      "2553/2553 [==============================] - 0s 132us/sample - loss: 1.0685 - accuracy: 0.4407 - val_loss: 1.0454 - val_accuracy: 0.4112\n",
      "Epoch 4/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0430 - accuracy: 0.4614 - val_loss: 1.0270 - val_accuracy: 0.4393\n",
      "Epoch 5/200\n",
      "2553/2553 [==============================] - 0s 94us/sample - loss: 1.0263 - accuracy: 0.4751 - val_loss: 1.0139 - val_accuracy: 0.4393\n",
      "Epoch 6/200\n",
      "2553/2553 [==============================] - 0s 99us/sample - loss: 1.0152 - accuracy: 0.4857 - val_loss: 1.0046 - val_accuracy: 0.4393\n",
      "Epoch 7/200\n",
      "2553/2553 [==============================] - 0s 97us/sample - loss: 1.0082 - accuracy: 0.4904 - val_loss: 0.9976 - val_accuracy: 0.4486\n",
      "Epoch 8/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.0034 - accuracy: 0.4951 - val_loss: 0.9924 - val_accuracy: 0.4579\n",
      "Epoch 9/200\n",
      "2553/2553 [==============================] - 0s 94us/sample - loss: 0.9999 - accuracy: 0.5002 - val_loss: 0.9886 - val_accuracy: 0.4673\n",
      "Epoch 10/200\n",
      "2553/2553 [==============================] - 0s 97us/sample - loss: 0.9974 - accuracy: 0.5002 - val_loss: 0.9857 - val_accuracy: 0.4673\n",
      "Epoch 11/200\n",
      "2553/2553 [==============================] - 0s 91us/sample - loss: 0.9954 - accuracy: 0.5010 - val_loss: 0.9835 - val_accuracy: 0.4673\n",
      "Epoch 12/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 0.9938 - accuracy: 0.5010 - val_loss: 0.9816 - val_accuracy: 0.4673\n",
      "Epoch 13/200\n",
      "2553/2553 [==============================] - 0s 94us/sample - loss: 0.9923 - accuracy: 0.5049 - val_loss: 0.9800 - val_accuracy: 0.4673\n",
      "Epoch 14/200\n",
      "2553/2553 [==============================] - 0s 99us/sample - loss: 0.9911 - accuracy: 0.5061 - val_loss: 0.9786 - val_accuracy: 0.4673\n",
      "Epoch 15/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 0.9899 - accuracy: 0.5072 - val_loss: 0.9773 - val_accuracy: 0.4766\n",
      "Epoch 16/200\n",
      "2553/2553 [==============================] - 0s 99us/sample - loss: 0.9887 - accuracy: 0.5072 - val_loss: 0.9761 - val_accuracy: 0.4766\n",
      "Epoch 17/200\n",
      "2553/2553 [==============================] - 0s 91us/sample - loss: 0.9876 - accuracy: 0.5080 - val_loss: 0.9749 - val_accuracy: 0.4766\n",
      "Epoch 18/200\n",
      "2553/2553 [==============================] - 0s 94us/sample - loss: 0.9864 - accuracy: 0.5096 - val_loss: 0.9735 - val_accuracy: 0.4766\n",
      "Epoch 19/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 0.9853 - accuracy: 0.5104 - val_loss: 0.9723 - val_accuracy: 0.4766\n",
      "Epoch 20/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 0.9842 - accuracy: 0.5108 - val_loss: 0.9712 - val_accuracy: 0.4766\n",
      "Epoch 21/200\n",
      "2553/2553 [==============================] - 0s 92us/sample - loss: 0.9831 - accuracy: 0.5104 - val_loss: 0.9702 - val_accuracy: 0.4953\n",
      "Epoch 22/200\n",
      "2553/2553 [==============================] - 0s 93us/sample - loss: 0.9821 - accuracy: 0.5119 - val_loss: 0.9692 - val_accuracy: 0.4953\n",
      "Epoch 23/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 0.9811 - accuracy: 0.5131 - val_loss: 0.9682 - val_accuracy: 0.5047\n",
      "Epoch 24/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 0.9801 - accuracy: 0.5147 - val_loss: 0.9672 - val_accuracy: 0.5047\n",
      "Epoch 25/200\n",
      "2553/2553 [==============================] - 0s 97us/sample - loss: 0.9792 - accuracy: 0.5139 - val_loss: 0.9665 - val_accuracy: 0.5140\n",
      "Epoch 26/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 0.9783 - accuracy: 0.5147 - val_loss: 0.9656 - val_accuracy: 0.5140\n",
      "Epoch 27/200\n",
      "2553/2553 [==============================] - 0s 97us/sample - loss: 0.9774 - accuracy: 0.5131 - val_loss: 0.9646 - val_accuracy: 0.5140\n",
      "Epoch 28/200\n",
      "2553/2553 [==============================] - 0s 97us/sample - loss: 0.9766 - accuracy: 0.5159 - val_loss: 0.9641 - val_accuracy: 0.5234\n",
      "Epoch 29/200\n",
      "2553/2553 [==============================] - 0s 89us/sample - loss: 0.9758 - accuracy: 0.5147 - val_loss: 0.9633 - val_accuracy: 0.5234\n",
      "Epoch 30/200\n",
      "2553/2553 [==============================] - 0s 91us/sample - loss: 0.9750 - accuracy: 0.5155 - val_loss: 0.9624 - val_accuracy: 0.5327\n",
      "Epoch 31/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 0.9742 - accuracy: 0.5174 - val_loss: 0.9617 - val_accuracy: 0.5327\n",
      "Epoch 32/200\n",
      "2553/2553 [==============================] - 0s 93us/sample - loss: 0.9735 - accuracy: 0.5182 - val_loss: 0.9610 - val_accuracy: 0.5327\n",
      "Epoch 33/200\n",
      "2553/2553 [==============================] - 0s 94us/sample - loss: 0.9728 - accuracy: 0.5186 - val_loss: 0.9603 - val_accuracy: 0.5327\n",
      "Epoch 34/200\n",
      "2553/2553 [==============================] - 0s 93us/sample - loss: 0.9721 - accuracy: 0.5194 - val_loss: 0.9593 - val_accuracy: 0.5421\n",
      "Epoch 35/200\n",
      "2553/2553 [==============================] - 0s 96us/sample - loss: 0.9714 - accuracy: 0.5206 - val_loss: 0.9586 - val_accuracy: 0.5421\n",
      "Epoch 36/200\n",
      "2553/2553 [==============================] - 0s 90us/sample - loss: 0.9707 - accuracy: 0.5206 - val_loss: 0.9578 - val_accuracy: 0.5514\n",
      "Epoch 37/200\n",
      "2553/2553 [==============================] - 0s 93us/sample - loss: 0.9701 - accuracy: 0.5206 - val_loss: 0.9570 - val_accuracy: 0.5514\n",
      "Epoch 38/200\n",
      "2553/2553 [==============================] - 0s 91us/sample - loss: 0.9694 - accuracy: 0.5217 - val_loss: 0.9563 - val_accuracy: 0.5514\n",
      "Epoch 39/200\n",
      "2553/2553 [==============================] - 0s 90us/sample - loss: 0.9687 - accuracy: 0.5233 - val_loss: 0.9555 - val_accuracy: 0.5421\n",
      "Epoch 40/200\n",
      "2553/2553 [==============================] - 0s 96us/sample - loss: 0.9682 - accuracy: 0.5245 - val_loss: 0.9549 - val_accuracy: 0.5421\n",
      "Epoch 41/200\n",
      "2553/2553 [==============================] - 0s 90us/sample - loss: 0.9676 - accuracy: 0.5249 - val_loss: 0.9540 - val_accuracy: 0.5327\n",
      "Epoch 42/200\n",
      "2553/2553 [==============================] - 0s 92us/sample - loss: 0.9669 - accuracy: 0.5260 - val_loss: 0.9535 - val_accuracy: 0.5327\n",
      "Epoch 43/200\n",
      "2553/2553 [==============================] - 0s 94us/sample - loss: 0.9663 - accuracy: 0.5272 - val_loss: 0.9529 - val_accuracy: 0.5327\n",
      "Epoch 44/200\n",
      "2553/2553 [==============================] - 0s 96us/sample - loss: 0.9657 - accuracy: 0.5272 - val_loss: 0.9521 - val_accuracy: 0.5327\n",
      "Epoch 45/200\n",
      "2553/2553 [==============================] - 0s 89us/sample - loss: 0.9652 - accuracy: 0.5276 - val_loss: 0.9516 - val_accuracy: 0.5327\n",
      "Epoch 46/200\n",
      "2553/2553 [==============================] - 0s 91us/sample - loss: 0.9647 - accuracy: 0.5296 - val_loss: 0.9511 - val_accuracy: 0.5327\n",
      "Epoch 47/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 110us/sample - loss: 0.9642 - accuracy: 0.5280 - val_loss: 0.9506 - val_accuracy: 0.5327\n",
      "Epoch 48/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 0.9637 - accuracy: 0.5288 - val_loss: 0.9501 - val_accuracy: 0.5327\n",
      "Epoch 49/200\n",
      "2553/2553 [==============================] - 0s 95us/sample - loss: 0.9632 - accuracy: 0.5292 - val_loss: 0.9495 - val_accuracy: 0.5327\n",
      "Epoch 50/200\n",
      "2553/2553 [==============================] - 0s 124us/sample - loss: 0.9628 - accuracy: 0.5296 - val_loss: 0.9489 - val_accuracy: 0.5327\n",
      "Epoch 51/200\n",
      "2553/2553 [==============================] - 0s 94us/sample - loss: 0.9623 - accuracy: 0.5315 - val_loss: 0.9484 - val_accuracy: 0.5327\n",
      "Epoch 52/200\n",
      "2553/2553 [==============================] - 0s 91us/sample - loss: 0.9619 - accuracy: 0.5319 - val_loss: 0.9479 - val_accuracy: 0.5327\n",
      "Epoch 53/200\n",
      "2553/2553 [==============================] - 0s 94us/sample - loss: 0.9615 - accuracy: 0.5307 - val_loss: 0.9474 - val_accuracy: 0.5327\n",
      "Epoch 54/200\n",
      "2553/2553 [==============================] - 0s 96us/sample - loss: 0.9611 - accuracy: 0.5307 - val_loss: 0.9472 - val_accuracy: 0.5327\n",
      "Epoch 55/200\n",
      "2553/2553 [==============================] - 0s 93us/sample - loss: 0.9607 - accuracy: 0.5307 - val_loss: 0.9466 - val_accuracy: 0.5327\n",
      "Epoch 56/200\n",
      "2553/2553 [==============================] - 0s 98us/sample - loss: 0.9602 - accuracy: 0.5315 - val_loss: 0.9463 - val_accuracy: 0.5327\n",
      "Epoch 57/200\n",
      "2553/2553 [==============================] - 0s 98us/sample - loss: 0.9599 - accuracy: 0.5331 - val_loss: 0.9459 - val_accuracy: 0.5327\n",
      "Epoch 58/200\n",
      "2553/2553 [==============================] - 0s 92us/sample - loss: 0.9594 - accuracy: 0.5323 - val_loss: 0.9456 - val_accuracy: 0.5327\n",
      "Epoch 59/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 0.9590 - accuracy: 0.5343 - val_loss: 0.9452 - val_accuracy: 0.5327\n",
      "Epoch 60/200\n",
      "2553/2553 [==============================] - 0s 90us/sample - loss: 0.9587 - accuracy: 0.5315 - val_loss: 0.9449 - val_accuracy: 0.5327\n",
      "Epoch 61/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 0.9582 - accuracy: 0.5331 - val_loss: 0.9447 - val_accuracy: 0.5327\n",
      "Epoch 62/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 0.9578 - accuracy: 0.5335 - val_loss: 0.9445 - val_accuracy: 0.5327\n",
      "Epoch 63/200\n",
      "2553/2553 [==============================] - 0s 121us/sample - loss: 0.9574 - accuracy: 0.5343 - val_loss: 0.9442 - val_accuracy: 0.5327\n",
      "Epoch 64/200\n",
      "2553/2553 [==============================] - 0s 118us/sample - loss: 0.9571 - accuracy: 0.5358 - val_loss: 0.9439 - val_accuracy: 0.5327\n",
      "Epoch 65/200\n",
      "2553/2553 [==============================] - 0s 96us/sample - loss: 0.9567 - accuracy: 0.5354 - val_loss: 0.9435 - val_accuracy: 0.5327\n",
      "Epoch 66/200\n",
      "2553/2553 [==============================] - 0s 92us/sample - loss: 0.9564 - accuracy: 0.5370 - val_loss: 0.9434 - val_accuracy: 0.5327\n",
      "Epoch 67/200\n",
      "2553/2553 [==============================] - 0s 96us/sample - loss: 0.9561 - accuracy: 0.5362 - val_loss: 0.9430 - val_accuracy: 0.5327\n",
      "Epoch 68/200\n",
      "2553/2553 [==============================] - 0s 92us/sample - loss: 0.9557 - accuracy: 0.5382 - val_loss: 0.9428 - val_accuracy: 0.5327\n",
      "Epoch 69/200\n",
      "2553/2553 [==============================] - 0s 94us/sample - loss: 0.9554 - accuracy: 0.5378 - val_loss: 0.9425 - val_accuracy: 0.5421\n",
      "Epoch 70/200\n",
      "2553/2553 [==============================] - 0s 95us/sample - loss: 0.9551 - accuracy: 0.5370 - val_loss: 0.9423 - val_accuracy: 0.5421\n",
      "Epoch 71/200\n",
      "2553/2553 [==============================] - 0s 123us/sample - loss: 0.9548 - accuracy: 0.5382 - val_loss: 0.9420 - val_accuracy: 0.5421\n",
      "Epoch 72/200\n",
      "2553/2553 [==============================] - 0s 96us/sample - loss: 0.9545 - accuracy: 0.5394 - val_loss: 0.9418 - val_accuracy: 0.5421\n",
      "Epoch 73/200\n",
      "2553/2553 [==============================] - 0s 95us/sample - loss: 0.9542 - accuracy: 0.5394 - val_loss: 0.9416 - val_accuracy: 0.5421\n",
      "Epoch 74/200\n",
      "2553/2553 [==============================] - 0s 95us/sample - loss: 0.9539 - accuracy: 0.5405 - val_loss: 0.9414 - val_accuracy: 0.5421\n",
      "Epoch 75/200\n",
      "2553/2553 [==============================] - 0s 99us/sample - loss: 0.9537 - accuracy: 0.5398 - val_loss: 0.9412 - val_accuracy: 0.5421\n",
      "Epoch 76/200\n",
      "2553/2553 [==============================] - 0s 95us/sample - loss: 0.9533 - accuracy: 0.5425 - val_loss: 0.9409 - val_accuracy: 0.5421\n",
      "Epoch 77/200\n",
      "2553/2553 [==============================] - 0s 94us/sample - loss: 0.9530 - accuracy: 0.5421 - val_loss: 0.9406 - val_accuracy: 0.5421\n",
      "Epoch 78/200\n",
      "2553/2553 [==============================] - ETA: 0s - loss: 0.9515 - accuracy: 0.54 - 0s 96us/sample - loss: 0.9528 - accuracy: 0.5433 - val_loss: 0.9404 - val_accuracy: 0.5327\n",
      "Epoch 79/200\n",
      "2553/2553 [==============================] - 0s 91us/sample - loss: 0.9526 - accuracy: 0.5425 - val_loss: 0.9401 - val_accuracy: 0.5327\n",
      "Epoch 80/200\n",
      "2553/2553 [==============================] - ETA: 0s - loss: 0.9549 - accuracy: 0.53 - 0s 98us/sample - loss: 0.9523 - accuracy: 0.5433 - val_loss: 0.9400 - val_accuracy: 0.5327\n",
      "Epoch 81/200\n",
      "2553/2553 [==============================] - 0s 93us/sample - loss: 0.9520 - accuracy: 0.5409 - val_loss: 0.9397 - val_accuracy: 0.5327\n",
      "Epoch 82/200\n",
      "2553/2553 [==============================] - 0s 98us/sample - loss: 0.9517 - accuracy: 0.5429 - val_loss: 0.9395 - val_accuracy: 0.5327\n",
      "Epoch 83/200\n",
      "2553/2553 [==============================] - 0s 94us/sample - loss: 0.9516 - accuracy: 0.5417 - val_loss: 0.9394 - val_accuracy: 0.5327\n",
      "Epoch 84/200\n",
      "2553/2553 [==============================] - 0s 98us/sample - loss: 0.9513 - accuracy: 0.5433 - val_loss: 0.9393 - val_accuracy: 0.5327\n",
      "Epoch 85/200\n",
      "2553/2553 [==============================] - 0s 89us/sample - loss: 0.9510 - accuracy: 0.5445 - val_loss: 0.9392 - val_accuracy: 0.5327\n",
      "Epoch 86/200\n",
      "2553/2553 [==============================] - 0s 94us/sample - loss: 0.9508 - accuracy: 0.5441 - val_loss: 0.9390 - val_accuracy: 0.5327\n",
      "Epoch 87/200\n",
      "2553/2553 [==============================] - 0s 91us/sample - loss: 0.9506 - accuracy: 0.5441 - val_loss: 0.9388 - val_accuracy: 0.5327\n",
      "Epoch 88/200\n",
      "2553/2553 [==============================] - 0s 98us/sample - loss: 0.9504 - accuracy: 0.5445 - val_loss: 0.9387 - val_accuracy: 0.5327\n",
      "Epoch 89/200\n",
      "2553/2553 [==============================] - 0s 91us/sample - loss: 0.9502 - accuracy: 0.5445 - val_loss: 0.9386 - val_accuracy: 0.5327\n",
      "Epoch 90/200\n",
      "2553/2553 [==============================] - 0s 93us/sample - loss: 0.9499 - accuracy: 0.5448 - val_loss: 0.9385 - val_accuracy: 0.5421\n",
      "Epoch 91/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 0.9497 - accuracy: 0.5452 - val_loss: 0.9383 - val_accuracy: 0.5421\n",
      "Epoch 92/200\n",
      "2553/2553 [==============================] - 0s 127us/sample - loss: 0.9495 - accuracy: 0.5448 - val_loss: 0.9381 - val_accuracy: 0.5421\n",
      "Epoch 93/200\n",
      "2553/2553 [==============================] - 0s 95us/sample - loss: 0.9493 - accuracy: 0.5456 - val_loss: 0.9381 - val_accuracy: 0.5421\n",
      "Epoch 94/200\n",
      "2553/2553 [==============================] - 0s 92us/sample - loss: 0.9491 - accuracy: 0.5460 - val_loss: 0.9378 - val_accuracy: 0.5421\n",
      "Epoch 95/200\n",
      "2553/2553 [==============================] - 0s 97us/sample - loss: 0.9489 - accuracy: 0.5468 - val_loss: 0.9377 - val_accuracy: 0.5421\n",
      "Epoch 96/200\n",
      "2553/2553 [==============================] - 0s 94us/sample - loss: 0.9488 - accuracy: 0.5460 - val_loss: 0.9375 - val_accuracy: 0.5421\n",
      "Epoch 97/200\n",
      "2553/2553 [==============================] - 0s 97us/sample - loss: 0.9486 - accuracy: 0.5480 - val_loss: 0.9373 - val_accuracy: 0.5421\n",
      "Epoch 98/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 0.9483 - accuracy: 0.5484 - val_loss: 0.9372 - val_accuracy: 0.5327\n",
      "Epoch 99/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 0.9481 - accuracy: 0.5488 - val_loss: 0.9370 - val_accuracy: 0.5327\n",
      "Epoch 100/200\n",
      "2553/2553 [==============================] - 0s 96us/sample - loss: 0.9480 - accuracy: 0.5495 - val_loss: 0.9369 - val_accuracy: 0.5421\n",
      "Epoch 101/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 98us/sample - loss: 0.9478 - accuracy: 0.5511 - val_loss: 0.9368 - val_accuracy: 0.5421\n",
      "Epoch 102/200\n",
      "2553/2553 [==============================] - 0s 92us/sample - loss: 0.9475 - accuracy: 0.5495 - val_loss: 0.9366 - val_accuracy: 0.5514\n",
      "Epoch 103/200\n",
      "2553/2553 [==============================] - 0s 95us/sample - loss: 0.9474 - accuracy: 0.5499 - val_loss: 0.9365 - val_accuracy: 0.5514\n",
      "Epoch 104/200\n",
      "2553/2553 [==============================] - 0s 93us/sample - loss: 0.9472 - accuracy: 0.5511 - val_loss: 0.9362 - val_accuracy: 0.5514\n",
      "Epoch 105/200\n",
      "2553/2553 [==============================] - 0s 120us/sample - loss: 0.9471 - accuracy: 0.5515 - val_loss: 0.9361 - val_accuracy: 0.5514\n",
      "Epoch 106/200\n",
      "2553/2553 [==============================] - 0s 131us/sample - loss: 0.9468 - accuracy: 0.5531 - val_loss: 0.9360 - val_accuracy: 0.5514\n",
      "Epoch 107/200\n",
      "2553/2553 [==============================] - 0s 144us/sample - loss: 0.9467 - accuracy: 0.5519 - val_loss: 0.9357 - val_accuracy: 0.5514\n",
      "Epoch 108/200\n",
      "2553/2553 [==============================] - 0s 132us/sample - loss: 0.9465 - accuracy: 0.5527 - val_loss: 0.9356 - val_accuracy: 0.5514\n",
      "Epoch 109/200\n",
      "2553/2553 [==============================] - 0s 93us/sample - loss: 0.9463 - accuracy: 0.5535 - val_loss: 0.9353 - val_accuracy: 0.5514\n",
      "Epoch 110/200\n",
      "2553/2553 [==============================] - 0s 95us/sample - loss: 0.9462 - accuracy: 0.5542 - val_loss: 0.9352 - val_accuracy: 0.5514\n",
      "Epoch 111/200\n",
      "2553/2553 [==============================] - 0s 97us/sample - loss: 0.9461 - accuracy: 0.5535 - val_loss: 0.9350 - val_accuracy: 0.5514\n",
      "Epoch 112/200\n",
      "2553/2553 [==============================] - 0s 95us/sample - loss: 0.9459 - accuracy: 0.5550 - val_loss: 0.9348 - val_accuracy: 0.5514\n",
      "Epoch 113/200\n",
      "2553/2553 [==============================] - 0s 93us/sample - loss: 0.9458 - accuracy: 0.5546 - val_loss: 0.9346 - val_accuracy: 0.5514\n",
      "Epoch 114/200\n",
      "2553/2553 [==============================] - 0s 92us/sample - loss: 0.9456 - accuracy: 0.5554 - val_loss: 0.9344 - val_accuracy: 0.5514\n",
      "Epoch 115/200\n",
      "2553/2553 [==============================] - 0s 99us/sample - loss: 0.9454 - accuracy: 0.5566 - val_loss: 0.9343 - val_accuracy: 0.5514\n",
      "Epoch 116/200\n",
      "2553/2553 [==============================] - 0s 93us/sample - loss: 0.9453 - accuracy: 0.5550 - val_loss: 0.9341 - val_accuracy: 0.5514\n",
      "Epoch 117/200\n",
      "2553/2553 [==============================] - 0s 98us/sample - loss: 0.9452 - accuracy: 0.5562 - val_loss: 0.9339 - val_accuracy: 0.5514\n",
      "Epoch 118/200\n",
      "2553/2553 [==============================] - 0s 135us/sample - loss: 0.9450 - accuracy: 0.5558 - val_loss: 0.9337 - val_accuracy: 0.5514\n",
      "Epoch 119/200\n",
      "2553/2553 [==============================] - 0s 123us/sample - loss: 0.9449 - accuracy: 0.5550 - val_loss: 0.9335 - val_accuracy: 0.5607\n",
      "Epoch 120/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 0.9447 - accuracy: 0.5562 - val_loss: 0.9334 - val_accuracy: 0.5514\n",
      "Epoch 121/200\n",
      "2553/2553 [==============================] - 0s 94us/sample - loss: 0.9445 - accuracy: 0.5562 - val_loss: 0.9331 - val_accuracy: 0.5607\n",
      "Epoch 122/200\n",
      "2553/2553 [==============================] - 0s 93us/sample - loss: 0.9444 - accuracy: 0.5554 - val_loss: 0.9330 - val_accuracy: 0.5607\n",
      "Epoch 123/200\n",
      "2553/2553 [==============================] - 0s 97us/sample - loss: 0.9443 - accuracy: 0.5550 - val_loss: 0.9329 - val_accuracy: 0.5607\n",
      "Epoch 124/200\n",
      "2553/2553 [==============================] - 0s 93us/sample - loss: 0.9441 - accuracy: 0.5562 - val_loss: 0.9326 - val_accuracy: 0.5607\n",
      "Epoch 125/200\n",
      "2553/2553 [==============================] - 0s 96us/sample - loss: 0.9440 - accuracy: 0.5546 - val_loss: 0.9324 - val_accuracy: 0.5607\n",
      "Epoch 126/200\n",
      "2553/2553 [==============================] - 0s 93us/sample - loss: 0.9439 - accuracy: 0.5539 - val_loss: 0.9323 - val_accuracy: 0.5607\n",
      "Epoch 127/200\n",
      "2553/2553 [==============================] - 0s 96us/sample - loss: 0.9437 - accuracy: 0.5546 - val_loss: 0.9323 - val_accuracy: 0.5607\n",
      "Epoch 128/200\n",
      "2553/2553 [==============================] - 0s 96us/sample - loss: 0.9436 - accuracy: 0.5562 - val_loss: 0.9321 - val_accuracy: 0.5607\n",
      "Epoch 129/200\n",
      "2553/2553 [==============================] - 0s 96us/sample - loss: 0.9435 - accuracy: 0.5558 - val_loss: 0.9318 - val_accuracy: 0.5607\n",
      "Epoch 130/200\n",
      "2553/2553 [==============================] - 0s 93us/sample - loss: 0.9433 - accuracy: 0.5570 - val_loss: 0.9317 - val_accuracy: 0.5607\n",
      "Epoch 131/200\n",
      "2553/2553 [==============================] - 0s 92us/sample - loss: 0.9431 - accuracy: 0.5570 - val_loss: 0.9314 - val_accuracy: 0.5607\n",
      "Epoch 132/200\n",
      "2553/2553 [==============================] - 0s 99us/sample - loss: 0.9430 - accuracy: 0.5550 - val_loss: 0.9314 - val_accuracy: 0.5607\n",
      "Epoch 133/200\n",
      "2553/2553 [==============================] - 0s 98us/sample - loss: 0.9429 - accuracy: 0.5562 - val_loss: 0.9312 - val_accuracy: 0.5607\n",
      "Epoch 134/200\n",
      "2553/2553 [==============================] - 0s 96us/sample - loss: 0.9428 - accuracy: 0.5558 - val_loss: 0.9310 - val_accuracy: 0.5607\n",
      "Epoch 135/200\n",
      "2553/2553 [==============================] - 0s 90us/sample - loss: 0.9426 - accuracy: 0.5558 - val_loss: 0.9308 - val_accuracy: 0.5607\n",
      "Epoch 136/200\n",
      "2553/2553 [==============================] - 0s 98us/sample - loss: 0.9425 - accuracy: 0.5562 - val_loss: 0.9306 - val_accuracy: 0.5607\n",
      "Epoch 137/200\n",
      "2553/2553 [==============================] - 0s 97us/sample - loss: 0.9424 - accuracy: 0.5554 - val_loss: 0.9306 - val_accuracy: 0.5607\n",
      "Epoch 138/200\n",
      "2553/2553 [==============================] - 0s 96us/sample - loss: 0.9422 - accuracy: 0.5562 - val_loss: 0.9304 - val_accuracy: 0.5607\n",
      "Epoch 139/200\n",
      "2553/2553 [==============================] - 0s 117us/sample - loss: 0.9421 - accuracy: 0.5570 - val_loss: 0.9303 - val_accuracy: 0.5607\n",
      "Epoch 140/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 0.9420 - accuracy: 0.5562 - val_loss: 0.9302 - val_accuracy: 0.5607\n",
      "Epoch 141/200\n",
      "2553/2553 [==============================] - 0s 91us/sample - loss: 0.9419 - accuracy: 0.5574 - val_loss: 0.9301 - val_accuracy: 0.5607\n",
      "Epoch 142/200\n",
      "2553/2553 [==============================] - 0s 97us/sample - loss: 0.9417 - accuracy: 0.5566 - val_loss: 0.9299 - val_accuracy: 0.5607\n",
      "Epoch 143/200\n",
      "2553/2553 [==============================] - 0s 90us/sample - loss: 0.9416 - accuracy: 0.5562 - val_loss: 0.9298 - val_accuracy: 0.5607\n",
      "Epoch 144/200\n",
      "2553/2553 [==============================] - 0s 96us/sample - loss: 0.9415 - accuracy: 0.5574 - val_loss: 0.9297 - val_accuracy: 0.5607\n",
      "Epoch 145/200\n",
      "2553/2553 [==============================] - 0s 95us/sample - loss: 0.9414 - accuracy: 0.5578 - val_loss: 0.9295 - val_accuracy: 0.5607\n",
      "Epoch 146/200\n",
      "2553/2553 [==============================] - 0s 135us/sample - loss: 0.9413 - accuracy: 0.5582 - val_loss: 0.9294 - val_accuracy: 0.5607\n",
      "Epoch 147/200\n",
      "2553/2553 [==============================] - 0s 119us/sample - loss: 0.9411 - accuracy: 0.5570 - val_loss: 0.9293 - val_accuracy: 0.5607\n",
      "Epoch 148/200\n",
      "2553/2553 [==============================] - 0s 99us/sample - loss: 0.9410 - accuracy: 0.5578 - val_loss: 0.9292 - val_accuracy: 0.5607\n",
      "Epoch 149/200\n",
      "2553/2553 [==============================] - 0s 92us/sample - loss: 0.9409 - accuracy: 0.5558 - val_loss: 0.9290 - val_accuracy: 0.5607\n",
      "Epoch 150/200\n",
      "2553/2553 [==============================] - 0s 123us/sample - loss: 0.9408 - accuracy: 0.5586 - val_loss: 0.9289 - val_accuracy: 0.5607\n",
      "Epoch 151/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 0.9406 - accuracy: 0.5574 - val_loss: 0.9288 - val_accuracy: 0.5607\n",
      "Epoch 152/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 0.9406 - accuracy: 0.5574 - val_loss: 0.9287 - val_accuracy: 0.5607\n",
      "Epoch 153/200\n",
      "2553/2553 [==============================] - 0s 94us/sample - loss: 0.9404 - accuracy: 0.5582 - val_loss: 0.9286 - val_accuracy: 0.5607\n",
      "Epoch 154/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 0.9404 - accuracy: 0.5578 - val_loss: 0.9286 - val_accuracy: 0.5607\n",
      "Epoch 155/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 93us/sample - loss: 0.9402 - accuracy: 0.5586 - val_loss: 0.9285 - val_accuracy: 0.5607\n",
      "Epoch 156/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 0.9401 - accuracy: 0.5578 - val_loss: 0.9284 - val_accuracy: 0.5701\n",
      "Epoch 157/200\n",
      "2553/2553 [==============================] - 0s 94us/sample - loss: 0.9400 - accuracy: 0.5578 - val_loss: 0.9284 - val_accuracy: 0.5701\n",
      "Epoch 158/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 0.9398 - accuracy: 0.5574 - val_loss: 0.9282 - val_accuracy: 0.5701\n",
      "Epoch 159/200\n",
      "2553/2553 [==============================] - 0s 92us/sample - loss: 0.9397 - accuracy: 0.5578 - val_loss: 0.9282 - val_accuracy: 0.5701\n",
      "Epoch 160/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 0.9396 - accuracy: 0.5574 - val_loss: 0.9281 - val_accuracy: 0.5701\n",
      "Epoch 161/200\n",
      "2553/2553 [==============================] - 0s 96us/sample - loss: 0.9395 - accuracy: 0.5590 - val_loss: 0.9280 - val_accuracy: 0.5701\n",
      "Epoch 162/200\n",
      "2553/2553 [==============================] - 0s 98us/sample - loss: 0.9393 - accuracy: 0.5582 - val_loss: 0.9280 - val_accuracy: 0.5701\n",
      "Epoch 163/200\n",
      "2553/2553 [==============================] - 0s 93us/sample - loss: 0.9393 - accuracy: 0.5578 - val_loss: 0.9279 - val_accuracy: 0.5701\n",
      "Epoch 164/200\n",
      "2553/2553 [==============================] - 0s 98us/sample - loss: 0.9392 - accuracy: 0.5586 - val_loss: 0.9279 - val_accuracy: 0.5701\n",
      "Epoch 165/200\n",
      "2553/2553 [==============================] - 0s 99us/sample - loss: 0.9390 - accuracy: 0.5582 - val_loss: 0.9278 - val_accuracy: 0.5607\n",
      "Epoch 166/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 0.9389 - accuracy: 0.5590 - val_loss: 0.9278 - val_accuracy: 0.5701\n",
      "Epoch 167/200\n",
      "2553/2553 [==============================] - 0s 124us/sample - loss: 0.9388 - accuracy: 0.5578 - val_loss: 0.9276 - val_accuracy: 0.5607\n",
      "Epoch 168/200\n",
      "2553/2553 [==============================] - 0s 93us/sample - loss: 0.9387 - accuracy: 0.5578 - val_loss: 0.9276 - val_accuracy: 0.5701\n",
      "Epoch 169/200\n",
      "2553/2553 [==============================] - 0s 99us/sample - loss: 0.9386 - accuracy: 0.5590 - val_loss: 0.9275 - val_accuracy: 0.5701\n",
      "Epoch 170/200\n",
      "2553/2553 [==============================] - 0s 91us/sample - loss: 0.9384 - accuracy: 0.5582 - val_loss: 0.9275 - val_accuracy: 0.5701\n",
      "Epoch 171/200\n",
      "2553/2553 [==============================] - 0s 99us/sample - loss: 0.9383 - accuracy: 0.5590 - val_loss: 0.9274 - val_accuracy: 0.5607\n",
      "Epoch 172/200\n",
      "2553/2553 [==============================] - 0s 94us/sample - loss: 0.9383 - accuracy: 0.5582 - val_loss: 0.9274 - val_accuracy: 0.5607\n",
      "Epoch 173/200\n",
      "2553/2553 [==============================] - 0s 99us/sample - loss: 0.9382 - accuracy: 0.5593 - val_loss: 0.9272 - val_accuracy: 0.5701\n",
      "Epoch 174/200\n",
      "2553/2553 [==============================] - 0s 99us/sample - loss: 0.9380 - accuracy: 0.5586 - val_loss: 0.9272 - val_accuracy: 0.5607\n",
      "Epoch 175/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 0.9379 - accuracy: 0.5582 - val_loss: 0.9271 - val_accuracy: 0.5607\n",
      "Epoch 176/200\n",
      "2553/2553 [==============================] - 0s 96us/sample - loss: 0.9378 - accuracy: 0.5574 - val_loss: 0.9270 - val_accuracy: 0.5607\n",
      "Epoch 177/200\n",
      "2553/2553 [==============================] - 0s 98us/sample - loss: 0.9377 - accuracy: 0.5593 - val_loss: 0.9269 - val_accuracy: 0.5607\n",
      "Epoch 178/200\n",
      "2553/2553 [==============================] - 0s 91us/sample - loss: 0.9375 - accuracy: 0.5566 - val_loss: 0.9267 - val_accuracy: 0.5607\n",
      "Epoch 179/200\n",
      "2553/2553 [==============================] - 0s 96us/sample - loss: 0.9375 - accuracy: 0.5582 - val_loss: 0.9266 - val_accuracy: 0.5607\n",
      "Epoch 180/200\n",
      "2553/2553 [==============================] - 0s 92us/sample - loss: 0.9374 - accuracy: 0.5574 - val_loss: 0.9266 - val_accuracy: 0.5607\n",
      "Epoch 181/200\n",
      "2553/2553 [==============================] - 0s 94us/sample - loss: 0.9373 - accuracy: 0.5582 - val_loss: 0.9265 - val_accuracy: 0.5607\n",
      "Epoch 182/200\n",
      "2553/2553 [==============================] - ETA: 0s - loss: 0.9321 - accuracy: 0.56 - 0s 95us/sample - loss: 0.9371 - accuracy: 0.5570 - val_loss: 0.9265 - val_accuracy: 0.5607\n",
      "Epoch 183/200\n",
      "2553/2553 [==============================] - 0s 93us/sample - loss: 0.9370 - accuracy: 0.5586 - val_loss: 0.9264 - val_accuracy: 0.5607\n",
      "Epoch 184/200\n",
      "2553/2553 [==============================] - 0s 98us/sample - loss: 0.9369 - accuracy: 0.5597 - val_loss: 0.9263 - val_accuracy: 0.5607\n",
      "Epoch 185/200\n",
      "2553/2553 [==============================] - 0s 96us/sample - loss: 0.9368 - accuracy: 0.5582 - val_loss: 0.9263 - val_accuracy: 0.5607\n",
      "Epoch 186/200\n",
      "2553/2553 [==============================] - 0s 97us/sample - loss: 0.9367 - accuracy: 0.5578 - val_loss: 0.9262 - val_accuracy: 0.5607\n",
      "Epoch 187/200\n",
      "2553/2553 [==============================] - 0s 91us/sample - loss: 0.9366 - accuracy: 0.5597 - val_loss: 0.9261 - val_accuracy: 0.5607\n",
      "Epoch 188/200\n",
      "2553/2553 [==============================] - 0s 97us/sample - loss: 0.9365 - accuracy: 0.5605 - val_loss: 0.9260 - val_accuracy: 0.5607\n",
      "Epoch 189/200\n",
      "2553/2553 [==============================] - 0s 96us/sample - loss: 0.9364 - accuracy: 0.5597 - val_loss: 0.9259 - val_accuracy: 0.5607\n",
      "Epoch 190/200\n",
      "2553/2553 [==============================] - 0s 98us/sample - loss: 0.9363 - accuracy: 0.5590 - val_loss: 0.9258 - val_accuracy: 0.5607\n",
      "Epoch 191/200\n",
      "2553/2553 [==============================] - 0s 91us/sample - loss: 0.9362 - accuracy: 0.5593 - val_loss: 0.9258 - val_accuracy: 0.5607\n",
      "Epoch 192/200\n",
      "2553/2553 [==============================] - 0s 98us/sample - loss: 0.9361 - accuracy: 0.5593 - val_loss: 0.9257 - val_accuracy: 0.5607\n",
      "Epoch 193/200\n",
      "2553/2553 [==============================] - 0s 96us/sample - loss: 0.9360 - accuracy: 0.5593 - val_loss: 0.9257 - val_accuracy: 0.5607\n",
      "Epoch 194/200\n",
      "2553/2553 [==============================] - 0s 96us/sample - loss: 0.9359 - accuracy: 0.5586 - val_loss: 0.9256 - val_accuracy: 0.5607\n",
      "Epoch 195/200\n",
      "2553/2553 [==============================] - 0s 94us/sample - loss: 0.9358 - accuracy: 0.5586 - val_loss: 0.9256 - val_accuracy: 0.5607\n",
      "Epoch 196/200\n",
      "2553/2553 [==============================] - 0s 94us/sample - loss: 0.9357 - accuracy: 0.5590 - val_loss: 0.9253 - val_accuracy: 0.5607\n",
      "Epoch 197/200\n",
      "2553/2553 [==============================] - 0s 97us/sample - loss: 0.9356 - accuracy: 0.5586 - val_loss: 0.9252 - val_accuracy: 0.5607\n",
      "Epoch 198/200\n",
      "2553/2553 [==============================] - 0s 95us/sample - loss: 0.9355 - accuracy: 0.5586 - val_loss: 0.9252 - val_accuracy: 0.5607\n",
      "Epoch 199/200\n",
      "2553/2553 [==============================] - 0s 97us/sample - loss: 0.9354 - accuracy: 0.5586 - val_loss: 0.9251 - val_accuracy: 0.5607\n",
      "Epoch 200/200\n",
      "2553/2553 [==============================] - 0s 93us/sample - loss: 0.9353 - accuracy: 0.5597 - val_loss: 0.9251 - val_accuracy: 0.5607\n",
      "0.5607477 {'loss': 0.9352710839117269, 'accuracy': 0.5597336, 'val_loss': 0.925082886887488, 'val_accuracy': 0.5607477}\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 29)]              0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 41)                1230      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 75)                3150      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 228       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 4,608\n",
      "Trainable params: 4,608\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2553 samples, validate on 107 samples\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 1s 244us/sample - loss: 1.1065 - accuracy: 0.3098 - val_loss: 1.1036 - val_accuracy: 0.2617\n",
      "Epoch 2/200\n",
      "2553/2553 [==============================] - 0s 50us/sample - loss: 1.1004 - accuracy: 0.3259 - val_loss: 1.0997 - val_accuracy: 0.2991\n",
      "Epoch 3/200\n",
      "2553/2553 [==============================] - 0s 50us/sample - loss: 1.0955 - accuracy: 0.3380 - val_loss: 1.0958 - val_accuracy: 0.3178\n",
      "Epoch 4/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.0903 - accuracy: 0.3568 - val_loss: 1.0903 - val_accuracy: 0.3271\n",
      "Epoch 5/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.0831 - accuracy: 0.3846 - val_loss: 1.0802 - val_accuracy: 0.3738\n",
      "Epoch 6/200\n",
      "2553/2553 [==============================] - 0s 51us/sample - loss: 1.0714 - accuracy: 0.4238 - val_loss: 1.0642 - val_accuracy: 0.3832\n",
      "Epoch 7/200\n",
      "2553/2553 [==============================] - 0s 49us/sample - loss: 1.0548 - accuracy: 0.4626 - val_loss: 1.0464 - val_accuracy: 0.4206\n",
      "Epoch 8/200\n",
      "2553/2553 [==============================] - 0s 51us/sample - loss: 1.0385 - accuracy: 0.4857 - val_loss: 1.0291 - val_accuracy: 0.4579\n",
      "Epoch 9/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0252 - accuracy: 0.4959 - val_loss: 1.0151 - val_accuracy: 0.4579\n",
      "Epoch 10/200\n",
      "2553/2553 [==============================] - 0s 49us/sample - loss: 1.0156 - accuracy: 0.5045 - val_loss: 1.0057 - val_accuracy: 0.4766\n",
      "Epoch 11/200\n",
      "2553/2553 [==============================] - 0s 51us/sample - loss: 1.0087 - accuracy: 0.5072 - val_loss: 0.9986 - val_accuracy: 0.4766\n",
      "Epoch 12/200\n",
      "2553/2553 [==============================] - 0s 51us/sample - loss: 1.0039 - accuracy: 0.5092 - val_loss: 0.9928 - val_accuracy: 0.4860\n",
      "Epoch 13/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0006 - accuracy: 0.5108 - val_loss: 0.9884 - val_accuracy: 0.4860\n",
      "Epoch 14/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 0.9981 - accuracy: 0.5116 - val_loss: 0.9854 - val_accuracy: 0.4860\n",
      "Epoch 15/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 0.9964 - accuracy: 0.5151 - val_loss: 0.9827 - val_accuracy: 0.4860\n",
      "Epoch 16/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 0.9950 - accuracy: 0.5170 - val_loss: 0.9808 - val_accuracy: 0.4860\n",
      "Epoch 17/200\n",
      "2553/2553 [==============================] - 0s 68us/sample - loss: 0.9939 - accuracy: 0.5174 - val_loss: 0.9791 - val_accuracy: 0.4860\n",
      "Epoch 18/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 0.9931 - accuracy: 0.5186 - val_loss: 0.9778 - val_accuracy: 0.4860\n",
      "Epoch 19/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 0.9924 - accuracy: 0.5194 - val_loss: 0.9767 - val_accuracy: 0.4860\n",
      "Epoch 20/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 0.9919 - accuracy: 0.5202 - val_loss: 0.9758 - val_accuracy: 0.4860\n",
      "Epoch 21/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 0.9914 - accuracy: 0.5202 - val_loss: 0.9749 - val_accuracy: 0.4766\n",
      "Epoch 22/200\n",
      "2553/2553 [==============================] - 0s 67us/sample - loss: 0.9910 - accuracy: 0.5166 - val_loss: 0.9742 - val_accuracy: 0.4766\n",
      "Epoch 23/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 0.9907 - accuracy: 0.5155 - val_loss: 0.9735 - val_accuracy: 0.4766\n",
      "Epoch 24/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 0.9904 - accuracy: 0.5155 - val_loss: 0.9731 - val_accuracy: 0.4766\n",
      "Epoch 25/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 0.9900 - accuracy: 0.5151 - val_loss: 0.9726 - val_accuracy: 0.4766\n",
      "Epoch 26/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 0.9898 - accuracy: 0.5155 - val_loss: 0.9722 - val_accuracy: 0.4766\n",
      "Epoch 27/200\n",
      "2553/2553 [==============================] - 0s 68us/sample - loss: 0.9895 - accuracy: 0.5151 - val_loss: 0.9717 - val_accuracy: 0.4860\n",
      "Epoch 28/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 0.9892 - accuracy: 0.5139 - val_loss: 0.9714 - val_accuracy: 0.4860\n",
      "Epoch 29/200\n",
      "2553/2553 [==============================] - 0s 66us/sample - loss: 0.9889 - accuracy: 0.5135 - val_loss: 0.9709 - val_accuracy: 0.4860\n",
      "Epoch 30/200\n",
      "2553/2553 [==============================] - 0s 73us/sample - loss: 0.9887 - accuracy: 0.5143 - val_loss: 0.9706 - val_accuracy: 0.4860\n",
      "Epoch 31/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 0.9885 - accuracy: 0.5131 - val_loss: 0.9702 - val_accuracy: 0.4860\n",
      "Epoch 32/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 0.9882 - accuracy: 0.5135 - val_loss: 0.9699 - val_accuracy: 0.4860\n",
      "Epoch 33/200\n",
      "2553/2553 [==============================] - 0s 77us/sample - loss: 0.9880 - accuracy: 0.5131 - val_loss: 0.9696 - val_accuracy: 0.4860\n",
      "Epoch 34/200\n",
      "2553/2553 [==============================] - 0s 74us/sample - loss: 0.9878 - accuracy: 0.5155 - val_loss: 0.9694 - val_accuracy: 0.4860\n",
      "Epoch 35/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 0.9875 - accuracy: 0.5143 - val_loss: 0.9690 - val_accuracy: 0.4860\n",
      "Epoch 36/200\n",
      "2553/2553 [==============================] - 0s 75us/sample - loss: 0.9873 - accuracy: 0.5147 - val_loss: 0.9686 - val_accuracy: 0.4860\n",
      "Epoch 37/200\n",
      "2553/2553 [==============================] - 0s 90us/sample - loss: 0.9871 - accuracy: 0.5151 - val_loss: 0.9684 - val_accuracy: 0.4860\n",
      "Epoch 38/200\n",
      "2553/2553 [==============================] - 0s 67us/sample - loss: 0.9869 - accuracy: 0.5159 - val_loss: 0.9681 - val_accuracy: 0.4860\n",
      "Epoch 39/200\n",
      "2553/2553 [==============================] - 0s 65us/sample - loss: 0.9867 - accuracy: 0.5170 - val_loss: 0.9679 - val_accuracy: 0.4860\n",
      "Epoch 40/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 0.9865 - accuracy: 0.5170 - val_loss: 0.9677 - val_accuracy: 0.4860\n",
      "Epoch 41/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 0.9863 - accuracy: 0.5166 - val_loss: 0.9674 - val_accuracy: 0.4860\n",
      "Epoch 42/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 0.9862 - accuracy: 0.5170 - val_loss: 0.9671 - val_accuracy: 0.4860\n",
      "Epoch 43/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 0.9860 - accuracy: 0.5170 - val_loss: 0.9668 - val_accuracy: 0.4860\n",
      "Epoch 44/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 0.9858 - accuracy: 0.5166 - val_loss: 0.9668 - val_accuracy: 0.4860\n",
      "Epoch 45/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 0.9856 - accuracy: 0.5170 - val_loss: 0.9665 - val_accuracy: 0.4860\n",
      "Epoch 46/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 0.9854 - accuracy: 0.5186 - val_loss: 0.9662 - val_accuracy: 0.4860\n",
      "Epoch 47/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 0.9852 - accuracy: 0.5194 - val_loss: 0.9660 - val_accuracy: 0.4860\n",
      "Epoch 48/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 0.9851 - accuracy: 0.5194 - val_loss: 0.9658 - val_accuracy: 0.4860\n",
      "Epoch 49/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 0.9849 - accuracy: 0.5190 - val_loss: 0.9656 - val_accuracy: 0.4766\n",
      "Epoch 50/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 0.9847 - accuracy: 0.5190 - val_loss: 0.9653 - val_accuracy: 0.4860\n",
      "Epoch 51/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 0.9846 - accuracy: 0.5186 - val_loss: 0.9651 - val_accuracy: 0.4860\n",
      "Epoch 52/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 0.9844 - accuracy: 0.5190 - val_loss: 0.9649 - val_accuracy: 0.4860\n",
      "Epoch 53/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 0.9842 - accuracy: 0.5194 - val_loss: 0.9647 - val_accuracy: 0.4860\n",
      "Epoch 54/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 0.9841 - accuracy: 0.5186 - val_loss: 0.9646 - val_accuracy: 0.4860\n",
      "Epoch 55/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 0.9839 - accuracy: 0.5190 - val_loss: 0.9644 - val_accuracy: 0.4860\n",
      "Epoch 56/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 59us/sample - loss: 0.9838 - accuracy: 0.5186 - val_loss: 0.9643 - val_accuracy: 0.4860\n",
      "Epoch 57/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 0.9837 - accuracy: 0.5190 - val_loss: 0.9641 - val_accuracy: 0.4860\n",
      "Epoch 58/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 0.9835 - accuracy: 0.5194 - val_loss: 0.9638 - val_accuracy: 0.4860\n",
      "Epoch 59/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 0.9833 - accuracy: 0.5190 - val_loss: 0.9637 - val_accuracy: 0.4860\n",
      "Epoch 60/200\n",
      "2553/2553 [==============================] - 0s 70us/sample - loss: 0.9832 - accuracy: 0.5194 - val_loss: 0.9637 - val_accuracy: 0.4860\n",
      "Epoch 61/200\n",
      "2553/2553 [==============================] - 0s 84us/sample - loss: 0.9831 - accuracy: 0.5198 - val_loss: 0.9634 - val_accuracy: 0.4860\n",
      "Epoch 62/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 0.9829 - accuracy: 0.5190 - val_loss: 0.9633 - val_accuracy: 0.4860\n",
      "Epoch 63/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 0.9828 - accuracy: 0.5198 - val_loss: 0.9631 - val_accuracy: 0.4860\n",
      "Epoch 64/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 0.9826 - accuracy: 0.5198 - val_loss: 0.9631 - val_accuracy: 0.4860\n",
      "Epoch 65/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 0.9825 - accuracy: 0.5198 - val_loss: 0.9629 - val_accuracy: 0.4860\n",
      "Epoch 66/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 0.9824 - accuracy: 0.5194 - val_loss: 0.9628 - val_accuracy: 0.4860\n",
      "Epoch 67/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 0.9823 - accuracy: 0.5198 - val_loss: 0.9626 - val_accuracy: 0.4860\n",
      "Epoch 68/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 0.9821 - accuracy: 0.5194 - val_loss: 0.9625 - val_accuracy: 0.4860\n",
      "Epoch 69/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 0.9820 - accuracy: 0.5198 - val_loss: 0.9625 - val_accuracy: 0.4860\n",
      "Epoch 70/200\n",
      "2553/2553 [==============================] - 0s 69us/sample - loss: 0.9819 - accuracy: 0.5202 - val_loss: 0.9623 - val_accuracy: 0.4860\n",
      "Epoch 71/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 0.9818 - accuracy: 0.5202 - val_loss: 0.9621 - val_accuracy: 0.4860\n",
      "Epoch 72/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 0.9817 - accuracy: 0.5198 - val_loss: 0.9620 - val_accuracy: 0.4860\n",
      "Epoch 73/200\n",
      "2553/2553 [==============================] - 0s 65us/sample - loss: 0.9815 - accuracy: 0.5198 - val_loss: 0.9620 - val_accuracy: 0.4860\n",
      "Epoch 74/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 0.9815 - accuracy: 0.5190 - val_loss: 0.9619 - val_accuracy: 0.4860\n",
      "Epoch 75/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 0.9813 - accuracy: 0.5194 - val_loss: 0.9617 - val_accuracy: 0.4860\n",
      "Epoch 76/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 0.9812 - accuracy: 0.5186 - val_loss: 0.9616 - val_accuracy: 0.4860\n",
      "Epoch 77/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 0.9811 - accuracy: 0.5194 - val_loss: 0.9616 - val_accuracy: 0.4860\n",
      "Epoch 78/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 0.9810 - accuracy: 0.5198 - val_loss: 0.9615 - val_accuracy: 0.4860\n",
      "Epoch 79/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 0.9809 - accuracy: 0.5194 - val_loss: 0.9613 - val_accuracy: 0.4860\n",
      "Epoch 80/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 0.9808 - accuracy: 0.5198 - val_loss: 0.9613 - val_accuracy: 0.4860\n",
      "Epoch 81/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 0.9807 - accuracy: 0.5213 - val_loss: 0.9612 - val_accuracy: 0.4860\n",
      "Epoch 82/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 0.9806 - accuracy: 0.5206 - val_loss: 0.9612 - val_accuracy: 0.4860\n",
      "Epoch 83/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 0.9805 - accuracy: 0.5210 - val_loss: 0.9610 - val_accuracy: 0.4860\n",
      "Epoch 84/200\n",
      "2553/2553 [==============================] - ETA: 0s - loss: 0.9849 - accuracy: 0.52 - 0s 71us/sample - loss: 0.9804 - accuracy: 0.5206 - val_loss: 0.9610 - val_accuracy: 0.4860\n",
      "Epoch 85/200\n",
      "2553/2553 [==============================] - 0s 94us/sample - loss: 0.9802 - accuracy: 0.5210 - val_loss: 0.9608 - val_accuracy: 0.4953\n",
      "Epoch 86/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 0.9801 - accuracy: 0.5194 - val_loss: 0.9608 - val_accuracy: 0.4953\n",
      "Epoch 87/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 0.9801 - accuracy: 0.5206 - val_loss: 0.9606 - val_accuracy: 0.4953\n",
      "Epoch 88/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 0.9799 - accuracy: 0.5206 - val_loss: 0.9605 - val_accuracy: 0.4953\n",
      "Epoch 89/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 0.9799 - accuracy: 0.5202 - val_loss: 0.9604 - val_accuracy: 0.4953\n",
      "Epoch 90/200\n",
      "2553/2553 [==============================] - 0s 72us/sample - loss: 0.9797 - accuracy: 0.5202 - val_loss: 0.9604 - val_accuracy: 0.4953\n",
      "Epoch 91/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 0.9797 - accuracy: 0.5213 - val_loss: 0.9604 - val_accuracy: 0.4953\n",
      "Epoch 92/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 0.9796 - accuracy: 0.5213 - val_loss: 0.9603 - val_accuracy: 0.4953\n",
      "Epoch 93/200\n",
      "2553/2553 [==============================] - 0s 65us/sample - loss: 0.9795 - accuracy: 0.5210 - val_loss: 0.9602 - val_accuracy: 0.4953\n",
      "Epoch 94/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 0.9794 - accuracy: 0.5202 - val_loss: 0.9600 - val_accuracy: 0.4953\n",
      "Epoch 95/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 0.9793 - accuracy: 0.5206 - val_loss: 0.9600 - val_accuracy: 0.4953\n",
      "Epoch 96/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 0.9792 - accuracy: 0.5210 - val_loss: 0.9600 - val_accuracy: 0.4953\n",
      "Epoch 97/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 0.9791 - accuracy: 0.5210 - val_loss: 0.9599 - val_accuracy: 0.4953\n",
      "Epoch 98/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 0.9790 - accuracy: 0.5210 - val_loss: 0.9598 - val_accuracy: 0.4953\n",
      "Epoch 99/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 0.9789 - accuracy: 0.5217 - val_loss: 0.9598 - val_accuracy: 0.4953\n",
      "Epoch 100/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 0.9789 - accuracy: 0.5210 - val_loss: 0.9596 - val_accuracy: 0.4953\n",
      "Epoch 101/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 0.9788 - accuracy: 0.5213 - val_loss: 0.9597 - val_accuracy: 0.4953\n",
      "Epoch 102/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 0.9787 - accuracy: 0.5217 - val_loss: 0.9596 - val_accuracy: 0.4953\n",
      "Epoch 103/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 0.9786 - accuracy: 0.5221 - val_loss: 0.9595 - val_accuracy: 0.4953\n",
      "Epoch 104/200\n",
      "2553/2553 [==============================] - 0s 67us/sample - loss: 0.9785 - accuracy: 0.5217 - val_loss: 0.9593 - val_accuracy: 0.4953\n",
      "Epoch 105/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 0.9784 - accuracy: 0.5229 - val_loss: 0.9594 - val_accuracy: 0.4953\n",
      "Epoch 106/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 0.9783 - accuracy: 0.5225 - val_loss: 0.9593 - val_accuracy: 0.4953\n",
      "Epoch 107/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 0.9782 - accuracy: 0.5233 - val_loss: 0.9592 - val_accuracy: 0.4953\n",
      "Epoch 108/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 0.9782 - accuracy: 0.5245 - val_loss: 0.9592 - val_accuracy: 0.4953\n",
      "Epoch 109/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 0.9781 - accuracy: 0.5245 - val_loss: 0.9592 - val_accuracy: 0.4953\n",
      "Epoch 110/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 0.9780 - accuracy: 0.5245 - val_loss: 0.9591 - val_accuracy: 0.4953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/200\n",
      "2553/2553 [==============================] - 0s 69us/sample - loss: 0.9779 - accuracy: 0.5241 - val_loss: 0.9589 - val_accuracy: 0.4953\n",
      "Epoch 112/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 0.9778 - accuracy: 0.5241 - val_loss: 0.9590 - val_accuracy: 0.4953\n",
      "Epoch 113/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 0.9777 - accuracy: 0.5245 - val_loss: 0.9588 - val_accuracy: 0.4953\n",
      "Epoch 114/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 0.9776 - accuracy: 0.5245 - val_loss: 0.9589 - val_accuracy: 0.4953\n",
      "Epoch 115/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 0.9775 - accuracy: 0.5237 - val_loss: 0.9588 - val_accuracy: 0.5047\n",
      "Epoch 116/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 0.9774 - accuracy: 0.5241 - val_loss: 0.9587 - val_accuracy: 0.5047\n",
      "Epoch 117/200\n",
      "2553/2553 [==============================] - 0s 69us/sample - loss: 0.9774 - accuracy: 0.5241 - val_loss: 0.9586 - val_accuracy: 0.5047\n",
      "Epoch 118/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 0.9773 - accuracy: 0.5241 - val_loss: 0.9585 - val_accuracy: 0.5047\n",
      "Epoch 119/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 0.9772 - accuracy: 0.5249 - val_loss: 0.9585 - val_accuracy: 0.5047\n",
      "Epoch 120/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 0.9771 - accuracy: 0.5241 - val_loss: 0.9584 - val_accuracy: 0.5047\n",
      "Epoch 121/200\n",
      "2553/2553 [==============================] - 0s 65us/sample - loss: 0.9770 - accuracy: 0.5241 - val_loss: 0.9584 - val_accuracy: 0.5047\n",
      "Epoch 122/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 0.9770 - accuracy: 0.5241 - val_loss: 0.9583 - val_accuracy: 0.5047\n",
      "Epoch 123/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 0.9769 - accuracy: 0.5253 - val_loss: 0.9583 - val_accuracy: 0.5047\n",
      "Epoch 124/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 0.9768 - accuracy: 0.5257 - val_loss: 0.9581 - val_accuracy: 0.5047\n",
      "Epoch 125/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 0.9767 - accuracy: 0.5253 - val_loss: 0.9580 - val_accuracy: 0.5047\n",
      "Epoch 126/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 0.9766 - accuracy: 0.5245 - val_loss: 0.9582 - val_accuracy: 0.5047\n",
      "Epoch 127/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 0.9766 - accuracy: 0.5253 - val_loss: 0.9581 - val_accuracy: 0.5047\n",
      "Epoch 128/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 0.9765 - accuracy: 0.5257 - val_loss: 0.9580 - val_accuracy: 0.5047\n",
      "Epoch 129/200\n",
      "2553/2553 [==============================] - 0s 51us/sample - loss: 0.9764 - accuracy: 0.5257 - val_loss: 0.9579 - val_accuracy: 0.5047\n",
      "Epoch 130/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 0.9763 - accuracy: 0.5257 - val_loss: 0.9578 - val_accuracy: 0.5140\n",
      "Epoch 131/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 0.9762 - accuracy: 0.5260 - val_loss: 0.9577 - val_accuracy: 0.5140\n",
      "Epoch 132/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 0.9761 - accuracy: 0.5260 - val_loss: 0.9578 - val_accuracy: 0.5140\n",
      "Epoch 133/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 0.9761 - accuracy: 0.5260 - val_loss: 0.9578 - val_accuracy: 0.5140\n",
      "Epoch 134/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 0.9761 - accuracy: 0.5257 - val_loss: 0.9577 - val_accuracy: 0.5140\n",
      "Epoch 135/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 0.9759 - accuracy: 0.5268 - val_loss: 0.9576 - val_accuracy: 0.5140\n",
      "Epoch 136/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 0.9758 - accuracy: 0.5264 - val_loss: 0.9575 - val_accuracy: 0.5140\n",
      "Epoch 137/200\n",
      "2553/2553 [==============================] - 0s 51us/sample - loss: 0.9758 - accuracy: 0.5264 - val_loss: 0.9575 - val_accuracy: 0.5140\n",
      "Epoch 138/200\n",
      "2553/2553 [==============================] - 0s 71us/sample - loss: 0.9757 - accuracy: 0.5276 - val_loss: 0.9574 - val_accuracy: 0.5140\n",
      "Epoch 139/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 0.9756 - accuracy: 0.5276 - val_loss: 0.9574 - val_accuracy: 0.5140\n",
      "Epoch 140/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 0.9755 - accuracy: 0.5280 - val_loss: 0.9573 - val_accuracy: 0.5140\n",
      "Epoch 141/200\n",
      "2553/2553 [==============================] - 0s 96us/sample - loss: 0.9754 - accuracy: 0.5280 - val_loss: 0.9573 - val_accuracy: 0.5140\n",
      "Epoch 142/200\n",
      "2553/2553 [==============================] - 0s 86us/sample - loss: 0.9754 - accuracy: 0.5276 - val_loss: 0.9572 - val_accuracy: 0.5140\n",
      "Epoch 143/200\n",
      "2553/2553 [==============================] - 0s 84us/sample - loss: 0.9753 - accuracy: 0.5284 - val_loss: 0.9573 - val_accuracy: 0.5140\n",
      "Epoch 144/200\n",
      "2553/2553 [==============================] - 0s 83us/sample - loss: 0.9752 - accuracy: 0.5280 - val_loss: 0.9573 - val_accuracy: 0.5140\n",
      "Epoch 145/200\n",
      "2553/2553 [==============================] - 0s 89us/sample - loss: 0.9751 - accuracy: 0.5284 - val_loss: 0.9572 - val_accuracy: 0.5140\n",
      "Epoch 146/200\n",
      "2553/2553 [==============================] - 0s 88us/sample - loss: 0.9750 - accuracy: 0.5288 - val_loss: 0.9572 - val_accuracy: 0.5140\n",
      "Epoch 147/200\n",
      "2553/2553 [==============================] - 0s 95us/sample - loss: 0.9750 - accuracy: 0.5284 - val_loss: 0.9572 - val_accuracy: 0.5140\n",
      "Epoch 148/200\n",
      "2553/2553 [==============================] - 0s 99us/sample - loss: 0.9749 - accuracy: 0.5288 - val_loss: 0.9570 - val_accuracy: 0.5140\n",
      "Epoch 149/200\n",
      "2553/2553 [==============================] - 0s 86us/sample - loss: 0.9748 - accuracy: 0.5292 - val_loss: 0.9572 - val_accuracy: 0.5140\n",
      "Epoch 150/200\n",
      "2553/2553 [==============================] - 0s 88us/sample - loss: 0.9748 - accuracy: 0.5296 - val_loss: 0.9570 - val_accuracy: 0.5140\n",
      "Epoch 151/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 0.9747 - accuracy: 0.5300 - val_loss: 0.9569 - val_accuracy: 0.5140\n",
      "Epoch 152/200\n",
      "2553/2553 [==============================] - 0s 89us/sample - loss: 0.9746 - accuracy: 0.5300 - val_loss: 0.9570 - val_accuracy: 0.5140\n",
      "Epoch 153/200\n",
      "2553/2553 [==============================] - 0s 91us/sample - loss: 0.9746 - accuracy: 0.5300 - val_loss: 0.9569 - val_accuracy: 0.5140\n",
      "Epoch 154/200\n",
      "2553/2553 [==============================] - 0s 83us/sample - loss: 0.9744 - accuracy: 0.5296 - val_loss: 0.9569 - val_accuracy: 0.5140\n",
      "Epoch 155/200\n",
      "2553/2553 [==============================] - 0s 88us/sample - loss: 0.9744 - accuracy: 0.5304 - val_loss: 0.9569 - val_accuracy: 0.5140\n",
      "Epoch 156/200\n",
      "2553/2553 [==============================] - 0s 99us/sample - loss: 0.9743 - accuracy: 0.5292 - val_loss: 0.9568 - val_accuracy: 0.5140\n",
      "Epoch 157/200\n",
      "2553/2553 [==============================] - 0s 123us/sample - loss: 0.9742 - accuracy: 0.5300 - val_loss: 0.9568 - val_accuracy: 0.5140\n",
      "Epoch 158/200\n",
      "2553/2553 [==============================] - 0s 115us/sample - loss: 0.9742 - accuracy: 0.5307 - val_loss: 0.9568 - val_accuracy: 0.5140\n",
      "Epoch 159/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 0.9740 - accuracy: 0.5304 - val_loss: 0.9567 - val_accuracy: 0.5140\n",
      "Epoch 160/200\n",
      "2553/2553 [==============================] - 0s 85us/sample - loss: 0.9740 - accuracy: 0.5304 - val_loss: 0.9567 - val_accuracy: 0.5140\n",
      "Epoch 161/200\n",
      "2553/2553 [==============================] - 0s 86us/sample - loss: 0.9739 - accuracy: 0.5304 - val_loss: 0.9566 - val_accuracy: 0.5234\n",
      "Epoch 162/200\n",
      "2553/2553 [==============================] - 0s 78us/sample - loss: 0.9738 - accuracy: 0.5300 - val_loss: 0.9566 - val_accuracy: 0.5140\n",
      "Epoch 163/200\n",
      "2553/2553 [==============================] - 0s 78us/sample - loss: 0.9738 - accuracy: 0.5300 - val_loss: 0.9568 - val_accuracy: 0.5140\n",
      "Epoch 164/200\n",
      "2553/2553 [==============================] - 0s 79us/sample - loss: 0.9737 - accuracy: 0.5300 - val_loss: 0.9566 - val_accuracy: 0.5140\n",
      "Epoch 165/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 61us/sample - loss: 0.9737 - accuracy: 0.5300 - val_loss: 0.9566 - val_accuracy: 0.5234\n",
      "Epoch 166/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 0.9736 - accuracy: 0.5304 - val_loss: 0.9566 - val_accuracy: 0.5140\n",
      "Epoch 167/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 0.9735 - accuracy: 0.5311 - val_loss: 0.9565 - val_accuracy: 0.5234\n",
      "Epoch 168/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 0.9734 - accuracy: 0.5304 - val_loss: 0.9566 - val_accuracy: 0.5234\n",
      "Epoch 169/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 0.9734 - accuracy: 0.5311 - val_loss: 0.9564 - val_accuracy: 0.5234\n",
      "Epoch 170/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 0.9733 - accuracy: 0.5315 - val_loss: 0.9564 - val_accuracy: 0.5327\n",
      "Epoch 171/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 0.9732 - accuracy: 0.5319 - val_loss: 0.9565 - val_accuracy: 0.5327\n",
      "Epoch 172/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 0.9732 - accuracy: 0.5315 - val_loss: 0.9563 - val_accuracy: 0.5327\n",
      "Epoch 173/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 0.9731 - accuracy: 0.5319 - val_loss: 0.9563 - val_accuracy: 0.5327\n",
      "Epoch 174/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 0.9730 - accuracy: 0.5327 - val_loss: 0.9563 - val_accuracy: 0.5327\n",
      "Epoch 175/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 0.9729 - accuracy: 0.5323 - val_loss: 0.9562 - val_accuracy: 0.5421\n",
      "Epoch 176/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 0.9729 - accuracy: 0.5331 - val_loss: 0.9561 - val_accuracy: 0.5421\n",
      "Epoch 177/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 0.9728 - accuracy: 0.5323 - val_loss: 0.9562 - val_accuracy: 0.5421\n",
      "Epoch 178/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 0.9727 - accuracy: 0.5327 - val_loss: 0.9559 - val_accuracy: 0.5421\n",
      "Epoch 179/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 0.9727 - accuracy: 0.5323 - val_loss: 0.9558 - val_accuracy: 0.5421\n",
      "Epoch 180/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 0.9726 - accuracy: 0.5327 - val_loss: 0.9557 - val_accuracy: 0.5421\n",
      "Epoch 181/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 0.9725 - accuracy: 0.5335 - val_loss: 0.9557 - val_accuracy: 0.5421\n",
      "Epoch 182/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 0.9725 - accuracy: 0.5327 - val_loss: 0.9557 - val_accuracy: 0.5421\n",
      "Epoch 183/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 0.9724 - accuracy: 0.5331 - val_loss: 0.9555 - val_accuracy: 0.5514\n",
      "Epoch 184/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 0.9723 - accuracy: 0.5331 - val_loss: 0.9555 - val_accuracy: 0.5514\n",
      "Epoch 185/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 0.9722 - accuracy: 0.5327 - val_loss: 0.9556 - val_accuracy: 0.5514\n",
      "Epoch 186/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 0.9722 - accuracy: 0.5331 - val_loss: 0.9555 - val_accuracy: 0.5514\n",
      "Epoch 187/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 0.9722 - accuracy: 0.5331 - val_loss: 0.9555 - val_accuracy: 0.5514\n",
      "Epoch 188/200\n",
      "2553/2553 [==============================] - 0s 68us/sample - loss: 0.9721 - accuracy: 0.5331 - val_loss: 0.9551 - val_accuracy: 0.5514\n",
      "Epoch 189/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 0.9720 - accuracy: 0.5335 - val_loss: 0.9551 - val_accuracy: 0.5514\n",
      "Epoch 190/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 0.9719 - accuracy: 0.5335 - val_loss: 0.9551 - val_accuracy: 0.5514\n",
      "Epoch 191/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 0.9719 - accuracy: 0.5335 - val_loss: 0.9552 - val_accuracy: 0.5514\n",
      "Epoch 192/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 0.9718 - accuracy: 0.5339 - val_loss: 0.9549 - val_accuracy: 0.5514\n",
      "Epoch 193/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 0.9718 - accuracy: 0.5327 - val_loss: 0.9548 - val_accuracy: 0.5514\n",
      "Epoch 194/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 0.9717 - accuracy: 0.5331 - val_loss: 0.9549 - val_accuracy: 0.5514\n",
      "Epoch 195/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 0.9716 - accuracy: 0.5315 - val_loss: 0.9547 - val_accuracy: 0.5514\n",
      "Epoch 196/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 0.9715 - accuracy: 0.5323 - val_loss: 0.9547 - val_accuracy: 0.5514\n",
      "Epoch 197/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 0.9715 - accuracy: 0.5339 - val_loss: 0.9546 - val_accuracy: 0.5514\n",
      "Epoch 198/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 0.9714 - accuracy: 0.5327 - val_loss: 0.9545 - val_accuracy: 0.5514\n",
      "Epoch 199/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 0.9714 - accuracy: 0.5323 - val_loss: 0.9545 - val_accuracy: 0.5514\n",
      "Epoch 200/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 0.9713 - accuracy: 0.5335 - val_loss: 0.9545 - val_accuracy: 0.5514\n",
      "0.55140185 {'loss': 0.9712734546000192, 'accuracy': 0.53349, 'val_loss': 0.9545081820443412, 'val_accuracy': 0.55140185}\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 29)]              0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 41)                1230      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 75)                3150      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 3)                 228       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 4,608\n",
      "Trainable params: 4,608\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2553 samples, validate on 107 samples\n",
      "Epoch 1/200\n",
      "2553/2553 [==============================] - 1s 352us/sample - loss: 1.1507 - accuracy: 0.2378 - val_loss: 1.1531 - val_accuracy: 0.1869\n",
      "Epoch 2/200\n",
      "2553/2553 [==============================] - 0s 119us/sample - loss: 1.1283 - accuracy: 0.2479 - val_loss: 1.1359 - val_accuracy: 0.1963\n",
      "Epoch 3/200\n",
      "2553/2553 [==============================] - 0s 124us/sample - loss: 1.1163 - accuracy: 0.2511 - val_loss: 1.1258 - val_accuracy: 0.1776\n",
      "Epoch 4/200\n",
      "2553/2553 [==============================] - 0s 124us/sample - loss: 1.1093 - accuracy: 0.2585 - val_loss: 1.1192 - val_accuracy: 0.1682\n",
      "Epoch 5/200\n",
      "2553/2553 [==============================] - 0s 155us/sample - loss: 1.1063 - accuracy: 0.2617 - val_loss: 1.1148 - val_accuracy: 0.1963\n",
      "Epoch 6/200\n",
      "2553/2553 [==============================] - 0s 179us/sample - loss: 1.1046 - accuracy: 0.2593 - val_loss: 1.1116 - val_accuracy: 0.2056\n",
      "Epoch 7/200\n",
      "2553/2553 [==============================] - 0s 182us/sample - loss: 1.1030 - accuracy: 0.2617 - val_loss: 1.1096 - val_accuracy: 0.2243\n",
      "Epoch 8/200\n",
      "2553/2553 [==============================] - 0s 127us/sample - loss: 1.1022 - accuracy: 0.2711 - val_loss: 1.1079 - val_accuracy: 0.2243\n",
      "Epoch 9/200\n",
      "2553/2553 [==============================] - 0s 137us/sample - loss: 1.1015 - accuracy: 0.2699 - val_loss: 1.1066 - val_accuracy: 0.2336\n",
      "Epoch 10/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 123us/sample - loss: 1.1004 - accuracy: 0.2746 - val_loss: 1.1057 - val_accuracy: 0.2336\n",
      "Epoch 11/200\n",
      "2553/2553 [==============================] - 0s 125us/sample - loss: 1.1005 - accuracy: 0.2750 - val_loss: 1.1051 - val_accuracy: 0.2336\n",
      "Epoch 12/200\n",
      "2553/2553 [==============================] - 0s 138us/sample - loss: 1.0999 - accuracy: 0.2738 - val_loss: 1.1049 - val_accuracy: 0.2430\n",
      "Epoch 13/200\n",
      "2553/2553 [==============================] - 0s 121us/sample - loss: 1.0993 - accuracy: 0.2777 - val_loss: 1.1047 - val_accuracy: 0.2430\n",
      "Epoch 14/200\n",
      "2553/2553 [==============================] - 0s 143us/sample - loss: 1.0998 - accuracy: 0.2754 - val_loss: 1.1043 - val_accuracy: 0.2336\n",
      "Epoch 15/200\n",
      "2553/2553 [==============================] - 0s 128us/sample - loss: 1.0996 - accuracy: 0.2754 - val_loss: 1.1040 - val_accuracy: 0.2336\n",
      "Epoch 16/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0993 - accuracy: 0.2758 - val_loss: 1.1038 - val_accuracy: 0.2336\n",
      "Epoch 17/200\n",
      "2553/2553 [==============================] - 0s 121us/sample - loss: 1.0994 - accuracy: 0.2754 - val_loss: 1.1035 - val_accuracy: 0.2336\n",
      "Epoch 18/200\n",
      "2553/2553 [==============================] - 0s 123us/sample - loss: 1.0985 - accuracy: 0.2801 - val_loss: 1.1034 - val_accuracy: 0.2336\n",
      "Epoch 19/200\n",
      "2553/2553 [==============================] - 0s 122us/sample - loss: 1.0990 - accuracy: 0.2801 - val_loss: 1.1033 - val_accuracy: 0.2336\n",
      "Epoch 20/200\n",
      "2553/2553 [==============================] - 0s 123us/sample - loss: 1.0991 - accuracy: 0.2801 - val_loss: 1.1030 - val_accuracy: 0.2336\n",
      "Epoch 21/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0989 - accuracy: 0.2805 - val_loss: 1.1028 - val_accuracy: 0.2336\n",
      "Epoch 22/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 1.0987 - accuracy: 0.2801 - val_loss: 1.1027 - val_accuracy: 0.2336\n",
      "Epoch 23/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0984 - accuracy: 0.2808 - val_loss: 1.1026 - val_accuracy: 0.2336\n",
      "Epoch 24/200\n",
      "2553/2553 [==============================] - 0s 120us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.1025 - val_accuracy: 0.2336\n",
      "Epoch 25/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0986 - accuracy: 0.2793 - val_loss: 1.1025 - val_accuracy: 0.2336\n",
      "Epoch 26/200\n",
      "2553/2553 [==============================] - 0s 117us/sample - loss: 1.0989 - accuracy: 0.2781 - val_loss: 1.1024 - val_accuracy: 0.2336\n",
      "Epoch 27/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.0988 - accuracy: 0.2797 - val_loss: 1.1022 - val_accuracy: 0.2336\n",
      "Epoch 28/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.0987 - accuracy: 0.2801 - val_loss: 1.1020 - val_accuracy: 0.2336\n",
      "Epoch 29/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.0987 - accuracy: 0.2793 - val_loss: 1.1021 - val_accuracy: 0.2336\n",
      "Epoch 30/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.0982 - accuracy: 0.2805 - val_loss: 1.1022 - val_accuracy: 0.2336\n",
      "Epoch 31/200\n",
      "2553/2553 [==============================] - 0s 121us/sample - loss: 1.0982 - accuracy: 0.2812 - val_loss: 1.1022 - val_accuracy: 0.2336\n",
      "Epoch 32/200\n",
      "2553/2553 [==============================] - 0s 115us/sample - loss: 1.0985 - accuracy: 0.2812 - val_loss: 1.1022 - val_accuracy: 0.2336\n",
      "Epoch 33/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.0981 - accuracy: 0.2816 - val_loss: 1.1023 - val_accuracy: 0.2336\n",
      "Epoch 34/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.0987 - accuracy: 0.2805 - val_loss: 1.1022 - val_accuracy: 0.2336\n",
      "Epoch 35/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0983 - accuracy: 0.2793 - val_loss: 1.1022 - val_accuracy: 0.2336\n",
      "Epoch 36/200\n",
      "2553/2553 [==============================] - 0s 98us/sample - loss: 1.0984 - accuracy: 0.2801 - val_loss: 1.1024 - val_accuracy: 0.2336\n",
      "Epoch 37/200\n",
      "2553/2553 [==============================] - 0s 98us/sample - loss: 1.0984 - accuracy: 0.2785 - val_loss: 1.1022 - val_accuracy: 0.2336\n",
      "Epoch 38/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0982 - accuracy: 0.2808 - val_loss: 1.1021 - val_accuracy: 0.2336\n",
      "Epoch 39/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.0985 - accuracy: 0.2805 - val_loss: 1.1022 - val_accuracy: 0.2336\n",
      "Epoch 40/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0984 - accuracy: 0.2797 - val_loss: 1.1023 - val_accuracy: 0.2336\n",
      "Epoch 41/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0981 - accuracy: 0.2812 - val_loss: 1.1024 - val_accuracy: 0.2336\n",
      "Epoch 42/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.0981 - accuracy: 0.2805 - val_loss: 1.1023 - val_accuracy: 0.2336\n",
      "Epoch 43/200\n",
      "2553/2553 [==============================] - 0s 115us/sample - loss: 1.0980 - accuracy: 0.2816 - val_loss: 1.1023 - val_accuracy: 0.2336\n",
      "Epoch 44/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0981 - accuracy: 0.2797 - val_loss: 1.1024 - val_accuracy: 0.2336\n",
      "Epoch 45/200\n",
      "2553/2553 [==============================] - 0s 120us/sample - loss: 1.0979 - accuracy: 0.2805 - val_loss: 1.1025 - val_accuracy: 0.2336\n",
      "Epoch 46/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.0980 - accuracy: 0.2808 - val_loss: 1.1025 - val_accuracy: 0.2336\n",
      "Epoch 47/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0980 - accuracy: 0.2793 - val_loss: 1.1025 - val_accuracy: 0.2336\n",
      "Epoch 48/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.0978 - accuracy: 0.2812 - val_loss: 1.1026 - val_accuracy: 0.2336\n",
      "Epoch 49/200\n",
      "2553/2553 [==============================] - 0s 117us/sample - loss: 1.0980 - accuracy: 0.2805 - val_loss: 1.1024 - val_accuracy: 0.2336\n",
      "Epoch 50/200\n",
      "2553/2553 [==============================] - 0s 117us/sample - loss: 1.0980 - accuracy: 0.2805 - val_loss: 1.1024 - val_accuracy: 0.2336\n",
      "Epoch 51/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.0975 - accuracy: 0.2820 - val_loss: 1.1025 - val_accuracy: 0.2336\n",
      "Epoch 52/200\n",
      "2553/2553 [==============================] - 0s 117us/sample - loss: 1.0981 - accuracy: 0.2805 - val_loss: 1.1025 - val_accuracy: 0.2336\n",
      "Epoch 53/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.0977 - accuracy: 0.2820 - val_loss: 1.1024 - val_accuracy: 0.2430\n",
      "Epoch 54/200\n",
      "2553/2553 [==============================] - 0s 115us/sample - loss: 1.0978 - accuracy: 0.2801 - val_loss: 1.1024 - val_accuracy: 0.2430\n",
      "Epoch 55/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0980 - accuracy: 0.2805 - val_loss: 1.1024 - val_accuracy: 0.2430\n",
      "Epoch 56/200\n",
      "2553/2553 [==============================] - 0s 120us/sample - loss: 1.0978 - accuracy: 0.2801 - val_loss: 1.1023 - val_accuracy: 0.2430\n",
      "Epoch 57/200\n",
      "2553/2553 [==============================] - 0s 118us/sample - loss: 1.0979 - accuracy: 0.2805 - val_loss: 1.1023 - val_accuracy: 0.2430\n",
      "Epoch 58/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0973 - accuracy: 0.2828 - val_loss: 1.1024 - val_accuracy: 0.2430\n",
      "Epoch 59/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0976 - accuracy: 0.2812 - val_loss: 1.1024 - val_accuracy: 0.2430\n",
      "Epoch 60/200\n",
      "2553/2553 [==============================] - 0s 115us/sample - loss: 1.0978 - accuracy: 0.2797 - val_loss: 1.1023 - val_accuracy: 0.2430\n",
      "Epoch 61/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0975 - accuracy: 0.2808 - val_loss: 1.1023 - val_accuracy: 0.2430\n",
      "Epoch 62/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.0982 - accuracy: 0.2793 - val_loss: 1.1021 - val_accuracy: 0.2430\n",
      "Epoch 63/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.0975 - accuracy: 0.2816 - val_loss: 1.1021 - val_accuracy: 0.2430\n",
      "Epoch 64/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.0974 - accuracy: 0.2816 - val_loss: 1.1022 - val_accuracy: 0.2430\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/200\n",
      "2553/2553 [==============================] - 0s 117us/sample - loss: 1.0977 - accuracy: 0.2797 - val_loss: 1.1021 - val_accuracy: 0.2430\n",
      "Epoch 66/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.0973 - accuracy: 0.2812 - val_loss: 1.1021 - val_accuracy: 0.2430\n",
      "Epoch 67/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.0980 - accuracy: 0.2789 - val_loss: 1.1020 - val_accuracy: 0.2430\n",
      "Epoch 68/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0973 - accuracy: 0.2828 - val_loss: 1.1021 - val_accuracy: 0.2430\n",
      "Epoch 69/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0972 - accuracy: 0.2801 - val_loss: 1.1022 - val_accuracy: 0.2430\n",
      "Epoch 70/200\n",
      "2553/2553 [==============================] - 0s 99us/sample - loss: 1.0974 - accuracy: 0.2808 - val_loss: 1.1020 - val_accuracy: 0.2430\n",
      "Epoch 71/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.0968 - accuracy: 0.2828 - val_loss: 1.1023 - val_accuracy: 0.2430\n",
      "Epoch 72/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0973 - accuracy: 0.2797 - val_loss: 1.1022 - val_accuracy: 0.2430\n",
      "Epoch 73/200\n",
      "2553/2553 [==============================] - 0s 118us/sample - loss: 1.0973 - accuracy: 0.2805 - val_loss: 1.1023 - val_accuracy: 0.2430\n",
      "Epoch 74/200\n",
      "2553/2553 [==============================] - 0s 133us/sample - loss: 1.0972 - accuracy: 0.2805 - val_loss: 1.1022 - val_accuracy: 0.2430\n",
      "Epoch 75/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 1.0973 - accuracy: 0.2805 - val_loss: 1.1023 - val_accuracy: 0.2430\n",
      "Epoch 76/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0972 - accuracy: 0.2816 - val_loss: 1.1022 - val_accuracy: 0.2430\n",
      "Epoch 77/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.0974 - accuracy: 0.2797 - val_loss: 1.1020 - val_accuracy: 0.2430\n",
      "Epoch 78/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0968 - accuracy: 0.2808 - val_loss: 1.1022 - val_accuracy: 0.2430\n",
      "Epoch 79/200\n",
      "2553/2553 [==============================] - 0s 98us/sample - loss: 1.0967 - accuracy: 0.2824 - val_loss: 1.1022 - val_accuracy: 0.2430\n",
      "Epoch 80/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0976 - accuracy: 0.2801 - val_loss: 1.1021 - val_accuracy: 0.2430\n",
      "Epoch 81/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.0972 - accuracy: 0.2812 - val_loss: 1.1020 - val_accuracy: 0.2430\n",
      "Epoch 82/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0970 - accuracy: 0.2816 - val_loss: 1.1021 - val_accuracy: 0.2430\n",
      "Epoch 83/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.0974 - accuracy: 0.2812 - val_loss: 1.1021 - val_accuracy: 0.2430\n",
      "Epoch 84/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0970 - accuracy: 0.2801 - val_loss: 1.1021 - val_accuracy: 0.2430\n",
      "Epoch 85/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0972 - accuracy: 0.2816 - val_loss: 1.1020 - val_accuracy: 0.2430\n",
      "Epoch 86/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0971 - accuracy: 0.2808 - val_loss: 1.1021 - val_accuracy: 0.2430\n",
      "Epoch 87/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0976 - accuracy: 0.2820 - val_loss: 1.1020 - val_accuracy: 0.2430\n",
      "Epoch 88/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0971 - accuracy: 0.2816 - val_loss: 1.1020 - val_accuracy: 0.2430\n",
      "Epoch 89/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.0968 - accuracy: 0.2820 - val_loss: 1.1021 - val_accuracy: 0.2430\n",
      "Epoch 90/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0967 - accuracy: 0.2816 - val_loss: 1.1022 - val_accuracy: 0.2430\n",
      "Epoch 91/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0966 - accuracy: 0.2805 - val_loss: 1.1022 - val_accuracy: 0.2430\n",
      "Epoch 92/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0970 - accuracy: 0.2808 - val_loss: 1.1022 - val_accuracy: 0.2430\n",
      "Epoch 93/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0969 - accuracy: 0.2816 - val_loss: 1.1023 - val_accuracy: 0.2430\n",
      "Epoch 94/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.0963 - accuracy: 0.2820 - val_loss: 1.1023 - val_accuracy: 0.2430\n",
      "Epoch 95/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0966 - accuracy: 0.2816 - val_loss: 1.1023 - val_accuracy: 0.2430\n",
      "Epoch 96/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0970 - accuracy: 0.2805 - val_loss: 1.1022 - val_accuracy: 0.2430\n",
      "Epoch 97/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.0968 - accuracy: 0.2820 - val_loss: 1.1022 - val_accuracy: 0.2430\n",
      "Epoch 98/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.0970 - accuracy: 0.2808 - val_loss: 1.1023 - val_accuracy: 0.2430\n",
      "Epoch 99/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0964 - accuracy: 0.2824 - val_loss: 1.1024 - val_accuracy: 0.2430\n",
      "Epoch 100/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.0966 - accuracy: 0.2820 - val_loss: 1.1024 - val_accuracy: 0.2430\n",
      "Epoch 101/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0966 - accuracy: 0.2824 - val_loss: 1.1024 - val_accuracy: 0.2430\n",
      "Epoch 102/200\n",
      "2553/2553 [==============================] - ETA: 0s - loss: 1.0966 - accuracy: 0.28 - 0s 112us/sample - loss: 1.0966 - accuracy: 0.2824 - val_loss: 1.1025 - val_accuracy: 0.2430\n",
      "Epoch 103/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0965 - accuracy: 0.2820 - val_loss: 1.1025 - val_accuracy: 0.2430\n",
      "Epoch 104/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0966 - accuracy: 0.2820 - val_loss: 1.1025 - val_accuracy: 0.2430\n",
      "Epoch 105/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0963 - accuracy: 0.2820 - val_loss: 1.1025 - val_accuracy: 0.2430\n",
      "Epoch 106/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.0968 - accuracy: 0.2824 - val_loss: 1.1025 - val_accuracy: 0.2430\n",
      "Epoch 107/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0965 - accuracy: 0.2820 - val_loss: 1.1027 - val_accuracy: 0.2430\n",
      "Epoch 108/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0962 - accuracy: 0.2840 - val_loss: 1.1026 - val_accuracy: 0.2430\n",
      "Epoch 109/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0965 - accuracy: 0.2820 - val_loss: 1.1024 - val_accuracy: 0.2430\n",
      "Epoch 110/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0967 - accuracy: 0.2820 - val_loss: 1.1023 - val_accuracy: 0.2430\n",
      "Epoch 111/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0962 - accuracy: 0.2816 - val_loss: 1.1024 - val_accuracy: 0.2430\n",
      "Epoch 112/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0961 - accuracy: 0.2824 - val_loss: 1.1026 - val_accuracy: 0.2430\n",
      "Epoch 113/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.0969 - accuracy: 0.2820 - val_loss: 1.1026 - val_accuracy: 0.2430\n",
      "Epoch 114/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0962 - accuracy: 0.2816 - val_loss: 1.1026 - val_accuracy: 0.2523\n",
      "Epoch 115/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0960 - accuracy: 0.2828 - val_loss: 1.1026 - val_accuracy: 0.2523\n",
      "Epoch 116/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0968 - accuracy: 0.2824 - val_loss: 1.1026 - val_accuracy: 0.2523\n",
      "Epoch 117/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.0961 - accuracy: 0.2816 - val_loss: 1.1028 - val_accuracy: 0.2523\n",
      "Epoch 118/200\n",
      "2553/2553 [==============================] - 0s 117us/sample - loss: 1.0957 - accuracy: 0.2824 - val_loss: 1.1027 - val_accuracy: 0.2523\n",
      "Epoch 119/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.0963 - accuracy: 0.2824 - val_loss: 1.1027 - val_accuracy: 0.2523\n",
      "Epoch 120/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0962 - accuracy: 0.2840 - val_loss: 1.1025 - val_accuracy: 0.2523\n",
      "Epoch 121/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.0957 - accuracy: 0.2816 - val_loss: 1.1026 - val_accuracy: 0.2523\n",
      "Epoch 122/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0965 - accuracy: 0.2824 - val_loss: 1.1027 - val_accuracy: 0.2523\n",
      "Epoch 123/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0966 - accuracy: 0.2836 - val_loss: 1.1026 - val_accuracy: 0.2523\n",
      "Epoch 124/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0966 - accuracy: 0.2820 - val_loss: 1.1025 - val_accuracy: 0.2523\n",
      "Epoch 125/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0968 - accuracy: 0.2816 - val_loss: 1.1023 - val_accuracy: 0.2523\n",
      "Epoch 126/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0960 - accuracy: 0.2816 - val_loss: 1.1024 - val_accuracy: 0.2523\n",
      "Epoch 127/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0963 - accuracy: 0.2832 - val_loss: 1.1024 - val_accuracy: 0.2523\n",
      "Epoch 128/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0957 - accuracy: 0.2824 - val_loss: 1.1026 - val_accuracy: 0.2523\n",
      "Epoch 129/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.0952 - accuracy: 0.2836 - val_loss: 1.1029 - val_accuracy: 0.2523\n",
      "Epoch 130/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.0962 - accuracy: 0.2828 - val_loss: 1.1028 - val_accuracy: 0.2523\n",
      "Epoch 131/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0959 - accuracy: 0.2801 - val_loss: 1.1027 - val_accuracy: 0.2523\n",
      "Epoch 132/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.0960 - accuracy: 0.2812 - val_loss: 1.1027 - val_accuracy: 0.2523\n",
      "Epoch 133/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0959 - accuracy: 0.2840 - val_loss: 1.1027 - val_accuracy: 0.2523\n",
      "Epoch 134/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.0951 - accuracy: 0.2828 - val_loss: 1.1028 - val_accuracy: 0.2523\n",
      "Epoch 135/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0956 - accuracy: 0.2824 - val_loss: 1.1028 - val_accuracy: 0.2523\n",
      "Epoch 136/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0949 - accuracy: 0.2812 - val_loss: 1.1030 - val_accuracy: 0.2523\n",
      "Epoch 137/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0963 - accuracy: 0.2844 - val_loss: 1.1027 - val_accuracy: 0.2523\n",
      "Epoch 138/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0949 - accuracy: 0.2828 - val_loss: 1.1028 - val_accuracy: 0.2523\n",
      "Epoch 139/200\n",
      "2553/2553 [==============================] - 0s 123us/sample - loss: 1.0955 - accuracy: 0.2832 - val_loss: 1.1029 - val_accuracy: 0.2523\n",
      "Epoch 140/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0961 - accuracy: 0.2816 - val_loss: 1.1027 - val_accuracy: 0.2523\n",
      "Epoch 141/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0955 - accuracy: 0.2808 - val_loss: 1.1026 - val_accuracy: 0.2523\n",
      "Epoch 142/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0954 - accuracy: 0.2832 - val_loss: 1.1027 - val_accuracy: 0.2523\n",
      "Epoch 143/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0949 - accuracy: 0.2828 - val_loss: 1.1029 - val_accuracy: 0.2523\n",
      "Epoch 144/200\n",
      "2553/2553 [==============================] - 0s 99us/sample - loss: 1.0957 - accuracy: 0.2824 - val_loss: 1.1030 - val_accuracy: 0.2523\n",
      "Epoch 145/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0953 - accuracy: 0.2812 - val_loss: 1.1029 - val_accuracy: 0.2523\n",
      "Epoch 146/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0948 - accuracy: 0.2824 - val_loss: 1.1031 - val_accuracy: 0.2523\n",
      "Epoch 147/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.0966 - accuracy: 0.2812 - val_loss: 1.1029 - val_accuracy: 0.2523\n",
      "Epoch 148/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0950 - accuracy: 0.2828 - val_loss: 1.1030 - val_accuracy: 0.2523\n",
      "Epoch 149/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0952 - accuracy: 0.2820 - val_loss: 1.1030 - val_accuracy: 0.2523\n",
      "Epoch 150/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0950 - accuracy: 0.2816 - val_loss: 1.1030 - val_accuracy: 0.2523\n",
      "Epoch 151/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0962 - accuracy: 0.2824 - val_loss: 1.1029 - val_accuracy: 0.2523\n",
      "Epoch 152/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.0949 - accuracy: 0.2801 - val_loss: 1.1032 - val_accuracy: 0.2523\n",
      "Epoch 153/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0947 - accuracy: 0.2808 - val_loss: 1.1031 - val_accuracy: 0.2523\n",
      "Epoch 154/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0951 - accuracy: 0.2816 - val_loss: 1.1029 - val_accuracy: 0.2523\n",
      "Epoch 155/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.0949 - accuracy: 0.2824 - val_loss: 1.1028 - val_accuracy: 0.2523\n",
      "Epoch 156/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0955 - accuracy: 0.2808 - val_loss: 1.1027 - val_accuracy: 0.2523\n",
      "Epoch 157/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0952 - accuracy: 0.2816 - val_loss: 1.1027 - val_accuracy: 0.2523\n",
      "Epoch 158/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.0949 - accuracy: 0.2824 - val_loss: 1.1028 - val_accuracy: 0.2523\n",
      "Epoch 159/200\n",
      "2553/2553 [==============================] - 0s 84us/sample - loss: 1.0951 - accuracy: 0.2820 - val_loss: 1.1027 - val_accuracy: 0.2523\n",
      "Epoch 160/200\n",
      "2553/2553 [==============================] - 0s 79us/sample - loss: 1.0941 - accuracy: 0.2824 - val_loss: 1.1028 - val_accuracy: 0.2523\n",
      "Epoch 161/200\n",
      "2553/2553 [==============================] - 0s 89us/sample - loss: 1.0948 - accuracy: 0.2816 - val_loss: 1.1028 - val_accuracy: 0.2523\n",
      "Epoch 162/200\n",
      "2553/2553 [==============================] - 0s 84us/sample - loss: 1.0940 - accuracy: 0.2801 - val_loss: 1.1031 - val_accuracy: 0.2523\n",
      "Epoch 163/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0940 - accuracy: 0.2820 - val_loss: 1.1031 - val_accuracy: 0.2523\n",
      "Epoch 164/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0930 - accuracy: 0.2852 - val_loss: 1.1029 - val_accuracy: 0.2523\n",
      "Epoch 165/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 1.0925 - accuracy: 0.2824 - val_loss: 1.1023 - val_accuracy: 0.2523\n",
      "Epoch 166/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0926 - accuracy: 0.2816 - val_loss: 1.1016 - val_accuracy: 0.2523\n",
      "Epoch 167/200\n",
      "2553/2553 [==============================] - 0s 118us/sample - loss: 1.0923 - accuracy: 0.2832 - val_loss: 1.1011 - val_accuracy: 0.2523\n",
      "Epoch 168/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0903 - accuracy: 0.2836 - val_loss: 1.1006 - val_accuracy: 0.2523\n",
      "Epoch 169/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.0900 - accuracy: 0.2824 - val_loss: 1.0997 - val_accuracy: 0.2523\n",
      "Epoch 170/200\n",
      "2553/2553 [==============================] - 0s 117us/sample - loss: 1.0923 - accuracy: 0.2820 - val_loss: 1.0989 - val_accuracy: 0.2523\n",
      "Epoch 171/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0884 - accuracy: 0.2832 - val_loss: 1.0982 - val_accuracy: 0.2523\n",
      "Epoch 172/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0894 - accuracy: 0.2824 - val_loss: 1.0978 - val_accuracy: 0.2523\n",
      "Epoch 173/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0854 - accuracy: 0.2812 - val_loss: 1.0971 - val_accuracy: 0.2523\n",
      "Epoch 174/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.0864 - accuracy: 0.2824 - val_loss: 1.0965 - val_accuracy: 0.2523\n",
      "Epoch 175/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0863 - accuracy: 0.2816 - val_loss: 1.0962 - val_accuracy: 0.2523\n",
      "Epoch 176/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0864 - accuracy: 0.2836 - val_loss: 1.0958 - val_accuracy: 0.2523\n",
      "Epoch 177/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0849 - accuracy: 0.2820 - val_loss: 1.0955 - val_accuracy: 0.2523\n",
      "Epoch 178/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0828 - accuracy: 0.2820 - val_loss: 1.0951 - val_accuracy: 0.2523\n",
      "Epoch 179/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.0870 - accuracy: 0.2832 - val_loss: 1.0947 - val_accuracy: 0.2523\n",
      "Epoch 180/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0842 - accuracy: 0.2828 - val_loss: 1.0946 - val_accuracy: 0.2523\n",
      "Epoch 181/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0851 - accuracy: 0.2824 - val_loss: 1.0942 - val_accuracy: 0.2523\n",
      "Epoch 182/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0852 - accuracy: 0.2816 - val_loss: 1.0940 - val_accuracy: 0.2523\n",
      "Epoch 183/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0802 - accuracy: 0.2816 - val_loss: 1.0938 - val_accuracy: 0.2523\n",
      "Epoch 184/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0832 - accuracy: 0.2812 - val_loss: 1.0935 - val_accuracy: 0.2523\n",
      "Epoch 185/200\n",
      "2553/2553 [==============================] - 0s 99us/sample - loss: 1.0840 - accuracy: 0.2836 - val_loss: 1.0933 - val_accuracy: 0.2523\n",
      "Epoch 186/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0847 - accuracy: 0.2832 - val_loss: 1.0929 - val_accuracy: 0.2523\n",
      "Epoch 187/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0809 - accuracy: 0.2836 - val_loss: 1.0929 - val_accuracy: 0.2523\n",
      "Epoch 188/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0811 - accuracy: 0.2820 - val_loss: 1.0927 - val_accuracy: 0.2523\n",
      "Epoch 189/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0794 - accuracy: 0.2820 - val_loss: 1.0927 - val_accuracy: 0.2523\n",
      "Epoch 190/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.0862 - accuracy: 0.2824 - val_loss: 1.0923 - val_accuracy: 0.2523\n",
      "Epoch 191/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0819 - accuracy: 0.2812 - val_loss: 1.0920 - val_accuracy: 0.2523\n",
      "Epoch 192/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.0823 - accuracy: 0.2840 - val_loss: 1.0920 - val_accuracy: 0.2523\n",
      "Epoch 193/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.0828 - accuracy: 0.2820 - val_loss: 1.0916 - val_accuracy: 0.2523\n",
      "Epoch 194/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0843 - accuracy: 0.2840 - val_loss: 1.0912 - val_accuracy: 0.2523\n",
      "Epoch 195/200\n",
      "2553/2553 [==============================] - 0s 98us/sample - loss: 1.0819 - accuracy: 0.2840 - val_loss: 1.0910 - val_accuracy: 0.2523\n",
      "Epoch 196/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0838 - accuracy: 0.2812 - val_loss: 1.0908 - val_accuracy: 0.2523\n",
      "Epoch 197/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0820 - accuracy: 0.2836 - val_loss: 1.0906 - val_accuracy: 0.2523\n",
      "Epoch 198/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0840 - accuracy: 0.2828 - val_loss: 1.0905 - val_accuracy: 0.2523\n",
      "Epoch 199/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0811 - accuracy: 0.2828 - val_loss: 1.0903 - val_accuracy: 0.2523\n",
      "Epoch 200/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0838 - accuracy: 0.2844 - val_loss: 1.0902 - val_accuracy: 0.2523\n",
      "0.25233644 {'loss': 1.0837724909238893, 'accuracy': 0.28437132, 'val_loss': 1.090225048154314, 'val_accuracy': 0.25233644}\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 29)]              0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 41)                1230      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 75)                3150      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 3)                 228       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 4,608\n",
      "Trainable params: 4,608\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2553 samples, validate on 107 samples\n",
      "Epoch 1/200\n",
      "2553/2553 [==============================] - 1s 323us/sample - loss: 1.3151 - accuracy: 0.2859 - val_loss: 1.3220 - val_accuracy: 0.2243\n",
      "Epoch 2/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.2908 - accuracy: 0.2863 - val_loss: 1.2913 - val_accuracy: 0.2243\n",
      "Epoch 3/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.2517 - accuracy: 0.2805 - val_loss: 1.2648 - val_accuracy: 0.2243\n",
      "Epoch 4/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.2371 - accuracy: 0.2832 - val_loss: 1.2392 - val_accuracy: 0.2243\n",
      "Epoch 5/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.2034 - accuracy: 0.2777 - val_loss: 1.2177 - val_accuracy: 0.2336\n",
      "Epoch 6/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1797 - accuracy: 0.2805 - val_loss: 1.1993 - val_accuracy: 0.2336\n",
      "Epoch 7/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1670 - accuracy: 0.2820 - val_loss: 1.1828 - val_accuracy: 0.2243\n",
      "Epoch 8/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1519 - accuracy: 0.2805 - val_loss: 1.1691 - val_accuracy: 0.2243\n",
      "Epoch 9/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1394 - accuracy: 0.2828 - val_loss: 1.1572 - val_accuracy: 0.2243\n",
      "Epoch 10/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.1296 - accuracy: 0.2797 - val_loss: 1.1473 - val_accuracy: 0.2150\n",
      "Epoch 11/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1230 - accuracy: 0.2812 - val_loss: 1.1389 - val_accuracy: 0.2150\n",
      "Epoch 12/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.1194 - accuracy: 0.2805 - val_loss: 1.1320 - val_accuracy: 0.2243\n",
      "Epoch 13/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1113 - accuracy: 0.2773 - val_loss: 1.1268 - val_accuracy: 0.2243\n",
      "Epoch 14/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1089 - accuracy: 0.2781 - val_loss: 1.1225 - val_accuracy: 0.2243\n",
      "Epoch 15/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1059 - accuracy: 0.2805 - val_loss: 1.1194 - val_accuracy: 0.2150\n",
      "Epoch 16/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.1043 - accuracy: 0.2789 - val_loss: 1.1167 - val_accuracy: 0.2243\n",
      "Epoch 17/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.1038 - accuracy: 0.2765 - val_loss: 1.1144 - val_accuracy: 0.2243\n",
      "Epoch 18/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1030 - accuracy: 0.2777 - val_loss: 1.1126 - val_accuracy: 0.2243\n",
      "Epoch 19/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.1005 - accuracy: 0.2805 - val_loss: 1.1111 - val_accuracy: 0.2243\n",
      "Epoch 20/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.1006 - accuracy: 0.2793 - val_loss: 1.1100 - val_accuracy: 0.2150\n",
      "Epoch 21/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1010 - accuracy: 0.2801 - val_loss: 1.1087 - val_accuracy: 0.2056\n",
      "Epoch 22/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1009 - accuracy: 0.2805 - val_loss: 1.1077 - val_accuracy: 0.2150\n",
      "Epoch 23/200\n",
      "2553/2553 [==============================] - 0s 73us/sample - loss: 1.0994 - accuracy: 0.2816 - val_loss: 1.1071 - val_accuracy: 0.2150\n",
      "Epoch 24/200\n",
      "2553/2553 [==============================] - 0s 66us/sample - loss: 1.1005 - accuracy: 0.2797 - val_loss: 1.1063 - val_accuracy: 0.2150\n",
      "Epoch 25/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0991 - accuracy: 0.2812 - val_loss: 1.1057 - val_accuracy: 0.2150\n",
      "Epoch 26/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.0997 - accuracy: 0.2816 - val_loss: 1.1051 - val_accuracy: 0.2150\n",
      "Epoch 27/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0984 - accuracy: 0.2812 - val_loss: 1.1049 - val_accuracy: 0.2243\n",
      "Epoch 28/200\n",
      "2553/2553 [==============================] - 0s 75us/sample - loss: 1.0986 - accuracy: 0.2805 - val_loss: 1.1048 - val_accuracy: 0.2243\n",
      "Epoch 29/200\n",
      "2553/2553 [==============================] - 0s 92us/sample - loss: 1.0981 - accuracy: 0.2820 - val_loss: 1.1052 - val_accuracy: 0.2243\n",
      "Epoch 30/200\n",
      "2553/2553 [==============================] - 0s 95us/sample - loss: 1.0991 - accuracy: 0.2820 - val_loss: 1.1051 - val_accuracy: 0.2243\n",
      "Epoch 31/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0987 - accuracy: 0.2816 - val_loss: 1.1049 - val_accuracy: 0.2243\n",
      "Epoch 32/200\n",
      "2553/2553 [==============================] - 0s 85us/sample - loss: 1.0989 - accuracy: 0.2824 - val_loss: 1.1048 - val_accuracy: 0.2243\n",
      "Epoch 33/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.0987 - accuracy: 0.2816 - val_loss: 1.1048 - val_accuracy: 0.2243\n",
      "Epoch 34/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0979 - accuracy: 0.2801 - val_loss: 1.1049 - val_accuracy: 0.2243\n",
      "Epoch 35/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0977 - accuracy: 0.2816 - val_loss: 1.1049 - val_accuracy: 0.2243\n",
      "Epoch 36/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0976 - accuracy: 0.2816 - val_loss: 1.1051 - val_accuracy: 0.2243\n",
      "Epoch 37/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0980 - accuracy: 0.2816 - val_loss: 1.1053 - val_accuracy: 0.2243\n",
      "Epoch 38/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0974 - accuracy: 0.2801 - val_loss: 1.1053 - val_accuracy: 0.2243\n",
      "Epoch 39/200\n",
      "2553/2553 [==============================] - 0s 51us/sample - loss: 1.0976 - accuracy: 0.2801 - val_loss: 1.1052 - val_accuracy: 0.2243\n",
      "Epoch 40/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.0974 - accuracy: 0.2805 - val_loss: 1.1051 - val_accuracy: 0.2243\n",
      "Epoch 41/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0978 - accuracy: 0.2797 - val_loss: 1.1048 - val_accuracy: 0.2243\n",
      "Epoch 42/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0978 - accuracy: 0.2801 - val_loss: 1.1048 - val_accuracy: 0.2243\n",
      "Epoch 43/200\n",
      "2553/2553 [==============================] - 0s 50us/sample - loss: 1.0977 - accuracy: 0.2793 - val_loss: 1.1047 - val_accuracy: 0.2243\n",
      "Epoch 44/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0978 - accuracy: 0.2797 - val_loss: 1.1047 - val_accuracy: 0.2243\n",
      "Epoch 45/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0969 - accuracy: 0.2805 - val_loss: 1.1045 - val_accuracy: 0.2243\n",
      "Epoch 46/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0968 - accuracy: 0.2805 - val_loss: 1.1045 - val_accuracy: 0.2243\n",
      "Epoch 47/200\n",
      "2553/2553 [==============================] - 0s 51us/sample - loss: 1.0980 - accuracy: 0.2801 - val_loss: 1.1044 - val_accuracy: 0.2243\n",
      "Epoch 48/200\n",
      "2553/2553 [==============================] - 0s 78us/sample - loss: 1.0968 - accuracy: 0.2801 - val_loss: 1.1045 - val_accuracy: 0.2243\n",
      "Epoch 49/200\n",
      "2553/2553 [==============================] - 0s 67us/sample - loss: 1.0963 - accuracy: 0.2793 - val_loss: 1.1046 - val_accuracy: 0.2243\n",
      "Epoch 50/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0971 - accuracy: 0.2797 - val_loss: 1.1049 - val_accuracy: 0.2243\n",
      "Epoch 51/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0965 - accuracy: 0.2805 - val_loss: 1.1049 - val_accuracy: 0.2243\n",
      "Epoch 52/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0973 - accuracy: 0.2801 - val_loss: 1.1048 - val_accuracy: 0.2243\n",
      "Epoch 53/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0964 - accuracy: 0.2805 - val_loss: 1.1049 - val_accuracy: 0.2243\n",
      "Epoch 54/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0976 - accuracy: 0.2801 - val_loss: 1.1048 - val_accuracy: 0.2243\n",
      "Epoch 55/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.0970 - accuracy: 0.2801 - val_loss: 1.1048 - val_accuracy: 0.2243\n",
      "Epoch 56/200\n",
      "2553/2553 [==============================] - 0s 65us/sample - loss: 1.0955 - accuracy: 0.2805 - val_loss: 1.1047 - val_accuracy: 0.2243\n",
      "Epoch 57/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0955 - accuracy: 0.2805 - val_loss: 1.1047 - val_accuracy: 0.2243\n",
      "Epoch 58/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0948 - accuracy: 0.2797 - val_loss: 1.1052 - val_accuracy: 0.2243\n",
      "Epoch 59/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0954 - accuracy: 0.2801 - val_loss: 1.1054 - val_accuracy: 0.2243\n",
      "Epoch 60/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0972 - accuracy: 0.2801 - val_loss: 1.1050 - val_accuracy: 0.2243\n",
      "Epoch 61/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0967 - accuracy: 0.2805 - val_loss: 1.1049 - val_accuracy: 0.2243\n",
      "Epoch 62/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0940 - accuracy: 0.2801 - val_loss: 1.1053 - val_accuracy: 0.2243\n",
      "Epoch 63/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0954 - accuracy: 0.2797 - val_loss: 1.1057 - val_accuracy: 0.2243\n",
      "Epoch 64/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0962 - accuracy: 0.2805 - val_loss: 1.1056 - val_accuracy: 0.2243\n",
      "Epoch 65/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0959 - accuracy: 0.2801 - val_loss: 1.1055 - val_accuracy: 0.2243\n",
      "Epoch 66/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.0928 - accuracy: 0.2801 - val_loss: 1.1059 - val_accuracy: 0.2243\n",
      "Epoch 67/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0951 - accuracy: 0.2801 - val_loss: 1.1057 - val_accuracy: 0.2243\n",
      "Epoch 68/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0912 - accuracy: 0.2805 - val_loss: 1.1059 - val_accuracy: 0.2243\n",
      "Epoch 69/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0908 - accuracy: 0.2805 - val_loss: 1.1064 - val_accuracy: 0.2243\n",
      "Epoch 70/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0931 - accuracy: 0.2801 - val_loss: 1.1061 - val_accuracy: 0.2243\n",
      "Epoch 71/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0938 - accuracy: 0.2805 - val_loss: 1.1059 - val_accuracy: 0.2243\n",
      "Epoch 72/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.0941 - accuracy: 0.2801 - val_loss: 1.1057 - val_accuracy: 0.2243\n",
      "Epoch 73/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0908 - accuracy: 0.2801 - val_loss: 1.1057 - val_accuracy: 0.2243\n",
      "Epoch 74/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0915 - accuracy: 0.2805 - val_loss: 1.1056 - val_accuracy: 0.2243\n",
      "Epoch 75/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0941 - accuracy: 0.2805 - val_loss: 1.1054 - val_accuracy: 0.2243\n",
      "Epoch 76/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0910 - accuracy: 0.2805 - val_loss: 1.1053 - val_accuracy: 0.2243\n",
      "Epoch 77/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0950 - accuracy: 0.2805 - val_loss: 1.1049 - val_accuracy: 0.2243\n",
      "Epoch 78/200\n",
      "2553/2553 [==============================] - 0s 65us/sample - loss: 1.0903 - accuracy: 0.2805 - val_loss: 1.1048 - val_accuracy: 0.2243\n",
      "Epoch 79/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0930 - accuracy: 0.2797 - val_loss: 1.1046 - val_accuracy: 0.2243\n",
      "Epoch 80/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0914 - accuracy: 0.2801 - val_loss: 1.1048 - val_accuracy: 0.2243\n",
      "Epoch 81/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0905 - accuracy: 0.2801 - val_loss: 1.1046 - val_accuracy: 0.2243\n",
      "Epoch 82/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0900 - accuracy: 0.2805 - val_loss: 1.1046 - val_accuracy: 0.2243\n",
      "Epoch 83/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0932 - accuracy: 0.2797 - val_loss: 1.1041 - val_accuracy: 0.2243\n",
      "Epoch 84/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0905 - accuracy: 0.2801 - val_loss: 1.1037 - val_accuracy: 0.2243\n",
      "Epoch 85/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0904 - accuracy: 0.2805 - val_loss: 1.1035 - val_accuracy: 0.2243\n",
      "Epoch 86/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0895 - accuracy: 0.2801 - val_loss: 1.1034 - val_accuracy: 0.2243\n",
      "Epoch 87/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0885 - accuracy: 0.2801 - val_loss: 1.1034 - val_accuracy: 0.2243\n",
      "Epoch 88/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0902 - accuracy: 0.2801 - val_loss: 1.1033 - val_accuracy: 0.2243\n",
      "Epoch 89/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0888 - accuracy: 0.2801 - val_loss: 1.1028 - val_accuracy: 0.2243\n",
      "Epoch 90/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0881 - accuracy: 0.2801 - val_loss: 1.1029 - val_accuracy: 0.2243\n",
      "Epoch 91/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0885 - accuracy: 0.2801 - val_loss: 1.1028 - val_accuracy: 0.2243\n",
      "Epoch 92/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0904 - accuracy: 0.2801 - val_loss: 1.1024 - val_accuracy: 0.2243\n",
      "Epoch 93/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0912 - accuracy: 0.2805 - val_loss: 1.1020 - val_accuracy: 0.2243\n",
      "Epoch 94/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.0877 - accuracy: 0.2797 - val_loss: 1.1020 - val_accuracy: 0.2243\n",
      "Epoch 95/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0849 - accuracy: 0.2805 - val_loss: 1.1021 - val_accuracy: 0.2243\n",
      "Epoch 96/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0854 - accuracy: 0.2801 - val_loss: 1.1019 - val_accuracy: 0.2243\n",
      "Epoch 97/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0872 - accuracy: 0.2801 - val_loss: 1.1019 - val_accuracy: 0.2243\n",
      "Epoch 98/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0945 - accuracy: 0.2801 - val_loss: 1.1012 - val_accuracy: 0.2243\n",
      "Epoch 99/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0885 - accuracy: 0.2801 - val_loss: 1.1010 - val_accuracy: 0.2243\n",
      "Epoch 100/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0866 - accuracy: 0.2801 - val_loss: 1.1008 - val_accuracy: 0.2243\n",
      "Epoch 101/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0883 - accuracy: 0.2805 - val_loss: 1.1008 - val_accuracy: 0.2243\n",
      "Epoch 102/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0916 - accuracy: 0.2805 - val_loss: 1.1002 - val_accuracy: 0.2243\n",
      "Epoch 103/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0868 - accuracy: 0.2801 - val_loss: 1.1001 - val_accuracy: 0.2243\n",
      "Epoch 104/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0907 - accuracy: 0.2797 - val_loss: 1.0999 - val_accuracy: 0.2243\n",
      "Epoch 105/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0894 - accuracy: 0.2805 - val_loss: 1.0995 - val_accuracy: 0.2243\n",
      "Epoch 106/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0878 - accuracy: 0.2801 - val_loss: 1.0993 - val_accuracy: 0.2243\n",
      "Epoch 107/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0905 - accuracy: 0.2797 - val_loss: 1.0991 - val_accuracy: 0.2243\n",
      "Epoch 108/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0896 - accuracy: 0.2801 - val_loss: 1.0989 - val_accuracy: 0.2243\n",
      "Epoch 109/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0891 - accuracy: 0.2805 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 110/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0888 - accuracy: 0.2805 - val_loss: 1.0983 - val_accuracy: 0.2243\n",
      "Epoch 111/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0872 - accuracy: 0.2805 - val_loss: 1.0982 - val_accuracy: 0.2243\n",
      "Epoch 112/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0899 - accuracy: 0.2801 - val_loss: 1.0979 - val_accuracy: 0.2243\n",
      "Epoch 113/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0868 - accuracy: 0.2801 - val_loss: 1.0980 - val_accuracy: 0.2243\n",
      "Epoch 114/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0906 - accuracy: 0.2801 - val_loss: 1.0976 - val_accuracy: 0.2243\n",
      "Epoch 115/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0861 - accuracy: 0.2801 - val_loss: 1.0975 - val_accuracy: 0.2243\n",
      "Epoch 116/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0886 - accuracy: 0.2805 - val_loss: 1.0973 - val_accuracy: 0.2243\n",
      "Epoch 117/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0861 - accuracy: 0.2805 - val_loss: 1.0973 - val_accuracy: 0.2243\n",
      "Epoch 118/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0878 - accuracy: 0.2805 - val_loss: 1.0971 - val_accuracy: 0.2243\n",
      "Epoch 119/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0888 - accuracy: 0.2797 - val_loss: 1.0969 - val_accuracy: 0.2243\n",
      "Epoch 120/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0881 - accuracy: 0.2805 - val_loss: 1.0967 - val_accuracy: 0.2243\n",
      "Epoch 121/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.0907 - accuracy: 0.2801 - val_loss: 1.0965 - val_accuracy: 0.2243\n",
      "Epoch 122/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0876 - accuracy: 0.2805 - val_loss: 1.0963 - val_accuracy: 0.2243\n",
      "Epoch 123/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0918 - accuracy: 0.2801 - val_loss: 1.0961 - val_accuracy: 0.2243\n",
      "Epoch 124/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0850 - accuracy: 0.2801 - val_loss: 1.0959 - val_accuracy: 0.2243\n",
      "Epoch 125/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0888 - accuracy: 0.2797 - val_loss: 1.0958 - val_accuracy: 0.2243\n",
      "Epoch 126/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0873 - accuracy: 0.2801 - val_loss: 1.0956 - val_accuracy: 0.2243\n",
      "Epoch 127/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0856 - accuracy: 0.2801 - val_loss: 1.0955 - val_accuracy: 0.2243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 128/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0889 - accuracy: 0.2801 - val_loss: 1.0954 - val_accuracy: 0.2243\n",
      "Epoch 129/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0877 - accuracy: 0.2801 - val_loss: 1.0952 - val_accuracy: 0.2243\n",
      "Epoch 130/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.0893 - accuracy: 0.2805 - val_loss: 1.0949 - val_accuracy: 0.2243\n",
      "Epoch 131/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0870 - accuracy: 0.2801 - val_loss: 1.0948 - val_accuracy: 0.2243\n",
      "Epoch 132/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.0894 - accuracy: 0.2805 - val_loss: 1.0946 - val_accuracy: 0.2243\n",
      "Epoch 133/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0873 - accuracy: 0.2805 - val_loss: 1.0944 - val_accuracy: 0.2243\n",
      "Epoch 134/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0889 - accuracy: 0.2805 - val_loss: 1.0942 - val_accuracy: 0.2243\n",
      "Epoch 135/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0855 - accuracy: 0.2805 - val_loss: 1.0941 - val_accuracy: 0.2243\n",
      "Epoch 136/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0848 - accuracy: 0.2805 - val_loss: 1.0940 - val_accuracy: 0.2243\n",
      "Epoch 137/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0852 - accuracy: 0.2805 - val_loss: 1.0938 - val_accuracy: 0.2243\n",
      "Epoch 138/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0866 - accuracy: 0.2801 - val_loss: 1.0936 - val_accuracy: 0.2243\n",
      "Epoch 139/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0859 - accuracy: 0.2797 - val_loss: 1.0935 - val_accuracy: 0.2243\n",
      "Epoch 140/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0846 - accuracy: 0.2805 - val_loss: 1.0933 - val_accuracy: 0.2243\n",
      "Epoch 141/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0854 - accuracy: 0.2801 - val_loss: 1.0932 - val_accuracy: 0.2243\n",
      "Epoch 142/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0856 - accuracy: 0.2801 - val_loss: 1.0931 - val_accuracy: 0.2243\n",
      "Epoch 143/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0865 - accuracy: 0.2797 - val_loss: 1.0930 - val_accuracy: 0.2243\n",
      "Epoch 144/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0859 - accuracy: 0.2805 - val_loss: 1.0928 - val_accuracy: 0.2243\n",
      "Epoch 145/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.0884 - accuracy: 0.2801 - val_loss: 1.0926 - val_accuracy: 0.2243\n",
      "Epoch 146/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.0886 - accuracy: 0.2801 - val_loss: 1.0925 - val_accuracy: 0.2243\n",
      "Epoch 147/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.0837 - accuracy: 0.2805 - val_loss: 1.0923 - val_accuracy: 0.2243\n",
      "Epoch 148/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.0838 - accuracy: 0.2805 - val_loss: 1.0923 - val_accuracy: 0.2243\n",
      "Epoch 149/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0815 - accuracy: 0.2801 - val_loss: 1.0923 - val_accuracy: 0.2243\n",
      "Epoch 150/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0872 - accuracy: 0.2805 - val_loss: 1.0920 - val_accuracy: 0.2243\n",
      "Epoch 151/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0857 - accuracy: 0.2805 - val_loss: 1.0919 - val_accuracy: 0.2243\n",
      "Epoch 152/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0838 - accuracy: 0.2801 - val_loss: 1.0918 - val_accuracy: 0.2243\n",
      "Epoch 153/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0844 - accuracy: 0.2805 - val_loss: 1.0917 - val_accuracy: 0.2243\n",
      "Epoch 154/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0855 - accuracy: 0.2805 - val_loss: 1.0915 - val_accuracy: 0.2243\n",
      "Epoch 155/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0848 - accuracy: 0.2801 - val_loss: 1.0914 - val_accuracy: 0.2243\n",
      "Epoch 156/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0864 - accuracy: 0.2805 - val_loss: 1.0912 - val_accuracy: 0.2243\n",
      "Epoch 157/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0836 - accuracy: 0.2805 - val_loss: 1.0911 - val_accuracy: 0.2243\n",
      "Epoch 158/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.0846 - accuracy: 0.2805 - val_loss: 1.0910 - val_accuracy: 0.2243\n",
      "Epoch 159/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0844 - accuracy: 0.2805 - val_loss: 1.0909 - val_accuracy: 0.2243\n",
      "Epoch 160/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0848 - accuracy: 0.2805 - val_loss: 1.0908 - val_accuracy: 0.2243\n",
      "Epoch 161/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0838 - accuracy: 0.2805 - val_loss: 1.0908 - val_accuracy: 0.2243\n",
      "Epoch 162/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0809 - accuracy: 0.2801 - val_loss: 1.0908 - val_accuracy: 0.2243\n",
      "Epoch 163/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0834 - accuracy: 0.2805 - val_loss: 1.0908 - val_accuracy: 0.2243\n",
      "Epoch 164/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0877 - accuracy: 0.2805 - val_loss: 1.0905 - val_accuracy: 0.2243\n",
      "Epoch 165/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0824 - accuracy: 0.2801 - val_loss: 1.0904 - val_accuracy: 0.2243\n",
      "Epoch 166/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0867 - accuracy: 0.2805 - val_loss: 1.0901 - val_accuracy: 0.2243\n",
      "Epoch 167/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0810 - accuracy: 0.2805 - val_loss: 1.0901 - val_accuracy: 0.2243\n",
      "Epoch 168/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0811 - accuracy: 0.2805 - val_loss: 1.0901 - val_accuracy: 0.2243\n",
      "Epoch 169/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.0844 - accuracy: 0.2805 - val_loss: 1.0900 - val_accuracy: 0.2243\n",
      "Epoch 170/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0823 - accuracy: 0.2805 - val_loss: 1.0899 - val_accuracy: 0.2243\n",
      "Epoch 171/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0830 - accuracy: 0.2797 - val_loss: 1.0898 - val_accuracy: 0.2243\n",
      "Epoch 172/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0862 - accuracy: 0.2805 - val_loss: 1.0897 - val_accuracy: 0.2243\n",
      "Epoch 173/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.0822 - accuracy: 0.2801 - val_loss: 1.0895 - val_accuracy: 0.2243\n",
      "Epoch 174/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0842 - accuracy: 0.2805 - val_loss: 1.0894 - val_accuracy: 0.2243\n",
      "Epoch 175/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0845 - accuracy: 0.2801 - val_loss: 1.0893 - val_accuracy: 0.2243\n",
      "Epoch 176/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0829 - accuracy: 0.2801 - val_loss: 1.0892 - val_accuracy: 0.2243\n",
      "Epoch 177/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0857 - accuracy: 0.2805 - val_loss: 1.0891 - val_accuracy: 0.2243\n",
      "Epoch 178/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0826 - accuracy: 0.2801 - val_loss: 1.0890 - val_accuracy: 0.2243\n",
      "Epoch 179/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0835 - accuracy: 0.2797 - val_loss: 1.0890 - val_accuracy: 0.2243\n",
      "Epoch 180/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0805 - accuracy: 0.2805 - val_loss: 1.0890 - val_accuracy: 0.2243\n",
      "Epoch 181/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0827 - accuracy: 0.2805 - val_loss: 1.0890 - val_accuracy: 0.2243\n",
      "Epoch 182/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0843 - accuracy: 0.2801 - val_loss: 1.0887 - val_accuracy: 0.2243\n",
      "Epoch 183/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0832 - accuracy: 0.2805 - val_loss: 1.0886 - val_accuracy: 0.2243\n",
      "Epoch 184/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0838 - accuracy: 0.2801 - val_loss: 1.0885 - val_accuracy: 0.2243\n",
      "Epoch 185/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0809 - accuracy: 0.2801 - val_loss: 1.0886 - val_accuracy: 0.2243\n",
      "Epoch 186/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0869 - accuracy: 0.2797 - val_loss: 1.0884 - val_accuracy: 0.2243\n",
      "Epoch 187/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0831 - accuracy: 0.2805 - val_loss: 1.0884 - val_accuracy: 0.2243\n",
      "Epoch 188/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0849 - accuracy: 0.2801 - val_loss: 1.0883 - val_accuracy: 0.2243\n",
      "Epoch 189/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.0789 - accuracy: 0.2801 - val_loss: 1.0883 - val_accuracy: 0.2243\n",
      "Epoch 190/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0866 - accuracy: 0.2801 - val_loss: 1.0882 - val_accuracy: 0.2243\n",
      "Epoch 191/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0867 - accuracy: 0.2801 - val_loss: 1.0880 - val_accuracy: 0.2243\n",
      "Epoch 192/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0826 - accuracy: 0.2801 - val_loss: 1.0879 - val_accuracy: 0.2243\n",
      "Epoch 193/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0842 - accuracy: 0.2801 - val_loss: 1.0879 - val_accuracy: 0.2243\n",
      "Epoch 194/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0825 - accuracy: 0.2801 - val_loss: 1.0878 - val_accuracy: 0.2243\n",
      "Epoch 195/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0858 - accuracy: 0.2797 - val_loss: 1.0878 - val_accuracy: 0.2243\n",
      "Epoch 196/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0849 - accuracy: 0.2805 - val_loss: 1.0877 - val_accuracy: 0.2243\n",
      "Epoch 197/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0853 - accuracy: 0.2801 - val_loss: 1.0876 - val_accuracy: 0.2243\n",
      "Epoch 198/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.0827 - accuracy: 0.2805 - val_loss: 1.0876 - val_accuracy: 0.2243\n",
      "Epoch 199/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0836 - accuracy: 0.2797 - val_loss: 1.0875 - val_accuracy: 0.2243\n",
      "Epoch 200/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0835 - accuracy: 0.2805 - val_loss: 1.0875 - val_accuracy: 0.2243\n",
      "0.22429906 {'loss': 1.0835074190060578, 'accuracy': 0.28045437, 'val_loss': 1.087467913315675, 'val_accuracy': 0.22429906}\n",
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, 29)]              0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 41)                1230      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 75)                3150      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 3)                 228       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 4,608\n",
      "Trainable params: 4,608\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2553 samples, validate on 107 samples\n",
      "Epoch 1/200\n",
      "2553/2553 [==============================] - 1s 313us/sample - loss: 1.9046 - accuracy: 0.3016 - val_loss: 1.3588 - val_accuracy: 0.2617\n",
      "Epoch 2/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.6715 - accuracy: 0.3063 - val_loss: 1.2492 - val_accuracy: 0.2897\n",
      "Epoch 3/200\n",
      "2553/2553 [==============================] - 0s 98us/sample - loss: 1.5334 - accuracy: 0.2965 - val_loss: 1.1645 - val_accuracy: 0.3551\n",
      "Epoch 4/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.4117 - accuracy: 0.3255 - val_loss: 1.1093 - val_accuracy: 0.3738\n",
      "Epoch 5/200\n",
      "2553/2553 [==============================] - 0s 99us/sample - loss: 1.2857 - accuracy: 0.3631 - val_loss: 1.0753 - val_accuracy: 0.4299\n",
      "Epoch 6/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.2601 - accuracy: 0.3615 - val_loss: 1.0551 - val_accuracy: 0.4579\n",
      "Epoch 7/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.2151 - accuracy: 0.3658 - val_loss: 1.0408 - val_accuracy: 0.4579\n",
      "Epoch 8/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.1731 - accuracy: 0.3619 - val_loss: 1.0326 - val_accuracy: 0.4860\n",
      "Epoch 9/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.1619 - accuracy: 0.3615 - val_loss: 1.0278 - val_accuracy: 0.4766\n",
      "Epoch 10/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.1444 - accuracy: 0.3682 - val_loss: 1.0231 - val_accuracy: 0.4860\n",
      "Epoch 11/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.1234 - accuracy: 0.3741 - val_loss: 1.0212 - val_accuracy: 0.4766\n",
      "Epoch 12/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.0952 - accuracy: 0.3921 - val_loss: 1.0182 - val_accuracy: 0.4673\n",
      "Epoch 13/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0864 - accuracy: 0.3886 - val_loss: 1.0175 - val_accuracy: 0.4766\n",
      "Epoch 14/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0770 - accuracy: 0.3905 - val_loss: 1.0182 - val_accuracy: 0.4766\n",
      "Epoch 15/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.0820 - accuracy: 0.3788 - val_loss: 1.0176 - val_accuracy: 0.4673\n",
      "Epoch 16/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.0739 - accuracy: 0.3815 - val_loss: 1.0175 - val_accuracy: 0.4579\n",
      "Epoch 17/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0692 - accuracy: 0.3811 - val_loss: 1.0163 - val_accuracy: 0.4579\n",
      "Epoch 18/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0595 - accuracy: 0.3933 - val_loss: 1.0162 - val_accuracy: 0.4579\n",
      "Epoch 19/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.0636 - accuracy: 0.3890 - val_loss: 1.0163 - val_accuracy: 0.4579\n",
      "Epoch 20/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0523 - accuracy: 0.4046 - val_loss: 1.0168 - val_accuracy: 0.4673\n",
      "Epoch 21/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0524 - accuracy: 0.4007 - val_loss: 1.0158 - val_accuracy: 0.4673\n",
      "Epoch 22/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0527 - accuracy: 0.3995 - val_loss: 1.0163 - val_accuracy: 0.4766\n",
      "Epoch 23/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0495 - accuracy: 0.3948 - val_loss: 1.0172 - val_accuracy: 0.4766\n",
      "Epoch 24/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0481 - accuracy: 0.4081 - val_loss: 1.0171 - val_accuracy: 0.4579\n",
      "Epoch 25/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0479 - accuracy: 0.4034 - val_loss: 1.0168 - val_accuracy: 0.4579\n",
      "Epoch 26/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.0460 - accuracy: 0.3984 - val_loss: 1.0162 - val_accuracy: 0.4579\n",
      "Epoch 27/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.0409 - accuracy: 0.4038 - val_loss: 1.0150 - val_accuracy: 0.4579\n",
      "Epoch 28/200\n",
      "2553/2553 [==============================] - 0s 118us/sample - loss: 1.0435 - accuracy: 0.4007 - val_loss: 1.0133 - val_accuracy: 0.4579\n",
      "Epoch 29/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 1.0489 - accuracy: 0.3901 - val_loss: 1.0131 - val_accuracy: 0.4579\n",
      "Epoch 30/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0546 - accuracy: 0.3850 - val_loss: 1.0150 - val_accuracy: 0.4579\n",
      "Epoch 31/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0412 - accuracy: 0.4097 - val_loss: 1.0144 - val_accuracy: 0.4579\n",
      "Epoch 32/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0437 - accuracy: 0.4034 - val_loss: 1.0141 - val_accuracy: 0.4486\n",
      "Epoch 33/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0443 - accuracy: 0.3987 - val_loss: 1.0144 - val_accuracy: 0.4486\n",
      "Epoch 34/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0539 - accuracy: 0.3878 - val_loss: 1.0145 - val_accuracy: 0.4486\n",
      "Epoch 35/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.0419 - accuracy: 0.4046 - val_loss: 1.0132 - val_accuracy: 0.4486\n",
      "Epoch 36/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.0401 - accuracy: 0.3886 - val_loss: 1.0126 - val_accuracy: 0.4579\n",
      "Epoch 37/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0460 - accuracy: 0.3890 - val_loss: 1.0129 - val_accuracy: 0.4579\n",
      "Epoch 38/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0386 - accuracy: 0.3972 - val_loss: 1.0126 - val_accuracy: 0.4579\n",
      "Epoch 39/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0453 - accuracy: 0.3976 - val_loss: 1.0117 - val_accuracy: 0.4673\n",
      "Epoch 40/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0282 - accuracy: 0.4148 - val_loss: 1.0102 - val_accuracy: 0.4953\n",
      "Epoch 41/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0463 - accuracy: 0.3956 - val_loss: 1.0110 - val_accuracy: 0.4953\n",
      "Epoch 42/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0442 - accuracy: 0.4007 - val_loss: 1.0102 - val_accuracy: 0.5047\n",
      "Epoch 43/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0326 - accuracy: 0.4034 - val_loss: 1.0098 - val_accuracy: 0.5047\n",
      "Epoch 44/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0412 - accuracy: 0.4023 - val_loss: 1.0098 - val_accuracy: 0.5047\n",
      "Epoch 45/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0434 - accuracy: 0.3980 - val_loss: 1.0100 - val_accuracy: 0.5047\n",
      "Epoch 46/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0412 - accuracy: 0.3960 - val_loss: 1.0102 - val_accuracy: 0.5047\n",
      "Epoch 47/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0386 - accuracy: 0.4050 - val_loss: 1.0082 - val_accuracy: 0.4953\n",
      "Epoch 48/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.0351 - accuracy: 0.3972 - val_loss: 1.0082 - val_accuracy: 0.5047\n",
      "Epoch 49/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0411 - accuracy: 0.3948 - val_loss: 1.0075 - val_accuracy: 0.5047\n",
      "Epoch 50/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0467 - accuracy: 0.4007 - val_loss: 1.0081 - val_accuracy: 0.5047\n",
      "Epoch 51/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0403 - accuracy: 0.3937 - val_loss: 1.0083 - val_accuracy: 0.5047\n",
      "Epoch 52/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0312 - accuracy: 0.3980 - val_loss: 1.0070 - val_accuracy: 0.5047\n",
      "Epoch 53/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0388 - accuracy: 0.3980 - val_loss: 1.0062 - val_accuracy: 0.5047\n",
      "Epoch 54/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0392 - accuracy: 0.3940 - val_loss: 1.0061 - val_accuracy: 0.5047\n",
      "Epoch 55/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0369 - accuracy: 0.4078 - val_loss: 1.0063 - val_accuracy: 0.5047\n",
      "Epoch 56/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0438 - accuracy: 0.3972 - val_loss: 1.0064 - val_accuracy: 0.5047\n",
      "Epoch 57/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0329 - accuracy: 0.4050 - val_loss: 1.0053 - val_accuracy: 0.5140\n",
      "Epoch 58/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0428 - accuracy: 0.3995 - val_loss: 1.0050 - val_accuracy: 0.5140\n",
      "Epoch 59/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0323 - accuracy: 0.4015 - val_loss: 1.0039 - val_accuracy: 0.5140\n",
      "Epoch 60/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0305 - accuracy: 0.4066 - val_loss: 1.0040 - val_accuracy: 0.5140\n",
      "Epoch 61/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0409 - accuracy: 0.3952 - val_loss: 1.0040 - val_accuracy: 0.5140\n",
      "Epoch 62/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0385 - accuracy: 0.3980 - val_loss: 1.0053 - val_accuracy: 0.5140\n",
      "Epoch 63/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0307 - accuracy: 0.4019 - val_loss: 1.0032 - val_accuracy: 0.5140\n",
      "Epoch 64/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0376 - accuracy: 0.3968 - val_loss: 1.0033 - val_accuracy: 0.5140\n",
      "Epoch 65/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0274 - accuracy: 0.4089 - val_loss: 1.0026 - val_accuracy: 0.5140\n",
      "Epoch 66/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.0327 - accuracy: 0.4034 - val_loss: 1.0020 - val_accuracy: 0.5140\n",
      "Epoch 67/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.0348 - accuracy: 0.3995 - val_loss: 1.0020 - val_accuracy: 0.5140\n",
      "Epoch 68/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0337 - accuracy: 0.4046 - val_loss: 1.0017 - val_accuracy: 0.5140\n",
      "Epoch 69/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0282 - accuracy: 0.3987 - val_loss: 1.0014 - val_accuracy: 0.5140\n",
      "Epoch 70/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0272 - accuracy: 0.4019 - val_loss: 1.0000 - val_accuracy: 0.5140\n",
      "Epoch 71/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0251 - accuracy: 0.4179 - val_loss: 0.9983 - val_accuracy: 0.5140\n",
      "Epoch 72/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0282 - accuracy: 0.4136 - val_loss: 0.9982 - val_accuracy: 0.5047\n",
      "Epoch 73/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0352 - accuracy: 0.3980 - val_loss: 0.9981 - val_accuracy: 0.5047\n",
      "Epoch 74/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.0276 - accuracy: 0.4034 - val_loss: 0.9983 - val_accuracy: 0.5047\n",
      "Epoch 75/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0307 - accuracy: 0.4058 - val_loss: 0.9979 - val_accuracy: 0.5047\n",
      "Epoch 76/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0322 - accuracy: 0.4101 - val_loss: 0.9975 - val_accuracy: 0.5047\n",
      "Epoch 77/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.0305 - accuracy: 0.3991 - val_loss: 0.9983 - val_accuracy: 0.5047\n",
      "Epoch 78/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.0305 - accuracy: 0.4070 - val_loss: 0.9977 - val_accuracy: 0.5047\n",
      "Epoch 79/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0396 - accuracy: 0.3972 - val_loss: 0.9983 - val_accuracy: 0.5140\n",
      "Epoch 80/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0335 - accuracy: 0.3991 - val_loss: 0.9972 - val_accuracy: 0.5047\n",
      "Epoch 81/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0328 - accuracy: 0.4132 - val_loss: 0.9965 - val_accuracy: 0.4953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0253 - accuracy: 0.4042 - val_loss: 0.9960 - val_accuracy: 0.4953\n",
      "Epoch 83/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0260 - accuracy: 0.3995 - val_loss: 0.9955 - val_accuracy: 0.5047\n",
      "Epoch 84/200\n",
      "2553/2553 [==============================] - 0s 118us/sample - loss: 1.0298 - accuracy: 0.4070 - val_loss: 0.9959 - val_accuracy: 0.5047\n",
      "Epoch 85/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0269 - accuracy: 0.4066 - val_loss: 0.9947 - val_accuracy: 0.4953\n",
      "Epoch 86/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 1.0391 - accuracy: 0.3925 - val_loss: 0.9951 - val_accuracy: 0.4953\n",
      "Epoch 87/200\n",
      "2553/2553 [==============================] - 0s 99us/sample - loss: 1.0316 - accuracy: 0.4034 - val_loss: 0.9962 - val_accuracy: 0.5047\n",
      "Epoch 88/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.0321 - accuracy: 0.3925 - val_loss: 0.9959 - val_accuracy: 0.5140\n",
      "Epoch 89/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0341 - accuracy: 0.3940 - val_loss: 0.9963 - val_accuracy: 0.5140\n",
      "Epoch 90/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0311 - accuracy: 0.4042 - val_loss: 0.9957 - val_accuracy: 0.4953\n",
      "Epoch 91/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.0275 - accuracy: 0.4034 - val_loss: 0.9952 - val_accuracy: 0.4953\n",
      "Epoch 92/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.0305 - accuracy: 0.4003 - val_loss: 0.9948 - val_accuracy: 0.5047\n",
      "Epoch 93/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.0245 - accuracy: 0.4156 - val_loss: 0.9939 - val_accuracy: 0.5047\n",
      "Epoch 94/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0329 - accuracy: 0.4027 - val_loss: 0.9940 - val_accuracy: 0.5047\n",
      "Epoch 95/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.0272 - accuracy: 0.4027 - val_loss: 0.9947 - val_accuracy: 0.5047\n",
      "Epoch 96/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.0266 - accuracy: 0.4113 - val_loss: 0.9929 - val_accuracy: 0.5047\n",
      "Epoch 97/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0329 - accuracy: 0.4058 - val_loss: 0.9937 - val_accuracy: 0.5140\n",
      "Epoch 98/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0279 - accuracy: 0.3999 - val_loss: 0.9939 - val_accuracy: 0.5047\n",
      "Epoch 99/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0325 - accuracy: 0.4027 - val_loss: 0.9936 - val_accuracy: 0.5140\n",
      "Epoch 100/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.0290 - accuracy: 0.4031 - val_loss: 0.9932 - val_accuracy: 0.5047\n",
      "Epoch 101/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0256 - accuracy: 0.3987 - val_loss: 0.9924 - val_accuracy: 0.5047\n",
      "Epoch 102/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0298 - accuracy: 0.4003 - val_loss: 0.9930 - val_accuracy: 0.5047\n",
      "Epoch 103/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.0316 - accuracy: 0.4062 - val_loss: 0.9930 - val_accuracy: 0.5047\n",
      "Epoch 104/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.0295 - accuracy: 0.4023 - val_loss: 0.9929 - val_accuracy: 0.5047\n",
      "Epoch 105/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0384 - accuracy: 0.3866 - val_loss: 0.9936 - val_accuracy: 0.5140\n",
      "Epoch 106/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0271 - accuracy: 0.4058 - val_loss: 0.9915 - val_accuracy: 0.5047\n",
      "Epoch 107/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0238 - accuracy: 0.4078 - val_loss: 0.9903 - val_accuracy: 0.5140\n",
      "Epoch 108/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0313 - accuracy: 0.4034 - val_loss: 0.9900 - val_accuracy: 0.5234\n",
      "Epoch 109/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0382 - accuracy: 0.3944 - val_loss: 0.9909 - val_accuracy: 0.5047\n",
      "Epoch 110/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0258 - accuracy: 0.4097 - val_loss: 0.9901 - val_accuracy: 0.5234\n",
      "Epoch 111/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0361 - accuracy: 0.3858 - val_loss: 0.9918 - val_accuracy: 0.5047\n",
      "Epoch 112/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.0267 - accuracy: 0.3976 - val_loss: 0.9909 - val_accuracy: 0.5140\n",
      "Epoch 113/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0281 - accuracy: 0.4046 - val_loss: 0.9913 - val_accuracy: 0.5140\n",
      "Epoch 114/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0274 - accuracy: 0.4019 - val_loss: 0.9900 - val_accuracy: 0.5234\n",
      "Epoch 115/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0292 - accuracy: 0.4003 - val_loss: 0.9899 - val_accuracy: 0.5234\n",
      "Epoch 116/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0349 - accuracy: 0.3917 - val_loss: 0.9896 - val_accuracy: 0.5234\n",
      "Epoch 117/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0330 - accuracy: 0.4081 - val_loss: 0.9895 - val_accuracy: 0.5234\n",
      "Epoch 118/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0436 - accuracy: 0.3874 - val_loss: 0.9915 - val_accuracy: 0.5234\n",
      "Epoch 119/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.0201 - accuracy: 0.4074 - val_loss: 0.9892 - val_accuracy: 0.5234\n",
      "Epoch 120/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0272 - accuracy: 0.4050 - val_loss: 0.9895 - val_accuracy: 0.5234\n",
      "Epoch 121/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0284 - accuracy: 0.4125 - val_loss: 0.9886 - val_accuracy: 0.5234\n",
      "Epoch 122/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0271 - accuracy: 0.3991 - val_loss: 0.9888 - val_accuracy: 0.5234\n",
      "Epoch 123/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.0251 - accuracy: 0.4207 - val_loss: 0.9873 - val_accuracy: 0.5234\n",
      "Epoch 124/200\n",
      "2553/2553 [==============================] - ETA: 0s - loss: 1.0377 - accuracy: 0.39 - 0s 134us/sample - loss: 1.0366 - accuracy: 0.3980 - val_loss: 0.9885 - val_accuracy: 0.5234\n",
      "Epoch 125/200\n",
      "2553/2553 [==============================] - 0s 158us/sample - loss: 1.0205 - accuracy: 0.4050 - val_loss: 0.9876 - val_accuracy: 0.5234\n",
      "Epoch 126/200\n",
      "2553/2553 [==============================] - 0s 152us/sample - loss: 1.0237 - accuracy: 0.4070 - val_loss: 0.9873 - val_accuracy: 0.5234\n",
      "Epoch 127/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 1.0241 - accuracy: 0.4101 - val_loss: 0.9856 - val_accuracy: 0.5234\n",
      "Epoch 128/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.0309 - accuracy: 0.4003 - val_loss: 0.9857 - val_accuracy: 0.5234\n",
      "Epoch 129/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 1.0355 - accuracy: 0.3921 - val_loss: 0.9862 - val_accuracy: 0.5234\n",
      "Epoch 130/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.0215 - accuracy: 0.4074 - val_loss: 0.9854 - val_accuracy: 0.5234\n",
      "Epoch 131/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0272 - accuracy: 0.4034 - val_loss: 0.9853 - val_accuracy: 0.5234\n",
      "Epoch 132/200\n",
      "2553/2553 [==============================] - 0s 123us/sample - loss: 1.0299 - accuracy: 0.4015 - val_loss: 0.9856 - val_accuracy: 0.5234\n",
      "Epoch 133/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.0266 - accuracy: 0.3987 - val_loss: 0.9852 - val_accuracy: 0.5234\n",
      "Epoch 134/200\n",
      "2553/2553 [==============================] - 0s 121us/sample - loss: 1.0244 - accuracy: 0.3972 - val_loss: 0.9850 - val_accuracy: 0.5234\n",
      "Epoch 135/200\n",
      "2553/2553 [==============================] - 0s 119us/sample - loss: 1.0250 - accuracy: 0.4128 - val_loss: 0.9843 - val_accuracy: 0.5234\n",
      "Epoch 136/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.0215 - accuracy: 0.4078 - val_loss: 0.9849 - val_accuracy: 0.5234\n",
      "Epoch 137/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0231 - accuracy: 0.4066 - val_loss: 0.9845 - val_accuracy: 0.5327\n",
      "Epoch 138/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0156 - accuracy: 0.4085 - val_loss: 0.9834 - val_accuracy: 0.5234\n",
      "Epoch 139/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0233 - accuracy: 0.4046 - val_loss: 0.9834 - val_accuracy: 0.5234\n",
      "Epoch 140/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.0200 - accuracy: 0.4085 - val_loss: 0.9833 - val_accuracy: 0.5234\n",
      "Epoch 141/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.0145 - accuracy: 0.4097 - val_loss: 0.9835 - val_accuracy: 0.5234\n",
      "Epoch 142/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0279 - accuracy: 0.3980 - val_loss: 0.9833 - val_accuracy: 0.5234\n",
      "Epoch 143/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 1.0255 - accuracy: 0.4148 - val_loss: 0.9834 - val_accuracy: 0.5234\n",
      "Epoch 144/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0276 - accuracy: 0.3968 - val_loss: 0.9836 - val_accuracy: 0.5234\n",
      "Epoch 145/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0325 - accuracy: 0.3984 - val_loss: 0.9839 - val_accuracy: 0.5234\n",
      "Epoch 146/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0166 - accuracy: 0.4175 - val_loss: 0.9835 - val_accuracy: 0.5234\n",
      "Epoch 147/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0239 - accuracy: 0.4058 - val_loss: 0.9836 - val_accuracy: 0.5234\n",
      "Epoch 148/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0282 - accuracy: 0.3944 - val_loss: 0.9834 - val_accuracy: 0.5234\n",
      "Epoch 149/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0217 - accuracy: 0.4070 - val_loss: 0.9822 - val_accuracy: 0.5327\n",
      "Epoch 150/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0339 - accuracy: 0.4015 - val_loss: 0.9831 - val_accuracy: 0.5327\n",
      "Epoch 151/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0232 - accuracy: 0.4175 - val_loss: 0.9827 - val_accuracy: 0.5327\n",
      "Epoch 152/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0253 - accuracy: 0.4050 - val_loss: 0.9831 - val_accuracy: 0.5327\n",
      "Epoch 153/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0169 - accuracy: 0.4117 - val_loss: 0.9824 - val_accuracy: 0.5327\n",
      "Epoch 154/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.0291 - accuracy: 0.3929 - val_loss: 0.9833 - val_accuracy: 0.5234\n",
      "Epoch 155/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0254 - accuracy: 0.3995 - val_loss: 0.9837 - val_accuracy: 0.5234\n",
      "Epoch 156/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0283 - accuracy: 0.4011 - val_loss: 0.9835 - val_accuracy: 0.5234\n",
      "Epoch 157/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0262 - accuracy: 0.4023 - val_loss: 0.9825 - val_accuracy: 0.5327\n",
      "Epoch 158/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.0172 - accuracy: 0.4144 - val_loss: 0.9817 - val_accuracy: 0.5234\n",
      "Epoch 159/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0215 - accuracy: 0.4183 - val_loss: 0.9816 - val_accuracy: 0.5234\n",
      "Epoch 160/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.0260 - accuracy: 0.4058 - val_loss: 0.9814 - val_accuracy: 0.5234\n",
      "Epoch 161/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0190 - accuracy: 0.4078 - val_loss: 0.9814 - val_accuracy: 0.5327\n",
      "Epoch 162/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.0285 - accuracy: 0.4019 - val_loss: 0.9821 - val_accuracy: 0.5327\n",
      "Epoch 163/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0223 - accuracy: 0.4219 - val_loss: 0.9822 - val_accuracy: 0.5327\n",
      "Epoch 164/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0291 - accuracy: 0.4046 - val_loss: 0.9821 - val_accuracy: 0.5327\n",
      "Epoch 165/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0195 - accuracy: 0.4125 - val_loss: 0.9813 - val_accuracy: 0.5327\n",
      "Epoch 166/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.0177 - accuracy: 0.4081 - val_loss: 0.9811 - val_accuracy: 0.5327\n",
      "Epoch 167/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0223 - accuracy: 0.4019 - val_loss: 0.9813 - val_accuracy: 0.5327\n",
      "Epoch 168/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0196 - accuracy: 0.4050 - val_loss: 0.9809 - val_accuracy: 0.5327\n",
      "Epoch 169/200\n",
      "2553/2553 [==============================] - 0s 118us/sample - loss: 1.0218 - accuracy: 0.4125 - val_loss: 0.9806 - val_accuracy: 0.5327\n",
      "Epoch 170/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0279 - accuracy: 0.3960 - val_loss: 0.9825 - val_accuracy: 0.5234\n",
      "Epoch 171/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0238 - accuracy: 0.4007 - val_loss: 0.9819 - val_accuracy: 0.5327\n",
      "Epoch 172/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.0197 - accuracy: 0.4078 - val_loss: 0.9815 - val_accuracy: 0.5327\n",
      "Epoch 173/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.0274 - accuracy: 0.4011 - val_loss: 0.9829 - val_accuracy: 0.5234\n",
      "Epoch 174/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.0225 - accuracy: 0.4070 - val_loss: 0.9821 - val_accuracy: 0.5234\n",
      "Epoch 175/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.0077 - accuracy: 0.4191 - val_loss: 0.9800 - val_accuracy: 0.5234\n",
      "Epoch 176/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0238 - accuracy: 0.4121 - val_loss: 0.9794 - val_accuracy: 0.5327\n",
      "Epoch 177/200\n",
      "2553/2553 [==============================] - 0s 115us/sample - loss: 1.0221 - accuracy: 0.4058 - val_loss: 0.9794 - val_accuracy: 0.5234\n",
      "Epoch 178/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0176 - accuracy: 0.4078 - val_loss: 0.9802 - val_accuracy: 0.5234\n",
      "Epoch 179/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.0281 - accuracy: 0.4003 - val_loss: 0.9804 - val_accuracy: 0.5327\n",
      "Epoch 180/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0187 - accuracy: 0.4179 - val_loss: 0.9795 - val_accuracy: 0.5327\n",
      "Epoch 181/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.0210 - accuracy: 0.4105 - val_loss: 0.9796 - val_accuracy: 0.5327\n",
      "Epoch 182/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.0286 - accuracy: 0.3987 - val_loss: 0.9800 - val_accuracy: 0.5327\n",
      "Epoch 183/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.0193 - accuracy: 0.4015 - val_loss: 0.9807 - val_accuracy: 0.5234\n",
      "Epoch 184/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.0220 - accuracy: 0.4148 - val_loss: 0.9793 - val_accuracy: 0.5327\n",
      "Epoch 185/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0235 - accuracy: 0.4027 - val_loss: 0.9808 - val_accuracy: 0.5327\n",
      "Epoch 186/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0202 - accuracy: 0.4054 - val_loss: 0.9811 - val_accuracy: 0.5327\n",
      "Epoch 187/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0216 - accuracy: 0.4089 - val_loss: 0.9803 - val_accuracy: 0.5327\n",
      "Epoch 188/200\n",
      "2553/2553 [==============================] - 0s 121us/sample - loss: 1.0248 - accuracy: 0.4058 - val_loss: 0.9800 - val_accuracy: 0.5327\n",
      "Epoch 189/200\n",
      "2553/2553 [==============================] - 0s 119us/sample - loss: 1.0199 - accuracy: 0.4132 - val_loss: 0.9795 - val_accuracy: 0.5327\n",
      "Epoch 190/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 122us/sample - loss: 1.0260 - accuracy: 0.4027 - val_loss: 0.9804 - val_accuracy: 0.5327\n",
      "Epoch 191/200\n",
      "2553/2553 [==============================] - 0s 122us/sample - loss: 1.0157 - accuracy: 0.4172 - val_loss: 0.9790 - val_accuracy: 0.5327\n",
      "Epoch 192/200\n",
      "2553/2553 [==============================] - 0s 122us/sample - loss: 1.0210 - accuracy: 0.4085 - val_loss: 0.9796 - val_accuracy: 0.5327\n",
      "Epoch 193/200\n",
      "2553/2553 [==============================] - 0s 115us/sample - loss: 1.0183 - accuracy: 0.4105 - val_loss: 0.9793 - val_accuracy: 0.5327\n",
      "Epoch 194/200\n",
      "2553/2553 [==============================] - 0s 121us/sample - loss: 1.0251 - accuracy: 0.4050 - val_loss: 0.9796 - val_accuracy: 0.5327\n",
      "Epoch 195/200\n",
      "2553/2553 [==============================] - 0s 121us/sample - loss: 1.0205 - accuracy: 0.4062 - val_loss: 0.9796 - val_accuracy: 0.5327\n",
      "Epoch 196/200\n",
      "2553/2553 [==============================] - 0s 130us/sample - loss: 1.0277 - accuracy: 0.3976 - val_loss: 0.9804 - val_accuracy: 0.5327\n",
      "Epoch 197/200\n",
      "2553/2553 [==============================] - 0s 119us/sample - loss: 1.0220 - accuracy: 0.4101 - val_loss: 0.9793 - val_accuracy: 0.5327\n",
      "Epoch 198/200\n",
      "2553/2553 [==============================] - 0s 123us/sample - loss: 1.0284 - accuracy: 0.3980 - val_loss: 0.9798 - val_accuracy: 0.5327\n",
      "Epoch 199/200\n",
      "2553/2553 [==============================] - 0s 121us/sample - loss: 1.0096 - accuracy: 0.4207 - val_loss: 0.9784 - val_accuracy: 0.5327\n",
      "Epoch 200/200\n",
      "2553/2553 [==============================] - 0s 117us/sample - loss: 1.0317 - accuracy: 0.4062 - val_loss: 0.9787 - val_accuracy: 0.5327\n",
      "0.53271025 {'loss': 1.031739786961851, 'accuracy': 0.4061888, 'val_loss': 0.9787415722820246, 'val_accuracy': 0.53271025}\n",
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, 29)]              0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 41)                1230      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 75)                3150      \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 3)                 228       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 4,608\n",
      "Trainable params: 4,608\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2553 samples, validate on 107 samples\n",
      "Epoch 1/200\n",
      "2553/2553 [==============================] - 1s 306us/sample - loss: 1.4548 - accuracy: 0.2832 - val_loss: 1.3620 - val_accuracy: 0.2336\n",
      "Epoch 2/200\n",
      "2553/2553 [==============================] - 0s 65us/sample - loss: 1.4107 - accuracy: 0.2836 - val_loss: 1.3190 - val_accuracy: 0.2336\n",
      "Epoch 3/200\n",
      "2553/2553 [==============================] - 0s 66us/sample - loss: 1.3595 - accuracy: 0.2828 - val_loss: 1.2813 - val_accuracy: 0.2243\n",
      "Epoch 4/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.2867 - accuracy: 0.2840 - val_loss: 1.2490 - val_accuracy: 0.2336\n",
      "Epoch 5/200\n",
      "2553/2553 [==============================] - 0s 70us/sample - loss: 1.2706 - accuracy: 0.2828 - val_loss: 1.2221 - val_accuracy: 0.2336\n",
      "Epoch 6/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.2394 - accuracy: 0.2820 - val_loss: 1.1964 - val_accuracy: 0.2336\n",
      "Epoch 7/200\n",
      "2553/2553 [==============================] - 0s 65us/sample - loss: 1.2034 - accuracy: 0.2824 - val_loss: 1.1773 - val_accuracy: 0.2430\n",
      "Epoch 8/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.1753 - accuracy: 0.2840 - val_loss: 1.1630 - val_accuracy: 0.2336\n",
      "Epoch 9/200\n",
      "2553/2553 [==============================] - 0s 65us/sample - loss: 1.1653 - accuracy: 0.2816 - val_loss: 1.1502 - val_accuracy: 0.2336\n",
      "Epoch 10/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.1560 - accuracy: 0.2828 - val_loss: 1.1389 - val_accuracy: 0.2336\n",
      "Epoch 11/200\n",
      "2553/2553 [==============================] - 0s 65us/sample - loss: 1.1346 - accuracy: 0.2840 - val_loss: 1.1309 - val_accuracy: 0.2243\n",
      "Epoch 12/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.1332 - accuracy: 0.2820 - val_loss: 1.1232 - val_accuracy: 0.2243\n",
      "Epoch 13/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.1158 - accuracy: 0.2828 - val_loss: 1.1184 - val_accuracy: 0.2243\n",
      "Epoch 14/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.1170 - accuracy: 0.2828 - val_loss: 1.1142 - val_accuracy: 0.2243\n",
      "Epoch 15/200\n",
      "2553/2553 [==============================] - 0s 66us/sample - loss: 1.1125 - accuracy: 0.2805 - val_loss: 1.1112 - val_accuracy: 0.2243\n",
      "Epoch 16/200\n",
      "2553/2553 [==============================] - 0s 70us/sample - loss: 1.1108 - accuracy: 0.2812 - val_loss: 1.1086 - val_accuracy: 0.2243\n",
      "Epoch 17/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.1094 - accuracy: 0.2836 - val_loss: 1.1062 - val_accuracy: 0.2243\n",
      "Epoch 18/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.1085 - accuracy: 0.2812 - val_loss: 1.1044 - val_accuracy: 0.2243\n",
      "Epoch 19/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.1016 - accuracy: 0.2836 - val_loss: 1.1032 - val_accuracy: 0.2243\n",
      "Epoch 20/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.1047 - accuracy: 0.2808 - val_loss: 1.1019 - val_accuracy: 0.2243\n",
      "Epoch 21/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.1005 - accuracy: 0.2840 - val_loss: 1.1012 - val_accuracy: 0.2243\n",
      "Epoch 22/200\n",
      "2553/2553 [==============================] - 0s 66us/sample - loss: 1.0996 - accuracy: 0.2820 - val_loss: 1.1004 - val_accuracy: 0.2243\n",
      "Epoch 23/200\n",
      "2553/2553 [==============================] - 0s 65us/sample - loss: 1.1067 - accuracy: 0.2836 - val_loss: 1.0996 - val_accuracy: 0.2243\n",
      "Epoch 24/200\n",
      "2553/2553 [==============================] - 0s 66us/sample - loss: 1.0978 - accuracy: 0.2812 - val_loss: 1.0991 - val_accuracy: 0.2243\n",
      "Epoch 25/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0992 - accuracy: 0.2828 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 26/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.0978 - accuracy: 0.2824 - val_loss: 1.0982 - val_accuracy: 0.2243\n",
      "Epoch 27/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.0967 - accuracy: 0.2828 - val_loss: 1.0976 - val_accuracy: 0.2336\n",
      "Epoch 28/200\n",
      "2553/2553 [==============================] - 0s 72us/sample - loss: 1.1014 - accuracy: 0.2812 - val_loss: 1.0970 - val_accuracy: 0.2336\n",
      "Epoch 29/200\n",
      "2553/2553 [==============================] - 0s 67us/sample - loss: 1.0975 - accuracy: 0.2852 - val_loss: 1.0967 - val_accuracy: 0.2336\n",
      "Epoch 30/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.0958 - accuracy: 0.2824 - val_loss: 1.0964 - val_accuracy: 0.2336\n",
      "Epoch 31/200\n",
      "2553/2553 [==============================] - 0s 66us/sample - loss: 1.0953 - accuracy: 0.2812 - val_loss: 1.0962 - val_accuracy: 0.2336\n",
      "Epoch 32/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0964 - accuracy: 0.2840 - val_loss: 1.0958 - val_accuracy: 0.2336\n",
      "Epoch 33/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0977 - accuracy: 0.2840 - val_loss: 1.0954 - val_accuracy: 0.2336\n",
      "Epoch 34/200\n",
      "2553/2553 [==============================] - 0s 66us/sample - loss: 1.0957 - accuracy: 0.2832 - val_loss: 1.0951 - val_accuracy: 0.2336\n",
      "Epoch 35/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 66us/sample - loss: 1.0970 - accuracy: 0.2832 - val_loss: 1.0949 - val_accuracy: 0.2336\n",
      "Epoch 36/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.0938 - accuracy: 0.2859 - val_loss: 1.0946 - val_accuracy: 0.2336\n",
      "Epoch 37/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.0946 - accuracy: 0.2828 - val_loss: 1.0945 - val_accuracy: 0.2336\n",
      "Epoch 38/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0951 - accuracy: 0.2836 - val_loss: 1.0942 - val_accuracy: 0.2336\n",
      "Epoch 39/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0943 - accuracy: 0.2836 - val_loss: 1.0941 - val_accuracy: 0.2336\n",
      "Epoch 40/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0936 - accuracy: 0.2832 - val_loss: 1.0939 - val_accuracy: 0.2336\n",
      "Epoch 41/200\n",
      "2553/2553 [==============================] - 0s 76us/sample - loss: 1.0944 - accuracy: 0.2852 - val_loss: 1.0936 - val_accuracy: 0.2336\n",
      "Epoch 42/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0918 - accuracy: 0.2836 - val_loss: 1.0933 - val_accuracy: 0.2336\n",
      "Epoch 43/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0946 - accuracy: 0.2824 - val_loss: 1.0931 - val_accuracy: 0.2336\n",
      "Epoch 44/200\n",
      "2553/2553 [==============================] - 0s 66us/sample - loss: 1.0956 - accuracy: 0.2832 - val_loss: 1.0929 - val_accuracy: 0.2336\n",
      "Epoch 45/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0927 - accuracy: 0.2852 - val_loss: 1.0926 - val_accuracy: 0.2336\n",
      "Epoch 46/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0935 - accuracy: 0.2855 - val_loss: 1.0924 - val_accuracy: 0.2336\n",
      "Epoch 47/200\n",
      "2553/2553 [==============================] - 0s 70us/sample - loss: 1.0953 - accuracy: 0.2848 - val_loss: 1.0922 - val_accuracy: 0.2336\n",
      "Epoch 48/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.0911 - accuracy: 0.2859 - val_loss: 1.0919 - val_accuracy: 0.2336\n",
      "Epoch 49/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0911 - accuracy: 0.2844 - val_loss: 1.0916 - val_accuracy: 0.2336\n",
      "Epoch 50/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0904 - accuracy: 0.2840 - val_loss: 1.0914 - val_accuracy: 0.2336\n",
      "Epoch 51/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0919 - accuracy: 0.2848 - val_loss: 1.0911 - val_accuracy: 0.2336\n",
      "Epoch 52/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0923 - accuracy: 0.2844 - val_loss: 1.0909 - val_accuracy: 0.2336\n",
      "Epoch 53/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0907 - accuracy: 0.2871 - val_loss: 1.0906 - val_accuracy: 0.2336\n",
      "Epoch 54/200\n",
      "2553/2553 [==============================] - 0s 72us/sample - loss: 1.0923 - accuracy: 0.2844 - val_loss: 1.0903 - val_accuracy: 0.2243\n",
      "Epoch 55/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0936 - accuracy: 0.2836 - val_loss: 1.0900 - val_accuracy: 0.2243\n",
      "Epoch 56/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.0912 - accuracy: 0.2844 - val_loss: 1.0897 - val_accuracy: 0.2243\n",
      "Epoch 57/200\n",
      "2553/2553 [==============================] - 0s 65us/sample - loss: 1.0888 - accuracy: 0.2840 - val_loss: 1.0895 - val_accuracy: 0.2336\n",
      "Epoch 58/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.0894 - accuracy: 0.2808 - val_loss: 1.0893 - val_accuracy: 0.2336\n",
      "Epoch 59/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0887 - accuracy: 0.2844 - val_loss: 1.0890 - val_accuracy: 0.2336\n",
      "Epoch 60/200\n",
      "2553/2553 [==============================] - 0s 70us/sample - loss: 1.0916 - accuracy: 0.2801 - val_loss: 1.0887 - val_accuracy: 0.2243\n",
      "Epoch 61/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0903 - accuracy: 0.2859 - val_loss: 1.0884 - val_accuracy: 0.2243\n",
      "Epoch 62/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.0949 - accuracy: 0.2855 - val_loss: 1.0880 - val_accuracy: 0.2243\n",
      "Epoch 63/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.0852 - accuracy: 0.2848 - val_loss: 1.0877 - val_accuracy: 0.2243\n",
      "Epoch 64/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0856 - accuracy: 0.2871 - val_loss: 1.0875 - val_accuracy: 0.2243\n",
      "Epoch 65/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.0903 - accuracy: 0.2844 - val_loss: 1.0873 - val_accuracy: 0.2243\n",
      "Epoch 66/200\n",
      "2553/2553 [==============================] - 0s 68us/sample - loss: 1.0876 - accuracy: 0.2848 - val_loss: 1.0872 - val_accuracy: 0.2243\n",
      "Epoch 67/200\n",
      "2553/2553 [==============================] - 0s 69us/sample - loss: 1.0895 - accuracy: 0.2855 - val_loss: 1.0869 - val_accuracy: 0.2336\n",
      "Epoch 68/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.0906 - accuracy: 0.2879 - val_loss: 1.0867 - val_accuracy: 0.2336\n",
      "Epoch 69/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.0881 - accuracy: 0.2895 - val_loss: 1.0867 - val_accuracy: 0.2336\n",
      "Epoch 70/200\n",
      "2553/2553 [==============================] - 0s 67us/sample - loss: 1.0884 - accuracy: 0.2899 - val_loss: 1.0864 - val_accuracy: 0.2430\n",
      "Epoch 71/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.0927 - accuracy: 0.2828 - val_loss: 1.0863 - val_accuracy: 0.2430\n",
      "Epoch 72/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.0863 - accuracy: 0.2891 - val_loss: 1.0860 - val_accuracy: 0.2523\n",
      "Epoch 73/200\n",
      "2553/2553 [==============================] - 0s 65us/sample - loss: 1.0872 - accuracy: 0.2867 - val_loss: 1.0858 - val_accuracy: 0.2523\n",
      "Epoch 74/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0893 - accuracy: 0.2902 - val_loss: 1.0856 - val_accuracy: 0.2523\n",
      "Epoch 75/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.0859 - accuracy: 0.2879 - val_loss: 1.0853 - val_accuracy: 0.2523\n",
      "Epoch 76/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.0856 - accuracy: 0.2953 - val_loss: 1.0850 - val_accuracy: 0.2523\n",
      "Epoch 77/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.0862 - accuracy: 0.2926 - val_loss: 1.0848 - val_accuracy: 0.2336\n",
      "Epoch 78/200\n",
      "2553/2553 [==============================] - 0s 70us/sample - loss: 1.0864 - accuracy: 0.2942 - val_loss: 1.0845 - val_accuracy: 0.2336\n",
      "Epoch 79/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0864 - accuracy: 0.2934 - val_loss: 1.0843 - val_accuracy: 0.2523\n",
      "Epoch 80/200\n",
      "2553/2553 [==============================] - 0s 68us/sample - loss: 1.0869 - accuracy: 0.3008 - val_loss: 1.0840 - val_accuracy: 0.2523\n",
      "Epoch 81/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.0871 - accuracy: 0.3032 - val_loss: 1.0830 - val_accuracy: 0.2710\n",
      "Epoch 82/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0836 - accuracy: 0.3040 - val_loss: 1.0804 - val_accuracy: 0.3364\n",
      "Epoch 83/200\n",
      "2553/2553 [==============================] - 0s 68us/sample - loss: 1.0831 - accuracy: 0.3196 - val_loss: 1.0722 - val_accuracy: 0.3832\n",
      "Epoch 84/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.0767 - accuracy: 0.3463 - val_loss: 1.0545 - val_accuracy: 0.4486\n",
      "Epoch 85/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.0627 - accuracy: 0.3956 - val_loss: 1.0338 - val_accuracy: 0.4579\n",
      "Epoch 86/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0376 - accuracy: 0.4089 - val_loss: 1.0204 - val_accuracy: 0.4766\n",
      "Epoch 87/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0396 - accuracy: 0.4015 - val_loss: 1.0148 - val_accuracy: 0.4860\n",
      "Epoch 88/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0438 - accuracy: 0.3913 - val_loss: 1.0115 - val_accuracy: 0.4860\n",
      "Epoch 89/200\n",
      "2553/2553 [==============================] - 0s 65us/sample - loss: 1.0322 - accuracy: 0.4101 - val_loss: 1.0086 - val_accuracy: 0.4860\n",
      "Epoch 90/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 66us/sample - loss: 1.0409 - accuracy: 0.4078 - val_loss: 1.0070 - val_accuracy: 0.4953\n",
      "Epoch 91/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0391 - accuracy: 0.4015 - val_loss: 1.0064 - val_accuracy: 0.5047\n",
      "Epoch 92/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.0410 - accuracy: 0.4062 - val_loss: 1.0055 - val_accuracy: 0.5047\n",
      "Epoch 93/200\n",
      "2553/2553 [==============================] - 0s 66us/sample - loss: 1.0376 - accuracy: 0.4027 - val_loss: 1.0039 - val_accuracy: 0.5047\n",
      "Epoch 94/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.0414 - accuracy: 0.4038 - val_loss: 1.0039 - val_accuracy: 0.5047\n",
      "Epoch 95/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0300 - accuracy: 0.4085 - val_loss: 1.0022 - val_accuracy: 0.5047\n",
      "Epoch 96/200\n",
      "2553/2553 [==============================] - 0s 67us/sample - loss: 1.0348 - accuracy: 0.4050 - val_loss: 1.0014 - val_accuracy: 0.5140\n",
      "Epoch 97/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0409 - accuracy: 0.3980 - val_loss: 1.0011 - val_accuracy: 0.5047\n",
      "Epoch 98/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.0376 - accuracy: 0.3984 - val_loss: 1.0008 - val_accuracy: 0.5140\n",
      "Epoch 99/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0302 - accuracy: 0.4144 - val_loss: 1.0005 - val_accuracy: 0.5140\n",
      "Epoch 100/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.0429 - accuracy: 0.4019 - val_loss: 1.0009 - val_accuracy: 0.5047\n",
      "Epoch 101/200\n",
      "2553/2553 [==============================] - 0s 66us/sample - loss: 1.0325 - accuracy: 0.4070 - val_loss: 0.9999 - val_accuracy: 0.5140\n",
      "Epoch 102/200\n",
      "2553/2553 [==============================] - 0s 70us/sample - loss: 1.0432 - accuracy: 0.4038 - val_loss: 1.0002 - val_accuracy: 0.5047\n",
      "Epoch 103/200\n",
      "2553/2553 [==============================] - 0s 65us/sample - loss: 1.0339 - accuracy: 0.4023 - val_loss: 0.9998 - val_accuracy: 0.5047\n",
      "Epoch 104/200\n",
      "2553/2553 [==============================] - 0s 66us/sample - loss: 1.0396 - accuracy: 0.3976 - val_loss: 0.9998 - val_accuracy: 0.5047\n",
      "Epoch 105/200\n",
      "2553/2553 [==============================] - 0s 69us/sample - loss: 1.0409 - accuracy: 0.4070 - val_loss: 0.9992 - val_accuracy: 0.5047\n",
      "Epoch 106/200\n",
      "2553/2553 [==============================] - 0s 65us/sample - loss: 1.0376 - accuracy: 0.4003 - val_loss: 0.9993 - val_accuracy: 0.5047\n",
      "Epoch 107/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.0309 - accuracy: 0.4121 - val_loss: 0.9987 - val_accuracy: 0.5140\n",
      "Epoch 108/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.0331 - accuracy: 0.4078 - val_loss: 0.9979 - val_accuracy: 0.5047\n",
      "Epoch 109/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0306 - accuracy: 0.4097 - val_loss: 0.9977 - val_accuracy: 0.4953\n",
      "Epoch 110/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0344 - accuracy: 0.4046 - val_loss: 0.9976 - val_accuracy: 0.5140\n",
      "Epoch 111/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0221 - accuracy: 0.4230 - val_loss: 0.9966 - val_accuracy: 0.5140\n",
      "Epoch 112/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0409 - accuracy: 0.3995 - val_loss: 0.9970 - val_accuracy: 0.5140\n",
      "Epoch 113/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.0303 - accuracy: 0.4023 - val_loss: 0.9966 - val_accuracy: 0.5140\n",
      "Epoch 114/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0272 - accuracy: 0.4078 - val_loss: 0.9965 - val_accuracy: 0.5140\n",
      "Epoch 115/200\n",
      "2553/2553 [==============================] - 0s 65us/sample - loss: 1.0334 - accuracy: 0.4109 - val_loss: 0.9963 - val_accuracy: 0.5140\n",
      "Epoch 116/200\n",
      "2553/2553 [==============================] - 0s 66us/sample - loss: 1.0348 - accuracy: 0.3964 - val_loss: 0.9960 - val_accuracy: 0.5140\n",
      "Epoch 117/200\n",
      "2553/2553 [==============================] - 0s 68us/sample - loss: 1.0198 - accuracy: 0.4175 - val_loss: 0.9946 - val_accuracy: 0.5140\n",
      "Epoch 118/200\n",
      "2553/2553 [==============================] - 0s 69us/sample - loss: 1.0331 - accuracy: 0.4136 - val_loss: 0.9948 - val_accuracy: 0.5140\n",
      "Epoch 119/200\n",
      "2553/2553 [==============================] - 0s 65us/sample - loss: 1.0353 - accuracy: 0.3987 - val_loss: 0.9957 - val_accuracy: 0.5140\n",
      "Epoch 120/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.0295 - accuracy: 0.4085 - val_loss: 0.9959 - val_accuracy: 0.5140\n",
      "Epoch 121/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0400 - accuracy: 0.3999 - val_loss: 0.9965 - val_accuracy: 0.5140\n",
      "Epoch 122/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.0234 - accuracy: 0.4160 - val_loss: 0.9955 - val_accuracy: 0.5140\n",
      "Epoch 123/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0384 - accuracy: 0.3980 - val_loss: 0.9964 - val_accuracy: 0.5140\n",
      "Epoch 124/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0275 - accuracy: 0.4144 - val_loss: 0.9958 - val_accuracy: 0.5140\n",
      "Epoch 125/200\n",
      "2553/2553 [==============================] - 0s 66us/sample - loss: 1.0268 - accuracy: 0.4081 - val_loss: 0.9944 - val_accuracy: 0.5140\n",
      "Epoch 126/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0241 - accuracy: 0.4070 - val_loss: 0.9930 - val_accuracy: 0.5140\n",
      "Epoch 127/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0355 - accuracy: 0.4023 - val_loss: 0.9934 - val_accuracy: 0.5140\n",
      "Epoch 128/200\n",
      "2553/2553 [==============================] - 0s 68us/sample - loss: 1.0371 - accuracy: 0.3925 - val_loss: 0.9945 - val_accuracy: 0.5140\n",
      "Epoch 129/200\n",
      "2553/2553 [==============================] - 0s 67us/sample - loss: 1.0252 - accuracy: 0.4195 - val_loss: 0.9936 - val_accuracy: 0.5140\n",
      "Epoch 130/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0226 - accuracy: 0.4097 - val_loss: 0.9930 - val_accuracy: 0.5140\n",
      "Epoch 131/200\n",
      "2553/2553 [==============================] - 0s 65us/sample - loss: 1.0318 - accuracy: 0.4101 - val_loss: 0.9922 - val_accuracy: 0.5140\n",
      "Epoch 132/200\n",
      "2553/2553 [==============================] - 0s 69us/sample - loss: 1.0245 - accuracy: 0.4152 - val_loss: 0.9917 - val_accuracy: 0.5140\n",
      "Epoch 133/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.0344 - accuracy: 0.4117 - val_loss: 0.9928 - val_accuracy: 0.5140\n",
      "Epoch 134/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0397 - accuracy: 0.4019 - val_loss: 0.9939 - val_accuracy: 0.5140\n",
      "Epoch 135/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0355 - accuracy: 0.4003 - val_loss: 0.9936 - val_accuracy: 0.5140\n",
      "Epoch 136/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.0283 - accuracy: 0.4038 - val_loss: 0.9933 - val_accuracy: 0.5140\n",
      "Epoch 137/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0313 - accuracy: 0.4226 - val_loss: 0.9931 - val_accuracy: 0.5140\n",
      "Epoch 138/200\n",
      "2553/2553 [==============================] - 0s 70us/sample - loss: 1.0361 - accuracy: 0.4074 - val_loss: 0.9936 - val_accuracy: 0.5140\n",
      "Epoch 139/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0359 - accuracy: 0.4081 - val_loss: 0.9937 - val_accuracy: 0.5140\n",
      "Epoch 140/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.0251 - accuracy: 0.4191 - val_loss: 0.9934 - val_accuracy: 0.5234\n",
      "Epoch 141/200\n",
      "2553/2553 [==============================] - 0s 72us/sample - loss: 1.0210 - accuracy: 0.4219 - val_loss: 0.9924 - val_accuracy: 0.5140\n",
      "Epoch 142/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0314 - accuracy: 0.3987 - val_loss: 0.9926 - val_accuracy: 0.5140\n",
      "Epoch 143/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.0287 - accuracy: 0.4085 - val_loss: 0.9929 - val_accuracy: 0.5140\n",
      "Epoch 144/200\n",
      "2553/2553 [==============================] - 0s 65us/sample - loss: 1.0377 - accuracy: 0.4054 - val_loss: 0.9936 - val_accuracy: 0.5234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.0281 - accuracy: 0.4179 - val_loss: 0.9931 - val_accuracy: 0.5140\n",
      "Epoch 146/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0217 - accuracy: 0.4136 - val_loss: 0.9917 - val_accuracy: 0.5234\n",
      "Epoch 147/200\n",
      "2553/2553 [==============================] - 0s 68us/sample - loss: 1.0353 - accuracy: 0.3972 - val_loss: 0.9926 - val_accuracy: 0.5140\n",
      "Epoch 148/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.0329 - accuracy: 0.4027 - val_loss: 0.9933 - val_accuracy: 0.5140\n",
      "Epoch 149/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.0332 - accuracy: 0.4011 - val_loss: 0.9933 - val_accuracy: 0.5234\n",
      "Epoch 150/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.0269 - accuracy: 0.4140 - val_loss: 0.9929 - val_accuracy: 0.5234\n",
      "Epoch 151/200\n",
      "2553/2553 [==============================] - 0s 69us/sample - loss: 1.0320 - accuracy: 0.4093 - val_loss: 0.9936 - val_accuracy: 0.5140\n",
      "Epoch 152/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0289 - accuracy: 0.4062 - val_loss: 0.9927 - val_accuracy: 0.5140\n",
      "Epoch 153/200\n",
      "2553/2553 [==============================] - 0s 66us/sample - loss: 1.0181 - accuracy: 0.4301 - val_loss: 0.9919 - val_accuracy: 0.5234\n",
      "Epoch 154/200\n",
      "2553/2553 [==============================] - 0s 65us/sample - loss: 1.0290 - accuracy: 0.4062 - val_loss: 0.9914 - val_accuracy: 0.5234\n",
      "Epoch 155/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0239 - accuracy: 0.4144 - val_loss: 0.9911 - val_accuracy: 0.5234\n",
      "Epoch 156/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0347 - accuracy: 0.4128 - val_loss: 0.9924 - val_accuracy: 0.5234\n",
      "Epoch 157/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.0262 - accuracy: 0.4078 - val_loss: 0.9914 - val_accuracy: 0.5140\n",
      "Epoch 158/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.0256 - accuracy: 0.4105 - val_loss: 0.9912 - val_accuracy: 0.5234\n",
      "Epoch 159/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0261 - accuracy: 0.4128 - val_loss: 0.9905 - val_accuracy: 0.5140\n",
      "Epoch 160/200\n",
      "2553/2553 [==============================] - 0s 66us/sample - loss: 1.0265 - accuracy: 0.4113 - val_loss: 0.9904 - val_accuracy: 0.5140\n",
      "Epoch 161/200\n",
      "2553/2553 [==============================] - 0s 65us/sample - loss: 1.0343 - accuracy: 0.3987 - val_loss: 0.9916 - val_accuracy: 0.5140\n",
      "Epoch 162/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.0289 - accuracy: 0.4105 - val_loss: 0.9913 - val_accuracy: 0.5234\n",
      "Epoch 163/200\n",
      "2553/2553 [==============================] - 0s 65us/sample - loss: 1.0216 - accuracy: 0.4125 - val_loss: 0.9910 - val_accuracy: 0.5234\n",
      "Epoch 164/200\n",
      "2553/2553 [==============================] - 0s 65us/sample - loss: 1.0255 - accuracy: 0.4097 - val_loss: 0.9913 - val_accuracy: 0.5140\n",
      "Epoch 165/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0227 - accuracy: 0.4078 - val_loss: 0.9909 - val_accuracy: 0.5140\n",
      "Epoch 166/200\n",
      "2553/2553 [==============================] - 0s 66us/sample - loss: 1.0278 - accuracy: 0.4152 - val_loss: 0.9902 - val_accuracy: 0.5140\n",
      "Epoch 167/200\n",
      "2553/2553 [==============================] - 0s 68us/sample - loss: 1.0319 - accuracy: 0.4058 - val_loss: 0.9907 - val_accuracy: 0.5140\n",
      "Epoch 168/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0321 - accuracy: 0.4062 - val_loss: 0.9914 - val_accuracy: 0.5140\n",
      "Epoch 169/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.0308 - accuracy: 0.3968 - val_loss: 0.9915 - val_accuracy: 0.5140\n",
      "Epoch 170/200\n",
      "2553/2553 [==============================] - 0s 66us/sample - loss: 1.0271 - accuracy: 0.4168 - val_loss: 0.9908 - val_accuracy: 0.5140\n",
      "Epoch 171/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0330 - accuracy: 0.3960 - val_loss: 0.9909 - val_accuracy: 0.5140\n",
      "Epoch 172/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0254 - accuracy: 0.4140 - val_loss: 0.9903 - val_accuracy: 0.5140\n",
      "Epoch 173/200\n",
      "2553/2553 [==============================] - 0s 69us/sample - loss: 1.0158 - accuracy: 0.4230 - val_loss: 0.9889 - val_accuracy: 0.5140\n",
      "Epoch 174/200\n",
      "2553/2553 [==============================] - 0s 65us/sample - loss: 1.0294 - accuracy: 0.3995 - val_loss: 0.9893 - val_accuracy: 0.5140\n",
      "Epoch 175/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0267 - accuracy: 0.4078 - val_loss: 0.9897 - val_accuracy: 0.5140\n",
      "Epoch 176/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.0200 - accuracy: 0.4148 - val_loss: 0.9892 - val_accuracy: 0.5140\n",
      "Epoch 177/200\n",
      "2553/2553 [==============================] - 0s 68us/sample - loss: 1.0144 - accuracy: 0.4234 - val_loss: 0.9881 - val_accuracy: 0.5140\n",
      "Epoch 178/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0162 - accuracy: 0.4164 - val_loss: 0.9874 - val_accuracy: 0.5140\n",
      "Epoch 179/200\n",
      "2553/2553 [==============================] - 0s 67us/sample - loss: 1.0328 - accuracy: 0.4038 - val_loss: 0.9884 - val_accuracy: 0.5140\n",
      "Epoch 180/200\n",
      "2553/2553 [==============================] - 0s 67us/sample - loss: 1.0276 - accuracy: 0.4050 - val_loss: 0.9898 - val_accuracy: 0.5140\n",
      "Epoch 181/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0290 - accuracy: 0.4011 - val_loss: 0.9904 - val_accuracy: 0.5140\n",
      "Epoch 182/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.0265 - accuracy: 0.4066 - val_loss: 0.9901 - val_accuracy: 0.5140\n",
      "Epoch 183/200\n",
      "2553/2553 [==============================] - 0s 68us/sample - loss: 1.0285 - accuracy: 0.4066 - val_loss: 0.9897 - val_accuracy: 0.5140\n",
      "Epoch 184/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.0194 - accuracy: 0.4160 - val_loss: 0.9887 - val_accuracy: 0.5140\n",
      "Epoch 185/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.0190 - accuracy: 0.4121 - val_loss: 0.9880 - val_accuracy: 0.5140\n",
      "Epoch 186/200\n",
      "2553/2553 [==============================] - 0s 72us/sample - loss: 1.0286 - accuracy: 0.4054 - val_loss: 0.9888 - val_accuracy: 0.5140\n",
      "Epoch 187/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.0255 - accuracy: 0.4074 - val_loss: 0.9892 - val_accuracy: 0.5140\n",
      "Epoch 188/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.0331 - accuracy: 0.4011 - val_loss: 0.9902 - val_accuracy: 0.5140\n",
      "Epoch 189/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.0238 - accuracy: 0.4031 - val_loss: 0.9891 - val_accuracy: 0.5140\n",
      "Epoch 190/200\n",
      "2553/2553 [==============================] - 0s 65us/sample - loss: 1.0217 - accuracy: 0.4172 - val_loss: 0.9890 - val_accuracy: 0.5140\n",
      "Epoch 191/200\n",
      "2553/2553 [==============================] - 0s 68us/sample - loss: 1.0206 - accuracy: 0.4195 - val_loss: 0.9885 - val_accuracy: 0.5140\n",
      "Epoch 192/200\n",
      "2553/2553 [==============================] - 0s 70us/sample - loss: 1.0155 - accuracy: 0.4125 - val_loss: 0.9876 - val_accuracy: 0.5140\n",
      "Epoch 193/200\n",
      "2553/2553 [==============================] - 0s 65us/sample - loss: 1.0254 - accuracy: 0.4074 - val_loss: 0.9874 - val_accuracy: 0.5140\n",
      "Epoch 194/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0262 - accuracy: 0.4109 - val_loss: 0.9876 - val_accuracy: 0.5140\n",
      "Epoch 195/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.0243 - accuracy: 0.4136 - val_loss: 0.9883 - val_accuracy: 0.5140\n",
      "Epoch 196/200\n",
      "2553/2553 [==============================] - 0s 69us/sample - loss: 1.0268 - accuracy: 0.4074 - val_loss: 0.9885 - val_accuracy: 0.5140\n",
      "Epoch 197/200\n",
      "2553/2553 [==============================] - 0s 67us/sample - loss: 1.0140 - accuracy: 0.4234 - val_loss: 0.9874 - val_accuracy: 0.5234\n",
      "Epoch 198/200\n",
      "2553/2553 [==============================] - 0s 84us/sample - loss: 1.0250 - accuracy: 0.3972 - val_loss: 0.9887 - val_accuracy: 0.5140\n",
      "Epoch 199/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 72us/sample - loss: 1.0172 - accuracy: 0.4140 - val_loss: 0.9885 - val_accuracy: 0.5140\n",
      "Epoch 200/200\n",
      "2553/2553 [==============================] - 0s 65us/sample - loss: 1.0222 - accuracy: 0.4042 - val_loss: 0.9885 - val_accuracy: 0.5140\n",
      "0.5140187 {'loss': 1.0221766046202048, 'accuracy': 0.40423033, 'val_loss': 0.988469571710747, 'val_accuracy': 0.5140187}\n",
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         [(None, 29)]              0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 41)                1230      \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 75)                3150      \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 3)                 228       \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 4,608\n",
      "Trainable params: 4,608\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2553 samples, validate on 107 samples\n",
      "Epoch 1/200\n",
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "2553/2553 [==============================] - 1s 363us/sample - loss: 1.1427 - accuracy: 0.3169 - val_loss: 1.0621 - val_accuracy: 0.3551\n",
      "Epoch 2/200\n",
      "2553/2553 [==============================] - 0s 123us/sample - loss: 1.1232 - accuracy: 0.3161 - val_loss: 1.0556 - val_accuracy: 0.3551\n",
      "Epoch 3/200\n",
      "2553/2553 [==============================] - 0s 127us/sample - loss: 1.1002 - accuracy: 0.3177 - val_loss: 1.0517 - val_accuracy: 0.3645\n",
      "Epoch 4/200\n",
      "2553/2553 [==============================] - 0s 115us/sample - loss: 1.1078 - accuracy: 0.3130 - val_loss: 1.0529 - val_accuracy: 0.3645\n",
      "Epoch 5/200\n",
      "2553/2553 [==============================] - 0s 115us/sample - loss: 1.0977 - accuracy: 0.3094 - val_loss: 1.0522 - val_accuracy: 0.3738\n",
      "Epoch 6/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.0916 - accuracy: 0.3192 - val_loss: 1.0506 - val_accuracy: 0.3738\n",
      "Epoch 7/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.0948 - accuracy: 0.3204 - val_loss: 1.0491 - val_accuracy: 0.3832\n",
      "Epoch 8/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0891 - accuracy: 0.3216 - val_loss: 1.0478 - val_accuracy: 0.3832\n",
      "Epoch 9/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.0868 - accuracy: 0.3298 - val_loss: 1.0473 - val_accuracy: 0.3832\n",
      "Epoch 10/200\n",
      "2553/2553 [==============================] - 0s 128us/sample - loss: 1.0867 - accuracy: 0.3302 - val_loss: 1.0453 - val_accuracy: 0.3832\n",
      "Epoch 11/200\n",
      "2553/2553 [==============================] - 0s 174us/sample - loss: 1.0872 - accuracy: 0.3235 - val_loss: 1.0437 - val_accuracy: 0.3925\n",
      "Epoch 12/200\n",
      "2553/2553 [==============================] - 0s 182us/sample - loss: 1.0907 - accuracy: 0.3231 - val_loss: 1.0438 - val_accuracy: 0.3925\n",
      "Epoch 13/200\n",
      "2553/2553 [==============================] - 0s 143us/sample - loss: 1.0805 - accuracy: 0.3278 - val_loss: 1.0422 - val_accuracy: 0.3925\n",
      "Epoch 14/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0875 - accuracy: 0.3263 - val_loss: 1.0412 - val_accuracy: 0.3925\n",
      "Epoch 15/200\n",
      "2553/2553 [==============================] - 0s 117us/sample - loss: 1.0863 - accuracy: 0.3231 - val_loss: 1.0411 - val_accuracy: 0.3925\n",
      "Epoch 16/200\n",
      "2553/2553 [==============================] - 0s 119us/sample - loss: 1.0774 - accuracy: 0.3298 - val_loss: 1.0398 - val_accuracy: 0.3925\n",
      "Epoch 17/200\n",
      "2553/2553 [==============================] - 0s 120us/sample - loss: 1.0769 - accuracy: 0.3369 - val_loss: 1.0374 - val_accuracy: 0.3925\n",
      "Epoch 18/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0747 - accuracy: 0.3310 - val_loss: 1.0366 - val_accuracy: 0.3925\n",
      "Epoch 19/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0934 - accuracy: 0.3278 - val_loss: 1.0381 - val_accuracy: 0.3925\n",
      "Epoch 20/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 1.0886 - accuracy: 0.3212 - val_loss: 1.0393 - val_accuracy: 0.3925\n",
      "Epoch 21/200\n",
      "2553/2553 [==============================] - 0s 115us/sample - loss: 1.0776 - accuracy: 0.3310 - val_loss: 1.0387 - val_accuracy: 0.3925\n",
      "Epoch 22/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.0832 - accuracy: 0.3255 - val_loss: 1.0388 - val_accuracy: 0.3925\n",
      "Epoch 23/200\n",
      "2553/2553 [==============================] - 0s 117us/sample - loss: 1.0814 - accuracy: 0.3263 - val_loss: 1.0380 - val_accuracy: 0.3925\n",
      "Epoch 24/200\n",
      "2553/2553 [==============================] - 0s 123us/sample - loss: 1.0796 - accuracy: 0.3314 - val_loss: 1.0390 - val_accuracy: 0.3925\n",
      "Epoch 25/200\n",
      "2553/2553 [==============================] - 0s 126us/sample - loss: 1.0755 - accuracy: 0.3310 - val_loss: 1.0379 - val_accuracy: 0.3925\n",
      "Epoch 26/200\n",
      "2553/2553 [==============================] - 0s 123us/sample - loss: 1.0795 - accuracy: 0.3251 - val_loss: 1.0378 - val_accuracy: 0.3925\n",
      "Epoch 27/200\n",
      "2553/2553 [==============================] - 0s 120us/sample - loss: 1.0729 - accuracy: 0.3318 - val_loss: 1.0377 - val_accuracy: 0.3925\n",
      "Epoch 28/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.0762 - accuracy: 0.3306 - val_loss: 1.0377 - val_accuracy: 0.3925\n",
      "Epoch 29/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.0723 - accuracy: 0.3408 - val_loss: 1.0363 - val_accuracy: 0.3925\n",
      "Epoch 30/200\n",
      "2553/2553 [==============================] - 0s 118us/sample - loss: 1.0787 - accuracy: 0.3318 - val_loss: 1.0372 - val_accuracy: 0.3925\n",
      "Epoch 31/200\n",
      "2553/2553 [==============================] - 0s 122us/sample - loss: 1.0797 - accuracy: 0.3290 - val_loss: 1.0376 - val_accuracy: 0.3925\n",
      "Epoch 32/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 1.0856 - accuracy: 0.3255 - val_loss: 1.0382 - val_accuracy: 0.3925\n",
      "Epoch 33/200\n",
      "2553/2553 [==============================] - 0s 120us/sample - loss: 1.0887 - accuracy: 0.3255 - val_loss: 1.0392 - val_accuracy: 0.3925\n",
      "Epoch 34/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 1.0786 - accuracy: 0.3318 - val_loss: 1.0386 - val_accuracy: 0.3925\n",
      "Epoch 35/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0784 - accuracy: 0.3302 - val_loss: 1.0388 - val_accuracy: 0.4019\n",
      "Epoch 36/200\n",
      "2553/2553 [==============================] - 0s 118us/sample - loss: 1.0702 - accuracy: 0.3467 - val_loss: 1.0373 - val_accuracy: 0.4019\n",
      "Epoch 37/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.0722 - accuracy: 0.3357 - val_loss: 1.0359 - val_accuracy: 0.4019\n",
      "Epoch 38/200\n",
      "2553/2553 [==============================] - 0s 119us/sample - loss: 1.0809 - accuracy: 0.3263 - val_loss: 1.0364 - val_accuracy: 0.4019\n",
      "Epoch 39/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0823 - accuracy: 0.3282 - val_loss: 1.0370 - val_accuracy: 0.4019\n",
      "Epoch 40/200\n",
      "2553/2553 [==============================] - 0s 122us/sample - loss: 1.0732 - accuracy: 0.3345 - val_loss: 1.0364 - val_accuracy: 0.4019\n",
      "Epoch 41/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0676 - accuracy: 0.3423 - val_loss: 1.0354 - val_accuracy: 0.4019\n",
      "Epoch 42/200\n",
      "2553/2553 [==============================] - 0s 118us/sample - loss: 1.0828 - accuracy: 0.3341 - val_loss: 1.0378 - val_accuracy: 0.4019\n",
      "Epoch 43/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 1.0733 - accuracy: 0.3302 - val_loss: 1.0369 - val_accuracy: 0.4019\n",
      "Epoch 44/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 1.0701 - accuracy: 0.3451 - val_loss: 1.0353 - val_accuracy: 0.4112\n",
      "Epoch 45/200\n",
      "2553/2553 [==============================] - 0s 121us/sample - loss: 1.0776 - accuracy: 0.3384 - val_loss: 1.0361 - val_accuracy: 0.4112\n",
      "Epoch 46/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0698 - accuracy: 0.3427 - val_loss: 1.0345 - val_accuracy: 0.4112\n",
      "Epoch 47/200\n",
      "2553/2553 [==============================] - 0s 121us/sample - loss: 1.0728 - accuracy: 0.3365 - val_loss: 1.0348 - val_accuracy: 0.4112\n",
      "Epoch 48/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.0689 - accuracy: 0.3427 - val_loss: 1.0355 - val_accuracy: 0.4112\n",
      "Epoch 49/200\n",
      "2553/2553 [==============================] - 0s 118us/sample - loss: 1.0744 - accuracy: 0.3404 - val_loss: 1.0350 - val_accuracy: 0.4019\n",
      "Epoch 50/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 1.0809 - accuracy: 0.3314 - val_loss: 1.0359 - val_accuracy: 0.3925\n",
      "Epoch 51/200\n",
      "2553/2553 [==============================] - 0s 120us/sample - loss: 1.0717 - accuracy: 0.3392 - val_loss: 1.0353 - val_accuracy: 0.4019\n",
      "Epoch 52/200\n",
      "2553/2553 [==============================] - 0s 119us/sample - loss: 1.0719 - accuracy: 0.3384 - val_loss: 1.0354 - val_accuracy: 0.4019\n",
      "Epoch 53/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.0706 - accuracy: 0.3396 - val_loss: 1.0358 - val_accuracy: 0.4019\n",
      "Epoch 54/200\n",
      "2553/2553 [==============================] - 0s 115us/sample - loss: 1.0702 - accuracy: 0.3388 - val_loss: 1.0359 - val_accuracy: 0.4019\n",
      "Epoch 55/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 1.0765 - accuracy: 0.3322 - val_loss: 1.0365 - val_accuracy: 0.4019\n",
      "Epoch 56/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.0737 - accuracy: 0.3306 - val_loss: 1.0347 - val_accuracy: 0.4206\n",
      "Epoch 57/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.0811 - accuracy: 0.3294 - val_loss: 1.0351 - val_accuracy: 0.4206\n",
      "Epoch 58/200\n",
      "2553/2553 [==============================] - 0s 119us/sample - loss: 1.0724 - accuracy: 0.3435 - val_loss: 1.0349 - val_accuracy: 0.4206\n",
      "Epoch 59/200\n",
      "2553/2553 [==============================] - 0s 120us/sample - loss: 1.0796 - accuracy: 0.3337 - val_loss: 1.0367 - val_accuracy: 0.3925\n",
      "Epoch 60/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.0730 - accuracy: 0.3376 - val_loss: 1.0360 - val_accuracy: 0.4112\n",
      "Epoch 61/200\n",
      "2553/2553 [==============================] - 0s 119us/sample - loss: 1.0623 - accuracy: 0.3490 - val_loss: 1.0345 - val_accuracy: 0.4206\n",
      "Epoch 62/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 1.0698 - accuracy: 0.3400 - val_loss: 1.0354 - val_accuracy: 0.4299\n",
      "Epoch 63/200\n",
      "2553/2553 [==============================] - 0s 115us/sample - loss: 1.0717 - accuracy: 0.3423 - val_loss: 1.0334 - val_accuracy: 0.4112\n",
      "Epoch 64/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0670 - accuracy: 0.3423 - val_loss: 1.0323 - val_accuracy: 0.4112\n",
      "Epoch 65/200\n",
      "2553/2553 [==============================] - 0s 120us/sample - loss: 1.0779 - accuracy: 0.3353 - val_loss: 1.0336 - val_accuracy: 0.4112\n",
      "Epoch 66/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.0768 - accuracy: 0.3365 - val_loss: 1.0349 - val_accuracy: 0.4112\n",
      "Epoch 67/200\n",
      "2553/2553 [==============================] - 0s 117us/sample - loss: 1.0702 - accuracy: 0.3392 - val_loss: 1.0348 - val_accuracy: 0.4112\n",
      "Epoch 68/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.0711 - accuracy: 0.3420 - val_loss: 1.0346 - val_accuracy: 0.4019\n",
      "Epoch 69/200\n",
      "2553/2553 [==============================] - 0s 118us/sample - loss: 1.0754 - accuracy: 0.3353 - val_loss: 1.0340 - val_accuracy: 0.4019\n",
      "Epoch 70/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 1.0678 - accuracy: 0.3376 - val_loss: 1.0328 - val_accuracy: 0.4019\n",
      "Epoch 71/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0706 - accuracy: 0.3373 - val_loss: 1.0326 - val_accuracy: 0.4019\n",
      "Epoch 72/200\n",
      "2553/2553 [==============================] - 0s 120us/sample - loss: 1.0730 - accuracy: 0.3416 - val_loss: 1.0328 - val_accuracy: 0.4019\n",
      "Epoch 73/200\n",
      "2553/2553 [==============================] - 0s 133us/sample - loss: 1.0646 - accuracy: 0.3486 - val_loss: 1.0322 - val_accuracy: 0.4019\n",
      "Epoch 74/200\n",
      "2553/2553 [==============================] - 0s 135us/sample - loss: 1.0732 - accuracy: 0.3357 - val_loss: 1.0334 - val_accuracy: 0.4112\n",
      "Epoch 75/200\n",
      "2553/2553 [==============================] - 0s 117us/sample - loss: 1.0680 - accuracy: 0.3420 - val_loss: 1.0330 - val_accuracy: 0.4112\n",
      "Epoch 76/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.0653 - accuracy: 0.3482 - val_loss: 1.0327 - val_accuracy: 0.4206\n",
      "Epoch 77/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 1.0651 - accuracy: 0.3494 - val_loss: 1.0329 - val_accuracy: 0.4206\n",
      "Epoch 78/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.0750 - accuracy: 0.3365 - val_loss: 1.0344 - val_accuracy: 0.4206\n",
      "Epoch 79/200\n",
      "2553/2553 [==============================] - 0s 120us/sample - loss: 1.0653 - accuracy: 0.3408 - val_loss: 1.0337 - val_accuracy: 0.4206\n",
      "Epoch 80/200\n",
      "2553/2553 [==============================] - 0s 120us/sample - loss: 1.0637 - accuracy: 0.3474 - val_loss: 1.0322 - val_accuracy: 0.4206\n",
      "Epoch 81/200\n",
      "2553/2553 [==============================] - 0s 119us/sample - loss: 1.0683 - accuracy: 0.3490 - val_loss: 1.0319 - val_accuracy: 0.4206\n",
      "Epoch 82/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.0659 - accuracy: 0.3435 - val_loss: 1.0329 - val_accuracy: 0.4206\n",
      "Epoch 83/200\n",
      "2553/2553 [==============================] - 0s 115us/sample - loss: 1.0645 - accuracy: 0.3474 - val_loss: 1.0328 - val_accuracy: 0.4206\n",
      "Epoch 84/200\n",
      "2553/2553 [==============================] - 0s 120us/sample - loss: 1.0645 - accuracy: 0.3506 - val_loss: 1.0323 - val_accuracy: 0.4206\n",
      "Epoch 85/200\n",
      "2553/2553 [==============================] - 0s 117us/sample - loss: 1.0695 - accuracy: 0.3467 - val_loss: 1.0331 - val_accuracy: 0.4206\n",
      "Epoch 86/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 1.0768 - accuracy: 0.3341 - val_loss: 1.0355 - val_accuracy: 0.4206\n",
      "Epoch 87/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.0695 - accuracy: 0.3400 - val_loss: 1.0356 - val_accuracy: 0.4206\n",
      "Epoch 88/200\n",
      "2553/2553 [==============================] - 0s 120us/sample - loss: 1.0685 - accuracy: 0.3451 - val_loss: 1.0344 - val_accuracy: 0.4206\n",
      "Epoch 89/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.0669 - accuracy: 0.3416 - val_loss: 1.0352 - val_accuracy: 0.4206\n",
      "Epoch 90/200\n",
      "2553/2553 [==============================] - 0s 115us/sample - loss: 1.0687 - accuracy: 0.3451 - val_loss: 1.0344 - val_accuracy: 0.4206\n",
      "Epoch 91/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 1.0671 - accuracy: 0.3431 - val_loss: 1.0336 - val_accuracy: 0.4206\n",
      "Epoch 92/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.0625 - accuracy: 0.3498 - val_loss: 1.0326 - val_accuracy: 0.4206\n",
      "Epoch 93/200\n",
      "2553/2553 [==============================] - 0s 115us/sample - loss: 1.0654 - accuracy: 0.3510 - val_loss: 1.0318 - val_accuracy: 0.4206\n",
      "Epoch 94/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.0595 - accuracy: 0.3498 - val_loss: 1.0312 - val_accuracy: 0.4206\n",
      "Epoch 95/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 1.0604 - accuracy: 0.3545 - val_loss: 1.0293 - val_accuracy: 0.4299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.0585 - accuracy: 0.3533 - val_loss: 1.0292 - val_accuracy: 0.4299\n",
      "Epoch 97/200\n",
      "2553/2553 [==============================] - 0s 118us/sample - loss: 1.0714 - accuracy: 0.3400 - val_loss: 1.0320 - val_accuracy: 0.4206\n",
      "Epoch 98/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0689 - accuracy: 0.3420 - val_loss: 1.0336 - val_accuracy: 0.4206\n",
      "Epoch 99/200\n",
      "2553/2553 [==============================] - 0s 117us/sample - loss: 1.0629 - accuracy: 0.3490 - val_loss: 1.0333 - val_accuracy: 0.4206\n",
      "Epoch 100/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.0606 - accuracy: 0.3549 - val_loss: 1.0320 - val_accuracy: 0.4206\n",
      "Epoch 101/200\n",
      "2553/2553 [==============================] - 0s 119us/sample - loss: 1.0656 - accuracy: 0.3420 - val_loss: 1.0318 - val_accuracy: 0.4206\n",
      "Epoch 102/200\n",
      "2553/2553 [==============================] - 0s 124us/sample - loss: 1.0671 - accuracy: 0.3498 - val_loss: 1.0328 - val_accuracy: 0.4206\n",
      "Epoch 103/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.0671 - accuracy: 0.3463 - val_loss: 1.0320 - val_accuracy: 0.4206\n",
      "Epoch 104/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.0609 - accuracy: 0.3533 - val_loss: 1.0320 - val_accuracy: 0.4299\n",
      "Epoch 105/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.0661 - accuracy: 0.3416 - val_loss: 1.0335 - val_accuracy: 0.4206\n",
      "Epoch 106/200\n",
      "2553/2553 [==============================] - 0s 119us/sample - loss: 1.0658 - accuracy: 0.3412 - val_loss: 1.0347 - val_accuracy: 0.4206\n",
      "Epoch 107/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.0780 - accuracy: 0.3384 - val_loss: 1.0370 - val_accuracy: 0.4206\n",
      "Epoch 108/200\n",
      "2553/2553 [==============================] - 0s 119us/sample - loss: 1.0637 - accuracy: 0.3514 - val_loss: 1.0350 - val_accuracy: 0.4206\n",
      "Epoch 109/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.0773 - accuracy: 0.3376 - val_loss: 1.0355 - val_accuracy: 0.4206\n",
      "Epoch 110/200\n",
      "2553/2553 [==============================] - 0s 123us/sample - loss: 1.0633 - accuracy: 0.3474 - val_loss: 1.0347 - val_accuracy: 0.4206\n",
      "Epoch 111/200\n",
      "2553/2553 [==============================] - 0s 118us/sample - loss: 1.0717 - accuracy: 0.3361 - val_loss: 1.0350 - val_accuracy: 0.4206\n",
      "Epoch 112/200\n",
      "2553/2553 [==============================] - 0s 118us/sample - loss: 1.0658 - accuracy: 0.3412 - val_loss: 1.0351 - val_accuracy: 0.4206\n",
      "Epoch 113/200\n",
      "2553/2553 [==============================] - 0s 118us/sample - loss: 1.0620 - accuracy: 0.3478 - val_loss: 1.0335 - val_accuracy: 0.4299\n",
      "Epoch 114/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.0668 - accuracy: 0.3423 - val_loss: 1.0334 - val_accuracy: 0.4299\n",
      "Epoch 115/200\n",
      "2553/2553 [==============================] - 0s 121us/sample - loss: 1.0729 - accuracy: 0.3345 - val_loss: 1.0348 - val_accuracy: 0.4299\n",
      "Epoch 116/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 1.0575 - accuracy: 0.3486 - val_loss: 1.0334 - val_accuracy: 0.4299\n",
      "Epoch 117/200\n",
      "2553/2553 [==============================] - 0s 115us/sample - loss: 1.0759 - accuracy: 0.3329 - val_loss: 1.0353 - val_accuracy: 0.4299\n",
      "Epoch 118/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.0636 - accuracy: 0.3506 - val_loss: 1.0336 - val_accuracy: 0.4299\n",
      "Epoch 119/200\n",
      "2553/2553 [==============================] - 0s 117us/sample - loss: 1.0596 - accuracy: 0.3498 - val_loss: 1.0307 - val_accuracy: 0.4299\n",
      "Epoch 120/200\n",
      "2553/2553 [==============================] - 0s 119us/sample - loss: 1.0731 - accuracy: 0.3392 - val_loss: 1.0336 - val_accuracy: 0.4299\n",
      "Epoch 121/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.0625 - accuracy: 0.3549 - val_loss: 1.0329 - val_accuracy: 0.4299\n",
      "Epoch 122/200\n",
      "2553/2553 [==============================] - 0s 121us/sample - loss: 1.0687 - accuracy: 0.3447 - val_loss: 1.0343 - val_accuracy: 0.4299\n",
      "Epoch 123/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.0624 - accuracy: 0.3502 - val_loss: 1.0325 - val_accuracy: 0.4299\n",
      "Epoch 124/200\n",
      "2553/2553 [==============================] - 0s 118us/sample - loss: 1.0670 - accuracy: 0.3427 - val_loss: 1.0318 - val_accuracy: 0.4299\n",
      "Epoch 125/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.0656 - accuracy: 0.3482 - val_loss: 1.0319 - val_accuracy: 0.4299\n",
      "Epoch 126/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 1.0707 - accuracy: 0.3318 - val_loss: 1.0363 - val_accuracy: 0.4393\n",
      "Epoch 127/200\n",
      "2553/2553 [==============================] - 0s 117us/sample - loss: 1.0656 - accuracy: 0.3486 - val_loss: 1.0344 - val_accuracy: 0.4299\n",
      "Epoch 128/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.0650 - accuracy: 0.3533 - val_loss: 1.0345 - val_accuracy: 0.4393\n",
      "Epoch 129/200\n",
      "2553/2553 [==============================] - 0s 121us/sample - loss: 1.0686 - accuracy: 0.3470 - val_loss: 1.0354 - val_accuracy: 0.4393\n",
      "Epoch 130/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.0712 - accuracy: 0.3408 - val_loss: 1.0350 - val_accuracy: 0.4393\n",
      "Epoch 131/200\n",
      "2553/2553 [==============================] - 0s 119us/sample - loss: 1.0534 - accuracy: 0.3580 - val_loss: 1.0315 - val_accuracy: 0.4299\n",
      "Epoch 132/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.0740 - accuracy: 0.3443 - val_loss: 1.0343 - val_accuracy: 0.4299\n",
      "Epoch 133/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.0705 - accuracy: 0.3380 - val_loss: 1.0365 - val_accuracy: 0.4299\n",
      "Epoch 134/200\n",
      "2553/2553 [==============================] - 0s 117us/sample - loss: 1.0638 - accuracy: 0.3474 - val_loss: 1.0355 - val_accuracy: 0.4299\n",
      "Epoch 135/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0716 - accuracy: 0.3384 - val_loss: 1.0365 - val_accuracy: 0.4299\n",
      "Epoch 136/200\n",
      "2553/2553 [==============================] - 0s 120us/sample - loss: 1.0673 - accuracy: 0.3455 - val_loss: 1.0350 - val_accuracy: 0.4299\n",
      "Epoch 137/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 1.0659 - accuracy: 0.3431 - val_loss: 1.0352 - val_accuracy: 0.4299\n",
      "Epoch 138/200\n",
      "2553/2553 [==============================] - 0s 117us/sample - loss: 1.0671 - accuracy: 0.3423 - val_loss: 1.0351 - val_accuracy: 0.4299\n",
      "Epoch 139/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0614 - accuracy: 0.3467 - val_loss: 1.0333 - val_accuracy: 0.4299\n",
      "Epoch 140/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.0647 - accuracy: 0.3498 - val_loss: 1.0348 - val_accuracy: 0.4299\n",
      "Epoch 141/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.0633 - accuracy: 0.3474 - val_loss: 1.0340 - val_accuracy: 0.4299\n",
      "Epoch 142/200\n",
      "2553/2553 [==============================] - 0s 119us/sample - loss: 1.0684 - accuracy: 0.3427 - val_loss: 1.0349 - val_accuracy: 0.4299\n",
      "Epoch 143/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.0607 - accuracy: 0.3529 - val_loss: 1.0327 - val_accuracy: 0.4299\n",
      "Epoch 144/200\n",
      "2553/2553 [==============================] - 0s 118us/sample - loss: 1.0563 - accuracy: 0.3572 - val_loss: 1.0316 - val_accuracy: 0.4299\n",
      "Epoch 145/200\n",
      "2553/2553 [==============================] - 0s 118us/sample - loss: 1.0670 - accuracy: 0.3439 - val_loss: 1.0342 - val_accuracy: 0.4299\n",
      "Epoch 146/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0671 - accuracy: 0.3447 - val_loss: 1.0343 - val_accuracy: 0.4299\n",
      "Epoch 147/200\n",
      "2553/2553 [==============================] - 0s 117us/sample - loss: 1.0626 - accuracy: 0.3506 - val_loss: 1.0340 - val_accuracy: 0.4299\n",
      "Epoch 148/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0674 - accuracy: 0.3470 - val_loss: 1.0337 - val_accuracy: 0.4299\n",
      "Epoch 149/200\n",
      "2553/2553 [==============================] - 0s 119us/sample - loss: 1.0636 - accuracy: 0.3494 - val_loss: 1.0333 - val_accuracy: 0.4299\n",
      "Epoch 150/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0646 - accuracy: 0.3416 - val_loss: 1.0341 - val_accuracy: 0.4299\n",
      "Epoch 151/200\n",
      "2553/2553 [==============================] - 0s 117us/sample - loss: 1.0588 - accuracy: 0.3545 - val_loss: 1.0330 - val_accuracy: 0.4299\n",
      "Epoch 152/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 1.0619 - accuracy: 0.3510 - val_loss: 1.0331 - val_accuracy: 0.4393\n",
      "Epoch 153/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.0630 - accuracy: 0.3451 - val_loss: 1.0338 - val_accuracy: 0.4393\n",
      "Epoch 154/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.0711 - accuracy: 0.3412 - val_loss: 1.0352 - val_accuracy: 0.4393\n",
      "Epoch 155/200\n",
      "2553/2553 [==============================] - 0s 117us/sample - loss: 1.0585 - accuracy: 0.3537 - val_loss: 1.0339 - val_accuracy: 0.4393\n",
      "Epoch 156/200\n",
      "2553/2553 [==============================] - 0s 120us/sample - loss: 1.0635 - accuracy: 0.3553 - val_loss: 1.0328 - val_accuracy: 0.4393\n",
      "Epoch 157/200\n",
      "2553/2553 [==============================] - 0s 115us/sample - loss: 1.0637 - accuracy: 0.3431 - val_loss: 1.0327 - val_accuracy: 0.4393\n",
      "Epoch 158/200\n",
      "2553/2553 [==============================] - 0s 118us/sample - loss: 1.0650 - accuracy: 0.3467 - val_loss: 1.0332 - val_accuracy: 0.4393\n",
      "Epoch 159/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.0650 - accuracy: 0.3455 - val_loss: 1.0336 - val_accuracy: 0.4393\n",
      "Epoch 160/200\n",
      "2553/2553 [==============================] - 0s 115us/sample - loss: 1.0590 - accuracy: 0.3506 - val_loss: 1.0331 - val_accuracy: 0.4393\n",
      "Epoch 161/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0659 - accuracy: 0.3463 - val_loss: 1.0333 - val_accuracy: 0.4393\n",
      "Epoch 162/200\n",
      "2553/2553 [==============================] - 0s 120us/sample - loss: 1.0617 - accuracy: 0.3510 - val_loss: 1.0337 - val_accuracy: 0.4393\n",
      "Epoch 163/200\n",
      "2553/2553 [==============================] - 0s 118us/sample - loss: 1.0592 - accuracy: 0.3486 - val_loss: 1.0332 - val_accuracy: 0.4393\n",
      "Epoch 164/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.0623 - accuracy: 0.3467 - val_loss: 1.0330 - val_accuracy: 0.4393\n",
      "Epoch 165/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.0683 - accuracy: 0.3431 - val_loss: 1.0349 - val_accuracy: 0.4393\n",
      "Epoch 166/200\n",
      "2553/2553 [==============================] - 0s 115us/sample - loss: 1.0576 - accuracy: 0.3498 - val_loss: 1.0326 - val_accuracy: 0.4393\n",
      "Epoch 167/200\n",
      "2553/2553 [==============================] - 0s 115us/sample - loss: 1.0652 - accuracy: 0.3463 - val_loss: 1.0330 - val_accuracy: 0.4393\n",
      "Epoch 168/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0608 - accuracy: 0.3494 - val_loss: 1.0333 - val_accuracy: 0.4393\n",
      "Epoch 169/200\n",
      "2553/2553 [==============================] - 0s 117us/sample - loss: 1.0564 - accuracy: 0.3498 - val_loss: 1.0314 - val_accuracy: 0.4393\n",
      "Epoch 170/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.0697 - accuracy: 0.3447 - val_loss: 1.0335 - val_accuracy: 0.4393\n",
      "Epoch 171/200\n",
      "2553/2553 [==============================] - 0s 119us/sample - loss: 1.0603 - accuracy: 0.3443 - val_loss: 1.0334 - val_accuracy: 0.4393\n",
      "Epoch 172/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.0621 - accuracy: 0.3553 - val_loss: 1.0332 - val_accuracy: 0.4393\n",
      "Epoch 173/200\n",
      "2553/2553 [==============================] - 0s 120us/sample - loss: 1.0585 - accuracy: 0.3564 - val_loss: 1.0313 - val_accuracy: 0.4393\n",
      "Epoch 174/200\n",
      "2553/2553 [==============================] - 0s 117us/sample - loss: 1.0626 - accuracy: 0.3392 - val_loss: 1.0330 - val_accuracy: 0.4393\n",
      "Epoch 175/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0666 - accuracy: 0.3439 - val_loss: 1.0337 - val_accuracy: 0.4393\n",
      "Epoch 176/200\n",
      "2553/2553 [==============================] - 0s 122us/sample - loss: 1.0670 - accuracy: 0.3423 - val_loss: 1.0346 - val_accuracy: 0.4393\n",
      "Epoch 177/200\n",
      "2553/2553 [==============================] - 0s 115us/sample - loss: 1.0717 - accuracy: 0.3451 - val_loss: 1.0360 - val_accuracy: 0.4393\n",
      "Epoch 178/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 1.0652 - accuracy: 0.3494 - val_loss: 1.0347 - val_accuracy: 0.4393\n",
      "Epoch 179/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.0603 - accuracy: 0.3474 - val_loss: 1.0344 - val_accuracy: 0.4393\n",
      "Epoch 180/200\n",
      "2553/2553 [==============================] - 0s 123us/sample - loss: 1.0652 - accuracy: 0.3517 - val_loss: 1.0340 - val_accuracy: 0.4393\n",
      "Epoch 181/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 1.0569 - accuracy: 0.3525 - val_loss: 1.0335 - val_accuracy: 0.4393\n",
      "Epoch 182/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0602 - accuracy: 0.3561 - val_loss: 1.0348 - val_accuracy: 0.4393\n",
      "Epoch 183/200\n",
      "2553/2553 [==============================] - 0s 123us/sample - loss: 1.0652 - accuracy: 0.3482 - val_loss: 1.0340 - val_accuracy: 0.4393\n",
      "Epoch 184/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.0650 - accuracy: 0.3459 - val_loss: 1.0346 - val_accuracy: 0.4393\n",
      "Epoch 185/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 1.0694 - accuracy: 0.3416 - val_loss: 1.0344 - val_accuracy: 0.4393\n",
      "Epoch 186/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.0569 - accuracy: 0.3521 - val_loss: 1.0336 - val_accuracy: 0.4393\n",
      "Epoch 187/200\n",
      "2553/2553 [==============================] - 0s 117us/sample - loss: 1.0637 - accuracy: 0.3486 - val_loss: 1.0334 - val_accuracy: 0.4393\n",
      "Epoch 188/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.0536 - accuracy: 0.3576 - val_loss: 1.0306 - val_accuracy: 0.4486\n",
      "Epoch 189/200\n",
      "2553/2553 [==============================] - 0s 119us/sample - loss: 1.0671 - accuracy: 0.3451 - val_loss: 1.0332 - val_accuracy: 0.4393\n",
      "Epoch 190/200\n",
      "2553/2553 [==============================] - 0s 119us/sample - loss: 1.0567 - accuracy: 0.3498 - val_loss: 1.0322 - val_accuracy: 0.4393\n",
      "Epoch 191/200\n",
      "2553/2553 [==============================] - 0s 118us/sample - loss: 1.0609 - accuracy: 0.3514 - val_loss: 1.0321 - val_accuracy: 0.4393\n",
      "Epoch 192/200\n",
      "2553/2553 [==============================] - 0s 120us/sample - loss: 1.0606 - accuracy: 0.3459 - val_loss: 1.0335 - val_accuracy: 0.4393\n",
      "Epoch 193/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.0633 - accuracy: 0.3427 - val_loss: 1.0343 - val_accuracy: 0.4486\n",
      "Epoch 194/200\n",
      "2553/2553 [==============================] - 0s 121us/sample - loss: 1.0589 - accuracy: 0.3514 - val_loss: 1.0336 - val_accuracy: 0.4393\n",
      "Epoch 195/200\n",
      "2553/2553 [==============================] - 0s 115us/sample - loss: 1.0620 - accuracy: 0.3463 - val_loss: 1.0337 - val_accuracy: 0.4393\n",
      "Epoch 196/200\n",
      "2553/2553 [==============================] - 0s 118us/sample - loss: 1.0606 - accuracy: 0.3533 - val_loss: 1.0331 - val_accuracy: 0.4393\n",
      "Epoch 197/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.0679 - accuracy: 0.3412 - val_loss: 1.0358 - val_accuracy: 0.4393\n",
      "Epoch 198/200\n",
      "2553/2553 [==============================] - 0s 118us/sample - loss: 1.0692 - accuracy: 0.3416 - val_loss: 1.0352 - val_accuracy: 0.4393\n",
      "Epoch 199/200\n",
      "2553/2553 [==============================] - 0s 117us/sample - loss: 1.0531 - accuracy: 0.3533 - val_loss: 1.0346 - val_accuracy: 0.4393\n",
      "Epoch 200/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.0561 - accuracy: 0.3564 - val_loss: 1.0321 - val_accuracy: 0.4486\n",
      "0.44859812 {'loss': 1.056134997210781, 'accuracy': 0.3564434, 'val_loss': 1.0321482910174076, 'val_accuracy': 0.44859812}\n",
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         [(None, 29)]              0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 41)                1230      \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 75)                3150      \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 3)                 228       \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 4,608\n",
      "Trainable params: 4,608\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2553 samples, validate on 107 samples\n",
      "Epoch 1/200\n",
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "2553/2553 [==============================] - 1s 379us/sample - loss: 1.2207 - accuracy: 0.2644 - val_loss: 1.1564 - val_accuracy: 0.2336\n",
      "Epoch 2/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.1767 - accuracy: 0.2703 - val_loss: 1.1431 - val_accuracy: 0.2430\n",
      "Epoch 3/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.1702 - accuracy: 0.2664 - val_loss: 1.1333 - val_accuracy: 0.2710\n",
      "Epoch 4/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.1500 - accuracy: 0.2671 - val_loss: 1.1261 - val_accuracy: 0.2430\n",
      "Epoch 5/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.1341 - accuracy: 0.2695 - val_loss: 1.1218 - val_accuracy: 0.2056\n",
      "Epoch 6/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.1230 - accuracy: 0.2742 - val_loss: 1.1181 - val_accuracy: 0.1869\n",
      "Epoch 7/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.1187 - accuracy: 0.2769 - val_loss: 1.1157 - val_accuracy: 0.1963\n",
      "Epoch 8/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.1163 - accuracy: 0.2750 - val_loss: 1.1133 - val_accuracy: 0.1869\n",
      "Epoch 9/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.1130 - accuracy: 0.2742 - val_loss: 1.1111 - val_accuracy: 0.1776\n",
      "Epoch 10/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.1073 - accuracy: 0.2785 - val_loss: 1.1095 - val_accuracy: 0.2056\n",
      "Epoch 11/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.1096 - accuracy: 0.2738 - val_loss: 1.1074 - val_accuracy: 0.1963\n",
      "Epoch 12/200\n",
      "2553/2553 [==============================] - 0s 77us/sample - loss: 1.1089 - accuracy: 0.2738 - val_loss: 1.1056 - val_accuracy: 0.2056\n",
      "Epoch 13/200\n",
      "2553/2553 [==============================] - 0s 79us/sample - loss: 1.1040 - accuracy: 0.2805 - val_loss: 1.1044 - val_accuracy: 0.1963\n",
      "Epoch 14/200\n",
      "2553/2553 [==============================] - 0s 85us/sample - loss: 1.1072 - accuracy: 0.2746 - val_loss: 1.1033 - val_accuracy: 0.1963\n",
      "Epoch 15/200\n",
      "2553/2553 [==============================] - 0s 94us/sample - loss: 1.1041 - accuracy: 0.2754 - val_loss: 1.1022 - val_accuracy: 0.2056\n",
      "Epoch 16/200\n",
      "2553/2553 [==============================] - 0s 88us/sample - loss: 1.1056 - accuracy: 0.2750 - val_loss: 1.1011 - val_accuracy: 0.2056\n",
      "Epoch 17/200\n",
      "2553/2553 [==============================] - 0s 95us/sample - loss: 1.1032 - accuracy: 0.2781 - val_loss: 1.1004 - val_accuracy: 0.1963\n",
      "Epoch 18/200\n",
      "2553/2553 [==============================] - 0s 65us/sample - loss: 1.1018 - accuracy: 0.2820 - val_loss: 1.1000 - val_accuracy: 0.1963\n",
      "Epoch 19/200\n",
      "2553/2553 [==============================] - 0s 66us/sample - loss: 1.0997 - accuracy: 0.2824 - val_loss: 1.0998 - val_accuracy: 0.1963\n",
      "Epoch 20/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.1005 - accuracy: 0.2797 - val_loss: 1.0995 - val_accuracy: 0.2243\n",
      "Epoch 21/200\n",
      "2553/2553 [==============================] - 0s 70us/sample - loss: 1.1014 - accuracy: 0.2797 - val_loss: 1.0993 - val_accuracy: 0.2243\n",
      "Epoch 22/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.1025 - accuracy: 0.2789 - val_loss: 1.0991 - val_accuracy: 0.2243\n",
      "Epoch 23/200\n",
      "2553/2553 [==============================] - 0s 68us/sample - loss: 1.1031 - accuracy: 0.2758 - val_loss: 1.0989 - val_accuracy: 0.2243\n",
      "Epoch 24/200\n",
      "2553/2553 [==============================] - 0s 66us/sample - loss: 1.0994 - accuracy: 0.2828 - val_loss: 1.0988 - val_accuracy: 0.2243\n",
      "Epoch 25/200\n",
      "2553/2553 [==============================] - 0s 65us/sample - loss: 1.1011 - accuracy: 0.2789 - val_loss: 1.0987 - val_accuracy: 0.2243\n",
      "Epoch 26/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0996 - accuracy: 0.2805 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 27/200\n",
      "2553/2553 [==============================] - 0s 79us/sample - loss: 1.0992 - accuracy: 0.2844 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 28/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.1006 - accuracy: 0.2801 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 29/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.1017 - accuracy: 0.2761 - val_loss: 1.0985 - val_accuracy: 0.2243\n",
      "Epoch 30/200\n",
      "2553/2553 [==============================] - 0s 82us/sample - loss: 1.0996 - accuracy: 0.2805 - val_loss: 1.0985 - val_accuracy: 0.2243\n",
      "Epoch 31/200\n",
      "2553/2553 [==============================] - 0s 75us/sample - loss: 1.0990 - accuracy: 0.2832 - val_loss: 1.0985 - val_accuracy: 0.2243\n",
      "Epoch 32/200\n",
      "2553/2553 [==============================] - 0s 68us/sample - loss: 1.0982 - accuracy: 0.2848 - val_loss: 1.0985 - val_accuracy: 0.2243\n",
      "Epoch 33/200\n",
      "2553/2553 [==============================] - 0s 69us/sample - loss: 1.0987 - accuracy: 0.2840 - val_loss: 1.0985 - val_accuracy: 0.2243\n",
      "Epoch 34/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.0998 - accuracy: 0.2777 - val_loss: 1.0985 - val_accuracy: 0.2243\n",
      "Epoch 35/200\n",
      "2553/2553 [==============================] - 0s 73us/sample - loss: 1.0991 - accuracy: 0.2773 - val_loss: 1.0984 - val_accuracy: 0.2243\n",
      "Epoch 36/200\n",
      "2553/2553 [==============================] - 0s 67us/sample - loss: 1.0979 - accuracy: 0.2836 - val_loss: 1.0984 - val_accuracy: 0.2243\n",
      "Epoch 37/200\n",
      "2553/2553 [==============================] - 0s 65us/sample - loss: 1.0981 - accuracy: 0.2808 - val_loss: 1.0984 - val_accuracy: 0.2243\n",
      "Epoch 38/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.0987 - accuracy: 0.2844 - val_loss: 1.0984 - val_accuracy: 0.2243\n",
      "Epoch 39/200\n",
      "2553/2553 [==============================] - 0s 70us/sample - loss: 1.0995 - accuracy: 0.2820 - val_loss: 1.0984 - val_accuracy: 0.2243\n",
      "Epoch 40/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0986 - accuracy: 0.2855 - val_loss: 1.0985 - val_accuracy: 0.2243\n",
      "Epoch 41/200\n",
      "2553/2553 [==============================] - 0s 69us/sample - loss: 1.0987 - accuracy: 0.2840 - val_loss: 1.0985 - val_accuracy: 0.2243\n",
      "Epoch 42/200\n",
      "2553/2553 [==============================] - 0s 73us/sample - loss: 1.0996 - accuracy: 0.2801 - val_loss: 1.0985 - val_accuracy: 0.2243\n",
      "Epoch 43/200\n",
      "2553/2553 [==============================] - 0s 65us/sample - loss: 1.0984 - accuracy: 0.2820 - val_loss: 1.0984 - val_accuracy: 0.2243\n",
      "Epoch 44/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0992 - accuracy: 0.2801 - val_loss: 1.0984 - val_accuracy: 0.2243\n",
      "Epoch 45/200\n",
      "2553/2553 [==============================] - 0s 69us/sample - loss: 1.0987 - accuracy: 0.2801 - val_loss: 1.0984 - val_accuracy: 0.2243\n",
      "Epoch 46/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0978 - accuracy: 0.2820 - val_loss: 1.0984 - val_accuracy: 0.2243\n",
      "Epoch 47/200\n",
      "2553/2553 [==============================] - 0s 65us/sample - loss: 1.0989 - accuracy: 0.2816 - val_loss: 1.0984 - val_accuracy: 0.2243\n",
      "Epoch 48/200\n",
      "2553/2553 [==============================] - 0s 69us/sample - loss: 1.0983 - accuracy: 0.2832 - val_loss: 1.0984 - val_accuracy: 0.2243\n",
      "Epoch 49/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.0992 - accuracy: 0.2824 - val_loss: 1.0985 - val_accuracy: 0.2243\n",
      "Epoch 50/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.0987 - accuracy: 0.2793 - val_loss: 1.0984 - val_accuracy: 0.2243\n",
      "Epoch 51/200\n",
      "2553/2553 [==============================] - 0s 70us/sample - loss: 1.0983 - accuracy: 0.2805 - val_loss: 1.0984 - val_accuracy: 0.2243\n",
      "Epoch 52/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.0985 - accuracy: 0.2808 - val_loss: 1.0984 - val_accuracy: 0.2243\n",
      "Epoch 53/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0985 - accuracy: 0.2836 - val_loss: 1.0985 - val_accuracy: 0.2243\n",
      "Epoch 54/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.0999 - accuracy: 0.2805 - val_loss: 1.0985 - val_accuracy: 0.2243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.0981 - accuracy: 0.2820 - val_loss: 1.0985 - val_accuracy: 0.2243\n",
      "Epoch 56/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.0984 - accuracy: 0.2808 - val_loss: 1.0985 - val_accuracy: 0.2243\n",
      "Epoch 57/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0989 - accuracy: 0.2801 - val_loss: 1.0985 - val_accuracy: 0.2243\n",
      "Epoch 58/200\n",
      "2553/2553 [==============================] - 0s 67us/sample - loss: 1.0978 - accuracy: 0.2824 - val_loss: 1.0985 - val_accuracy: 0.2243\n",
      "Epoch 59/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.0977 - accuracy: 0.2852 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 60/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0990 - accuracy: 0.2832 - val_loss: 1.0985 - val_accuracy: 0.2243\n",
      "Epoch 61/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0990 - accuracy: 0.2812 - val_loss: 1.0985 - val_accuracy: 0.2243\n",
      "Epoch 62/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.0990 - accuracy: 0.2777 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 63/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.0984 - accuracy: 0.2852 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 64/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.0984 - accuracy: 0.2820 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 65/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0986 - accuracy: 0.2824 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 66/200\n",
      "2553/2553 [==============================] - 0s 74us/sample - loss: 1.0981 - accuracy: 0.2820 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 67/200\n",
      "2553/2553 [==============================] - 0s 66us/sample - loss: 1.0974 - accuracy: 0.2836 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 68/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0982 - accuracy: 0.2805 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 69/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0985 - accuracy: 0.2812 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 70/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0990 - accuracy: 0.2805 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 71/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.0975 - accuracy: 0.2836 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 72/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.0973 - accuracy: 0.2805 - val_loss: 1.0987 - val_accuracy: 0.2243\n",
      "Epoch 73/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.0987 - accuracy: 0.2828 - val_loss: 1.0987 - val_accuracy: 0.2243\n",
      "Epoch 74/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.0978 - accuracy: 0.2812 - val_loss: 1.0987 - val_accuracy: 0.2243\n",
      "Epoch 75/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.0983 - accuracy: 0.2793 - val_loss: 1.0987 - val_accuracy: 0.2243\n",
      "Epoch 76/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0985 - accuracy: 0.2805 - val_loss: 1.0987 - val_accuracy: 0.2243\n",
      "Epoch 77/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0972 - accuracy: 0.2824 - val_loss: 1.0987 - val_accuracy: 0.2243\n",
      "Epoch 78/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0971 - accuracy: 0.2824 - val_loss: 1.0987 - val_accuracy: 0.2243\n",
      "Epoch 79/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0979 - accuracy: 0.2848 - val_loss: 1.0987 - val_accuracy: 0.2243\n",
      "Epoch 80/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0982 - accuracy: 0.2808 - val_loss: 1.0987 - val_accuracy: 0.2243\n",
      "Epoch 81/200\n",
      "2553/2553 [==============================] - 0s 66us/sample - loss: 1.0976 - accuracy: 0.2855 - val_loss: 1.0987 - val_accuracy: 0.2243\n",
      "Epoch 82/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0965 - accuracy: 0.2828 - val_loss: 1.0987 - val_accuracy: 0.2243\n",
      "Epoch 83/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0974 - accuracy: 0.2820 - val_loss: 1.0987 - val_accuracy: 0.2243\n",
      "Epoch 84/200\n",
      "2553/2553 [==============================] - 0s 65us/sample - loss: 1.0974 - accuracy: 0.2789 - val_loss: 1.0987 - val_accuracy: 0.2243\n",
      "Epoch 85/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.0971 - accuracy: 0.2852 - val_loss: 1.0987 - val_accuracy: 0.2243\n",
      "Epoch 86/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0972 - accuracy: 0.2836 - val_loss: 1.0987 - val_accuracy: 0.2243\n",
      "Epoch 87/200\n",
      "2553/2553 [==============================] - 0s 65us/sample - loss: 1.0971 - accuracy: 0.2797 - val_loss: 1.0987 - val_accuracy: 0.2243\n",
      "Epoch 88/200\n",
      "2553/2553 [==============================] - 0s 66us/sample - loss: 1.0985 - accuracy: 0.2801 - val_loss: 1.0987 - val_accuracy: 0.2243\n",
      "Epoch 89/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0974 - accuracy: 0.2820 - val_loss: 1.0987 - val_accuracy: 0.2243\n",
      "Epoch 90/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0979 - accuracy: 0.2824 - val_loss: 1.0987 - val_accuracy: 0.2243\n",
      "Epoch 91/200\n",
      "2553/2553 [==============================] - 0s 66us/sample - loss: 1.0972 - accuracy: 0.2832 - val_loss: 1.0987 - val_accuracy: 0.2243\n",
      "Epoch 92/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0979 - accuracy: 0.2832 - val_loss: 1.0987 - val_accuracy: 0.2243\n",
      "Epoch 93/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.0976 - accuracy: 0.2797 - val_loss: 1.0987 - val_accuracy: 0.2243\n",
      "Epoch 94/200\n",
      "2553/2553 [==============================] - 0s 68us/sample - loss: 1.0966 - accuracy: 0.2852 - val_loss: 1.0988 - val_accuracy: 0.2243\n",
      "Epoch 95/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.0977 - accuracy: 0.2812 - val_loss: 1.0988 - val_accuracy: 0.2243\n",
      "Epoch 96/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0972 - accuracy: 0.2855 - val_loss: 1.0988 - val_accuracy: 0.2243\n",
      "Epoch 97/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.0975 - accuracy: 0.2824 - val_loss: 1.0988 - val_accuracy: 0.2243\n",
      "Epoch 98/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0959 - accuracy: 0.2855 - val_loss: 1.0988 - val_accuracy: 0.2243\n",
      "Epoch 99/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0974 - accuracy: 0.2797 - val_loss: 1.0988 - val_accuracy: 0.2243\n",
      "Epoch 100/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0978 - accuracy: 0.2808 - val_loss: 1.0988 - val_accuracy: 0.2243\n",
      "Epoch 101/200\n",
      "2553/2553 [==============================] - 0s 68us/sample - loss: 1.0983 - accuracy: 0.2844 - val_loss: 1.0988 - val_accuracy: 0.2243\n",
      "Epoch 102/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0986 - accuracy: 0.2793 - val_loss: 1.0988 - val_accuracy: 0.2243\n",
      "Epoch 103/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0980 - accuracy: 0.2836 - val_loss: 1.0988 - val_accuracy: 0.2243\n",
      "Epoch 104/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.0955 - accuracy: 0.2848 - val_loss: 1.0988 - val_accuracy: 0.2243\n",
      "Epoch 105/200\n",
      "2553/2553 [==============================] - 0s 67us/sample - loss: 1.0968 - accuracy: 0.2852 - val_loss: 1.0989 - val_accuracy: 0.2243\n",
      "Epoch 106/200\n",
      "2553/2553 [==============================] - 0s 76us/sample - loss: 1.0974 - accuracy: 0.2789 - val_loss: 1.0988 - val_accuracy: 0.2243\n",
      "Epoch 107/200\n",
      "2553/2553 [==============================] - 0s 68us/sample - loss: 1.0974 - accuracy: 0.2824 - val_loss: 1.0989 - val_accuracy: 0.2243\n",
      "Epoch 108/200\n",
      "2553/2553 [==============================] - 0s 76us/sample - loss: 1.0967 - accuracy: 0.2824 - val_loss: 1.0989 - val_accuracy: 0.2243\n",
      "Epoch 109/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0976 - accuracy: 0.2836 - val_loss: 1.0989 - val_accuracy: 0.2243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110/200\n",
      "2553/2553 [==============================] - 0s 66us/sample - loss: 1.0969 - accuracy: 0.2859 - val_loss: 1.0990 - val_accuracy: 0.2243\n",
      "Epoch 111/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0960 - accuracy: 0.2840 - val_loss: 1.0989 - val_accuracy: 0.2243\n",
      "Epoch 112/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0985 - accuracy: 0.2805 - val_loss: 1.0989 - val_accuracy: 0.2243\n",
      "Epoch 113/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.0968 - accuracy: 0.2855 - val_loss: 1.0990 - val_accuracy: 0.2243\n",
      "Epoch 114/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0992 - accuracy: 0.2761 - val_loss: 1.0988 - val_accuracy: 0.2243\n",
      "Epoch 115/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0975 - accuracy: 0.2828 - val_loss: 1.0989 - val_accuracy: 0.2243\n",
      "Epoch 116/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0967 - accuracy: 0.2824 - val_loss: 1.0988 - val_accuracy: 0.2243\n",
      "Epoch 117/200\n",
      "2553/2553 [==============================] - 0s 66us/sample - loss: 1.0956 - accuracy: 0.2863 - val_loss: 1.0990 - val_accuracy: 0.2243\n",
      "Epoch 118/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.0974 - accuracy: 0.2808 - val_loss: 1.0989 - val_accuracy: 0.2243\n",
      "Epoch 119/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0975 - accuracy: 0.2797 - val_loss: 1.0989 - val_accuracy: 0.2243\n",
      "Epoch 120/200\n",
      "2553/2553 [==============================] - 0s 67us/sample - loss: 1.0964 - accuracy: 0.2863 - val_loss: 1.0989 - val_accuracy: 0.2243\n",
      "Epoch 121/200\n",
      "2553/2553 [==============================] - 0s 68us/sample - loss: 1.0973 - accuracy: 0.2824 - val_loss: 1.0989 - val_accuracy: 0.2243\n",
      "Epoch 122/200\n",
      "2553/2553 [==============================] - 0s 73us/sample - loss: 1.0958 - accuracy: 0.2855 - val_loss: 1.0989 - val_accuracy: 0.2243\n",
      "Epoch 123/200\n",
      "2553/2553 [==============================] - 0s 72us/sample - loss: 1.0969 - accuracy: 0.2832 - val_loss: 1.0989 - val_accuracy: 0.2243\n",
      "Epoch 124/200\n",
      "2553/2553 [==============================] - 0s 69us/sample - loss: 1.0972 - accuracy: 0.2828 - val_loss: 1.0989 - val_accuracy: 0.2243\n",
      "Epoch 125/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.0965 - accuracy: 0.2836 - val_loss: 1.0990 - val_accuracy: 0.2243\n",
      "Epoch 126/200\n",
      "2553/2553 [==============================] - 0s 67us/sample - loss: 1.0974 - accuracy: 0.2852 - val_loss: 1.0990 - val_accuracy: 0.2243\n",
      "Epoch 127/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0955 - accuracy: 0.2816 - val_loss: 1.0990 - val_accuracy: 0.2243\n",
      "Epoch 128/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0980 - accuracy: 0.2820 - val_loss: 1.0990 - val_accuracy: 0.2243\n",
      "Epoch 129/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.0971 - accuracy: 0.2824 - val_loss: 1.0990 - val_accuracy: 0.2243\n",
      "Epoch 130/200\n",
      "2553/2553 [==============================] - 0s 73us/sample - loss: 1.0976 - accuracy: 0.2848 - val_loss: 1.0990 - val_accuracy: 0.2243\n",
      "Epoch 131/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.0966 - accuracy: 0.2863 - val_loss: 1.0990 - val_accuracy: 0.2243\n",
      "Epoch 132/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.0969 - accuracy: 0.2812 - val_loss: 1.0990 - val_accuracy: 0.2243\n",
      "Epoch 133/200\n",
      "2553/2553 [==============================] - 0s 68us/sample - loss: 1.0968 - accuracy: 0.2840 - val_loss: 1.0991 - val_accuracy: 0.2243\n",
      "Epoch 134/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0966 - accuracy: 0.2859 - val_loss: 1.0992 - val_accuracy: 0.2150\n",
      "Epoch 135/200\n",
      "2553/2553 [==============================] - 0s 74us/sample - loss: 1.0968 - accuracy: 0.2832 - val_loss: 1.0991 - val_accuracy: 0.2150\n",
      "Epoch 136/200\n",
      "2553/2553 [==============================] - 0s 88us/sample - loss: 1.0969 - accuracy: 0.2848 - val_loss: 1.0991 - val_accuracy: 0.2150\n",
      "Epoch 137/200\n",
      "2553/2553 [==============================] - 0s 88us/sample - loss: 1.0975 - accuracy: 0.2836 - val_loss: 1.0991 - val_accuracy: 0.2150\n",
      "Epoch 138/200\n",
      "2553/2553 [==============================] - 0s 89us/sample - loss: 1.0961 - accuracy: 0.2808 - val_loss: 1.0991 - val_accuracy: 0.2150\n",
      "Epoch 139/200\n",
      "2553/2553 [==============================] - 0s 77us/sample - loss: 1.0979 - accuracy: 0.2812 - val_loss: 1.0991 - val_accuracy: 0.2243\n",
      "Epoch 140/200\n",
      "2553/2553 [==============================] - 0s 70us/sample - loss: 1.0963 - accuracy: 0.2844 - val_loss: 1.0991 - val_accuracy: 0.2243\n",
      "Epoch 141/200\n",
      "2553/2553 [==============================] - 0s 79us/sample - loss: 1.0976 - accuracy: 0.2816 - val_loss: 1.0991 - val_accuracy: 0.2243\n",
      "Epoch 142/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0980 - accuracy: 0.2844 - val_loss: 1.0991 - val_accuracy: 0.2243\n",
      "Epoch 143/200\n",
      "2553/2553 [==============================] - 0s 66us/sample - loss: 1.0968 - accuracy: 0.2852 - val_loss: 1.0991 - val_accuracy: 0.2150\n",
      "Epoch 144/200\n",
      "2553/2553 [==============================] - 0s 86us/sample - loss: 1.0967 - accuracy: 0.2824 - val_loss: 1.0991 - val_accuracy: 0.2150\n",
      "Epoch 145/200\n",
      "2553/2553 [==============================] - 0s 94us/sample - loss: 1.0968 - accuracy: 0.2840 - val_loss: 1.0991 - val_accuracy: 0.2243\n",
      "Epoch 146/200\n",
      "2553/2553 [==============================] - 0s 72us/sample - loss: 1.0954 - accuracy: 0.2832 - val_loss: 1.0992 - val_accuracy: 0.2243\n",
      "Epoch 147/200\n",
      "2553/2553 [==============================] - 0s 81us/sample - loss: 1.0959 - accuracy: 0.2820 - val_loss: 1.0992 - val_accuracy: 0.2243\n",
      "Epoch 148/200\n",
      "2553/2553 [==============================] - 0s 70us/sample - loss: 1.0963 - accuracy: 0.2852 - val_loss: 1.0992 - val_accuracy: 0.2150\n",
      "Epoch 149/200\n",
      "2553/2553 [==============================] - 0s 70us/sample - loss: 1.0973 - accuracy: 0.2793 - val_loss: 1.0992 - val_accuracy: 0.2243\n",
      "Epoch 150/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0964 - accuracy: 0.2848 - val_loss: 1.0992 - val_accuracy: 0.2243\n",
      "Epoch 151/200\n",
      "2553/2553 [==============================] - 0s 84us/sample - loss: 1.0960 - accuracy: 0.2844 - val_loss: 1.0992 - val_accuracy: 0.2150\n",
      "Epoch 152/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0973 - accuracy: 0.2812 - val_loss: 1.0992 - val_accuracy: 0.2243\n",
      "Epoch 153/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0969 - accuracy: 0.2836 - val_loss: 1.0992 - val_accuracy: 0.2150\n",
      "Epoch 154/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.0961 - accuracy: 0.2840 - val_loss: 1.0992 - val_accuracy: 0.2150\n",
      "Epoch 155/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0964 - accuracy: 0.2812 - val_loss: 1.0992 - val_accuracy: 0.2150\n",
      "Epoch 156/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0966 - accuracy: 0.2852 - val_loss: 1.0992 - val_accuracy: 0.2150\n",
      "Epoch 157/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0959 - accuracy: 0.2859 - val_loss: 1.0992 - val_accuracy: 0.2150\n",
      "Epoch 158/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0976 - accuracy: 0.2805 - val_loss: 1.0992 - val_accuracy: 0.2150\n",
      "Epoch 159/200\n",
      "2553/2553 [==============================] - 0s 66us/sample - loss: 1.0949 - accuracy: 0.2875 - val_loss: 1.0991 - val_accuracy: 0.2243\n",
      "Epoch 160/200\n",
      "2553/2553 [==============================] - 0s 70us/sample - loss: 1.0965 - accuracy: 0.2832 - val_loss: 1.0992 - val_accuracy: 0.2243\n",
      "Epoch 161/200\n",
      "2553/2553 [==============================] - 0s 66us/sample - loss: 1.0956 - accuracy: 0.2852 - val_loss: 1.0991 - val_accuracy: 0.2243\n",
      "Epoch 162/200\n",
      "2553/2553 [==============================] - 0s 69us/sample - loss: 1.0959 - accuracy: 0.2914 - val_loss: 1.0991 - val_accuracy: 0.2243\n",
      "Epoch 163/200\n",
      "2553/2553 [==============================] - 0s 67us/sample - loss: 1.0954 - accuracy: 0.2855 - val_loss: 1.0990 - val_accuracy: 0.2336\n",
      "Epoch 164/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 68us/sample - loss: 1.0951 - accuracy: 0.2832 - val_loss: 1.0990 - val_accuracy: 0.2336\n",
      "Epoch 165/200\n",
      "2553/2553 [==============================] - 0s 70us/sample - loss: 1.0971 - accuracy: 0.2816 - val_loss: 1.0989 - val_accuracy: 0.2336\n",
      "Epoch 166/200\n",
      "2553/2553 [==============================] - 0s 70us/sample - loss: 1.0960 - accuracy: 0.2844 - val_loss: 1.0989 - val_accuracy: 0.2336\n",
      "Epoch 167/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0952 - accuracy: 0.2859 - val_loss: 1.0989 - val_accuracy: 0.2336\n",
      "Epoch 168/200\n",
      "2553/2553 [==============================] - 0s 72us/sample - loss: 1.0958 - accuracy: 0.2855 - val_loss: 1.0988 - val_accuracy: 0.2336\n",
      "Epoch 169/200\n",
      "2553/2553 [==============================] - 0s 70us/sample - loss: 1.0950 - accuracy: 0.2852 - val_loss: 1.0986 - val_accuracy: 0.2336\n",
      "Epoch 170/200\n",
      "2553/2553 [==============================] - 0s 65us/sample - loss: 1.0958 - accuracy: 0.2824 - val_loss: 1.0985 - val_accuracy: 0.2336\n",
      "Epoch 171/200\n",
      "2553/2553 [==============================] - 0s 71us/sample - loss: 1.0966 - accuracy: 0.2859 - val_loss: 1.0983 - val_accuracy: 0.2336\n",
      "Epoch 172/200\n",
      "2553/2553 [==============================] - 0s 69us/sample - loss: 1.0956 - accuracy: 0.2879 - val_loss: 1.0981 - val_accuracy: 0.2336\n",
      "Epoch 173/200\n",
      "2553/2553 [==============================] - 0s 68us/sample - loss: 1.0957 - accuracy: 0.2875 - val_loss: 1.0980 - val_accuracy: 0.2336\n",
      "Epoch 174/200\n",
      "2553/2553 [==============================] - 0s 73us/sample - loss: 1.0942 - accuracy: 0.2938 - val_loss: 1.0971 - val_accuracy: 0.2430\n",
      "Epoch 175/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.0906 - accuracy: 0.3071 - val_loss: 1.0945 - val_accuracy: 0.2991\n",
      "Epoch 176/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.0882 - accuracy: 0.3196 - val_loss: 1.0822 - val_accuracy: 0.3738\n",
      "Epoch 177/200\n",
      "2553/2553 [==============================] - 0s 69us/sample - loss: 1.0779 - accuracy: 0.3392 - val_loss: 1.0694 - val_accuracy: 0.3925\n",
      "Epoch 178/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.0762 - accuracy: 0.3400 - val_loss: 1.0624 - val_accuracy: 0.3925\n",
      "Epoch 179/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0672 - accuracy: 0.3545 - val_loss: 1.0562 - val_accuracy: 0.3832\n",
      "Epoch 180/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0684 - accuracy: 0.3455 - val_loss: 1.0541 - val_accuracy: 0.3925\n",
      "Epoch 181/200\n",
      "2553/2553 [==============================] - 0s 67us/sample - loss: 1.0698 - accuracy: 0.3412 - val_loss: 1.0521 - val_accuracy: 0.4019\n",
      "Epoch 182/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0696 - accuracy: 0.3451 - val_loss: 1.0507 - val_accuracy: 0.4019\n",
      "Epoch 183/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0603 - accuracy: 0.3631 - val_loss: 1.0489 - val_accuracy: 0.4019\n",
      "Epoch 184/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0682 - accuracy: 0.3435 - val_loss: 1.0481 - val_accuracy: 0.4112\n",
      "Epoch 185/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0636 - accuracy: 0.3541 - val_loss: 1.0468 - val_accuracy: 0.4112\n",
      "Epoch 186/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0682 - accuracy: 0.3388 - val_loss: 1.0465 - val_accuracy: 0.4206\n",
      "Epoch 187/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.0722 - accuracy: 0.3388 - val_loss: 1.0473 - val_accuracy: 0.4299\n",
      "Epoch 188/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0727 - accuracy: 0.3420 - val_loss: 1.0487 - val_accuracy: 0.4206\n",
      "Epoch 189/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0625 - accuracy: 0.3459 - val_loss: 1.0476 - val_accuracy: 0.4299\n",
      "Epoch 190/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0686 - accuracy: 0.3455 - val_loss: 1.0468 - val_accuracy: 0.4393\n",
      "Epoch 191/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0700 - accuracy: 0.3459 - val_loss: 1.0472 - val_accuracy: 0.4393\n",
      "Epoch 192/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.0613 - accuracy: 0.3537 - val_loss: 1.0457 - val_accuracy: 0.4393\n",
      "Epoch 193/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0637 - accuracy: 0.3494 - val_loss: 1.0459 - val_accuracy: 0.4393\n",
      "Epoch 194/200\n",
      "2553/2553 [==============================] - 0s 70us/sample - loss: 1.0639 - accuracy: 0.3564 - val_loss: 1.0446 - val_accuracy: 0.4299\n",
      "Epoch 195/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0570 - accuracy: 0.3564 - val_loss: 1.0437 - val_accuracy: 0.4393\n",
      "Epoch 196/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0588 - accuracy: 0.3604 - val_loss: 1.0422 - val_accuracy: 0.4486\n",
      "Epoch 197/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0728 - accuracy: 0.3435 - val_loss: 1.0430 - val_accuracy: 0.4393\n",
      "Epoch 198/200\n",
      "2553/2553 [==============================] - 0s 65us/sample - loss: 1.0616 - accuracy: 0.3584 - val_loss: 1.0438 - val_accuracy: 0.4393\n",
      "Epoch 199/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0691 - accuracy: 0.3467 - val_loss: 1.0444 - val_accuracy: 0.4393\n",
      "Epoch 200/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0657 - accuracy: 0.3435 - val_loss: 1.0442 - val_accuracy: 0.4393\n",
      "0.43925235 {'loss': 1.0657294067363388, 'accuracy': 0.34351742, 'val_loss': 1.044191596664001, 'val_accuracy': 0.43925235}\n",
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         [(None, 29)]              0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 41)                1230      \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 10)                420       \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 3)                 33        \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 1,903\n",
      "Trainable params: 1,903\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2553 samples, validate on 107 samples\n",
      "Epoch 1/200\n",
      "2553/2553 [==============================] - 1s 364us/sample - loss: 1.0867 - accuracy: 0.3745 - val_loss: 1.1075 - val_accuracy: 0.2991\n",
      "Epoch 2/200\n",
      "2553/2553 [==============================] - 0s 115us/sample - loss: 1.0794 - accuracy: 0.3890 - val_loss: 1.0989 - val_accuracy: 0.3364\n",
      "Epoch 3/200\n",
      "2553/2553 [==============================] - 0s 124us/sample - loss: 1.0729 - accuracy: 0.3995 - val_loss: 1.0911 - val_accuracy: 0.3271\n",
      "Epoch 4/200\n",
      "2553/2553 [==============================] - 0s 117us/sample - loss: 1.0667 - accuracy: 0.4121 - val_loss: 1.0838 - val_accuracy: 0.3551\n",
      "Epoch 5/200\n",
      "2553/2553 [==============================] - 0s 119us/sample - loss: 1.0606 - accuracy: 0.4246 - val_loss: 1.0764 - val_accuracy: 0.3645\n",
      "Epoch 6/200\n",
      "2553/2553 [==============================] - 0s 118us/sample - loss: 1.0548 - accuracy: 0.4305 - val_loss: 1.0698 - val_accuracy: 0.4206\n",
      "Epoch 7/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 141us/sample - loss: 1.0493 - accuracy: 0.4348 - val_loss: 1.0632 - val_accuracy: 0.4206\n",
      "Epoch 8/200\n",
      "2553/2553 [==============================] - 0s 161us/sample - loss: 1.0441 - accuracy: 0.4422 - val_loss: 1.0571 - val_accuracy: 0.4299\n",
      "Epoch 9/200\n",
      "2553/2553 [==============================] - 0s 150us/sample - loss: 1.0390 - accuracy: 0.4497 - val_loss: 1.0514 - val_accuracy: 0.4393\n",
      "Epoch 10/200\n",
      "2553/2553 [==============================] - 0s 125us/sample - loss: 1.0339 - accuracy: 0.4532 - val_loss: 1.0460 - val_accuracy: 0.4486\n",
      "Epoch 11/200\n",
      "2553/2553 [==============================] - 0s 122us/sample - loss: 1.0291 - accuracy: 0.4610 - val_loss: 1.0409 - val_accuracy: 0.4766\n",
      "Epoch 12/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.0246 - accuracy: 0.4642 - val_loss: 1.0364 - val_accuracy: 0.4486\n",
      "Epoch 13/200\n",
      "2553/2553 [==============================] - 0s 121us/sample - loss: 1.0203 - accuracy: 0.4673 - val_loss: 1.0321 - val_accuracy: 0.4486\n",
      "Epoch 14/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.0162 - accuracy: 0.4677 - val_loss: 1.0285 - val_accuracy: 0.4486\n",
      "Epoch 15/200\n",
      "2553/2553 [==============================] - 0s 117us/sample - loss: 1.0125 - accuracy: 0.4728 - val_loss: 1.0242 - val_accuracy: 0.4579\n",
      "Epoch 16/200\n",
      "2553/2553 [==============================] - 0s 127us/sample - loss: 1.0093 - accuracy: 0.4704 - val_loss: 1.0205 - val_accuracy: 0.4766\n",
      "Epoch 17/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 1.0066 - accuracy: 0.4743 - val_loss: 1.0172 - val_accuracy: 0.4673\n",
      "Epoch 18/200\n",
      "2553/2553 [==============================] - 0s 119us/sample - loss: 1.0042 - accuracy: 0.4759 - val_loss: 1.0141 - val_accuracy: 0.4766\n",
      "Epoch 19/200\n",
      "2553/2553 [==============================] - 0s 117us/sample - loss: 1.0021 - accuracy: 0.4779 - val_loss: 1.0116 - val_accuracy: 0.4579\n",
      "Epoch 20/200\n",
      "2553/2553 [==============================] - 0s 122us/sample - loss: 1.0002 - accuracy: 0.4830 - val_loss: 1.0096 - val_accuracy: 0.4673\n",
      "Epoch 21/200\n",
      "2553/2553 [==============================] - 0s 118us/sample - loss: 0.9986 - accuracy: 0.4837 - val_loss: 1.0077 - val_accuracy: 0.4673\n",
      "Epoch 22/200\n",
      "2553/2553 [==============================] - 0s 122us/sample - loss: 0.9972 - accuracy: 0.4845 - val_loss: 1.0063 - val_accuracy: 0.4579\n",
      "Epoch 23/200\n",
      "2553/2553 [==============================] - 0s 117us/sample - loss: 0.9960 - accuracy: 0.4818 - val_loss: 1.0051 - val_accuracy: 0.4579\n",
      "Epoch 24/200\n",
      "2553/2553 [==============================] - 0s 117us/sample - loss: 0.9950 - accuracy: 0.4794 - val_loss: 1.0040 - val_accuracy: 0.4579\n",
      "Epoch 25/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 0.9941 - accuracy: 0.4767 - val_loss: 1.0030 - val_accuracy: 0.4766\n",
      "Epoch 26/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 0.9933 - accuracy: 0.4806 - val_loss: 1.0019 - val_accuracy: 0.4860\n",
      "Epoch 27/200\n",
      "2553/2553 [==============================] - 0s 117us/sample - loss: 0.9926 - accuracy: 0.4814 - val_loss: 1.0010 - val_accuracy: 0.4766\n",
      "Epoch 28/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 0.9920 - accuracy: 0.4853 - val_loss: 1.0005 - val_accuracy: 0.4766\n",
      "Epoch 29/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 0.9914 - accuracy: 0.4861 - val_loss: 0.9998 - val_accuracy: 0.4673\n",
      "Epoch 30/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 0.9909 - accuracy: 0.4861 - val_loss: 0.9992 - val_accuracy: 0.4579\n",
      "Epoch 31/200\n",
      "2553/2553 [==============================] - 0s 115us/sample - loss: 0.9904 - accuracy: 0.4881 - val_loss: 0.9986 - val_accuracy: 0.4673\n",
      "Epoch 32/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 0.9899 - accuracy: 0.4939 - val_loss: 0.9980 - val_accuracy: 0.4673\n",
      "Epoch 33/200\n",
      "2553/2553 [==============================] - 0s 115us/sample - loss: 0.9895 - accuracy: 0.4990 - val_loss: 0.9973 - val_accuracy: 0.4953\n",
      "Epoch 34/200\n",
      "2553/2553 [==============================] - 0s 121us/sample - loss: 0.9891 - accuracy: 0.5022 - val_loss: 0.9971 - val_accuracy: 0.4953\n",
      "Epoch 35/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 0.9887 - accuracy: 0.5069 - val_loss: 0.9968 - val_accuracy: 0.4953\n",
      "Epoch 36/200\n",
      "2553/2553 [==============================] - 0s 125us/sample - loss: 0.9884 - accuracy: 0.5100 - val_loss: 0.9965 - val_accuracy: 0.4953\n",
      "Epoch 37/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 0.9880 - accuracy: 0.5116 - val_loss: 0.9963 - val_accuracy: 0.4953\n",
      "Epoch 38/200\n",
      "2553/2553 [==============================] - 0s 117us/sample - loss: 0.9877 - accuracy: 0.5123 - val_loss: 0.9960 - val_accuracy: 0.4953\n",
      "Epoch 39/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 0.9874 - accuracy: 0.5116 - val_loss: 0.9958 - val_accuracy: 0.4860\n",
      "Epoch 40/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 0.9871 - accuracy: 0.5119 - val_loss: 0.9956 - val_accuracy: 0.4860\n",
      "Epoch 41/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 0.9868 - accuracy: 0.5112 - val_loss: 0.9955 - val_accuracy: 0.4860\n",
      "Epoch 42/200\n",
      "2553/2553 [==============================] - 0s 123us/sample - loss: 0.9866 - accuracy: 0.5112 - val_loss: 0.9953 - val_accuracy: 0.4860\n",
      "Epoch 43/200\n",
      "2553/2553 [==============================] - 0s 122us/sample - loss: 0.9863 - accuracy: 0.5123 - val_loss: 0.9952 - val_accuracy: 0.4860\n",
      "Epoch 44/200\n",
      "2553/2553 [==============================] - 0s 117us/sample - loss: 0.9861 - accuracy: 0.5135 - val_loss: 0.9952 - val_accuracy: 0.4860\n",
      "Epoch 45/200\n",
      "2553/2553 [==============================] - 0s 119us/sample - loss: 0.9859 - accuracy: 0.5139 - val_loss: 0.9950 - val_accuracy: 0.4860\n",
      "Epoch 46/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 0.9856 - accuracy: 0.5143 - val_loss: 0.9946 - val_accuracy: 0.4860\n",
      "Epoch 47/200\n",
      "2553/2553 [==============================] - 0s 119us/sample - loss: 0.9854 - accuracy: 0.5143 - val_loss: 0.9945 - val_accuracy: 0.4860\n",
      "Epoch 48/200\n",
      "2553/2553 [==============================] - 0s 115us/sample - loss: 0.9852 - accuracy: 0.5151 - val_loss: 0.9942 - val_accuracy: 0.4860\n",
      "Epoch 49/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 0.9850 - accuracy: 0.5151 - val_loss: 0.9942 - val_accuracy: 0.4860\n",
      "Epoch 50/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 0.9848 - accuracy: 0.5159 - val_loss: 0.9940 - val_accuracy: 0.4860\n",
      "Epoch 51/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 0.9846 - accuracy: 0.5155 - val_loss: 0.9938 - val_accuracy: 0.4860\n",
      "Epoch 52/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 0.9844 - accuracy: 0.5151 - val_loss: 0.9938 - val_accuracy: 0.4860\n",
      "Epoch 53/200\n",
      "2553/2553 [==============================] - 0s 115us/sample - loss: 0.9842 - accuracy: 0.5151 - val_loss: 0.9937 - val_accuracy: 0.4860\n",
      "Epoch 54/200\n",
      "2553/2553 [==============================] - 0s 118us/sample - loss: 0.9840 - accuracy: 0.5163 - val_loss: 0.9935 - val_accuracy: 0.4860\n",
      "Epoch 55/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 0.9838 - accuracy: 0.5166 - val_loss: 0.9934 - val_accuracy: 0.4860\n",
      "Epoch 56/200\n",
      "2553/2553 [==============================] - 0s 115us/sample - loss: 0.9836 - accuracy: 0.5174 - val_loss: 0.9935 - val_accuracy: 0.4860\n",
      "Epoch 57/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 0.9835 - accuracy: 0.5178 - val_loss: 0.9934 - val_accuracy: 0.4766\n",
      "Epoch 58/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 0.9833 - accuracy: 0.5170 - val_loss: 0.9932 - val_accuracy: 0.4766\n",
      "Epoch 59/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 0.9831 - accuracy: 0.5174 - val_loss: 0.9932 - val_accuracy: 0.4766\n",
      "Epoch 60/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 0.9829 - accuracy: 0.5178 - val_loss: 0.9933 - val_accuracy: 0.4766\n",
      "Epoch 61/200\n",
      "2553/2553 [==============================] - 0s 119us/sample - loss: 0.9827 - accuracy: 0.5174 - val_loss: 0.9931 - val_accuracy: 0.4766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 0.9826 - accuracy: 0.5174 - val_loss: 0.9929 - val_accuracy: 0.4766\n",
      "Epoch 63/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 0.9824 - accuracy: 0.5166 - val_loss: 0.9929 - val_accuracy: 0.4766\n",
      "Epoch 64/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 0.9822 - accuracy: 0.5182 - val_loss: 0.9929 - val_accuracy: 0.4766\n",
      "Epoch 65/200\n",
      "2553/2553 [==============================] - 0s 118us/sample - loss: 0.9821 - accuracy: 0.5174 - val_loss: 0.9927 - val_accuracy: 0.4766\n",
      "Epoch 66/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 0.9819 - accuracy: 0.5174 - val_loss: 0.9926 - val_accuracy: 0.4766\n",
      "Epoch 67/200\n",
      "2553/2553 [==============================] - 0s 115us/sample - loss: 0.9817 - accuracy: 0.5170 - val_loss: 0.9924 - val_accuracy: 0.4766\n",
      "Epoch 68/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 0.9816 - accuracy: 0.5178 - val_loss: 0.9923 - val_accuracy: 0.4766\n",
      "Epoch 69/200\n",
      "2553/2553 [==============================] - 0s 115us/sample - loss: 0.9814 - accuracy: 0.5178 - val_loss: 0.9921 - val_accuracy: 0.4766\n",
      "Epoch 70/200\n",
      "2553/2553 [==============================] - 0s 120us/sample - loss: 0.9812 - accuracy: 0.5174 - val_loss: 0.9919 - val_accuracy: 0.4766\n",
      "Epoch 71/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 0.9810 - accuracy: 0.5178 - val_loss: 0.9918 - val_accuracy: 0.4766\n",
      "Epoch 72/200\n",
      "2553/2553 [==============================] - 0s 118us/sample - loss: 0.9809 - accuracy: 0.5182 - val_loss: 0.9916 - val_accuracy: 0.4860\n",
      "Epoch 73/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 0.9807 - accuracy: 0.5186 - val_loss: 0.9915 - val_accuracy: 0.4860\n",
      "Epoch 74/200\n",
      "2553/2553 [==============================] - 0s 117us/sample - loss: 0.9805 - accuracy: 0.5174 - val_loss: 0.9913 - val_accuracy: 0.4860\n",
      "Epoch 75/200\n",
      "2553/2553 [==============================] - 0s 115us/sample - loss: 0.9804 - accuracy: 0.5174 - val_loss: 0.9911 - val_accuracy: 0.4860\n",
      "Epoch 76/200\n",
      "2553/2553 [==============================] - 0s 118us/sample - loss: 0.9802 - accuracy: 0.5182 - val_loss: 0.9909 - val_accuracy: 0.4860\n",
      "Epoch 77/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 0.9801 - accuracy: 0.5182 - val_loss: 0.9907 - val_accuracy: 0.4860\n",
      "Epoch 78/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 0.9799 - accuracy: 0.5190 - val_loss: 0.9906 - val_accuracy: 0.4860\n",
      "Epoch 79/200\n",
      "2553/2553 [==============================] - 0s 118us/sample - loss: 0.9798 - accuracy: 0.5190 - val_loss: 0.9904 - val_accuracy: 0.4953\n",
      "Epoch 80/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 0.9796 - accuracy: 0.5186 - val_loss: 0.9901 - val_accuracy: 0.4953\n",
      "Epoch 81/200\n",
      "2553/2553 [==============================] - 0s 117us/sample - loss: 0.9794 - accuracy: 0.5186 - val_loss: 0.9901 - val_accuracy: 0.4953\n",
      "Epoch 82/200\n",
      "2553/2553 [==============================] - 0s 117us/sample - loss: 0.9793 - accuracy: 0.5190 - val_loss: 0.9899 - val_accuracy: 0.4953\n",
      "Epoch 83/200\n",
      "2553/2553 [==============================] - 0s 122us/sample - loss: 0.9792 - accuracy: 0.5190 - val_loss: 0.9897 - val_accuracy: 0.4953\n",
      "Epoch 84/200\n",
      "2553/2553 [==============================] - 0s 115us/sample - loss: 0.9790 - accuracy: 0.5186 - val_loss: 0.9896 - val_accuracy: 0.4953\n",
      "Epoch 85/200\n",
      "2553/2553 [==============================] - 0s 120us/sample - loss: 0.9789 - accuracy: 0.5194 - val_loss: 0.9895 - val_accuracy: 0.4953\n",
      "Epoch 86/200\n",
      "2553/2553 [==============================] - 0s 117us/sample - loss: 0.9787 - accuracy: 0.5190 - val_loss: 0.9894 - val_accuracy: 0.4953\n",
      "Epoch 87/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 0.9786 - accuracy: 0.5202 - val_loss: 0.9892 - val_accuracy: 0.4953\n",
      "Epoch 88/200\n",
      "2553/2553 [==============================] - 0s 121us/sample - loss: 0.9785 - accuracy: 0.5194 - val_loss: 0.9891 - val_accuracy: 0.4953\n",
      "Epoch 89/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 0.9783 - accuracy: 0.5202 - val_loss: 0.9890 - val_accuracy: 0.4953\n",
      "Epoch 90/200\n",
      "2553/2553 [==============================] - 0s 137us/sample - loss: 0.9782 - accuracy: 0.5198 - val_loss: 0.9889 - val_accuracy: 0.4953\n",
      "Epoch 91/200\n",
      "2553/2553 [==============================] - 0s 164us/sample - loss: 0.9780 - accuracy: 0.5202 - val_loss: 0.9888 - val_accuracy: 0.4953\n",
      "Epoch 92/200\n",
      "2553/2553 [==============================] - 0s 163us/sample - loss: 0.9779 - accuracy: 0.5194 - val_loss: 0.9886 - val_accuracy: 0.4953\n",
      "Epoch 93/200\n",
      "2553/2553 [==============================] - 0s 148us/sample - loss: 0.9777 - accuracy: 0.5198 - val_loss: 0.9886 - val_accuracy: 0.4953\n",
      "Epoch 94/200\n",
      "2553/2553 [==============================] - 0s 125us/sample - loss: 0.9776 - accuracy: 0.5194 - val_loss: 0.9885 - val_accuracy: 0.4953\n",
      "Epoch 95/200\n",
      "2553/2553 [==============================] - 0s 120us/sample - loss: 0.9775 - accuracy: 0.5194 - val_loss: 0.9883 - val_accuracy: 0.4953\n",
      "Epoch 96/200\n",
      "2553/2553 [==============================] - 0s 120us/sample - loss: 0.9774 - accuracy: 0.5190 - val_loss: 0.9882 - val_accuracy: 0.4953\n",
      "Epoch 97/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 0.9772 - accuracy: 0.5190 - val_loss: 0.9880 - val_accuracy: 0.4953\n",
      "Epoch 98/200\n",
      "2553/2553 [==============================] - 0s 118us/sample - loss: 0.9771 - accuracy: 0.5194 - val_loss: 0.9879 - val_accuracy: 0.4953\n",
      "Epoch 99/200\n",
      "2553/2553 [==============================] - 0s 123us/sample - loss: 0.9770 - accuracy: 0.5190 - val_loss: 0.9878 - val_accuracy: 0.4953\n",
      "Epoch 100/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 0.9768 - accuracy: 0.5198 - val_loss: 0.9877 - val_accuracy: 0.4953\n",
      "Epoch 101/200\n",
      "2553/2553 [==============================] - 0s 120us/sample - loss: 0.9767 - accuracy: 0.5202 - val_loss: 0.9875 - val_accuracy: 0.4953\n",
      "Epoch 102/200\n",
      "2553/2553 [==============================] - 0s 120us/sample - loss: 0.9766 - accuracy: 0.5194 - val_loss: 0.9874 - val_accuracy: 0.4953\n",
      "Epoch 103/200\n",
      "2553/2553 [==============================] - 0s 122us/sample - loss: 0.9765 - accuracy: 0.5202 - val_loss: 0.9873 - val_accuracy: 0.4953\n",
      "Epoch 104/200\n",
      "2553/2553 [==============================] - 0s 120us/sample - loss: 0.9763 - accuracy: 0.5198 - val_loss: 0.9873 - val_accuracy: 0.4953\n",
      "Epoch 105/200\n",
      "2553/2553 [==============================] - 0s 127us/sample - loss: 0.9762 - accuracy: 0.5198 - val_loss: 0.9871 - val_accuracy: 0.4953\n",
      "Epoch 106/200\n",
      "2553/2553 [==============================] - 0s 130us/sample - loss: 0.9761 - accuracy: 0.5202 - val_loss: 0.9869 - val_accuracy: 0.4953\n",
      "Epoch 107/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 0.9759 - accuracy: 0.5198 - val_loss: 0.9868 - val_accuracy: 0.4953\n",
      "Epoch 108/200\n",
      "2553/2553 [==============================] - 0s 123us/sample - loss: 0.9758 - accuracy: 0.5206 - val_loss: 0.9866 - val_accuracy: 0.4953\n",
      "Epoch 109/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 0.9757 - accuracy: 0.5210 - val_loss: 0.9865 - val_accuracy: 0.4953\n",
      "Epoch 110/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 0.9756 - accuracy: 0.5210 - val_loss: 0.9862 - val_accuracy: 0.4953\n",
      "Epoch 111/200\n",
      "2553/2553 [==============================] - 0s 125us/sample - loss: 0.9755 - accuracy: 0.5213 - val_loss: 0.9861 - val_accuracy: 0.4953\n",
      "Epoch 112/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 0.9754 - accuracy: 0.5213 - val_loss: 0.9858 - val_accuracy: 0.4953\n",
      "Epoch 113/200\n",
      "2553/2553 [==============================] - 0s 115us/sample - loss: 0.9752 - accuracy: 0.5221 - val_loss: 0.9857 - val_accuracy: 0.4953\n",
      "Epoch 114/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 0.9751 - accuracy: 0.5217 - val_loss: 0.9857 - val_accuracy: 0.4953\n",
      "Epoch 115/200\n",
      "2553/2553 [==============================] - 0s 124us/sample - loss: 0.9750 - accuracy: 0.5213 - val_loss: 0.9854 - val_accuracy: 0.4953\n",
      "Epoch 116/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 114us/sample - loss: 0.9749 - accuracy: 0.5221 - val_loss: 0.9853 - val_accuracy: 0.4953\n",
      "Epoch 117/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 0.9748 - accuracy: 0.5221 - val_loss: 0.9851 - val_accuracy: 0.4953\n",
      "Epoch 118/200\n",
      "2553/2553 [==============================] - 0s 115us/sample - loss: 0.9746 - accuracy: 0.5225 - val_loss: 0.9849 - val_accuracy: 0.4953\n",
      "Epoch 119/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 0.9745 - accuracy: 0.5221 - val_loss: 0.9849 - val_accuracy: 0.4953\n",
      "Epoch 120/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 0.9744 - accuracy: 0.5225 - val_loss: 0.9848 - val_accuracy: 0.4953\n",
      "Epoch 121/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 0.9743 - accuracy: 0.5225 - val_loss: 0.9847 - val_accuracy: 0.5047\n",
      "Epoch 122/200\n",
      "2553/2553 [==============================] - 0s 118us/sample - loss: 0.9742 - accuracy: 0.5225 - val_loss: 0.9845 - val_accuracy: 0.5047\n",
      "Epoch 123/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 0.9741 - accuracy: 0.5233 - val_loss: 0.9844 - val_accuracy: 0.5047\n",
      "Epoch 124/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 0.9740 - accuracy: 0.5241 - val_loss: 0.9843 - val_accuracy: 0.5047\n",
      "Epoch 125/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 0.9739 - accuracy: 0.5241 - val_loss: 0.9842 - val_accuracy: 0.5047\n",
      "Epoch 126/200\n",
      "2553/2553 [==============================] - 0s 123us/sample - loss: 0.9738 - accuracy: 0.5245 - val_loss: 0.9842 - val_accuracy: 0.5047\n",
      "Epoch 127/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 0.9737 - accuracy: 0.5245 - val_loss: 0.9840 - val_accuracy: 0.5047\n",
      "Epoch 128/200\n",
      "2553/2553 [==============================] - 0s 118us/sample - loss: 0.9736 - accuracy: 0.5245 - val_loss: 0.9838 - val_accuracy: 0.4953\n",
      "Epoch 129/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 0.9735 - accuracy: 0.5241 - val_loss: 0.9837 - val_accuracy: 0.4953\n",
      "Epoch 130/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 0.9734 - accuracy: 0.5241 - val_loss: 0.9837 - val_accuracy: 0.4953\n",
      "Epoch 131/200\n",
      "2553/2553 [==============================] - 0s 125us/sample - loss: 0.9733 - accuracy: 0.5241 - val_loss: 0.9836 - val_accuracy: 0.4953\n",
      "Epoch 132/200\n",
      "2553/2553 [==============================] - 0s 115us/sample - loss: 0.9731 - accuracy: 0.5245 - val_loss: 0.9836 - val_accuracy: 0.4953\n",
      "Epoch 133/200\n",
      "2553/2553 [==============================] - 0s 121us/sample - loss: 0.9730 - accuracy: 0.5241 - val_loss: 0.9834 - val_accuracy: 0.5047\n",
      "Epoch 134/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 0.9729 - accuracy: 0.5249 - val_loss: 0.9832 - val_accuracy: 0.5047\n",
      "Epoch 135/200\n",
      "2553/2553 [==============================] - 0s 118us/sample - loss: 0.9728 - accuracy: 0.5249 - val_loss: 0.9833 - val_accuracy: 0.5047\n",
      "Epoch 136/200\n",
      "2553/2553 [==============================] - 0s 119us/sample - loss: 0.9727 - accuracy: 0.5245 - val_loss: 0.9831 - val_accuracy: 0.5047\n",
      "Epoch 137/200\n",
      "2553/2553 [==============================] - 0s 125us/sample - loss: 0.9726 - accuracy: 0.5245 - val_loss: 0.9828 - val_accuracy: 0.5047\n",
      "Epoch 138/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 0.9725 - accuracy: 0.5249 - val_loss: 0.9827 - val_accuracy: 0.5047\n",
      "Epoch 139/200\n",
      "2553/2553 [==============================] - 0s 123us/sample - loss: 0.9723 - accuracy: 0.5249 - val_loss: 0.9826 - val_accuracy: 0.5047\n",
      "Epoch 140/200\n",
      "2553/2553 [==============================] - 0s 140us/sample - loss: 0.9722 - accuracy: 0.5245 - val_loss: 0.9824 - val_accuracy: 0.5047\n",
      "Epoch 141/200\n",
      "2553/2553 [==============================] - 0s 127us/sample - loss: 0.9721 - accuracy: 0.5245 - val_loss: 0.9822 - val_accuracy: 0.5047\n",
      "Epoch 142/200\n",
      "2553/2553 [==============================] - 0s 127us/sample - loss: 0.9720 - accuracy: 0.5241 - val_loss: 0.9822 - val_accuracy: 0.5047\n",
      "Epoch 143/200\n",
      "2553/2553 [==============================] - 0s 121us/sample - loss: 0.9719 - accuracy: 0.5249 - val_loss: 0.9820 - val_accuracy: 0.5047\n",
      "Epoch 144/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 0.9718 - accuracy: 0.5245 - val_loss: 0.9818 - val_accuracy: 0.5047\n",
      "Epoch 145/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 0.9716 - accuracy: 0.5245 - val_loss: 0.9817 - val_accuracy: 0.5047\n",
      "Epoch 146/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 0.9715 - accuracy: 0.5245 - val_loss: 0.9814 - val_accuracy: 0.5047\n",
      "Epoch 147/200\n",
      "2553/2553 [==============================] - 0s 115us/sample - loss: 0.9714 - accuracy: 0.5241 - val_loss: 0.9812 - val_accuracy: 0.5047\n",
      "Epoch 148/200\n",
      "2553/2553 [==============================] - 0s 119us/sample - loss: 0.9713 - accuracy: 0.5241 - val_loss: 0.9811 - val_accuracy: 0.5047\n",
      "Epoch 149/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 0.9712 - accuracy: 0.5241 - val_loss: 0.9809 - val_accuracy: 0.5047\n",
      "Epoch 150/200\n",
      "2553/2553 [==============================] - 0s 119us/sample - loss: 0.9711 - accuracy: 0.5249 - val_loss: 0.9808 - val_accuracy: 0.5047\n",
      "Epoch 151/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 0.9710 - accuracy: 0.5249 - val_loss: 0.9806 - val_accuracy: 0.5047\n",
      "Epoch 152/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 0.9708 - accuracy: 0.5257 - val_loss: 0.9803 - val_accuracy: 0.5047\n",
      "Epoch 153/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 0.9707 - accuracy: 0.5264 - val_loss: 0.9801 - val_accuracy: 0.5047\n",
      "Epoch 154/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 0.9706 - accuracy: 0.5264 - val_loss: 0.9799 - val_accuracy: 0.5047\n",
      "Epoch 155/200\n",
      "2553/2553 [==============================] - 0s 117us/sample - loss: 0.9705 - accuracy: 0.5264 - val_loss: 0.9797 - val_accuracy: 0.5047\n",
      "Epoch 156/200\n",
      "2553/2553 [==============================] - 0s 118us/sample - loss: 0.9704 - accuracy: 0.5257 - val_loss: 0.9794 - val_accuracy: 0.5047\n",
      "Epoch 157/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 0.9703 - accuracy: 0.5264 - val_loss: 0.9794 - val_accuracy: 0.5047\n",
      "Epoch 158/200\n",
      "2553/2553 [==============================] - 0s 115us/sample - loss: 0.9702 - accuracy: 0.5264 - val_loss: 0.9793 - val_accuracy: 0.5047\n",
      "Epoch 159/200\n",
      "2553/2553 [==============================] - 0s 117us/sample - loss: 0.9701 - accuracy: 0.5260 - val_loss: 0.9792 - val_accuracy: 0.5047\n",
      "Epoch 160/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 0.9700 - accuracy: 0.5257 - val_loss: 0.9789 - val_accuracy: 0.5047\n",
      "Epoch 161/200\n",
      "2553/2553 [==============================] - 0s 118us/sample - loss: 0.9699 - accuracy: 0.5257 - val_loss: 0.9789 - val_accuracy: 0.5047\n",
      "Epoch 162/200\n",
      "2553/2553 [==============================] - 0s 122us/sample - loss: 0.9698 - accuracy: 0.5253 - val_loss: 0.9784 - val_accuracy: 0.5047\n",
      "Epoch 163/200\n",
      "2553/2553 [==============================] - 0s 118us/sample - loss: 0.9696 - accuracy: 0.5260 - val_loss: 0.9785 - val_accuracy: 0.5047\n",
      "Epoch 164/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 0.9696 - accuracy: 0.5264 - val_loss: 0.9782 - val_accuracy: 0.5047\n",
      "Epoch 165/200\n",
      "2553/2553 [==============================] - 0s 119us/sample - loss: 0.9694 - accuracy: 0.5268 - val_loss: 0.9781 - val_accuracy: 0.5047\n",
      "Epoch 166/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 0.9693 - accuracy: 0.5268 - val_loss: 0.9779 - val_accuracy: 0.5047\n",
      "Epoch 167/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 0.9692 - accuracy: 0.5268 - val_loss: 0.9778 - val_accuracy: 0.5047\n",
      "Epoch 168/200\n",
      "2553/2553 [==============================] - 0s 119us/sample - loss: 0.9691 - accuracy: 0.5268 - val_loss: 0.9775 - val_accuracy: 0.5047\n",
      "Epoch 169/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 0.9690 - accuracy: 0.5272 - val_loss: 0.9774 - val_accuracy: 0.5047\n",
      "Epoch 170/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 119us/sample - loss: 0.9689 - accuracy: 0.5276 - val_loss: 0.9771 - val_accuracy: 0.5047\n",
      "Epoch 171/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 0.9688 - accuracy: 0.5280 - val_loss: 0.9770 - val_accuracy: 0.5047\n",
      "Epoch 172/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 0.9687 - accuracy: 0.5280 - val_loss: 0.9770 - val_accuracy: 0.5047\n",
      "Epoch 173/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 0.9686 - accuracy: 0.5284 - val_loss: 0.9768 - val_accuracy: 0.5047\n",
      "Epoch 174/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 0.9685 - accuracy: 0.5288 - val_loss: 0.9767 - val_accuracy: 0.5047\n",
      "Epoch 175/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 0.9684 - accuracy: 0.5276 - val_loss: 0.9764 - val_accuracy: 0.5047\n",
      "Epoch 176/200\n",
      "2553/2553 [==============================] - 0s 93us/sample - loss: 0.9683 - accuracy: 0.5288 - val_loss: 0.9762 - val_accuracy: 0.5047\n",
      "Epoch 177/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 0.9682 - accuracy: 0.5288 - val_loss: 0.9760 - val_accuracy: 0.5047\n",
      "Epoch 178/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 0.9681 - accuracy: 0.5307 - val_loss: 0.9761 - val_accuracy: 0.5047\n",
      "Epoch 179/200\n",
      "2553/2553 [==============================] - 0s 115us/sample - loss: 0.9680 - accuracy: 0.5304 - val_loss: 0.9758 - val_accuracy: 0.5047\n",
      "Epoch 180/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 0.9679 - accuracy: 0.5307 - val_loss: 0.9757 - val_accuracy: 0.5047\n",
      "Epoch 181/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 0.9678 - accuracy: 0.5311 - val_loss: 0.9753 - val_accuracy: 0.5140\n",
      "Epoch 182/200\n",
      "2553/2553 [==============================] - 0s 115us/sample - loss: 0.9677 - accuracy: 0.5315 - val_loss: 0.9752 - val_accuracy: 0.5140\n",
      "Epoch 183/200\n",
      "2553/2553 [==============================] - 0s 115us/sample - loss: 0.9676 - accuracy: 0.5307 - val_loss: 0.9749 - val_accuracy: 0.5140\n",
      "Epoch 184/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 0.9675 - accuracy: 0.5315 - val_loss: 0.9750 - val_accuracy: 0.5140\n",
      "Epoch 185/200\n",
      "2553/2553 [==============================] - 0s 119us/sample - loss: 0.9674 - accuracy: 0.5315 - val_loss: 0.9748 - val_accuracy: 0.5140\n",
      "Epoch 186/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 0.9673 - accuracy: 0.5315 - val_loss: 0.9746 - val_accuracy: 0.5140\n",
      "Epoch 187/200\n",
      "2553/2553 [==============================] - 0s 118us/sample - loss: 0.9672 - accuracy: 0.5315 - val_loss: 0.9746 - val_accuracy: 0.5140\n",
      "Epoch 188/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 0.9671 - accuracy: 0.5319 - val_loss: 0.9745 - val_accuracy: 0.5140\n",
      "Epoch 189/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 0.9670 - accuracy: 0.5319 - val_loss: 0.9745 - val_accuracy: 0.5140\n",
      "Epoch 190/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 0.9669 - accuracy: 0.5315 - val_loss: 0.9743 - val_accuracy: 0.5140\n",
      "Epoch 191/200\n",
      "2553/2553 [==============================] - 0s 117us/sample - loss: 0.9668 - accuracy: 0.5315 - val_loss: 0.9741 - val_accuracy: 0.5140\n",
      "Epoch 192/200\n",
      "2553/2553 [==============================] - 0s 119us/sample - loss: 0.9667 - accuracy: 0.5315 - val_loss: 0.9742 - val_accuracy: 0.5140\n",
      "Epoch 193/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 0.9666 - accuracy: 0.5315 - val_loss: 0.9741 - val_accuracy: 0.5140\n",
      "Epoch 194/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 0.9665 - accuracy: 0.5319 - val_loss: 0.9740 - val_accuracy: 0.5140\n",
      "Epoch 195/200\n",
      "2553/2553 [==============================] - 0s 117us/sample - loss: 0.9664 - accuracy: 0.5315 - val_loss: 0.9737 - val_accuracy: 0.5140\n",
      "Epoch 196/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 0.9663 - accuracy: 0.5319 - val_loss: 0.9737 - val_accuracy: 0.5140\n",
      "Epoch 197/200\n",
      "2553/2553 [==============================] - 0s 120us/sample - loss: 0.9662 - accuracy: 0.5323 - val_loss: 0.9735 - val_accuracy: 0.5140\n",
      "Epoch 198/200\n",
      "2553/2553 [==============================] - 0s 118us/sample - loss: 0.9661 - accuracy: 0.5331 - val_loss: 0.9734 - val_accuracy: 0.5140\n",
      "Epoch 199/200\n",
      "2553/2553 [==============================] - 0s 126us/sample - loss: 0.9661 - accuracy: 0.5323 - val_loss: 0.9733 - val_accuracy: 0.5140\n",
      "Epoch 200/200\n",
      "2553/2553 [==============================] - 0s 117us/sample - loss: 0.9660 - accuracy: 0.5327 - val_loss: 0.9732 - val_accuracy: 0.5140\n",
      "0.5140187 {'loss': 0.9659754360044325, 'accuracy': 0.5327066, 'val_loss': 0.9732264341595017, 'val_accuracy': 0.5140187}\n",
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        [(None, 29)]              0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 41)                1230      \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 10)                420       \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 3)                 33        \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 1,903\n",
      "Trainable params: 1,903\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2553 samples, validate on 107 samples\n",
      "Epoch 1/200\n",
      "2553/2553 [==============================] - 1s 313us/sample - loss: 1.1053 - accuracy: 0.3271 - val_loss: 1.1192 - val_accuracy: 0.2897\n",
      "Epoch 2/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1004 - accuracy: 0.3490 - val_loss: 1.1143 - val_accuracy: 0.3271\n",
      "Epoch 3/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0959 - accuracy: 0.3713 - val_loss: 1.1095 - val_accuracy: 0.3364\n",
      "Epoch 4/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0913 - accuracy: 0.3909 - val_loss: 1.1050 - val_accuracy: 0.3551\n",
      "Epoch 5/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0870 - accuracy: 0.4113 - val_loss: 1.1007 - val_accuracy: 0.3738\n",
      "Epoch 6/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0827 - accuracy: 0.4340 - val_loss: 1.0966 - val_accuracy: 0.4112\n",
      "Epoch 7/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0787 - accuracy: 0.4485 - val_loss: 1.0929 - val_accuracy: 0.4206\n",
      "Epoch 8/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0747 - accuracy: 0.4696 - val_loss: 1.0898 - val_accuracy: 0.4019\n",
      "Epoch 9/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.0706 - accuracy: 0.4708 - val_loss: 1.0867 - val_accuracy: 0.4019\n",
      "Epoch 10/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.0666 - accuracy: 0.4837 - val_loss: 1.0831 - val_accuracy: 0.4393\n",
      "Epoch 11/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0627 - accuracy: 0.4877 - val_loss: 1.0790 - val_accuracy: 0.4673\n",
      "Epoch 12/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.0587 - accuracy: 0.4939 - val_loss: 1.0740 - val_accuracy: 0.4766\n",
      "Epoch 13/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0547 - accuracy: 0.4978 - val_loss: 1.0692 - val_accuracy: 0.4766\n",
      "Epoch 14/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0506 - accuracy: 0.4978 - val_loss: 1.0647 - val_accuracy: 0.4766\n",
      "Epoch 15/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.0465 - accuracy: 0.4998 - val_loss: 1.0599 - val_accuracy: 0.4860\n",
      "Epoch 16/200\n",
      "2553/2553 [==============================] - 0s 71us/sample - loss: 1.0425 - accuracy: 0.5025 - val_loss: 1.0547 - val_accuracy: 0.4860\n",
      "Epoch 17/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0383 - accuracy: 0.5033 - val_loss: 1.0502 - val_accuracy: 0.4766\n",
      "Epoch 18/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0343 - accuracy: 0.5092 - val_loss: 1.0461 - val_accuracy: 0.4766\n",
      "Epoch 19/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.0304 - accuracy: 0.5116 - val_loss: 1.0426 - val_accuracy: 0.4766\n",
      "Epoch 20/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0266 - accuracy: 0.5135 - val_loss: 1.0390 - val_accuracy: 0.4673\n",
      "Epoch 21/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0230 - accuracy: 0.5182 - val_loss: 1.0358 - val_accuracy: 0.4579\n",
      "Epoch 22/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0195 - accuracy: 0.5210 - val_loss: 1.0328 - val_accuracy: 0.4673\n",
      "Epoch 23/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0163 - accuracy: 0.5225 - val_loss: 1.0302 - val_accuracy: 0.4860\n",
      "Epoch 24/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0131 - accuracy: 0.5257 - val_loss: 1.0278 - val_accuracy: 0.4953\n",
      "Epoch 25/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0102 - accuracy: 0.5268 - val_loss: 1.0256 - val_accuracy: 0.4860\n",
      "Epoch 26/200\n",
      "2553/2553 [==============================] - 0s 65us/sample - loss: 1.0074 - accuracy: 0.5292 - val_loss: 1.0231 - val_accuracy: 0.4953\n",
      "Epoch 27/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0047 - accuracy: 0.5280 - val_loss: 1.0207 - val_accuracy: 0.4953\n",
      "Epoch 28/200\n",
      "2553/2553 [==============================] - ETA: 0s - loss: 1.0065 - accuracy: 0.52 - 0s 58us/sample - loss: 1.0022 - accuracy: 0.5268 - val_loss: 1.0185 - val_accuracy: 0.4953\n",
      "Epoch 29/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 0.9998 - accuracy: 0.5264 - val_loss: 1.0165 - val_accuracy: 0.5047\n",
      "Epoch 30/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 0.9976 - accuracy: 0.5264 - val_loss: 1.0146 - val_accuracy: 0.5047\n",
      "Epoch 31/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 0.9956 - accuracy: 0.5264 - val_loss: 1.0129 - val_accuracy: 0.5047\n",
      "Epoch 32/200\n",
      "2553/2553 [==============================] - 0s 67us/sample - loss: 0.9938 - accuracy: 0.5260 - val_loss: 1.0112 - val_accuracy: 0.5047\n",
      "Epoch 33/200\n",
      "2553/2553 [==============================] - 0s 75us/sample - loss: 0.9922 - accuracy: 0.5272 - val_loss: 1.0098 - val_accuracy: 0.5047\n",
      "Epoch 34/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 0.9907 - accuracy: 0.5272 - val_loss: 1.0084 - val_accuracy: 0.4953\n",
      "Epoch 35/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 0.9894 - accuracy: 0.5280 - val_loss: 1.0072 - val_accuracy: 0.4953\n",
      "Epoch 36/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 0.9882 - accuracy: 0.5288 - val_loss: 1.0062 - val_accuracy: 0.4953\n",
      "Epoch 37/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 0.9871 - accuracy: 0.5300 - val_loss: 1.0051 - val_accuracy: 0.4953\n",
      "Epoch 38/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 0.9862 - accuracy: 0.5319 - val_loss: 1.0041 - val_accuracy: 0.4953\n",
      "Epoch 39/200\n",
      "2553/2553 [==============================] - 0s 66us/sample - loss: 0.9853 - accuracy: 0.5311 - val_loss: 1.0033 - val_accuracy: 0.4953\n",
      "Epoch 40/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 0.9845 - accuracy: 0.5311 - val_loss: 1.0026 - val_accuracy: 0.4953\n",
      "Epoch 41/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 0.9839 - accuracy: 0.5307 - val_loss: 1.0019 - val_accuracy: 0.4953\n",
      "Epoch 42/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 0.9832 - accuracy: 0.5311 - val_loss: 1.0013 - val_accuracy: 0.4953\n",
      "Epoch 43/200\n",
      "2553/2553 [==============================] - 0s 66us/sample - loss: 0.9827 - accuracy: 0.5319 - val_loss: 1.0007 - val_accuracy: 0.4953\n",
      "Epoch 44/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 0.9822 - accuracy: 0.5311 - val_loss: 1.0001 - val_accuracy: 0.4953\n",
      "Epoch 45/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 0.9817 - accuracy: 0.5315 - val_loss: 0.9996 - val_accuracy: 0.4953\n",
      "Epoch 46/200\n",
      "2553/2553 [==============================] - 0s 65us/sample - loss: 0.9813 - accuracy: 0.5315 - val_loss: 0.9991 - val_accuracy: 0.4953\n",
      "Epoch 47/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 0.9809 - accuracy: 0.5315 - val_loss: 0.9986 - val_accuracy: 0.4953\n",
      "Epoch 48/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 0.9806 - accuracy: 0.5315 - val_loss: 0.9981 - val_accuracy: 0.4953\n",
      "Epoch 49/200\n",
      "2553/2553 [==============================] - 0s 66us/sample - loss: 0.9802 - accuracy: 0.5311 - val_loss: 0.9978 - val_accuracy: 0.4953\n",
      "Epoch 50/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 0.9799 - accuracy: 0.5311 - val_loss: 0.9974 - val_accuracy: 0.4953\n",
      "Epoch 51/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 0.9796 - accuracy: 0.5311 - val_loss: 0.9970 - val_accuracy: 0.4953\n",
      "Epoch 52/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 0.9793 - accuracy: 0.5307 - val_loss: 0.9966 - val_accuracy: 0.4953\n",
      "Epoch 53/200\n",
      "2553/2553 [==============================] - 0s 69us/sample - loss: 0.9791 - accuracy: 0.5300 - val_loss: 0.9963 - val_accuracy: 0.4953\n",
      "Epoch 54/200\n",
      "2553/2553 [==============================] - 0s 65us/sample - loss: 0.9788 - accuracy: 0.5304 - val_loss: 0.9959 - val_accuracy: 0.4953\n",
      "Epoch 55/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 0.9786 - accuracy: 0.5307 - val_loss: 0.9956 - val_accuracy: 0.4953\n",
      "Epoch 56/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 0.9784 - accuracy: 0.5304 - val_loss: 0.9953 - val_accuracy: 0.4953\n",
      "Epoch 57/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 0.9781 - accuracy: 0.5304 - val_loss: 0.9950 - val_accuracy: 0.4953\n",
      "Epoch 58/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 0.9779 - accuracy: 0.5307 - val_loss: 0.9947 - val_accuracy: 0.5047\n",
      "Epoch 59/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 0.9777 - accuracy: 0.5307 - val_loss: 0.9944 - val_accuracy: 0.5047\n",
      "Epoch 60/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 0.9775 - accuracy: 0.5307 - val_loss: 0.9940 - val_accuracy: 0.5047\n",
      "Epoch 61/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 0.9773 - accuracy: 0.5307 - val_loss: 0.9938 - val_accuracy: 0.5047\n",
      "Epoch 62/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 0.9771 - accuracy: 0.5307 - val_loss: 0.9935 - val_accuracy: 0.5047\n",
      "Epoch 63/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 0.9769 - accuracy: 0.5307 - val_loss: 0.9932 - val_accuracy: 0.5047\n",
      "Epoch 64/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 0.9767 - accuracy: 0.5307 - val_loss: 0.9929 - val_accuracy: 0.5047\n",
      "Epoch 65/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 0.9765 - accuracy: 0.5307 - val_loss: 0.9926 - val_accuracy: 0.5047\n",
      "Epoch 66/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 0.9763 - accuracy: 0.5311 - val_loss: 0.9924 - val_accuracy: 0.5047\n",
      "Epoch 67/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 0.9761 - accuracy: 0.5311 - val_loss: 0.9921 - val_accuracy: 0.5047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 0.9760 - accuracy: 0.5311 - val_loss: 0.9919 - val_accuracy: 0.5047\n",
      "Epoch 69/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 0.9758 - accuracy: 0.5311 - val_loss: 0.9916 - val_accuracy: 0.5047\n",
      "Epoch 70/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 0.9756 - accuracy: 0.5315 - val_loss: 0.9913 - val_accuracy: 0.5047\n",
      "Epoch 71/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 0.9754 - accuracy: 0.5319 - val_loss: 0.9910 - val_accuracy: 0.5047\n",
      "Epoch 72/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 0.9752 - accuracy: 0.5315 - val_loss: 0.9908 - val_accuracy: 0.5047\n",
      "Epoch 73/200\n",
      "2553/2553 [==============================] - 0s 65us/sample - loss: 0.9751 - accuracy: 0.5319 - val_loss: 0.9905 - val_accuracy: 0.5047\n",
      "Epoch 74/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 0.9749 - accuracy: 0.5323 - val_loss: 0.9903 - val_accuracy: 0.5047\n",
      "Epoch 75/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 0.9748 - accuracy: 0.5327 - val_loss: 0.9900 - val_accuracy: 0.5047\n",
      "Epoch 76/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 0.9746 - accuracy: 0.5323 - val_loss: 0.9898 - val_accuracy: 0.5047\n",
      "Epoch 77/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 0.9744 - accuracy: 0.5323 - val_loss: 0.9895 - val_accuracy: 0.5047\n",
      "Epoch 78/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 0.9742 - accuracy: 0.5323 - val_loss: 0.9893 - val_accuracy: 0.5047\n",
      "Epoch 79/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 0.9741 - accuracy: 0.5319 - val_loss: 0.9891 - val_accuracy: 0.5047\n",
      "Epoch 80/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 0.9739 - accuracy: 0.5331 - val_loss: 0.9888 - val_accuracy: 0.5047\n",
      "Epoch 81/200\n",
      "2553/2553 [==============================] - 0s 68us/sample - loss: 0.9737 - accuracy: 0.5327 - val_loss: 0.9885 - val_accuracy: 0.5047\n",
      "Epoch 82/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 0.9736 - accuracy: 0.5327 - val_loss: 0.9882 - val_accuracy: 0.5047\n",
      "Epoch 83/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 0.9734 - accuracy: 0.5323 - val_loss: 0.9880 - val_accuracy: 0.5047\n",
      "Epoch 84/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 0.9732 - accuracy: 0.5331 - val_loss: 0.9877 - val_accuracy: 0.5047\n",
      "Epoch 85/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 0.9731 - accuracy: 0.5335 - val_loss: 0.9874 - val_accuracy: 0.5047\n",
      "Epoch 86/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 0.9729 - accuracy: 0.5331 - val_loss: 0.9872 - val_accuracy: 0.5047\n",
      "Epoch 87/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 0.9728 - accuracy: 0.5331 - val_loss: 0.9869 - val_accuracy: 0.5047\n",
      "Epoch 88/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 0.9726 - accuracy: 0.5343 - val_loss: 0.9867 - val_accuracy: 0.5047\n",
      "Epoch 89/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 0.9725 - accuracy: 0.5354 - val_loss: 0.9864 - val_accuracy: 0.5047\n",
      "Epoch 90/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 0.9723 - accuracy: 0.5354 - val_loss: 0.9861 - val_accuracy: 0.5047\n",
      "Epoch 91/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 0.9722 - accuracy: 0.5354 - val_loss: 0.9859 - val_accuracy: 0.5047\n",
      "Epoch 92/200\n",
      "2553/2553 [==============================] - 0s 65us/sample - loss: 0.9720 - accuracy: 0.5354 - val_loss: 0.9856 - val_accuracy: 0.5047\n",
      "Epoch 93/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 0.9718 - accuracy: 0.5354 - val_loss: 0.9854 - val_accuracy: 0.5047\n",
      "Epoch 94/200\n",
      "2553/2553 [==============================] - 0s 68us/sample - loss: 0.9717 - accuracy: 0.5354 - val_loss: 0.9850 - val_accuracy: 0.5047\n",
      "Epoch 95/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 0.9715 - accuracy: 0.5354 - val_loss: 0.9848 - val_accuracy: 0.5047\n",
      "Epoch 96/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 0.9714 - accuracy: 0.5354 - val_loss: 0.9845 - val_accuracy: 0.5047\n",
      "Epoch 97/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 0.9713 - accuracy: 0.5354 - val_loss: 0.9842 - val_accuracy: 0.5047\n",
      "Epoch 98/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 0.9711 - accuracy: 0.5354 - val_loss: 0.9839 - val_accuracy: 0.5047\n",
      "Epoch 99/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 0.9709 - accuracy: 0.5354 - val_loss: 0.9836 - val_accuracy: 0.5047\n",
      "Epoch 100/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 0.9708 - accuracy: 0.5354 - val_loss: 0.9834 - val_accuracy: 0.5047\n",
      "Epoch 101/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 0.9707 - accuracy: 0.5354 - val_loss: 0.9831 - val_accuracy: 0.5047\n",
      "Epoch 102/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 0.9705 - accuracy: 0.5362 - val_loss: 0.9828 - val_accuracy: 0.5047\n",
      "Epoch 103/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 0.9704 - accuracy: 0.5370 - val_loss: 0.9825 - val_accuracy: 0.5047\n",
      "Epoch 104/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 0.9702 - accuracy: 0.5370 - val_loss: 0.9822 - val_accuracy: 0.5047\n",
      "Epoch 105/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 0.9701 - accuracy: 0.5374 - val_loss: 0.9819 - val_accuracy: 0.5047\n",
      "Epoch 106/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 0.9699 - accuracy: 0.5382 - val_loss: 0.9816 - val_accuracy: 0.5047\n",
      "Epoch 107/200\n",
      "2553/2553 [==============================] - 0s 72us/sample - loss: 0.9698 - accuracy: 0.5386 - val_loss: 0.9814 - val_accuracy: 0.5047\n",
      "Epoch 108/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 0.9696 - accuracy: 0.5394 - val_loss: 0.9811 - val_accuracy: 0.5047\n",
      "Epoch 109/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 0.9695 - accuracy: 0.5390 - val_loss: 0.9809 - val_accuracy: 0.5047\n",
      "Epoch 110/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 0.9694 - accuracy: 0.5390 - val_loss: 0.9806 - val_accuracy: 0.5047\n",
      "Epoch 111/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 0.9693 - accuracy: 0.5390 - val_loss: 0.9804 - val_accuracy: 0.5047\n",
      "Epoch 112/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 0.9691 - accuracy: 0.5386 - val_loss: 0.9801 - val_accuracy: 0.5047\n",
      "Epoch 113/200\n",
      "2553/2553 [==============================] - 0s 66us/sample - loss: 0.9690 - accuracy: 0.5390 - val_loss: 0.9799 - val_accuracy: 0.5047\n",
      "Epoch 114/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 0.9689 - accuracy: 0.5386 - val_loss: 0.9796 - val_accuracy: 0.5047\n",
      "Epoch 115/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 0.9687 - accuracy: 0.5394 - val_loss: 0.9794 - val_accuracy: 0.5047\n",
      "Epoch 116/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 0.9686 - accuracy: 0.5394 - val_loss: 0.9791 - val_accuracy: 0.5047\n",
      "Epoch 117/200\n",
      "2553/2553 [==============================] - 0s 68us/sample - loss: 0.9685 - accuracy: 0.5390 - val_loss: 0.9789 - val_accuracy: 0.5047\n",
      "Epoch 118/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 0.9684 - accuracy: 0.5394 - val_loss: 0.9787 - val_accuracy: 0.5047\n",
      "Epoch 119/200\n",
      "2553/2553 [==============================] - 0s 65us/sample - loss: 0.9682 - accuracy: 0.5394 - val_loss: 0.9784 - val_accuracy: 0.5047\n",
      "Epoch 120/200\n",
      "2553/2553 [==============================] - 0s 72us/sample - loss: 0.9681 - accuracy: 0.5394 - val_loss: 0.9781 - val_accuracy: 0.5047\n",
      "Epoch 121/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 0.9679 - accuracy: 0.5390 - val_loss: 0.9778 - val_accuracy: 0.5047\n",
      "Epoch 122/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 0.9678 - accuracy: 0.5398 - val_loss: 0.9775 - val_accuracy: 0.5047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 0.9677 - accuracy: 0.5398 - val_loss: 0.9773 - val_accuracy: 0.5047\n",
      "Epoch 124/200\n",
      "2553/2553 [==============================] - 0s 65us/sample - loss: 0.9675 - accuracy: 0.5394 - val_loss: 0.9770 - val_accuracy: 0.5047\n",
      "Epoch 125/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 0.9674 - accuracy: 0.5394 - val_loss: 0.9767 - val_accuracy: 0.5047\n",
      "Epoch 126/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 0.9673 - accuracy: 0.5398 - val_loss: 0.9765 - val_accuracy: 0.5140\n",
      "Epoch 127/200\n",
      "2553/2553 [==============================] - 0s 66us/sample - loss: 0.9672 - accuracy: 0.5398 - val_loss: 0.9762 - val_accuracy: 0.5140\n",
      "Epoch 128/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 0.9670 - accuracy: 0.5398 - val_loss: 0.9760 - val_accuracy: 0.5140\n",
      "Epoch 129/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 0.9669 - accuracy: 0.5394 - val_loss: 0.9758 - val_accuracy: 0.5140\n",
      "Epoch 130/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 0.9668 - accuracy: 0.5394 - val_loss: 0.9755 - val_accuracy: 0.5140\n",
      "Epoch 131/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 0.9667 - accuracy: 0.5398 - val_loss: 0.9753 - val_accuracy: 0.5140\n",
      "Epoch 132/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 0.9666 - accuracy: 0.5398 - val_loss: 0.9751 - val_accuracy: 0.5140\n",
      "Epoch 133/200\n",
      "2553/2553 [==============================] - 0s 65us/sample - loss: 0.9665 - accuracy: 0.5401 - val_loss: 0.9749 - val_accuracy: 0.5140\n",
      "Epoch 134/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 0.9663 - accuracy: 0.5398 - val_loss: 0.9746 - val_accuracy: 0.5140\n",
      "Epoch 135/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 0.9662 - accuracy: 0.5401 - val_loss: 0.9744 - val_accuracy: 0.5140\n",
      "Epoch 136/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 0.9661 - accuracy: 0.5405 - val_loss: 0.9742 - val_accuracy: 0.5140\n",
      "Epoch 137/200\n",
      "2553/2553 [==============================] - 0s 68us/sample - loss: 0.9660 - accuracy: 0.5401 - val_loss: 0.9740 - val_accuracy: 0.5140\n",
      "Epoch 138/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 0.9659 - accuracy: 0.5398 - val_loss: 0.9738 - val_accuracy: 0.5140\n",
      "Epoch 139/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 0.9658 - accuracy: 0.5401 - val_loss: 0.9737 - val_accuracy: 0.5140\n",
      "Epoch 140/200\n",
      "2553/2553 [==============================] - 0s 65us/sample - loss: 0.9657 - accuracy: 0.5401 - val_loss: 0.9734 - val_accuracy: 0.5140\n",
      "Epoch 141/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 0.9656 - accuracy: 0.5405 - val_loss: 0.9732 - val_accuracy: 0.5140\n",
      "Epoch 142/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 0.9655 - accuracy: 0.5401 - val_loss: 0.9730 - val_accuracy: 0.5140\n",
      "Epoch 143/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 0.9654 - accuracy: 0.5394 - val_loss: 0.9728 - val_accuracy: 0.5140\n",
      "Epoch 144/200\n",
      "2553/2553 [==============================] - 0s 69us/sample - loss: 0.9653 - accuracy: 0.5398 - val_loss: 0.9727 - val_accuracy: 0.5140\n",
      "Epoch 145/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 0.9652 - accuracy: 0.5398 - val_loss: 0.9725 - val_accuracy: 0.5140\n",
      "Epoch 146/200\n",
      "2553/2553 [==============================] - 0s 65us/sample - loss: 0.9650 - accuracy: 0.5394 - val_loss: 0.9723 - val_accuracy: 0.5140\n",
      "Epoch 147/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 0.9650 - accuracy: 0.5390 - val_loss: 0.9721 - val_accuracy: 0.5140\n",
      "Epoch 148/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 0.9649 - accuracy: 0.5394 - val_loss: 0.9719 - val_accuracy: 0.5140\n",
      "Epoch 149/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 0.9647 - accuracy: 0.5386 - val_loss: 0.9717 - val_accuracy: 0.5140\n",
      "Epoch 150/200\n",
      "2553/2553 [==============================] - 0s 66us/sample - loss: 0.9646 - accuracy: 0.5390 - val_loss: 0.9715 - val_accuracy: 0.5140\n",
      "Epoch 151/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 0.9645 - accuracy: 0.5386 - val_loss: 0.9714 - val_accuracy: 0.5140\n",
      "Epoch 152/200\n",
      "2553/2553 [==============================] - 0s 65us/sample - loss: 0.9644 - accuracy: 0.5394 - val_loss: 0.9712 - val_accuracy: 0.5140\n",
      "Epoch 153/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 0.9643 - accuracy: 0.5390 - val_loss: 0.9710 - val_accuracy: 0.5140\n",
      "Epoch 154/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 0.9642 - accuracy: 0.5394 - val_loss: 0.9708 - val_accuracy: 0.5140\n",
      "Epoch 155/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 0.9641 - accuracy: 0.5386 - val_loss: 0.9707 - val_accuracy: 0.5140\n",
      "Epoch 156/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 0.9640 - accuracy: 0.5386 - val_loss: 0.9705 - val_accuracy: 0.5140\n",
      "Epoch 157/200\n",
      "2553/2553 [==============================] - 0s 66us/sample - loss: 0.9639 - accuracy: 0.5386 - val_loss: 0.9703 - val_accuracy: 0.5140\n",
      "Epoch 158/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 0.9638 - accuracy: 0.5390 - val_loss: 0.9701 - val_accuracy: 0.5140\n",
      "Epoch 159/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 0.9637 - accuracy: 0.5398 - val_loss: 0.9699 - val_accuracy: 0.5140\n",
      "Epoch 160/200\n",
      "2553/2553 [==============================] - 0s 68us/sample - loss: 0.9636 - accuracy: 0.5394 - val_loss: 0.9697 - val_accuracy: 0.5140\n",
      "Epoch 161/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 0.9635 - accuracy: 0.5398 - val_loss: 0.9695 - val_accuracy: 0.5140\n",
      "Epoch 162/200\n",
      "2553/2553 [==============================] - 0s 65us/sample - loss: 0.9634 - accuracy: 0.5398 - val_loss: 0.9694 - val_accuracy: 0.5140\n",
      "Epoch 163/200\n",
      "2553/2553 [==============================] - 0s 80us/sample - loss: 0.9633 - accuracy: 0.5398 - val_loss: 0.9692 - val_accuracy: 0.5140\n",
      "Epoch 164/200\n",
      "2553/2553 [==============================] - 0s 86us/sample - loss: 0.9632 - accuracy: 0.5398 - val_loss: 0.9690 - val_accuracy: 0.5140\n",
      "Epoch 165/200\n",
      "2553/2553 [==============================] - 0s 96us/sample - loss: 0.9631 - accuracy: 0.5398 - val_loss: 0.9688 - val_accuracy: 0.5140\n",
      "Epoch 166/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 0.9630 - accuracy: 0.5398 - val_loss: 0.9686 - val_accuracy: 0.5140\n",
      "Epoch 167/200\n",
      "2553/2553 [==============================] - 0s 98us/sample - loss: 0.9629 - accuracy: 0.5398 - val_loss: 0.9684 - val_accuracy: 0.5234\n",
      "Epoch 168/200\n",
      "2553/2553 [==============================] - 0s 78us/sample - loss: 0.9628 - accuracy: 0.5405 - val_loss: 0.9682 - val_accuracy: 0.5234\n",
      "Epoch 169/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 0.9627 - accuracy: 0.5409 - val_loss: 0.9680 - val_accuracy: 0.5234\n",
      "Epoch 170/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 0.9626 - accuracy: 0.5413 - val_loss: 0.9678 - val_accuracy: 0.5234\n",
      "Epoch 171/200\n",
      "2553/2553 [==============================] - 0s 77us/sample - loss: 0.9625 - accuracy: 0.5405 - val_loss: 0.9676 - val_accuracy: 0.5234\n",
      "Epoch 172/200\n",
      "2553/2553 [==============================] - 0s 84us/sample - loss: 0.9624 - accuracy: 0.5413 - val_loss: 0.9674 - val_accuracy: 0.5234\n",
      "Epoch 173/200\n",
      "2553/2553 [==============================] - 0s 84us/sample - loss: 0.9623 - accuracy: 0.5413 - val_loss: 0.9672 - val_accuracy: 0.5234\n",
      "Epoch 174/200\n",
      "2553/2553 [==============================] - 0s 71us/sample - loss: 0.9622 - accuracy: 0.5417 - val_loss: 0.9670 - val_accuracy: 0.5234\n",
      "Epoch 175/200\n",
      "2553/2553 [==============================] - 0s 70us/sample - loss: 0.9621 - accuracy: 0.5417 - val_loss: 0.9669 - val_accuracy: 0.5234\n",
      "Epoch 176/200\n",
      "2553/2553 [==============================] - 0s 99us/sample - loss: 0.9620 - accuracy: 0.5417 - val_loss: 0.9667 - val_accuracy: 0.5234\n",
      "Epoch 177/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 65us/sample - loss: 0.9619 - accuracy: 0.5421 - val_loss: 0.9665 - val_accuracy: 0.5234\n",
      "Epoch 178/200\n",
      "2553/2553 [==============================] - 0s 66us/sample - loss: 0.9619 - accuracy: 0.5421 - val_loss: 0.9663 - val_accuracy: 0.5234\n",
      "Epoch 179/200\n",
      "2553/2553 [==============================] - 0s 84us/sample - loss: 0.9618 - accuracy: 0.5425 - val_loss: 0.9662 - val_accuracy: 0.5234\n",
      "Epoch 180/200\n",
      "2553/2553 [==============================] - 0s 78us/sample - loss: 0.9617 - accuracy: 0.5425 - val_loss: 0.9660 - val_accuracy: 0.5234\n",
      "Epoch 181/200\n",
      "2553/2553 [==============================] - 0s 84us/sample - loss: 0.9616 - accuracy: 0.5425 - val_loss: 0.9658 - val_accuracy: 0.5234\n",
      "Epoch 182/200\n",
      "2553/2553 [==============================] - 0s 67us/sample - loss: 0.9615 - accuracy: 0.5417 - val_loss: 0.9657 - val_accuracy: 0.5234\n",
      "Epoch 183/200\n",
      "2553/2553 [==============================] - 0s 68us/sample - loss: 0.9614 - accuracy: 0.5417 - val_loss: 0.9655 - val_accuracy: 0.5234\n",
      "Epoch 184/200\n",
      "2553/2553 [==============================] - 0s 78us/sample - loss: 0.9613 - accuracy: 0.5425 - val_loss: 0.9653 - val_accuracy: 0.5234\n",
      "Epoch 185/200\n",
      "2553/2553 [==============================] - 0s 91us/sample - loss: 0.9612 - accuracy: 0.5425 - val_loss: 0.9652 - val_accuracy: 0.5234\n",
      "Epoch 186/200\n",
      "2553/2553 [==============================] - 0s 84us/sample - loss: 0.9612 - accuracy: 0.5421 - val_loss: 0.9650 - val_accuracy: 0.5234\n",
      "Epoch 187/200\n",
      "2553/2553 [==============================] - 0s 92us/sample - loss: 0.9611 - accuracy: 0.5421 - val_loss: 0.9648 - val_accuracy: 0.5234\n",
      "Epoch 188/200\n",
      "2553/2553 [==============================] - 0s 71us/sample - loss: 0.9610 - accuracy: 0.5421 - val_loss: 0.9646 - val_accuracy: 0.5234\n",
      "Epoch 189/200\n",
      "2553/2553 [==============================] - 0s 75us/sample - loss: 0.9609 - accuracy: 0.5421 - val_loss: 0.9645 - val_accuracy: 0.5234\n",
      "Epoch 190/200\n",
      "2553/2553 [==============================] - 0s 75us/sample - loss: 0.9608 - accuracy: 0.5421 - val_loss: 0.9643 - val_accuracy: 0.5234\n",
      "Epoch 191/200\n",
      "2553/2553 [==============================] - 0s 75us/sample - loss: 0.9607 - accuracy: 0.5421 - val_loss: 0.9641 - val_accuracy: 0.5234\n",
      "Epoch 192/200\n",
      "2553/2553 [==============================] - 0s 72us/sample - loss: 0.9606 - accuracy: 0.5421 - val_loss: 0.9639 - val_accuracy: 0.5234\n",
      "Epoch 193/200\n",
      "2553/2553 [==============================] - 0s 70us/sample - loss: 0.9605 - accuracy: 0.5425 - val_loss: 0.9637 - val_accuracy: 0.5327\n",
      "Epoch 194/200\n",
      "2553/2553 [==============================] - 0s 70us/sample - loss: 0.9604 - accuracy: 0.5425 - val_loss: 0.9636 - val_accuracy: 0.5327\n",
      "Epoch 195/200\n",
      "2553/2553 [==============================] - 0s 72us/sample - loss: 0.9603 - accuracy: 0.5425 - val_loss: 0.9634 - val_accuracy: 0.5327\n",
      "Epoch 196/200\n",
      "2553/2553 [==============================] - 0s 78us/sample - loss: 0.9602 - accuracy: 0.5425 - val_loss: 0.9632 - val_accuracy: 0.5327\n",
      "Epoch 197/200\n",
      "2553/2553 [==============================] - 0s 71us/sample - loss: 0.9601 - accuracy: 0.5441 - val_loss: 0.9630 - val_accuracy: 0.5327\n",
      "Epoch 198/200\n",
      "2553/2553 [==============================] - 0s 70us/sample - loss: 0.9600 - accuracy: 0.5437 - val_loss: 0.9628 - val_accuracy: 0.5327\n",
      "Epoch 199/200\n",
      "2553/2553 [==============================] - 0s 79us/sample - loss: 0.9599 - accuracy: 0.5437 - val_loss: 0.9626 - val_accuracy: 0.5327\n",
      "Epoch 200/200\n",
      "2553/2553 [==============================] - 0s 69us/sample - loss: 0.9599 - accuracy: 0.5433 - val_loss: 0.9623 - val_accuracy: 0.5327\n",
      "0.53271025 {'loss': 0.9598539168583473, 'accuracy': 0.5432824, 'val_loss': 0.9623381812995839, 'val_accuracy': 0.53271025}\n",
      "Model: \"model_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_11 (InputLayer)        [(None, 29)]              0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 41)                1230      \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 10)                420       \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 3)                 33        \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 1,903\n",
      "Trainable params: 1,903\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2553 samples, validate on 107 samples\n",
      "Epoch 1/200\n",
      "2553/2553 [==============================] - 1s 402us/sample - loss: 1.1038 - accuracy: 0.3921 - val_loss: 1.0768 - val_accuracy: 0.5140\n",
      "Epoch 2/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.1017 - accuracy: 0.3976 - val_loss: 1.0746 - val_accuracy: 0.5140\n",
      "Epoch 3/200\n",
      "2553/2553 [==============================] - 0s 119us/sample - loss: 1.0997 - accuracy: 0.3956 - val_loss: 1.0723 - val_accuracy: 0.5234\n",
      "Epoch 4/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.0946 - accuracy: 0.4070 - val_loss: 1.0700 - val_accuracy: 0.5234\n",
      "Epoch 5/200\n",
      "2553/2553 [==============================] - 0s 117us/sample - loss: 1.0922 - accuracy: 0.4128 - val_loss: 1.0672 - val_accuracy: 0.5234\n",
      "Epoch 6/200\n",
      "2553/2553 [==============================] - 0s 122us/sample - loss: 1.0922 - accuracy: 0.4038 - val_loss: 1.0647 - val_accuracy: 0.5234\n",
      "Epoch 7/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.0828 - accuracy: 0.4097 - val_loss: 1.0620 - val_accuracy: 0.5327\n",
      "Epoch 8/200\n",
      "2553/2553 [==============================] - 0s 121us/sample - loss: 1.0815 - accuracy: 0.4160 - val_loss: 1.0591 - val_accuracy: 0.5327\n",
      "Epoch 9/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.0757 - accuracy: 0.4175 - val_loss: 1.0560 - val_accuracy: 0.5234\n",
      "Epoch 10/200\n",
      "2553/2553 [==============================] - 0s 121us/sample - loss: 1.0746 - accuracy: 0.4191 - val_loss: 1.0525 - val_accuracy: 0.5234\n",
      "Epoch 11/200\n",
      "2553/2553 [==============================] - 0s 115us/sample - loss: 1.0714 - accuracy: 0.4136 - val_loss: 1.0493 - val_accuracy: 0.5234\n",
      "Epoch 12/200\n",
      "2553/2553 [==============================] - 0s 123us/sample - loss: 1.0716 - accuracy: 0.4148 - val_loss: 1.0462 - val_accuracy: 0.5234\n",
      "Epoch 13/200\n",
      "2553/2553 [==============================] - 0s 118us/sample - loss: 1.0695 - accuracy: 0.4070 - val_loss: 1.0432 - val_accuracy: 0.5234\n",
      "Epoch 14/200\n",
      "2553/2553 [==============================] - 0s 117us/sample - loss: 1.0665 - accuracy: 0.4058 - val_loss: 1.0404 - val_accuracy: 0.5234\n",
      "Epoch 15/200\n",
      "2553/2553 [==============================] - 0s 124us/sample - loss: 1.0580 - accuracy: 0.4203 - val_loss: 1.0374 - val_accuracy: 0.5234\n",
      "Epoch 16/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0580 - accuracy: 0.4207 - val_loss: 1.0347 - val_accuracy: 0.5234\n",
      "Epoch 17/200\n",
      "2553/2553 [==============================] - 0s 120us/sample - loss: 1.0552 - accuracy: 0.4266 - val_loss: 1.0319 - val_accuracy: 0.5234\n",
      "Epoch 18/200\n",
      "2553/2553 [==============================] - 0s 117us/sample - loss: 1.0513 - accuracy: 0.4262 - val_loss: 1.0292 - val_accuracy: 0.5234\n",
      "Epoch 19/200\n",
      "2553/2553 [==============================] - 0s 119us/sample - loss: 1.0554 - accuracy: 0.4093 - val_loss: 1.0269 - val_accuracy: 0.5234\n",
      "Epoch 20/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 121us/sample - loss: 1.0565 - accuracy: 0.3937 - val_loss: 1.0248 - val_accuracy: 0.5234\n",
      "Epoch 21/200\n",
      "2553/2553 [==============================] - 0s 117us/sample - loss: 1.0445 - accuracy: 0.4246 - val_loss: 1.0227 - val_accuracy: 0.5234\n",
      "Epoch 22/200\n",
      "2553/2553 [==============================] - 0s 121us/sample - loss: 1.0530 - accuracy: 0.3937 - val_loss: 1.0212 - val_accuracy: 0.5234\n",
      "Epoch 23/200\n",
      "2553/2553 [==============================] - 0s 157us/sample - loss: 1.0528 - accuracy: 0.3909 - val_loss: 1.0197 - val_accuracy: 0.5234\n",
      "Epoch 24/200\n",
      "2553/2553 [==============================] - 0s 140us/sample - loss: 1.0459 - accuracy: 0.4109 - val_loss: 1.0181 - val_accuracy: 0.5234\n",
      "Epoch 25/200\n",
      "2553/2553 [==============================] - 0s 119us/sample - loss: 1.0469 - accuracy: 0.4050 - val_loss: 1.0168 - val_accuracy: 0.5234\n",
      "Epoch 26/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.0402 - accuracy: 0.4305 - val_loss: 1.0154 - val_accuracy: 0.5234\n",
      "Epoch 27/200\n",
      "2553/2553 [==============================] - 0s 122us/sample - loss: 1.0393 - accuracy: 0.4215 - val_loss: 1.0138 - val_accuracy: 0.5234\n",
      "Epoch 28/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.0417 - accuracy: 0.4140 - val_loss: 1.0127 - val_accuracy: 0.5234\n",
      "Epoch 29/200\n",
      "2553/2553 [==============================] - 0s 120us/sample - loss: 1.0401 - accuracy: 0.4101 - val_loss: 1.0116 - val_accuracy: 0.5234\n",
      "Epoch 30/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 1.0382 - accuracy: 0.4164 - val_loss: 1.0104 - val_accuracy: 0.5140\n",
      "Epoch 31/200\n",
      "2553/2553 [==============================] - 0s 124us/sample - loss: 1.0317 - accuracy: 0.4207 - val_loss: 1.0091 - val_accuracy: 0.5140\n",
      "Epoch 32/200\n",
      "2553/2553 [==============================] - 0s 119us/sample - loss: 1.0301 - accuracy: 0.4172 - val_loss: 1.0081 - val_accuracy: 0.5140\n",
      "Epoch 33/200\n",
      "2553/2553 [==============================] - 0s 115us/sample - loss: 1.0299 - accuracy: 0.4254 - val_loss: 1.0072 - val_accuracy: 0.5140\n",
      "Epoch 34/200\n",
      "2553/2553 [==============================] - 0s 121us/sample - loss: 1.0335 - accuracy: 0.4160 - val_loss: 1.0063 - val_accuracy: 0.5140\n",
      "Epoch 35/200\n",
      "2553/2553 [==============================] - 0s 115us/sample - loss: 1.0272 - accuracy: 0.4160 - val_loss: 1.0053 - val_accuracy: 0.5140\n",
      "Epoch 36/200\n",
      "2553/2553 [==============================] - 0s 118us/sample - loss: 1.0312 - accuracy: 0.4078 - val_loss: 1.0044 - val_accuracy: 0.5140\n",
      "Epoch 37/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 1.0308 - accuracy: 0.4172 - val_loss: 1.0033 - val_accuracy: 0.5140\n",
      "Epoch 38/200\n",
      "2553/2553 [==============================] - ETA: 0s - loss: 1.0398 - accuracy: 0.40 - 0s 118us/sample - loss: 1.0378 - accuracy: 0.4081 - val_loss: 1.0024 - val_accuracy: 0.5140\n",
      "Epoch 39/200\n",
      "2553/2553 [==============================] - 0s 121us/sample - loss: 1.0309 - accuracy: 0.4183 - val_loss: 1.0016 - val_accuracy: 0.5140\n",
      "Epoch 40/200\n",
      "2553/2553 [==============================] - 0s 118us/sample - loss: 1.0246 - accuracy: 0.4320 - val_loss: 1.0006 - val_accuracy: 0.5140\n",
      "Epoch 41/200\n",
      "2553/2553 [==============================] - 0s 121us/sample - loss: 1.0274 - accuracy: 0.4281 - val_loss: 0.9999 - val_accuracy: 0.5140\n",
      "Epoch 42/200\n",
      "2553/2553 [==============================] - 0s 118us/sample - loss: 1.0219 - accuracy: 0.4305 - val_loss: 0.9994 - val_accuracy: 0.5140\n",
      "Epoch 43/200\n",
      "2553/2553 [==============================] - 0s 119us/sample - loss: 1.0272 - accuracy: 0.4285 - val_loss: 0.9987 - val_accuracy: 0.5140\n",
      "Epoch 44/200\n",
      "2553/2553 [==============================] - 0s 122us/sample - loss: 1.0214 - accuracy: 0.4262 - val_loss: 0.9982 - val_accuracy: 0.5234\n",
      "Epoch 45/200\n",
      "2553/2553 [==============================] - ETA: 0s - loss: 1.0214 - accuracy: 0.42 - 0s 120us/sample - loss: 1.0233 - accuracy: 0.4254 - val_loss: 0.9976 - val_accuracy: 0.5234\n",
      "Epoch 46/200\n",
      "2553/2553 [==============================] - 0s 121us/sample - loss: 1.0199 - accuracy: 0.4375 - val_loss: 0.9971 - val_accuracy: 0.5327\n",
      "Epoch 47/200\n",
      "2553/2553 [==============================] - 0s 118us/sample - loss: 1.0176 - accuracy: 0.4344 - val_loss: 0.9963 - val_accuracy: 0.5234\n",
      "Epoch 48/200\n",
      "2553/2553 [==============================] - 0s 121us/sample - loss: 1.0227 - accuracy: 0.4301 - val_loss: 0.9960 - val_accuracy: 0.5234\n",
      "Epoch 49/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.0274 - accuracy: 0.4269 - val_loss: 0.9955 - val_accuracy: 0.5140\n",
      "Epoch 50/200\n",
      "2553/2553 [==============================] - 0s 119us/sample - loss: 1.0289 - accuracy: 0.4219 - val_loss: 0.9952 - val_accuracy: 0.5140\n",
      "Epoch 51/200\n",
      "2553/2553 [==============================] - 0s 120us/sample - loss: 1.0189 - accuracy: 0.4407 - val_loss: 0.9943 - val_accuracy: 0.5140\n",
      "Epoch 52/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 1.0226 - accuracy: 0.4320 - val_loss: 0.9937 - val_accuracy: 0.5140\n",
      "Epoch 53/200\n",
      "2553/2553 [==============================] - 0s 120us/sample - loss: 1.0220 - accuracy: 0.4375 - val_loss: 0.9931 - val_accuracy: 0.5421\n",
      "Epoch 54/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 1.0186 - accuracy: 0.4395 - val_loss: 0.9927 - val_accuracy: 0.5421\n",
      "Epoch 55/200\n",
      "2553/2553 [==============================] - 0s 117us/sample - loss: 1.0213 - accuracy: 0.4371 - val_loss: 0.9924 - val_accuracy: 0.5421\n",
      "Epoch 56/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.0259 - accuracy: 0.4328 - val_loss: 0.9920 - val_accuracy: 0.5421\n",
      "Epoch 57/200\n",
      "2553/2553 [==============================] - 0s 119us/sample - loss: 1.0186 - accuracy: 0.4387 - val_loss: 0.9916 - val_accuracy: 0.5514\n",
      "Epoch 58/200\n",
      "2553/2553 [==============================] - 0s 118us/sample - loss: 1.0267 - accuracy: 0.4277 - val_loss: 0.9914 - val_accuracy: 0.5514\n",
      "Epoch 59/200\n",
      "2553/2553 [==============================] - 0s 125us/sample - loss: 1.0232 - accuracy: 0.4367 - val_loss: 0.9911 - val_accuracy: 0.5514\n",
      "Epoch 60/200\n",
      "2553/2553 [==============================] - 0s 123us/sample - loss: 1.0181 - accuracy: 0.4403 - val_loss: 0.9907 - val_accuracy: 0.5421\n",
      "Epoch 61/200\n",
      "2553/2553 [==============================] - 0s 120us/sample - loss: 1.0188 - accuracy: 0.4540 - val_loss: 0.9902 - val_accuracy: 0.5421\n",
      "Epoch 62/200\n",
      "2553/2553 [==============================] - 0s 123us/sample - loss: 1.0237 - accuracy: 0.4430 - val_loss: 0.9901 - val_accuracy: 0.5234\n",
      "Epoch 63/200\n",
      "2553/2553 [==============================] - 0s 119us/sample - loss: 1.0164 - accuracy: 0.4567 - val_loss: 0.9895 - val_accuracy: 0.5234\n",
      "Epoch 64/200\n",
      "2553/2553 [==============================] - 0s 117us/sample - loss: 1.0194 - accuracy: 0.4540 - val_loss: 0.9892 - val_accuracy: 0.5234\n",
      "Epoch 65/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.0273 - accuracy: 0.4340 - val_loss: 0.9891 - val_accuracy: 0.5234\n",
      "Epoch 66/200\n",
      "2553/2553 [==============================] - 0s 118us/sample - loss: 1.0238 - accuracy: 0.4442 - val_loss: 0.9892 - val_accuracy: 0.5234\n",
      "Epoch 67/200\n",
      "2553/2553 [==============================] - 0s 119us/sample - loss: 1.0246 - accuracy: 0.4461 - val_loss: 0.9888 - val_accuracy: 0.5234\n",
      "Epoch 68/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.0194 - accuracy: 0.4505 - val_loss: 0.9884 - val_accuracy: 0.5234\n",
      "Epoch 69/200\n",
      "2553/2553 [==============================] - 0s 123us/sample - loss: 1.0227 - accuracy: 0.4450 - val_loss: 0.9883 - val_accuracy: 0.5234\n",
      "Epoch 70/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.0263 - accuracy: 0.4481 - val_loss: 0.9882 - val_accuracy: 0.5327\n",
      "Epoch 71/200\n",
      "2553/2553 [==============================] - 0s 123us/sample - loss: 1.0231 - accuracy: 0.4387 - val_loss: 0.9879 - val_accuracy: 0.5327\n",
      "Epoch 72/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 1.0213 - accuracy: 0.4532 - val_loss: 0.9877 - val_accuracy: 0.5327\n",
      "Epoch 73/200\n",
      "2553/2553 [==============================] - 0s 121us/sample - loss: 1.0219 - accuracy: 0.4516 - val_loss: 0.9877 - val_accuracy: 0.5327\n",
      "Epoch 74/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 119us/sample - loss: 1.0193 - accuracy: 0.4485 - val_loss: 0.9875 - val_accuracy: 0.5327\n",
      "Epoch 75/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 1.0224 - accuracy: 0.4410 - val_loss: 0.9873 - val_accuracy: 0.5327\n",
      "Epoch 76/200\n",
      "2553/2553 [==============================] - 0s 120us/sample - loss: 1.0226 - accuracy: 0.4508 - val_loss: 0.9872 - val_accuracy: 0.5327\n",
      "Epoch 77/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.0237 - accuracy: 0.4438 - val_loss: 0.9872 - val_accuracy: 0.5327\n",
      "Epoch 78/200\n",
      "2553/2553 [==============================] - 0s 123us/sample - loss: 1.0244 - accuracy: 0.4379 - val_loss: 0.9872 - val_accuracy: 0.5421\n",
      "Epoch 79/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.0197 - accuracy: 0.4512 - val_loss: 0.9872 - val_accuracy: 0.5421\n",
      "Epoch 80/200\n",
      "2553/2553 [==============================] - 0s 124us/sample - loss: 1.0200 - accuracy: 0.4610 - val_loss: 0.9868 - val_accuracy: 0.5421\n",
      "Epoch 81/200\n",
      "2553/2553 [==============================] - 0s 117us/sample - loss: 1.0223 - accuracy: 0.4552 - val_loss: 0.9868 - val_accuracy: 0.5421\n",
      "Epoch 82/200\n",
      "2553/2553 [==============================] - 0s 117us/sample - loss: 1.0169 - accuracy: 0.4524 - val_loss: 0.9866 - val_accuracy: 0.5421\n",
      "Epoch 83/200\n",
      "2553/2553 [==============================] - 0s 125us/sample - loss: 1.0172 - accuracy: 0.4559 - val_loss: 0.9863 - val_accuracy: 0.5421\n",
      "Epoch 84/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.0214 - accuracy: 0.4524 - val_loss: 0.9863 - val_accuracy: 0.5327\n",
      "Epoch 85/200\n",
      "2553/2553 [==============================] - 0s 122us/sample - loss: 1.0164 - accuracy: 0.4567 - val_loss: 0.9860 - val_accuracy: 0.5327\n",
      "Epoch 86/200\n",
      "2553/2553 [==============================] - 0s 115us/sample - loss: 1.0191 - accuracy: 0.4505 - val_loss: 0.9860 - val_accuracy: 0.5327\n",
      "Epoch 87/200\n",
      "2553/2553 [==============================] - 0s 115us/sample - loss: 1.0118 - accuracy: 0.4552 - val_loss: 0.9856 - val_accuracy: 0.5327\n",
      "Epoch 88/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0219 - accuracy: 0.4520 - val_loss: 0.9856 - val_accuracy: 0.5327\n",
      "Epoch 89/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0218 - accuracy: 0.4454 - val_loss: 0.9857 - val_accuracy: 0.5327\n",
      "Epoch 90/200\n",
      "2553/2553 [==============================] - 0s 115us/sample - loss: 1.0188 - accuracy: 0.4461 - val_loss: 0.9857 - val_accuracy: 0.5327\n",
      "Epoch 91/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.0165 - accuracy: 0.4575 - val_loss: 0.9854 - val_accuracy: 0.5327\n",
      "Epoch 92/200\n",
      "2553/2553 [==============================] - 0s 117us/sample - loss: 1.0208 - accuracy: 0.4552 - val_loss: 0.9853 - val_accuracy: 0.5327\n",
      "Epoch 93/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0155 - accuracy: 0.4610 - val_loss: 0.9852 - val_accuracy: 0.5327\n",
      "Epoch 94/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.0262 - accuracy: 0.4528 - val_loss: 0.9854 - val_accuracy: 0.5327\n",
      "Epoch 95/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0104 - accuracy: 0.4591 - val_loss: 0.9850 - val_accuracy: 0.5327\n",
      "Epoch 96/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.0117 - accuracy: 0.4536 - val_loss: 0.9847 - val_accuracy: 0.5327\n",
      "Epoch 97/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.0177 - accuracy: 0.4595 - val_loss: 0.9847 - val_accuracy: 0.5327\n",
      "Epoch 98/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.0212 - accuracy: 0.4477 - val_loss: 0.9847 - val_accuracy: 0.5327\n",
      "Epoch 99/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0169 - accuracy: 0.4559 - val_loss: 0.9847 - val_accuracy: 0.5327\n",
      "Epoch 100/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.0220 - accuracy: 0.4540 - val_loss: 0.9848 - val_accuracy: 0.5327\n",
      "Epoch 101/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0258 - accuracy: 0.4516 - val_loss: 0.9849 - val_accuracy: 0.5327\n",
      "Epoch 102/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0255 - accuracy: 0.4438 - val_loss: 0.9850 - val_accuracy: 0.5327\n",
      "Epoch 103/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0192 - accuracy: 0.4520 - val_loss: 0.9851 - val_accuracy: 0.5327\n",
      "Epoch 104/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.0124 - accuracy: 0.4571 - val_loss: 0.9847 - val_accuracy: 0.5421\n",
      "Epoch 105/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.0125 - accuracy: 0.4606 - val_loss: 0.9843 - val_accuracy: 0.5421\n",
      "Epoch 106/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0239 - accuracy: 0.4407 - val_loss: 0.9844 - val_accuracy: 0.5327\n",
      "Epoch 107/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.0105 - accuracy: 0.4653 - val_loss: 0.9842 - val_accuracy: 0.5327\n",
      "Epoch 108/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0264 - accuracy: 0.4438 - val_loss: 0.9843 - val_accuracy: 0.5421\n",
      "Epoch 109/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.0189 - accuracy: 0.4579 - val_loss: 0.9843 - val_accuracy: 0.5327\n",
      "Epoch 110/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.0176 - accuracy: 0.4532 - val_loss: 0.9841 - val_accuracy: 0.5327\n",
      "Epoch 111/200\n",
      "2553/2553 [==============================] - 0s 115us/sample - loss: 1.0169 - accuracy: 0.4602 - val_loss: 0.9840 - val_accuracy: 0.5327\n",
      "Epoch 112/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0177 - accuracy: 0.4563 - val_loss: 0.9838 - val_accuracy: 0.5327\n",
      "Epoch 113/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.0151 - accuracy: 0.4634 - val_loss: 0.9836 - val_accuracy: 0.5327\n",
      "Epoch 114/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.0166 - accuracy: 0.4548 - val_loss: 0.9834 - val_accuracy: 0.5421\n",
      "Epoch 115/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.0138 - accuracy: 0.4642 - val_loss: 0.9831 - val_accuracy: 0.5327\n",
      "Epoch 116/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.0108 - accuracy: 0.4693 - val_loss: 0.9829 - val_accuracy: 0.5421\n",
      "Epoch 117/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0170 - accuracy: 0.4614 - val_loss: 0.9828 - val_accuracy: 0.5421\n",
      "Epoch 118/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.0187 - accuracy: 0.4630 - val_loss: 0.9829 - val_accuracy: 0.5421\n",
      "Epoch 119/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0121 - accuracy: 0.4661 - val_loss: 0.9825 - val_accuracy: 0.5421\n",
      "Epoch 120/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.0228 - accuracy: 0.4477 - val_loss: 0.9826 - val_accuracy: 0.5421\n",
      "Epoch 121/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.0213 - accuracy: 0.4481 - val_loss: 0.9827 - val_accuracy: 0.5421\n",
      "Epoch 122/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.0194 - accuracy: 0.4559 - val_loss: 0.9827 - val_accuracy: 0.5421\n",
      "Epoch 123/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0194 - accuracy: 0.4489 - val_loss: 0.9827 - val_accuracy: 0.5421\n",
      "Epoch 124/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.0233 - accuracy: 0.4505 - val_loss: 0.9829 - val_accuracy: 0.5421\n",
      "Epoch 125/200\n",
      "2553/2553 [==============================] - 0s 115us/sample - loss: 1.0184 - accuracy: 0.4606 - val_loss: 0.9828 - val_accuracy: 0.5421\n",
      "Epoch 126/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.0157 - accuracy: 0.4505 - val_loss: 0.9828 - val_accuracy: 0.5421\n",
      "Epoch 127/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0172 - accuracy: 0.4669 - val_loss: 0.9826 - val_accuracy: 0.5421\n",
      "Epoch 128/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 117us/sample - loss: 1.0169 - accuracy: 0.4642 - val_loss: 0.9826 - val_accuracy: 0.5421\n",
      "Epoch 129/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0155 - accuracy: 0.4591 - val_loss: 0.9826 - val_accuracy: 0.5421\n",
      "Epoch 130/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.0114 - accuracy: 0.4771 - val_loss: 0.9823 - val_accuracy: 0.5421\n",
      "Epoch 131/200\n",
      "2553/2553 [==============================] - ETA: 0s - loss: 1.0087 - accuracy: 0.46 - 0s 112us/sample - loss: 1.0086 - accuracy: 0.4693 - val_loss: 0.9820 - val_accuracy: 0.5421\n",
      "Epoch 132/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0169 - accuracy: 0.4610 - val_loss: 0.9821 - val_accuracy: 0.5421\n",
      "Epoch 133/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0182 - accuracy: 0.4559 - val_loss: 0.9820 - val_accuracy: 0.5421\n",
      "Epoch 134/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0175 - accuracy: 0.4634 - val_loss: 0.9820 - val_accuracy: 0.5421\n",
      "Epoch 135/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.0126 - accuracy: 0.4634 - val_loss: 0.9818 - val_accuracy: 0.5421\n",
      "Epoch 136/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0228 - accuracy: 0.4614 - val_loss: 0.9821 - val_accuracy: 0.5421\n",
      "Epoch 137/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0159 - accuracy: 0.4646 - val_loss: 0.9820 - val_accuracy: 0.5421\n",
      "Epoch 138/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0177 - accuracy: 0.4567 - val_loss: 0.9819 - val_accuracy: 0.5421\n",
      "Epoch 139/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.0157 - accuracy: 0.4622 - val_loss: 0.9819 - val_accuracy: 0.5421\n",
      "Epoch 140/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0041 - accuracy: 0.4818 - val_loss: 0.9814 - val_accuracy: 0.5421\n",
      "Epoch 141/200\n",
      "2553/2553 [==============================] - 0s 120us/sample - loss: 1.0273 - accuracy: 0.4567 - val_loss: 0.9817 - val_accuracy: 0.5421\n",
      "Epoch 142/200\n",
      "2553/2553 [==============================] - 0s 118us/sample - loss: 1.0093 - accuracy: 0.4677 - val_loss: 0.9815 - val_accuracy: 0.5421\n",
      "Epoch 143/200\n",
      "2553/2553 [==============================] - 0s 124us/sample - loss: 1.0204 - accuracy: 0.4638 - val_loss: 0.9817 - val_accuracy: 0.5421\n",
      "Epoch 144/200\n",
      "2553/2553 [==============================] - 0s 121us/sample - loss: 1.0140 - accuracy: 0.4669 - val_loss: 0.9817 - val_accuracy: 0.5421\n",
      "Epoch 145/200\n",
      "2553/2553 [==============================] - 0s 128us/sample - loss: 1.0089 - accuracy: 0.4665 - val_loss: 0.9814 - val_accuracy: 0.5421\n",
      "Epoch 146/200\n",
      "2553/2553 [==============================] - 0s 139us/sample - loss: 1.0092 - accuracy: 0.4720 - val_loss: 0.9811 - val_accuracy: 0.5421\n",
      "Epoch 147/200\n",
      "2553/2553 [==============================] - 0s 139us/sample - loss: 1.0069 - accuracy: 0.4716 - val_loss: 0.9808 - val_accuracy: 0.5421\n",
      "Epoch 148/200\n",
      "2553/2553 [==============================] - 0s 131us/sample - loss: 1.0170 - accuracy: 0.4638 - val_loss: 0.9808 - val_accuracy: 0.5421\n",
      "Epoch 149/200\n",
      "2553/2553 [==============================] - 0s 146us/sample - loss: 1.0192 - accuracy: 0.4567 - val_loss: 0.9810 - val_accuracy: 0.5421\n",
      "Epoch 150/200\n",
      "2553/2553 [==============================] - 0s 132us/sample - loss: 1.0021 - accuracy: 0.4755 - val_loss: 0.9805 - val_accuracy: 0.5421\n",
      "Epoch 151/200\n",
      "2553/2553 [==============================] - 0s 131us/sample - loss: 1.0169 - accuracy: 0.4544 - val_loss: 0.9807 - val_accuracy: 0.5421\n",
      "Epoch 152/200\n",
      "2553/2553 [==============================] - 0s 136us/sample - loss: 1.0257 - accuracy: 0.4555 - val_loss: 0.9810 - val_accuracy: 0.5421\n",
      "Epoch 153/200\n",
      "2553/2553 [==============================] - 0s 127us/sample - loss: 1.0213 - accuracy: 0.4559 - val_loss: 0.9811 - val_accuracy: 0.5421\n",
      "Epoch 154/200\n",
      "2553/2553 [==============================] - 0s 136us/sample - loss: 1.0204 - accuracy: 0.4508 - val_loss: 0.9814 - val_accuracy: 0.5421\n",
      "Epoch 155/200\n",
      "2553/2553 [==============================] - 0s 135us/sample - loss: 1.0227 - accuracy: 0.4595 - val_loss: 0.9815 - val_accuracy: 0.5421\n",
      "Epoch 156/200\n",
      "2553/2553 [==============================] - 0s 132us/sample - loss: 1.0154 - accuracy: 0.4618 - val_loss: 0.9815 - val_accuracy: 0.5421\n",
      "Epoch 157/200\n",
      "2553/2553 [==============================] - 0s 134us/sample - loss: 1.0213 - accuracy: 0.4575 - val_loss: 0.9817 - val_accuracy: 0.5421\n",
      "Epoch 158/200\n",
      "2553/2553 [==============================] - 0s 135us/sample - loss: 1.0154 - accuracy: 0.4685 - val_loss: 0.9815 - val_accuracy: 0.5421\n",
      "Epoch 159/200\n",
      "2553/2553 [==============================] - 0s 141us/sample - loss: 1.0165 - accuracy: 0.4665 - val_loss: 0.9813 - val_accuracy: 0.5421\n",
      "Epoch 160/200\n",
      "2553/2553 [==============================] - 0s 135us/sample - loss: 1.0082 - accuracy: 0.4712 - val_loss: 0.9811 - val_accuracy: 0.5421\n",
      "Epoch 161/200\n",
      "2553/2553 [==============================] - 0s 140us/sample - loss: 1.0206 - accuracy: 0.4520 - val_loss: 0.9813 - val_accuracy: 0.5421\n",
      "Epoch 162/200\n",
      "2553/2553 [==============================] - 0s 130us/sample - loss: 1.0151 - accuracy: 0.4618 - val_loss: 0.9811 - val_accuracy: 0.5421\n",
      "Epoch 163/200\n",
      "2553/2553 [==============================] - 0s 137us/sample - loss: 1.0239 - accuracy: 0.4505 - val_loss: 0.9814 - val_accuracy: 0.5421\n",
      "Epoch 164/200\n",
      "2553/2553 [==============================] - 0s 139us/sample - loss: 1.0147 - accuracy: 0.4673 - val_loss: 0.9811 - val_accuracy: 0.5421\n",
      "Epoch 165/200\n",
      "2553/2553 [==============================] - 0s 135us/sample - loss: 1.0161 - accuracy: 0.4653 - val_loss: 0.9810 - val_accuracy: 0.5421\n",
      "Epoch 166/200\n",
      "2553/2553 [==============================] - 0s 137us/sample - loss: 1.0207 - accuracy: 0.4602 - val_loss: 0.9810 - val_accuracy: 0.5421\n",
      "Epoch 167/200\n",
      "2553/2553 [==============================] - 0s 135us/sample - loss: 1.0198 - accuracy: 0.4571 - val_loss: 0.9812 - val_accuracy: 0.5421\n",
      "Epoch 168/200\n",
      "2553/2553 [==============================] - 0s 132us/sample - loss: 1.0104 - accuracy: 0.4665 - val_loss: 0.9808 - val_accuracy: 0.5421\n",
      "Epoch 169/200\n",
      "2553/2553 [==============================] - 0s 145us/sample - loss: 1.0144 - accuracy: 0.4634 - val_loss: 0.9806 - val_accuracy: 0.5421\n",
      "Epoch 170/200\n",
      "2553/2553 [==============================] - 0s 186us/sample - loss: 1.0162 - accuracy: 0.4610 - val_loss: 0.9805 - val_accuracy: 0.5421\n",
      "Epoch 171/200\n",
      "2553/2553 [==============================] - 0s 182us/sample - loss: 1.0111 - accuracy: 0.4720 - val_loss: 0.9803 - val_accuracy: 0.5421\n",
      "Epoch 172/200\n",
      "2553/2553 [==============================] - 0s 156us/sample - loss: 1.0125 - accuracy: 0.4700 - val_loss: 0.9803 - val_accuracy: 0.5421\n",
      "Epoch 173/200\n",
      "2553/2553 [==============================] - 0s 139us/sample - loss: 1.0170 - accuracy: 0.4673 - val_loss: 0.9801 - val_accuracy: 0.5421\n",
      "Epoch 174/200\n",
      "2553/2553 [==============================] - 0s 142us/sample - loss: 1.0138 - accuracy: 0.4669 - val_loss: 0.9800 - val_accuracy: 0.5421\n",
      "Epoch 175/200\n",
      "2553/2553 [==============================] - 0s 132us/sample - loss: 1.0164 - accuracy: 0.4673 - val_loss: 0.9800 - val_accuracy: 0.5421\n",
      "Epoch 176/200\n",
      "2553/2553 [==============================] - 0s 133us/sample - loss: 1.0182 - accuracy: 0.4563 - val_loss: 0.9802 - val_accuracy: 0.5421\n",
      "Epoch 177/200\n",
      "2553/2553 [==============================] - 0s 136us/sample - loss: 1.0166 - accuracy: 0.4685 - val_loss: 0.9802 - val_accuracy: 0.5421\n",
      "Epoch 178/200\n",
      "2553/2553 [==============================] - 0s 137us/sample - loss: 1.0121 - accuracy: 0.4775 - val_loss: 0.9798 - val_accuracy: 0.5421\n",
      "Epoch 179/200\n",
      "2553/2553 [==============================] - 0s 134us/sample - loss: 1.0177 - accuracy: 0.4516 - val_loss: 0.9799 - val_accuracy: 0.5421\n",
      "Epoch 180/200\n",
      "2553/2553 [==============================] - 0s 133us/sample - loss: 1.0194 - accuracy: 0.4595 - val_loss: 0.9800 - val_accuracy: 0.5421\n",
      "Epoch 181/200\n",
      "2553/2553 [==============================] - 0s 132us/sample - loss: 1.0194 - accuracy: 0.4583 - val_loss: 0.9799 - val_accuracy: 0.5421\n",
      "Epoch 182/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 131us/sample - loss: 1.0196 - accuracy: 0.4606 - val_loss: 0.9802 - val_accuracy: 0.5421\n",
      "Epoch 183/200\n",
      "2553/2553 [==============================] - 0s 125us/sample - loss: 1.0151 - accuracy: 0.4704 - val_loss: 0.9801 - val_accuracy: 0.5421\n",
      "Epoch 184/200\n",
      "2553/2553 [==============================] - 0s 131us/sample - loss: 1.0117 - accuracy: 0.4712 - val_loss: 0.9797 - val_accuracy: 0.5421\n",
      "Epoch 185/200\n",
      "2553/2553 [==============================] - 0s 133us/sample - loss: 1.0204 - accuracy: 0.4540 - val_loss: 0.9799 - val_accuracy: 0.5421\n",
      "Epoch 186/200\n",
      "2553/2553 [==============================] - 0s 118us/sample - loss: 1.0215 - accuracy: 0.4528 - val_loss: 0.9799 - val_accuracy: 0.5421\n",
      "Epoch 187/200\n",
      "2553/2553 [==============================] - 0s 118us/sample - loss: 1.0115 - accuracy: 0.4634 - val_loss: 0.9797 - val_accuracy: 0.5421\n",
      "Epoch 188/200\n",
      "2553/2553 [==============================] - 0s 115us/sample - loss: 1.0056 - accuracy: 0.4818 - val_loss: 0.9793 - val_accuracy: 0.5421\n",
      "Epoch 189/200\n",
      "2553/2553 [==============================] - 0s 141us/sample - loss: 1.0171 - accuracy: 0.4552 - val_loss: 0.9792 - val_accuracy: 0.5421\n",
      "Epoch 190/200\n",
      "2553/2553 [==============================] - 0s 133us/sample - loss: 1.0106 - accuracy: 0.4665 - val_loss: 0.9790 - val_accuracy: 0.5421\n",
      "Epoch 191/200\n",
      "2553/2553 [==============================] - 0s 115us/sample - loss: 1.0212 - accuracy: 0.4473 - val_loss: 0.9791 - val_accuracy: 0.5421\n",
      "Epoch 192/200\n",
      "2553/2553 [==============================] - 0s 119us/sample - loss: 1.0133 - accuracy: 0.4563 - val_loss: 0.9791 - val_accuracy: 0.5421\n",
      "Epoch 193/200\n",
      "2553/2553 [==============================] - 0s 115us/sample - loss: 1.0176 - accuracy: 0.4559 - val_loss: 0.9789 - val_accuracy: 0.5421\n",
      "Epoch 194/200\n",
      "2553/2553 [==============================] - 0s 118us/sample - loss: 1.0128 - accuracy: 0.4771 - val_loss: 0.9788 - val_accuracy: 0.5421\n",
      "Epoch 195/200\n",
      "2553/2553 [==============================] - 0s 136us/sample - loss: 1.0160 - accuracy: 0.4532 - val_loss: 0.9788 - val_accuracy: 0.5421\n",
      "Epoch 196/200\n",
      "2553/2553 [==============================] - 0s 119us/sample - loss: 1.0134 - accuracy: 0.4681 - val_loss: 0.9787 - val_accuracy: 0.5421\n",
      "Epoch 197/200\n",
      "2553/2553 [==============================] - 0s 118us/sample - loss: 1.0084 - accuracy: 0.4685 - val_loss: 0.9785 - val_accuracy: 0.5421\n",
      "Epoch 198/200\n",
      "2553/2553 [==============================] - 0s 117us/sample - loss: 1.0108 - accuracy: 0.4716 - val_loss: 0.9784 - val_accuracy: 0.5421\n",
      "Epoch 199/200\n",
      "2553/2553 [==============================] - 0s 118us/sample - loss: 1.0150 - accuracy: 0.4708 - val_loss: 0.9784 - val_accuracy: 0.5421\n",
      "Epoch 200/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.0094 - accuracy: 0.4689 - val_loss: 0.9781 - val_accuracy: 0.5421\n",
      "0.5420561 {'loss': 1.009417046251084, 'accuracy': 0.46886018, 'val_loss': 0.9780730649689647, 'val_accuracy': 0.5420561}\n",
      "Model: \"model_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_12 (InputLayer)        [(None, 29)]              0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 41)                1230      \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 10)                420       \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 3)                 33        \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 1,903\n",
      "Trainable params: 1,903\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2553 samples, validate on 107 samples\n",
      "Epoch 1/200\n",
      "2553/2553 [==============================] - 1s 336us/sample - loss: 1.2043 - accuracy: 0.2699 - val_loss: 1.1926 - val_accuracy: 0.2243\n",
      "Epoch 2/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1941 - accuracy: 0.2722 - val_loss: 1.1859 - val_accuracy: 0.2243\n",
      "Epoch 3/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.1972 - accuracy: 0.2589 - val_loss: 1.1799 - val_accuracy: 0.2243\n",
      "Epoch 4/200\n",
      "2553/2553 [==============================] - 0s 65us/sample - loss: 1.1796 - accuracy: 0.2761 - val_loss: 1.1743 - val_accuracy: 0.2243\n",
      "Epoch 5/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.1757 - accuracy: 0.2734 - val_loss: 1.1688 - val_accuracy: 0.2243\n",
      "Epoch 6/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.1678 - accuracy: 0.2805 - val_loss: 1.1638 - val_accuracy: 0.2243\n",
      "Epoch 7/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.1551 - accuracy: 0.2836 - val_loss: 1.1592 - val_accuracy: 0.2243\n",
      "Epoch 8/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.1579 - accuracy: 0.2820 - val_loss: 1.1549 - val_accuracy: 0.2243\n",
      "Epoch 9/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.1562 - accuracy: 0.2695 - val_loss: 1.1508 - val_accuracy: 0.2336\n",
      "Epoch 10/200\n",
      "2553/2553 [==============================] - 0s 65us/sample - loss: 1.1468 - accuracy: 0.2726 - val_loss: 1.1474 - val_accuracy: 0.2243\n",
      "Epoch 11/200\n",
      "2553/2553 [==============================] - 0s 66us/sample - loss: 1.1437 - accuracy: 0.2789 - val_loss: 1.1443 - val_accuracy: 0.2243\n",
      "Epoch 12/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.1409 - accuracy: 0.2828 - val_loss: 1.1412 - val_accuracy: 0.2150\n",
      "Epoch 13/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.1404 - accuracy: 0.2832 - val_loss: 1.1386 - val_accuracy: 0.2150\n",
      "Epoch 14/200\n",
      "2553/2553 [==============================] - 0s 74us/sample - loss: 1.1366 - accuracy: 0.2773 - val_loss: 1.1361 - val_accuracy: 0.2056\n",
      "Epoch 15/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.1323 - accuracy: 0.2840 - val_loss: 1.1336 - val_accuracy: 0.2056\n",
      "Epoch 16/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.1325 - accuracy: 0.2711 - val_loss: 1.1310 - val_accuracy: 0.2150\n",
      "Epoch 17/200\n",
      "2553/2553 [==============================] - 0s 68us/sample - loss: 1.1286 - accuracy: 0.2899 - val_loss: 1.1288 - val_accuracy: 0.2243\n",
      "Epoch 18/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.1224 - accuracy: 0.2883 - val_loss: 1.1266 - val_accuracy: 0.2243\n",
      "Epoch 19/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.1272 - accuracy: 0.2773 - val_loss: 1.1248 - val_accuracy: 0.2243\n",
      "Epoch 20/200\n",
      "2553/2553 [==============================] - 0s 72us/sample - loss: 1.1203 - accuracy: 0.2969 - val_loss: 1.1230 - val_accuracy: 0.2243\n",
      "Epoch 21/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.1213 - accuracy: 0.2840 - val_loss: 1.1216 - val_accuracy: 0.2243\n",
      "Epoch 22/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.1162 - accuracy: 0.2852 - val_loss: 1.1200 - val_accuracy: 0.2243\n",
      "Epoch 23/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.1172 - accuracy: 0.2816 - val_loss: 1.1184 - val_accuracy: 0.2243\n",
      "Epoch 24/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.1140 - accuracy: 0.2914 - val_loss: 1.1170 - val_accuracy: 0.2336\n",
      "Epoch 25/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 68us/sample - loss: 1.1121 - accuracy: 0.3000 - val_loss: 1.1155 - val_accuracy: 0.2336\n",
      "Epoch 26/200\n",
      "2553/2553 [==============================] - 0s 67us/sample - loss: 1.1074 - accuracy: 0.3051 - val_loss: 1.1142 - val_accuracy: 0.2430\n",
      "Epoch 27/200\n",
      "2553/2553 [==============================] - 0s 67us/sample - loss: 1.1132 - accuracy: 0.3024 - val_loss: 1.1127 - val_accuracy: 0.2523\n",
      "Epoch 28/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.1062 - accuracy: 0.3008 - val_loss: 1.1114 - val_accuracy: 0.2523\n",
      "Epoch 29/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.1076 - accuracy: 0.3181 - val_loss: 1.1100 - val_accuracy: 0.2523\n",
      "Epoch 30/200\n",
      "2553/2553 [==============================] - 0s 70us/sample - loss: 1.1036 - accuracy: 0.3126 - val_loss: 1.1088 - val_accuracy: 0.2617\n",
      "Epoch 31/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.1005 - accuracy: 0.3251 - val_loss: 1.1077 - val_accuracy: 0.2617\n",
      "Epoch 32/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.1032 - accuracy: 0.3188 - val_loss: 1.1065 - val_accuracy: 0.2804\n",
      "Epoch 33/200\n",
      "2553/2553 [==============================] - 0s 71us/sample - loss: 1.0996 - accuracy: 0.3267 - val_loss: 1.1054 - val_accuracy: 0.2804\n",
      "Epoch 34/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.0975 - accuracy: 0.3365 - val_loss: 1.1042 - val_accuracy: 0.2897\n",
      "Epoch 35/200\n",
      "2553/2553 [==============================] - 0s 71us/sample - loss: 1.1004 - accuracy: 0.3267 - val_loss: 1.1030 - val_accuracy: 0.2991\n",
      "Epoch 36/200\n",
      "2553/2553 [==============================] - 0s 69us/sample - loss: 1.0966 - accuracy: 0.3427 - val_loss: 1.1018 - val_accuracy: 0.3178\n",
      "Epoch 37/200\n",
      "2553/2553 [==============================] - 0s 66us/sample - loss: 1.0943 - accuracy: 0.3447 - val_loss: 1.1008 - val_accuracy: 0.3178\n",
      "Epoch 38/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.0937 - accuracy: 0.3486 - val_loss: 1.0999 - val_accuracy: 0.3271\n",
      "Epoch 39/200\n",
      "2553/2553 [==============================] - 0s 73us/sample - loss: 1.0950 - accuracy: 0.3467 - val_loss: 1.0990 - val_accuracy: 0.3364\n",
      "Epoch 40/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0940 - accuracy: 0.3658 - val_loss: 1.0980 - val_accuracy: 0.3364\n",
      "Epoch 41/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0931 - accuracy: 0.3584 - val_loss: 1.0972 - val_accuracy: 0.3458\n",
      "Epoch 42/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0893 - accuracy: 0.3780 - val_loss: 1.0964 - val_accuracy: 0.3551\n",
      "Epoch 43/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0911 - accuracy: 0.3662 - val_loss: 1.0957 - val_accuracy: 0.3925\n",
      "Epoch 44/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0890 - accuracy: 0.3866 - val_loss: 1.0950 - val_accuracy: 0.3925\n",
      "Epoch 45/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0885 - accuracy: 0.3811 - val_loss: 1.0943 - val_accuracy: 0.3925\n",
      "Epoch 46/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0908 - accuracy: 0.3733 - val_loss: 1.0936 - val_accuracy: 0.4019\n",
      "Epoch 47/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0872 - accuracy: 0.3925 - val_loss: 1.0930 - val_accuracy: 0.4112\n",
      "Epoch 48/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0869 - accuracy: 0.3956 - val_loss: 1.0923 - val_accuracy: 0.4206\n",
      "Epoch 49/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0863 - accuracy: 0.3999 - val_loss: 1.0917 - val_accuracy: 0.4112\n",
      "Epoch 50/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.0872 - accuracy: 0.4031 - val_loss: 1.0912 - val_accuracy: 0.4299\n",
      "Epoch 51/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0856 - accuracy: 0.4019 - val_loss: 1.0907 - val_accuracy: 0.4206\n",
      "Epoch 52/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0892 - accuracy: 0.4050 - val_loss: 1.0903 - val_accuracy: 0.4393\n",
      "Epoch 53/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.0864 - accuracy: 0.4140 - val_loss: 1.0898 - val_accuracy: 0.4579\n",
      "Epoch 54/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0848 - accuracy: 0.4179 - val_loss: 1.0894 - val_accuracy: 0.4673\n",
      "Epoch 55/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0839 - accuracy: 0.4093 - val_loss: 1.0891 - val_accuracy: 0.4766\n",
      "Epoch 56/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0817 - accuracy: 0.4219 - val_loss: 1.0888 - val_accuracy: 0.4766\n",
      "Epoch 57/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.0815 - accuracy: 0.4262 - val_loss: 1.0884 - val_accuracy: 0.4860\n",
      "Epoch 58/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0824 - accuracy: 0.4140 - val_loss: 1.0880 - val_accuracy: 0.4953\n",
      "Epoch 59/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0824 - accuracy: 0.4254 - val_loss: 1.0878 - val_accuracy: 0.4953\n",
      "Epoch 60/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0815 - accuracy: 0.4403 - val_loss: 1.0875 - val_accuracy: 0.4953\n",
      "Epoch 61/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0797 - accuracy: 0.4442 - val_loss: 1.0871 - val_accuracy: 0.5047\n",
      "Epoch 62/200\n",
      "2553/2553 [==============================] - 0s 65us/sample - loss: 1.0800 - accuracy: 0.4207 - val_loss: 1.0868 - val_accuracy: 0.5047\n",
      "Epoch 63/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0802 - accuracy: 0.4344 - val_loss: 1.0865 - val_accuracy: 0.5047\n",
      "Epoch 64/200\n",
      "2553/2553 [==============================] - 0s 69us/sample - loss: 1.0781 - accuracy: 0.4309 - val_loss: 1.0862 - val_accuracy: 0.4860\n",
      "Epoch 65/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0807 - accuracy: 0.4301 - val_loss: 1.0860 - val_accuracy: 0.4860\n",
      "Epoch 66/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0815 - accuracy: 0.4363 - val_loss: 1.0858 - val_accuracy: 0.4860\n",
      "Epoch 67/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0802 - accuracy: 0.4309 - val_loss: 1.0856 - val_accuracy: 0.4860\n",
      "Epoch 68/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0782 - accuracy: 0.4399 - val_loss: 1.0854 - val_accuracy: 0.4766\n",
      "Epoch 69/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0775 - accuracy: 0.4442 - val_loss: 1.0851 - val_accuracy: 0.4766\n",
      "Epoch 70/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0797 - accuracy: 0.4414 - val_loss: 1.0848 - val_accuracy: 0.4766\n",
      "Epoch 71/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0761 - accuracy: 0.4520 - val_loss: 1.0846 - val_accuracy: 0.4953\n",
      "Epoch 72/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0781 - accuracy: 0.4363 - val_loss: 1.0843 - val_accuracy: 0.5140\n",
      "Epoch 73/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0761 - accuracy: 0.4528 - val_loss: 1.0841 - val_accuracy: 0.5140\n",
      "Epoch 74/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0814 - accuracy: 0.4262 - val_loss: 1.0839 - val_accuracy: 0.5234\n",
      "Epoch 75/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0786 - accuracy: 0.4320 - val_loss: 1.0837 - val_accuracy: 0.5234\n",
      "Epoch 76/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0758 - accuracy: 0.4489 - val_loss: 1.0835 - val_accuracy: 0.5140\n",
      "Epoch 77/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0743 - accuracy: 0.4422 - val_loss: 1.0832 - val_accuracy: 0.5047\n",
      "Epoch 78/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.0750 - accuracy: 0.4532 - val_loss: 1.0830 - val_accuracy: 0.5047\n",
      "Epoch 79/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0774 - accuracy: 0.4438 - val_loss: 1.0827 - val_accuracy: 0.4953\n",
      "Epoch 80/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0772 - accuracy: 0.4391 - val_loss: 1.0824 - val_accuracy: 0.4953\n",
      "Epoch 81/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0736 - accuracy: 0.4567 - val_loss: 1.0822 - val_accuracy: 0.4953\n",
      "Epoch 82/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0714 - accuracy: 0.4446 - val_loss: 1.0819 - val_accuracy: 0.4953\n",
      "Epoch 83/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0717 - accuracy: 0.4563 - val_loss: 1.0817 - val_accuracy: 0.4953\n",
      "Epoch 84/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0717 - accuracy: 0.4473 - val_loss: 1.0814 - val_accuracy: 0.4953\n",
      "Epoch 85/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0730 - accuracy: 0.4512 - val_loss: 1.0811 - val_accuracy: 0.4953\n",
      "Epoch 86/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0700 - accuracy: 0.4520 - val_loss: 1.0808 - val_accuracy: 0.4953\n",
      "Epoch 87/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0757 - accuracy: 0.4363 - val_loss: 1.0805 - val_accuracy: 0.4953\n",
      "Epoch 88/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0725 - accuracy: 0.4403 - val_loss: 1.0802 - val_accuracy: 0.4953\n",
      "Epoch 89/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0696 - accuracy: 0.4516 - val_loss: 1.0799 - val_accuracy: 0.4953\n",
      "Epoch 90/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0714 - accuracy: 0.4563 - val_loss: 1.0796 - val_accuracy: 0.4953\n",
      "Epoch 91/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0726 - accuracy: 0.4501 - val_loss: 1.0793 - val_accuracy: 0.4953\n",
      "Epoch 92/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0702 - accuracy: 0.4512 - val_loss: 1.0790 - val_accuracy: 0.4953\n",
      "Epoch 93/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0728 - accuracy: 0.4422 - val_loss: 1.0787 - val_accuracy: 0.4860\n",
      "Epoch 94/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0716 - accuracy: 0.4469 - val_loss: 1.0784 - val_accuracy: 0.4860\n",
      "Epoch 95/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0703 - accuracy: 0.4567 - val_loss: 1.0781 - val_accuracy: 0.4860\n",
      "Epoch 96/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0720 - accuracy: 0.4485 - val_loss: 1.0778 - val_accuracy: 0.4860\n",
      "Epoch 97/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.0694 - accuracy: 0.4512 - val_loss: 1.0774 - val_accuracy: 0.4860\n",
      "Epoch 98/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0713 - accuracy: 0.4442 - val_loss: 1.0769 - val_accuracy: 0.4860\n",
      "Epoch 99/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0689 - accuracy: 0.4434 - val_loss: 1.0766 - val_accuracy: 0.4860\n",
      "Epoch 100/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0703 - accuracy: 0.4481 - val_loss: 1.0762 - val_accuracy: 0.4860\n",
      "Epoch 101/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0696 - accuracy: 0.4430 - val_loss: 1.0758 - val_accuracy: 0.4860\n",
      "Epoch 102/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0688 - accuracy: 0.4469 - val_loss: 1.0752 - val_accuracy: 0.4860\n",
      "Epoch 103/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0711 - accuracy: 0.4309 - val_loss: 1.0747 - val_accuracy: 0.4860\n",
      "Epoch 104/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0704 - accuracy: 0.4410 - val_loss: 1.0744 - val_accuracy: 0.4860\n",
      "Epoch 105/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0667 - accuracy: 0.4407 - val_loss: 1.0737 - val_accuracy: 0.4860\n",
      "Epoch 106/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0671 - accuracy: 0.4532 - val_loss: 1.0733 - val_accuracy: 0.4860\n",
      "Epoch 107/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0674 - accuracy: 0.4422 - val_loss: 1.0728 - val_accuracy: 0.4860\n",
      "Epoch 108/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0634 - accuracy: 0.4520 - val_loss: 1.0722 - val_accuracy: 0.4860\n",
      "Epoch 109/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0611 - accuracy: 0.4653 - val_loss: 1.0715 - val_accuracy: 0.4860\n",
      "Epoch 110/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.0617 - accuracy: 0.4602 - val_loss: 1.0709 - val_accuracy: 0.4860\n",
      "Epoch 111/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0637 - accuracy: 0.4536 - val_loss: 1.0701 - val_accuracy: 0.4860\n",
      "Epoch 112/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0673 - accuracy: 0.4356 - val_loss: 1.0696 - val_accuracy: 0.4860\n",
      "Epoch 113/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0619 - accuracy: 0.4536 - val_loss: 1.0689 - val_accuracy: 0.4860\n",
      "Epoch 114/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0592 - accuracy: 0.4552 - val_loss: 1.0681 - val_accuracy: 0.4860\n",
      "Epoch 115/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0609 - accuracy: 0.4595 - val_loss: 1.0671 - val_accuracy: 0.4860\n",
      "Epoch 116/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0679 - accuracy: 0.4324 - val_loss: 1.0665 - val_accuracy: 0.4860\n",
      "Epoch 117/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0568 - accuracy: 0.4567 - val_loss: 1.0655 - val_accuracy: 0.4860\n",
      "Epoch 118/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0596 - accuracy: 0.4583 - val_loss: 1.0644 - val_accuracy: 0.4860\n",
      "Epoch 119/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0617 - accuracy: 0.4332 - val_loss: 1.0636 - val_accuracy: 0.4860\n",
      "Epoch 120/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0571 - accuracy: 0.4552 - val_loss: 1.0623 - val_accuracy: 0.4860\n",
      "Epoch 121/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0558 - accuracy: 0.4473 - val_loss: 1.0611 - val_accuracy: 0.4860\n",
      "Epoch 122/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0572 - accuracy: 0.4559 - val_loss: 1.0600 - val_accuracy: 0.4860\n",
      "Epoch 123/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0552 - accuracy: 0.4481 - val_loss: 1.0586 - val_accuracy: 0.4860\n",
      "Epoch 124/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.0570 - accuracy: 0.4450 - val_loss: 1.0573 - val_accuracy: 0.4860\n",
      "Epoch 125/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0559 - accuracy: 0.4552 - val_loss: 1.0562 - val_accuracy: 0.4953\n",
      "Epoch 126/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0561 - accuracy: 0.4497 - val_loss: 1.0551 - val_accuracy: 0.5047\n",
      "Epoch 127/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0589 - accuracy: 0.4410 - val_loss: 1.0542 - val_accuracy: 0.5047\n",
      "Epoch 128/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.0500 - accuracy: 0.4610 - val_loss: 1.0530 - val_accuracy: 0.5047\n",
      "Epoch 129/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0495 - accuracy: 0.4489 - val_loss: 1.0518 - val_accuracy: 0.5047\n",
      "Epoch 130/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0521 - accuracy: 0.4516 - val_loss: 1.0507 - val_accuracy: 0.5047\n",
      "Epoch 131/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0472 - accuracy: 0.4595 - val_loss: 1.0494 - val_accuracy: 0.5047\n",
      "Epoch 132/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.0486 - accuracy: 0.4575 - val_loss: 1.0482 - val_accuracy: 0.5047\n",
      "Epoch 133/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0466 - accuracy: 0.4583 - val_loss: 1.0469 - val_accuracy: 0.5047\n",
      "Epoch 134/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0428 - accuracy: 0.4606 - val_loss: 1.0455 - val_accuracy: 0.5047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0439 - accuracy: 0.4548 - val_loss: 1.0442 - val_accuracy: 0.5047\n",
      "Epoch 136/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0407 - accuracy: 0.4524 - val_loss: 1.0426 - val_accuracy: 0.5047\n",
      "Epoch 137/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0386 - accuracy: 0.4602 - val_loss: 1.0413 - val_accuracy: 0.5047\n",
      "Epoch 138/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0427 - accuracy: 0.4599 - val_loss: 1.0400 - val_accuracy: 0.5047\n",
      "Epoch 139/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0427 - accuracy: 0.4454 - val_loss: 1.0390 - val_accuracy: 0.5047\n",
      "Epoch 140/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0391 - accuracy: 0.4520 - val_loss: 1.0378 - val_accuracy: 0.5047\n",
      "Epoch 141/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0402 - accuracy: 0.4579 - val_loss: 1.0365 - val_accuracy: 0.5047\n",
      "Epoch 142/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0398 - accuracy: 0.4528 - val_loss: 1.0353 - val_accuracy: 0.5047\n",
      "Epoch 143/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0468 - accuracy: 0.4375 - val_loss: 1.0344 - val_accuracy: 0.5047\n",
      "Epoch 144/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0417 - accuracy: 0.4473 - val_loss: 1.0333 - val_accuracy: 0.5047\n",
      "Epoch 145/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.0398 - accuracy: 0.4454 - val_loss: 1.0323 - val_accuracy: 0.5047\n",
      "Epoch 146/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0403 - accuracy: 0.4473 - val_loss: 1.0311 - val_accuracy: 0.5047\n",
      "Epoch 147/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0422 - accuracy: 0.4489 - val_loss: 1.0301 - val_accuracy: 0.5047\n",
      "Epoch 148/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0306 - accuracy: 0.4610 - val_loss: 1.0289 - val_accuracy: 0.5140\n",
      "Epoch 149/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0365 - accuracy: 0.4555 - val_loss: 1.0280 - val_accuracy: 0.5140\n",
      "Epoch 150/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0351 - accuracy: 0.4606 - val_loss: 1.0270 - val_accuracy: 0.5140\n",
      "Epoch 151/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0313 - accuracy: 0.4599 - val_loss: 1.0260 - val_accuracy: 0.5140\n",
      "Epoch 152/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0318 - accuracy: 0.4595 - val_loss: 1.0251 - val_accuracy: 0.5140\n",
      "Epoch 153/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0385 - accuracy: 0.4442 - val_loss: 1.0244 - val_accuracy: 0.5140\n",
      "Epoch 154/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0281 - accuracy: 0.4512 - val_loss: 1.0235 - val_accuracy: 0.5140\n",
      "Epoch 155/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0332 - accuracy: 0.4528 - val_loss: 1.0227 - val_accuracy: 0.5140\n",
      "Epoch 156/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0245 - accuracy: 0.4653 - val_loss: 1.0218 - val_accuracy: 0.5140\n",
      "Epoch 157/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0244 - accuracy: 0.4575 - val_loss: 1.0208 - val_accuracy: 0.5140\n",
      "Epoch 158/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0286 - accuracy: 0.4583 - val_loss: 1.0201 - val_accuracy: 0.5140\n",
      "Epoch 159/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0286 - accuracy: 0.4571 - val_loss: 1.0193 - val_accuracy: 0.5140\n",
      "Epoch 160/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0288 - accuracy: 0.4579 - val_loss: 1.0187 - val_accuracy: 0.5140\n",
      "Epoch 161/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0269 - accuracy: 0.4567 - val_loss: 1.0181 - val_accuracy: 0.5140\n",
      "Epoch 162/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0314 - accuracy: 0.4493 - val_loss: 1.0174 - val_accuracy: 0.5140\n",
      "Epoch 163/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.0306 - accuracy: 0.4461 - val_loss: 1.0168 - val_accuracy: 0.5140\n",
      "Epoch 164/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0233 - accuracy: 0.4591 - val_loss: 1.0159 - val_accuracy: 0.5140\n",
      "Epoch 165/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0273 - accuracy: 0.4422 - val_loss: 1.0152 - val_accuracy: 0.5140\n",
      "Epoch 166/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0267 - accuracy: 0.4442 - val_loss: 1.0146 - val_accuracy: 0.5140\n",
      "Epoch 167/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0297 - accuracy: 0.4548 - val_loss: 1.0140 - val_accuracy: 0.5140\n",
      "Epoch 168/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0173 - accuracy: 0.4712 - val_loss: 1.0132 - val_accuracy: 0.5140\n",
      "Epoch 169/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0211 - accuracy: 0.4552 - val_loss: 1.0123 - val_accuracy: 0.5140\n",
      "Epoch 170/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0231 - accuracy: 0.4559 - val_loss: 1.0117 - val_accuracy: 0.5140\n",
      "Epoch 171/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0243 - accuracy: 0.4559 - val_loss: 1.0110 - val_accuracy: 0.5140\n",
      "Epoch 172/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0199 - accuracy: 0.4630 - val_loss: 1.0103 - val_accuracy: 0.5140\n",
      "Epoch 173/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0189 - accuracy: 0.4571 - val_loss: 1.0097 - val_accuracy: 0.5234\n",
      "Epoch 174/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.0212 - accuracy: 0.4595 - val_loss: 1.0090 - val_accuracy: 0.5234\n",
      "Epoch 175/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0284 - accuracy: 0.4446 - val_loss: 1.0085 - val_accuracy: 0.5234\n",
      "Epoch 176/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0209 - accuracy: 0.4544 - val_loss: 1.0080 - val_accuracy: 0.5234\n",
      "Epoch 177/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0187 - accuracy: 0.4548 - val_loss: 1.0073 - val_accuracy: 0.5234\n",
      "Epoch 178/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0229 - accuracy: 0.4587 - val_loss: 1.0069 - val_accuracy: 0.5234\n",
      "Epoch 179/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0198 - accuracy: 0.4501 - val_loss: 1.0063 - val_accuracy: 0.5234\n",
      "Epoch 180/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0192 - accuracy: 0.4595 - val_loss: 1.0057 - val_accuracy: 0.5234\n",
      "Epoch 181/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.0169 - accuracy: 0.4618 - val_loss: 1.0051 - val_accuracy: 0.5234\n",
      "Epoch 182/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0205 - accuracy: 0.4465 - val_loss: 1.0045 - val_accuracy: 0.5234\n",
      "Epoch 183/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0178 - accuracy: 0.4555 - val_loss: 1.0040 - val_accuracy: 0.5234\n",
      "Epoch 184/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0283 - accuracy: 0.4414 - val_loss: 1.0036 - val_accuracy: 0.5234\n",
      "Epoch 185/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0131 - accuracy: 0.4638 - val_loss: 1.0030 - val_accuracy: 0.5327\n",
      "Epoch 186/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0149 - accuracy: 0.4673 - val_loss: 1.0025 - val_accuracy: 0.5327\n",
      "Epoch 187/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0213 - accuracy: 0.4548 - val_loss: 1.0021 - val_accuracy: 0.5327\n",
      "Epoch 188/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.0126 - accuracy: 0.4555 - val_loss: 1.0014 - val_accuracy: 0.5327\n",
      "Epoch 189/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0151 - accuracy: 0.4716 - val_loss: 1.0011 - val_accuracy: 0.5327\n",
      "Epoch 190/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0122 - accuracy: 0.4599 - val_loss: 1.0006 - val_accuracy: 0.5327\n",
      "Epoch 191/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0139 - accuracy: 0.4689 - val_loss: 1.0000 - val_accuracy: 0.5421\n",
      "Epoch 192/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0172 - accuracy: 0.4567 - val_loss: 0.9998 - val_accuracy: 0.5421\n",
      "Epoch 193/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0111 - accuracy: 0.4614 - val_loss: 0.9992 - val_accuracy: 0.5421\n",
      "Epoch 194/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0161 - accuracy: 0.4606 - val_loss: 0.9989 - val_accuracy: 0.5421\n",
      "Epoch 195/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0160 - accuracy: 0.4602 - val_loss: 0.9986 - val_accuracy: 0.5421\n",
      "Epoch 196/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0076 - accuracy: 0.4634 - val_loss: 0.9979 - val_accuracy: 0.5421\n",
      "Epoch 197/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0147 - accuracy: 0.4548 - val_loss: 0.9975 - val_accuracy: 0.5421\n",
      "Epoch 198/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0115 - accuracy: 0.4571 - val_loss: 0.9971 - val_accuracy: 0.5421\n",
      "Epoch 199/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0158 - accuracy: 0.4540 - val_loss: 0.9967 - val_accuracy: 0.5421\n",
      "Epoch 200/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0180 - accuracy: 0.4524 - val_loss: 0.9962 - val_accuracy: 0.5514\n",
      "0.55140185 {'loss': 1.0180113154021704, 'accuracy': 0.45240894, 'val_loss': 0.9962128267109951, 'val_accuracy': 0.55140185}\n",
      "Model: \"model_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_13 (InputLayer)        [(None, 29)]              0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 41)                1230      \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 10)                420       \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 3)                 33        \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 1,903\n",
      "Trainable params: 1,903\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2553 samples, validate on 107 samples\n",
      "Epoch 1/200\n",
      "2553/2553 [==============================] - 1s 369us/sample - loss: 1.1564 - accuracy: 0.2777 - val_loss: 1.0796 - val_accuracy: 0.3364\n",
      "Epoch 2/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.1458 - accuracy: 0.2718 - val_loss: 1.0788 - val_accuracy: 0.3271\n",
      "Epoch 3/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.1327 - accuracy: 0.2840 - val_loss: 1.0786 - val_accuracy: 0.3084\n",
      "Epoch 4/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.1339 - accuracy: 0.2660 - val_loss: 1.0786 - val_accuracy: 0.3178\n",
      "Epoch 5/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.1288 - accuracy: 0.2695 - val_loss: 1.0791 - val_accuracy: 0.3084\n",
      "Epoch 6/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.1232 - accuracy: 0.2758 - val_loss: 1.0797 - val_accuracy: 0.2991\n",
      "Epoch 7/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.1215 - accuracy: 0.2734 - val_loss: 1.0803 - val_accuracy: 0.2897\n",
      "Epoch 8/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.1128 - accuracy: 0.2793 - val_loss: 1.0808 - val_accuracy: 0.2897\n",
      "Epoch 9/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.1092 - accuracy: 0.2801 - val_loss: 1.0813 - val_accuracy: 0.2991\n",
      "Epoch 10/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.1126 - accuracy: 0.2605 - val_loss: 1.0819 - val_accuracy: 0.2897\n",
      "Epoch 11/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.1072 - accuracy: 0.2754 - val_loss: 1.0824 - val_accuracy: 0.2897\n",
      "Epoch 12/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.1050 - accuracy: 0.2734 - val_loss: 1.0828 - val_accuracy: 0.2991\n",
      "Epoch 13/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.1105 - accuracy: 0.2703 - val_loss: 1.0831 - val_accuracy: 0.3084\n",
      "Epoch 14/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.1050 - accuracy: 0.2730 - val_loss: 1.0834 - val_accuracy: 0.2991\n",
      "Epoch 15/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.1027 - accuracy: 0.2738 - val_loss: 1.0838 - val_accuracy: 0.2897\n",
      "Epoch 16/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.1022 - accuracy: 0.2824 - val_loss: 1.0840 - val_accuracy: 0.2897\n",
      "Epoch 17/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.1002 - accuracy: 0.2828 - val_loss: 1.0842 - val_accuracy: 0.2710\n",
      "Epoch 18/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0992 - accuracy: 0.2765 - val_loss: 1.0845 - val_accuracy: 0.2710\n",
      "Epoch 19/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 1.1032 - accuracy: 0.2773 - val_loss: 1.0849 - val_accuracy: 0.2710\n",
      "Epoch 20/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.1016 - accuracy: 0.2754 - val_loss: 1.0854 - val_accuracy: 0.2804\n",
      "Epoch 21/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.1015 - accuracy: 0.2812 - val_loss: 1.0854 - val_accuracy: 0.2710\n",
      "Epoch 22/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0967 - accuracy: 0.2938 - val_loss: 1.0854 - val_accuracy: 0.2897\n",
      "Epoch 23/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.1000 - accuracy: 0.2742 - val_loss: 1.0855 - val_accuracy: 0.2897\n",
      "Epoch 24/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.0966 - accuracy: 0.2820 - val_loss: 1.0857 - val_accuracy: 0.2897\n",
      "Epoch 25/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.0963 - accuracy: 0.2957 - val_loss: 1.0856 - val_accuracy: 0.2991\n",
      "Epoch 26/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.1000 - accuracy: 0.2711 - val_loss: 1.0860 - val_accuracy: 0.2804\n",
      "Epoch 27/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.0981 - accuracy: 0.2848 - val_loss: 1.0862 - val_accuracy: 0.2710\n",
      "Epoch 28/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0969 - accuracy: 0.2875 - val_loss: 1.0863 - val_accuracy: 0.2710\n",
      "Epoch 29/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.0964 - accuracy: 0.2875 - val_loss: 1.0865 - val_accuracy: 0.2804\n",
      "Epoch 30/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.0952 - accuracy: 0.2895 - val_loss: 1.0866 - val_accuracy: 0.2804\n",
      "Epoch 31/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0963 - accuracy: 0.2812 - val_loss: 1.0867 - val_accuracy: 0.2804\n",
      "Epoch 32/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0934 - accuracy: 0.2930 - val_loss: 1.0866 - val_accuracy: 0.2804\n",
      "Epoch 33/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.0931 - accuracy: 0.2922 - val_loss: 1.0866 - val_accuracy: 0.2804\n",
      "Epoch 34/200\n",
      "2553/2553 [==============================] - 0s 115us/sample - loss: 1.0958 - accuracy: 0.2902 - val_loss: 1.0867 - val_accuracy: 0.2897\n",
      "Epoch 35/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0943 - accuracy: 0.2844 - val_loss: 1.0866 - val_accuracy: 0.2897\n",
      "Epoch 36/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.0973 - accuracy: 0.2887 - val_loss: 1.0867 - val_accuracy: 0.2897\n",
      "Epoch 37/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0949 - accuracy: 0.2902 - val_loss: 1.0868 - val_accuracy: 0.2897\n",
      "Epoch 38/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.0977 - accuracy: 0.2906 - val_loss: 1.0869 - val_accuracy: 0.2897\n",
      "Epoch 39/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0931 - accuracy: 0.2977 - val_loss: 1.0867 - val_accuracy: 0.2897\n",
      "Epoch 40/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.0937 - accuracy: 0.2906 - val_loss: 1.0869 - val_accuracy: 0.2897\n",
      "Epoch 41/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0970 - accuracy: 0.2887 - val_loss: 1.0870 - val_accuracy: 0.2804\n",
      "Epoch 42/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.0941 - accuracy: 0.2910 - val_loss: 1.0868 - val_accuracy: 0.3084\n",
      "Epoch 43/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0929 - accuracy: 0.2969 - val_loss: 1.0865 - val_accuracy: 0.3178\n",
      "Epoch 44/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.0939 - accuracy: 0.2922 - val_loss: 1.0862 - val_accuracy: 0.3271\n",
      "Epoch 45/200\n",
      "2553/2553 [==============================] - 0s 123us/sample - loss: 1.0937 - accuracy: 0.2993 - val_loss: 1.0859 - val_accuracy: 0.3271\n",
      "Epoch 46/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.0924 - accuracy: 0.2989 - val_loss: 1.0852 - val_accuracy: 0.3271\n",
      "Epoch 47/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.0923 - accuracy: 0.2989 - val_loss: 1.0849 - val_accuracy: 0.3084\n",
      "Epoch 48/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0937 - accuracy: 0.2996 - val_loss: 1.0847 - val_accuracy: 0.3084\n",
      "Epoch 49/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.0974 - accuracy: 0.2914 - val_loss: 1.0846 - val_accuracy: 0.3084\n",
      "Epoch 50/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0940 - accuracy: 0.2953 - val_loss: 1.0844 - val_accuracy: 0.3178\n",
      "Epoch 51/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.0928 - accuracy: 0.3043 - val_loss: 1.0837 - val_accuracy: 0.3178\n",
      "Epoch 52/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0949 - accuracy: 0.2993 - val_loss: 1.0835 - val_accuracy: 0.3178\n",
      "Epoch 53/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0911 - accuracy: 0.3024 - val_loss: 1.0831 - val_accuracy: 0.3178\n",
      "Epoch 54/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0911 - accuracy: 0.3087 - val_loss: 1.0819 - val_accuracy: 0.3364\n",
      "Epoch 55/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.0916 - accuracy: 0.3012 - val_loss: 1.0817 - val_accuracy: 0.3271\n",
      "Epoch 56/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.0878 - accuracy: 0.3216 - val_loss: 1.0802 - val_accuracy: 0.3364\n",
      "Epoch 57/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0935 - accuracy: 0.3090 - val_loss: 1.0794 - val_accuracy: 0.3458\n",
      "Epoch 58/200\n",
      "2553/2553 [==============================] - 0s 117us/sample - loss: 1.0912 - accuracy: 0.3087 - val_loss: 1.0783 - val_accuracy: 0.3645\n",
      "Epoch 59/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0882 - accuracy: 0.3251 - val_loss: 1.0770 - val_accuracy: 0.3645\n",
      "Epoch 60/200\n",
      "2553/2553 [==============================] - 0s 129us/sample - loss: 1.0845 - accuracy: 0.3361 - val_loss: 1.0753 - val_accuracy: 0.3925\n",
      "Epoch 61/200\n",
      "2553/2553 [==============================] - 0s 153us/sample - loss: 1.0863 - accuracy: 0.3286 - val_loss: 1.0740 - val_accuracy: 0.3832\n",
      "Epoch 62/200\n",
      "2553/2553 [==============================] - 0s 167us/sample - loss: 1.0870 - accuracy: 0.3459 - val_loss: 1.0712 - val_accuracy: 0.3925\n",
      "Epoch 63/200\n",
      "2553/2553 [==============================] - 0s 144us/sample - loss: 1.0881 - accuracy: 0.3396 - val_loss: 1.0689 - val_accuracy: 0.3925\n",
      "Epoch 64/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.0849 - accuracy: 0.3467 - val_loss: 1.0660 - val_accuracy: 0.4019\n",
      "Epoch 65/200\n",
      "2553/2553 [==============================] - 0s 119us/sample - loss: 1.0848 - accuracy: 0.3600 - val_loss: 1.0626 - val_accuracy: 0.4112\n",
      "Epoch 66/200\n",
      "2553/2553 [==============================] - 0s 118us/sample - loss: 1.0774 - accuracy: 0.3643 - val_loss: 1.0589 - val_accuracy: 0.4206\n",
      "Epoch 67/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.0765 - accuracy: 0.3721 - val_loss: 1.0558 - val_accuracy: 0.4393\n",
      "Epoch 68/200\n",
      "2553/2553 [==============================] - 0s 133us/sample - loss: 1.0724 - accuracy: 0.3854 - val_loss: 1.0521 - val_accuracy: 0.4486\n",
      "Epoch 69/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0733 - accuracy: 0.3756 - val_loss: 1.0488 - val_accuracy: 0.4860\n",
      "Epoch 70/200\n",
      "2553/2553 [==============================] - 0s 126us/sample - loss: 1.0673 - accuracy: 0.3850 - val_loss: 1.0449 - val_accuracy: 0.4860\n",
      "Epoch 71/200\n",
      "2553/2553 [==============================] - 0s 126us/sample - loss: 1.0716 - accuracy: 0.3803 - val_loss: 1.0420 - val_accuracy: 0.5047\n",
      "Epoch 72/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0647 - accuracy: 0.3862 - val_loss: 1.0388 - val_accuracy: 0.5047\n",
      "Epoch 73/200\n",
      "2553/2553 [==============================] - 0s 118us/sample - loss: 1.0674 - accuracy: 0.3796 - val_loss: 1.0366 - val_accuracy: 0.5047\n",
      "Epoch 74/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.0687 - accuracy: 0.3796 - val_loss: 1.0343 - val_accuracy: 0.5140\n",
      "Epoch 75/200\n",
      "2553/2553 [==============================] - 0s 122us/sample - loss: 1.0573 - accuracy: 0.3968 - val_loss: 1.0312 - val_accuracy: 0.5140\n",
      "Epoch 76/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.0603 - accuracy: 0.3870 - val_loss: 1.0290 - val_accuracy: 0.5140\n",
      "Epoch 77/200\n",
      "2553/2553 [==============================] - 0s 119us/sample - loss: 1.0607 - accuracy: 0.3976 - val_loss: 1.0269 - val_accuracy: 0.5140\n",
      "Epoch 78/200\n",
      "2553/2553 [==============================] - 0s 115us/sample - loss: 1.0537 - accuracy: 0.3948 - val_loss: 1.0246 - val_accuracy: 0.5140\n",
      "Epoch 79/200\n",
      "2553/2553 [==============================] - 0s 120us/sample - loss: 1.0593 - accuracy: 0.3831 - val_loss: 1.0233 - val_accuracy: 0.5140\n",
      "Epoch 80/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.0531 - accuracy: 0.3968 - val_loss: 1.0211 - val_accuracy: 0.5140\n",
      "Epoch 81/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.0534 - accuracy: 0.3999 - val_loss: 1.0190 - val_accuracy: 0.5140\n",
      "Epoch 82/200\n",
      "2553/2553 [==============================] - 0s 120us/sample - loss: 1.0523 - accuracy: 0.4074 - val_loss: 1.0177 - val_accuracy: 0.5140\n",
      "Epoch 83/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.0489 - accuracy: 0.4078 - val_loss: 1.0163 - val_accuracy: 0.5140\n",
      "Epoch 84/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.0468 - accuracy: 0.3937 - val_loss: 1.0151 - val_accuracy: 0.5140\n",
      "Epoch 85/200\n",
      "2553/2553 [==============================] - 0s 120us/sample - loss: 1.0496 - accuracy: 0.4031 - val_loss: 1.0138 - val_accuracy: 0.5140\n",
      "Epoch 86/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.0485 - accuracy: 0.4007 - val_loss: 1.0128 - val_accuracy: 0.5140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/200\n",
      "2553/2553 [==============================] - 0s 115us/sample - loss: 1.0458 - accuracy: 0.4050 - val_loss: 1.0116 - val_accuracy: 0.5140\n",
      "Epoch 88/200\n",
      "2553/2553 [==============================] - 0s 120us/sample - loss: 1.0437 - accuracy: 0.4097 - val_loss: 1.0108 - val_accuracy: 0.5140\n",
      "Epoch 89/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.0500 - accuracy: 0.3925 - val_loss: 1.0102 - val_accuracy: 0.5140\n",
      "Epoch 90/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.0514 - accuracy: 0.3972 - val_loss: 1.0097 - val_accuracy: 0.5140\n",
      "Epoch 91/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.0448 - accuracy: 0.4058 - val_loss: 1.0090 - val_accuracy: 0.5140\n",
      "Epoch 92/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.0414 - accuracy: 0.4191 - val_loss: 1.0081 - val_accuracy: 0.5140\n",
      "Epoch 93/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.0495 - accuracy: 0.3937 - val_loss: 1.0081 - val_accuracy: 0.5140\n",
      "Epoch 94/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.0435 - accuracy: 0.4093 - val_loss: 1.0074 - val_accuracy: 0.5140\n",
      "Epoch 95/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.0413 - accuracy: 0.4101 - val_loss: 1.0066 - val_accuracy: 0.5047\n",
      "Epoch 96/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.0399 - accuracy: 0.4113 - val_loss: 1.0065 - val_accuracy: 0.5047\n",
      "Epoch 97/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 1.0451 - accuracy: 0.3999 - val_loss: 1.0058 - val_accuracy: 0.5047\n",
      "Epoch 98/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0399 - accuracy: 0.4034 - val_loss: 1.0052 - val_accuracy: 0.5047\n",
      "Epoch 99/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.0420 - accuracy: 0.4089 - val_loss: 1.0044 - val_accuracy: 0.5140\n",
      "Epoch 100/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.0370 - accuracy: 0.3999 - val_loss: 1.0040 - val_accuracy: 0.5140\n",
      "Epoch 101/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.0350 - accuracy: 0.4034 - val_loss: 1.0031 - val_accuracy: 0.5140\n",
      "Epoch 102/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0340 - accuracy: 0.4199 - val_loss: 1.0025 - val_accuracy: 0.5140\n",
      "Epoch 103/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.0412 - accuracy: 0.3976 - val_loss: 1.0021 - val_accuracy: 0.5140\n",
      "Epoch 104/200\n",
      "2553/2553 [==============================] - 0s 117us/sample - loss: 1.0379 - accuracy: 0.4136 - val_loss: 1.0021 - val_accuracy: 0.5140\n",
      "Epoch 105/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0434 - accuracy: 0.4003 - val_loss: 1.0022 - val_accuracy: 0.5140\n",
      "Epoch 106/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.0416 - accuracy: 0.3987 - val_loss: 1.0021 - val_accuracy: 0.5140\n",
      "Epoch 107/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.0388 - accuracy: 0.4042 - val_loss: 1.0019 - val_accuracy: 0.5140\n",
      "Epoch 108/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.0488 - accuracy: 0.3944 - val_loss: 1.0021 - val_accuracy: 0.5047\n",
      "Epoch 109/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0399 - accuracy: 0.3960 - val_loss: 1.0019 - val_accuracy: 0.5047\n",
      "Epoch 110/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.0390 - accuracy: 0.4054 - val_loss: 1.0013 - val_accuracy: 0.5047\n",
      "Epoch 111/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0417 - accuracy: 0.4125 - val_loss: 1.0012 - val_accuracy: 0.5047\n",
      "Epoch 112/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.0396 - accuracy: 0.4019 - val_loss: 1.0007 - val_accuracy: 0.5047\n",
      "Epoch 113/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0395 - accuracy: 0.4105 - val_loss: 1.0007 - val_accuracy: 0.5047\n",
      "Epoch 114/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0396 - accuracy: 0.3987 - val_loss: 1.0007 - val_accuracy: 0.5047\n",
      "Epoch 115/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0405 - accuracy: 0.4038 - val_loss: 1.0006 - val_accuracy: 0.5047\n",
      "Epoch 116/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.0383 - accuracy: 0.3913 - val_loss: 1.0005 - val_accuracy: 0.5047\n",
      "Epoch 117/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0404 - accuracy: 0.4132 - val_loss: 1.0009 - val_accuracy: 0.5047\n",
      "Epoch 118/200\n",
      "2553/2553 [==============================] - 0s 115us/sample - loss: 1.0384 - accuracy: 0.4046 - val_loss: 1.0005 - val_accuracy: 0.5047\n",
      "Epoch 119/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0359 - accuracy: 0.4109 - val_loss: 1.0002 - val_accuracy: 0.5047\n",
      "Epoch 120/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.0429 - accuracy: 0.4054 - val_loss: 1.0009 - val_accuracy: 0.5047\n",
      "Epoch 121/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0354 - accuracy: 0.4015 - val_loss: 1.0005 - val_accuracy: 0.5047\n",
      "Epoch 122/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.0390 - accuracy: 0.4015 - val_loss: 1.0010 - val_accuracy: 0.5047\n",
      "Epoch 123/200\n",
      "2553/2553 [==============================] - 0s 115us/sample - loss: 1.0405 - accuracy: 0.4062 - val_loss: 1.0006 - val_accuracy: 0.5047\n",
      "Epoch 124/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0404 - accuracy: 0.3897 - val_loss: 1.0008 - val_accuracy: 0.5047\n",
      "Epoch 125/200\n",
      "2553/2553 [==============================] - 0s 115us/sample - loss: 1.0401 - accuracy: 0.3948 - val_loss: 1.0006 - val_accuracy: 0.5047\n",
      "Epoch 126/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0409 - accuracy: 0.4019 - val_loss: 1.0008 - val_accuracy: 0.5047\n",
      "Epoch 127/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0418 - accuracy: 0.4031 - val_loss: 1.0013 - val_accuracy: 0.5047\n",
      "Epoch 128/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0442 - accuracy: 0.3901 - val_loss: 1.0013 - val_accuracy: 0.5047\n",
      "Epoch 129/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.0440 - accuracy: 0.4019 - val_loss: 1.0011 - val_accuracy: 0.5047\n",
      "Epoch 130/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0371 - accuracy: 0.4070 - val_loss: 1.0008 - val_accuracy: 0.5047\n",
      "Epoch 131/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.0467 - accuracy: 0.3995 - val_loss: 1.0015 - val_accuracy: 0.5047\n",
      "Epoch 132/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0347 - accuracy: 0.4074 - val_loss: 1.0015 - val_accuracy: 0.5047\n",
      "Epoch 133/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.0390 - accuracy: 0.3987 - val_loss: 1.0011 - val_accuracy: 0.5047\n",
      "Epoch 134/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0428 - accuracy: 0.3976 - val_loss: 1.0012 - val_accuracy: 0.5047\n",
      "Epoch 135/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.0370 - accuracy: 0.4101 - val_loss: 1.0011 - val_accuracy: 0.5047\n",
      "Epoch 136/200\n",
      "2553/2553 [==============================] - 0s 122us/sample - loss: 1.0391 - accuracy: 0.4034 - val_loss: 1.0005 - val_accuracy: 0.5047\n",
      "Epoch 137/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0374 - accuracy: 0.4015 - val_loss: 1.0008 - val_accuracy: 0.5047\n",
      "Epoch 138/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 1.0367 - accuracy: 0.4136 - val_loss: 1.0003 - val_accuracy: 0.5047\n",
      "Epoch 139/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0372 - accuracy: 0.4070 - val_loss: 1.0002 - val_accuracy: 0.5047\n",
      "Epoch 140/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 1.0443 - accuracy: 0.4038 - val_loss: 1.0006 - val_accuracy: 0.5047\n",
      "Epoch 141/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.0419 - accuracy: 0.3964 - val_loss: 1.0009 - val_accuracy: 0.5047\n",
      "Epoch 142/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 1.0386 - accuracy: 0.4081 - val_loss: 1.0009 - val_accuracy: 0.5047\n",
      "Epoch 143/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0327 - accuracy: 0.4164 - val_loss: 1.0003 - val_accuracy: 0.5047\n",
      "Epoch 144/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0354 - accuracy: 0.4054 - val_loss: 0.9999 - val_accuracy: 0.5047\n",
      "Epoch 145/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0382 - accuracy: 0.4042 - val_loss: 0.9998 - val_accuracy: 0.5047\n",
      "Epoch 146/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0366 - accuracy: 0.4062 - val_loss: 1.0004 - val_accuracy: 0.5047\n",
      "Epoch 147/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.0343 - accuracy: 0.4085 - val_loss: 0.9996 - val_accuracy: 0.5047\n",
      "Epoch 148/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0320 - accuracy: 0.4050 - val_loss: 0.9993 - val_accuracy: 0.5047\n",
      "Epoch 149/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.0410 - accuracy: 0.3980 - val_loss: 0.9991 - val_accuracy: 0.5047\n",
      "Epoch 150/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0341 - accuracy: 0.3999 - val_loss: 0.9992 - val_accuracy: 0.5047\n",
      "Epoch 151/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0378 - accuracy: 0.4085 - val_loss: 0.9997 - val_accuracy: 0.5047\n",
      "Epoch 152/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.0337 - accuracy: 0.4066 - val_loss: 0.9995 - val_accuracy: 0.5047\n",
      "Epoch 153/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0399 - accuracy: 0.3929 - val_loss: 0.9995 - val_accuracy: 0.5047\n",
      "Epoch 154/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0451 - accuracy: 0.4027 - val_loss: 1.0004 - val_accuracy: 0.5047\n",
      "Epoch 155/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.0433 - accuracy: 0.3913 - val_loss: 1.0010 - val_accuracy: 0.5047\n",
      "Epoch 156/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0301 - accuracy: 0.4097 - val_loss: 1.0001 - val_accuracy: 0.5047\n",
      "Epoch 157/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.0272 - accuracy: 0.4144 - val_loss: 0.9991 - val_accuracy: 0.5047\n",
      "Epoch 158/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0347 - accuracy: 0.4132 - val_loss: 0.9990 - val_accuracy: 0.5047\n",
      "Epoch 159/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.0453 - accuracy: 0.4003 - val_loss: 0.9992 - val_accuracy: 0.5047\n",
      "Epoch 160/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.0365 - accuracy: 0.4007 - val_loss: 0.9993 - val_accuracy: 0.5047\n",
      "Epoch 161/200\n",
      "2553/2553 [==============================] - ETA: 0s - loss: 1.0364 - accuracy: 0.41 - 0s 111us/sample - loss: 1.0361 - accuracy: 0.4113 - val_loss: 0.9992 - val_accuracy: 0.5047\n",
      "Epoch 162/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.0333 - accuracy: 0.4144 - val_loss: 0.9993 - val_accuracy: 0.5047\n",
      "Epoch 163/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.0325 - accuracy: 0.4085 - val_loss: 0.9981 - val_accuracy: 0.5047\n",
      "Epoch 164/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0410 - accuracy: 0.4042 - val_loss: 0.9984 - val_accuracy: 0.5047\n",
      "Epoch 165/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0365 - accuracy: 0.3999 - val_loss: 0.9989 - val_accuracy: 0.5047\n",
      "Epoch 166/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.0258 - accuracy: 0.4183 - val_loss: 0.9982 - val_accuracy: 0.5047\n",
      "Epoch 167/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0497 - accuracy: 0.3815 - val_loss: 0.9989 - val_accuracy: 0.5047\n",
      "Epoch 168/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.0397 - accuracy: 0.3968 - val_loss: 0.9997 - val_accuracy: 0.5047\n",
      "Epoch 169/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.0335 - accuracy: 0.4117 - val_loss: 0.9992 - val_accuracy: 0.5047\n",
      "Epoch 170/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.0347 - accuracy: 0.4031 - val_loss: 0.9991 - val_accuracy: 0.5047\n",
      "Epoch 171/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0310 - accuracy: 0.4140 - val_loss: 0.9986 - val_accuracy: 0.5047\n",
      "Epoch 172/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0360 - accuracy: 0.4031 - val_loss: 0.9984 - val_accuracy: 0.5047\n",
      "Epoch 173/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0339 - accuracy: 0.4117 - val_loss: 0.9979 - val_accuracy: 0.5047\n",
      "Epoch 174/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.0270 - accuracy: 0.4078 - val_loss: 0.9971 - val_accuracy: 0.5047\n",
      "Epoch 175/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.0325 - accuracy: 0.4097 - val_loss: 0.9962 - val_accuracy: 0.5047\n",
      "Epoch 176/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 1.0374 - accuracy: 0.4179 - val_loss: 0.9962 - val_accuracy: 0.5047\n",
      "Epoch 177/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0406 - accuracy: 0.4034 - val_loss: 0.9964 - val_accuracy: 0.5047\n",
      "Epoch 178/200\n",
      "2553/2553 [==============================] - 0s 117us/sample - loss: 1.0281 - accuracy: 0.4230 - val_loss: 0.9958 - val_accuracy: 0.5047\n",
      "Epoch 179/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.0389 - accuracy: 0.3984 - val_loss: 0.9958 - val_accuracy: 0.5047\n",
      "Epoch 180/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0316 - accuracy: 0.4132 - val_loss: 0.9956 - val_accuracy: 0.5047\n",
      "Epoch 181/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0319 - accuracy: 0.4097 - val_loss: 0.9956 - val_accuracy: 0.5047\n",
      "Epoch 182/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0313 - accuracy: 0.4195 - val_loss: 0.9954 - val_accuracy: 0.5047\n",
      "Epoch 183/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0336 - accuracy: 0.4101 - val_loss: 0.9953 - val_accuracy: 0.5047\n",
      "Epoch 184/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.0436 - accuracy: 0.3948 - val_loss: 0.9960 - val_accuracy: 0.5047\n",
      "Epoch 185/200\n",
      "2553/2553 [==============================] - 0s 115us/sample - loss: 1.0401 - accuracy: 0.3862 - val_loss: 0.9957 - val_accuracy: 0.5047\n",
      "Epoch 186/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0430 - accuracy: 0.4031 - val_loss: 0.9965 - val_accuracy: 0.5047\n",
      "Epoch 187/200\n",
      "2553/2553 [==============================] - 0s 115us/sample - loss: 1.0328 - accuracy: 0.4066 - val_loss: 0.9963 - val_accuracy: 0.5047\n",
      "Epoch 188/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0281 - accuracy: 0.4117 - val_loss: 0.9958 - val_accuracy: 0.5047\n",
      "Epoch 189/200\n",
      "2553/2553 [==============================] - ETA: 0s - loss: 1.0362 - accuracy: 0.40 - 0s 113us/sample - loss: 1.0373 - accuracy: 0.3995 - val_loss: 0.9961 - val_accuracy: 0.5047\n",
      "Epoch 190/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.0281 - accuracy: 0.4152 - val_loss: 0.9956 - val_accuracy: 0.5047\n",
      "Epoch 191/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 1.0314 - accuracy: 0.4050 - val_loss: 0.9952 - val_accuracy: 0.5047\n",
      "Epoch 192/200\n",
      "2553/2553 [==============================] - 0s 118us/sample - loss: 1.0379 - accuracy: 0.3987 - val_loss: 0.9949 - val_accuracy: 0.5047\n",
      "Epoch 193/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0368 - accuracy: 0.4042 - val_loss: 0.9943 - val_accuracy: 0.5140\n",
      "Epoch 194/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0298 - accuracy: 0.4019 - val_loss: 0.9945 - val_accuracy: 0.5047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 195/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.0290 - accuracy: 0.4058 - val_loss: 0.9943 - val_accuracy: 0.5047\n",
      "Epoch 196/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.0255 - accuracy: 0.4078 - val_loss: 0.9935 - val_accuracy: 0.5047\n",
      "Epoch 197/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.0313 - accuracy: 0.4066 - val_loss: 0.9933 - val_accuracy: 0.5140\n",
      "Epoch 198/200\n",
      "2553/2553 [==============================] - 0s 122us/sample - loss: 1.0240 - accuracy: 0.4195 - val_loss: 0.9932 - val_accuracy: 0.5047\n",
      "Epoch 199/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.0407 - accuracy: 0.3929 - val_loss: 0.9942 - val_accuracy: 0.5047\n",
      "Epoch 200/200\n",
      "2553/2553 [==============================] - 0s 117us/sample - loss: 1.0347 - accuracy: 0.4038 - val_loss: 0.9947 - val_accuracy: 0.5047\n",
      "0.5046729 {'loss': 1.0347311054310797, 'accuracy': 0.40383863, 'val_loss': 0.9946716951432629, 'val_accuracy': 0.5046729}\n",
      "Model: \"model_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_14 (InputLayer)        [(None, 29)]              0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 41)                1230      \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 10)                420       \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 3)                 33        \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 1,903\n",
      "Trainable params: 1,903\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2553 samples, validate on 107 samples\n",
      "Epoch 1/200\n",
      "2553/2553 [==============================] - 1s 327us/sample - loss: 1.1175 - accuracy: 0.2765 - val_loss: 1.0983 - val_accuracy: 0.2897\n",
      "Epoch 2/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.1126 - accuracy: 0.2852 - val_loss: 1.0979 - val_accuracy: 0.2897\n",
      "Epoch 3/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.1195 - accuracy: 0.2605 - val_loss: 1.0973 - val_accuracy: 0.2804\n",
      "Epoch 4/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.1126 - accuracy: 0.2683 - val_loss: 1.0969 - val_accuracy: 0.2710\n",
      "Epoch 5/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.1133 - accuracy: 0.2687 - val_loss: 1.0965 - val_accuracy: 0.2710\n",
      "Epoch 6/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.1103 - accuracy: 0.2691 - val_loss: 1.0962 - val_accuracy: 0.2710\n",
      "Epoch 7/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.1137 - accuracy: 0.2585 - val_loss: 1.0960 - val_accuracy: 0.2804\n",
      "Epoch 8/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.1104 - accuracy: 0.2703 - val_loss: 1.0957 - val_accuracy: 0.2804\n",
      "Epoch 9/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.1091 - accuracy: 0.2691 - val_loss: 1.0956 - val_accuracy: 0.2804\n",
      "Epoch 10/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.1079 - accuracy: 0.2754 - val_loss: 1.0955 - val_accuracy: 0.2991\n",
      "Epoch 11/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.1064 - accuracy: 0.2691 - val_loss: 1.0954 - val_accuracy: 0.2991\n",
      "Epoch 12/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.1060 - accuracy: 0.2699 - val_loss: 1.0953 - val_accuracy: 0.2897\n",
      "Epoch 13/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.1069 - accuracy: 0.2613 - val_loss: 1.0953 - val_accuracy: 0.2991\n",
      "Epoch 14/200\n",
      "2553/2553 [==============================] - 0s 65us/sample - loss: 1.1070 - accuracy: 0.2632 - val_loss: 1.0953 - val_accuracy: 0.2991\n",
      "Epoch 15/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.1023 - accuracy: 0.2785 - val_loss: 1.0952 - val_accuracy: 0.2991\n",
      "Epoch 16/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.1037 - accuracy: 0.2758 - val_loss: 1.0952 - val_accuracy: 0.2991\n",
      "Epoch 17/200\n",
      "2553/2553 [==============================] - 0s 65us/sample - loss: 1.1035 - accuracy: 0.2664 - val_loss: 1.0951 - val_accuracy: 0.2991\n",
      "Epoch 18/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.1033 - accuracy: 0.2687 - val_loss: 1.0950 - val_accuracy: 0.2991\n",
      "Epoch 19/200\n",
      "2553/2553 [==============================] - 0s 65us/sample - loss: 1.1019 - accuracy: 0.2765 - val_loss: 1.0950 - val_accuracy: 0.2991\n",
      "Epoch 20/200\n",
      "2553/2553 [==============================] - 0s 70us/sample - loss: 1.1028 - accuracy: 0.2703 - val_loss: 1.0947 - val_accuracy: 0.2897\n",
      "Epoch 21/200\n",
      "2553/2553 [==============================] - 0s 66us/sample - loss: 1.1011 - accuracy: 0.2789 - val_loss: 1.0945 - val_accuracy: 0.2991\n",
      "Epoch 22/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.1019 - accuracy: 0.2640 - val_loss: 1.0944 - val_accuracy: 0.2897\n",
      "Epoch 23/200\n",
      "2553/2553 [==============================] - 0s 69us/sample - loss: 1.1007 - accuracy: 0.2754 - val_loss: 1.0942 - val_accuracy: 0.2897\n",
      "Epoch 24/200\n",
      "2553/2553 [==============================] - 0s 68us/sample - loss: 1.0997 - accuracy: 0.2801 - val_loss: 1.0941 - val_accuracy: 0.2710\n",
      "Epoch 25/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0997 - accuracy: 0.2816 - val_loss: 1.0940 - val_accuracy: 0.2897\n",
      "Epoch 26/200\n",
      "2553/2553 [==============================] - 0s 67us/sample - loss: 1.0986 - accuracy: 0.2808 - val_loss: 1.0939 - val_accuracy: 0.2991\n",
      "Epoch 27/200\n",
      "2553/2553 [==============================] - 0s 65us/sample - loss: 1.0996 - accuracy: 0.2793 - val_loss: 1.0939 - val_accuracy: 0.2991\n",
      "Epoch 28/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.1004 - accuracy: 0.2781 - val_loss: 1.0939 - val_accuracy: 0.2991\n",
      "Epoch 29/200\n",
      "2553/2553 [==============================] - 0s 65us/sample - loss: 1.0990 - accuracy: 0.2859 - val_loss: 1.0940 - val_accuracy: 0.2991\n",
      "Epoch 30/200\n",
      "2553/2553 [==============================] - 0s 68us/sample - loss: 1.0994 - accuracy: 0.2808 - val_loss: 1.0940 - val_accuracy: 0.2991\n",
      "Epoch 31/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0992 - accuracy: 0.2785 - val_loss: 1.0940 - val_accuracy: 0.2991\n",
      "Epoch 32/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.0991 - accuracy: 0.2840 - val_loss: 1.0940 - val_accuracy: 0.2991\n",
      "Epoch 33/200\n",
      "2553/2553 [==============================] - 0s 65us/sample - loss: 1.0997 - accuracy: 0.2808 - val_loss: 1.0941 - val_accuracy: 0.2897\n",
      "Epoch 34/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0998 - accuracy: 0.2750 - val_loss: 1.0941 - val_accuracy: 0.2897\n",
      "Epoch 35/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0995 - accuracy: 0.2765 - val_loss: 1.0943 - val_accuracy: 0.2897\n",
      "Epoch 36/200\n",
      "2553/2553 [==============================] - 0s 66us/sample - loss: 1.0993 - accuracy: 0.2812 - val_loss: 1.0944 - val_accuracy: 0.2804\n",
      "Epoch 37/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.0985 - accuracy: 0.2855 - val_loss: 1.0944 - val_accuracy: 0.2710\n",
      "Epoch 38/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0990 - accuracy: 0.2820 - val_loss: 1.0943 - val_accuracy: 0.2710\n",
      "Epoch 39/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.0983 - accuracy: 0.2855 - val_loss: 1.0943 - val_accuracy: 0.2710\n",
      "Epoch 40/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0988 - accuracy: 0.2816 - val_loss: 1.0944 - val_accuracy: 0.2710\n",
      "Epoch 41/200\n",
      "2553/2553 [==============================] - 0s 70us/sample - loss: 1.0988 - accuracy: 0.2848 - val_loss: 1.0944 - val_accuracy: 0.2710\n",
      "Epoch 42/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0988 - accuracy: 0.2840 - val_loss: 1.0944 - val_accuracy: 0.2804\n",
      "Epoch 43/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.0988 - accuracy: 0.2836 - val_loss: 1.0945 - val_accuracy: 0.2897\n",
      "Epoch 44/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0984 - accuracy: 0.2852 - val_loss: 1.0945 - val_accuracy: 0.2897\n",
      "Epoch 45/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0987 - accuracy: 0.2836 - val_loss: 1.0945 - val_accuracy: 0.2897\n",
      "Epoch 46/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0989 - accuracy: 0.2859 - val_loss: 1.0946 - val_accuracy: 0.2897\n",
      "Epoch 47/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0984 - accuracy: 0.2875 - val_loss: 1.0946 - val_accuracy: 0.2897\n",
      "Epoch 48/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0989 - accuracy: 0.2852 - val_loss: 1.0947 - val_accuracy: 0.2897\n",
      "Epoch 49/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.0989 - accuracy: 0.2836 - val_loss: 1.0947 - val_accuracy: 0.2897\n",
      "Epoch 50/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0990 - accuracy: 0.2848 - val_loss: 1.0948 - val_accuracy: 0.2897\n",
      "Epoch 51/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0987 - accuracy: 0.2832 - val_loss: 1.0948 - val_accuracy: 0.2897\n",
      "Epoch 52/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0986 - accuracy: 0.2816 - val_loss: 1.0949 - val_accuracy: 0.2897\n",
      "Epoch 53/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0985 - accuracy: 0.2863 - val_loss: 1.0949 - val_accuracy: 0.2897\n",
      "Epoch 54/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.0981 - accuracy: 0.2922 - val_loss: 1.0949 - val_accuracy: 0.2897\n",
      "Epoch 55/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0985 - accuracy: 0.2879 - val_loss: 1.0949 - val_accuracy: 0.2897\n",
      "Epoch 56/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0950 - val_accuracy: 0.2897\n",
      "Epoch 57/200\n",
      "2553/2553 [==============================] - 0s 65us/sample - loss: 1.0986 - accuracy: 0.2801 - val_loss: 1.0951 - val_accuracy: 0.2804\n",
      "Epoch 58/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0985 - accuracy: 0.2899 - val_loss: 1.0951 - val_accuracy: 0.2897\n",
      "Epoch 59/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0981 - accuracy: 0.2867 - val_loss: 1.0951 - val_accuracy: 0.2804\n",
      "Epoch 60/200\n",
      "2553/2553 [==============================] - 0s 66us/sample - loss: 1.0986 - accuracy: 0.2840 - val_loss: 1.0952 - val_accuracy: 0.2897\n",
      "Epoch 61/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.0981 - accuracy: 0.2875 - val_loss: 1.0952 - val_accuracy: 0.2897\n",
      "Epoch 62/200\n",
      "2553/2553 [==============================] - 0s 65us/sample - loss: 1.0987 - accuracy: 0.2781 - val_loss: 1.0953 - val_accuracy: 0.2897\n",
      "Epoch 63/200\n",
      "2553/2553 [==============================] - 0s 65us/sample - loss: 1.0983 - accuracy: 0.2910 - val_loss: 1.0952 - val_accuracy: 0.2897\n",
      "Epoch 64/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0989 - accuracy: 0.2855 - val_loss: 1.0953 - val_accuracy: 0.2897\n",
      "Epoch 65/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0983 - accuracy: 0.2883 - val_loss: 1.0953 - val_accuracy: 0.2897\n",
      "Epoch 66/200\n",
      "2553/2553 [==============================] - 0s 68us/sample - loss: 1.0986 - accuracy: 0.2875 - val_loss: 1.0953 - val_accuracy: 0.2897\n",
      "Epoch 67/200\n",
      "2553/2553 [==============================] - 0s 73us/sample - loss: 1.0986 - accuracy: 0.2875 - val_loss: 1.0953 - val_accuracy: 0.2897\n",
      "Epoch 68/200\n",
      "2553/2553 [==============================] - 0s 67us/sample - loss: 1.0984 - accuracy: 0.2859 - val_loss: 1.0952 - val_accuracy: 0.2897\n",
      "Epoch 69/200\n",
      "2553/2553 [==============================] - 0s 69us/sample - loss: 1.0978 - accuracy: 0.2895 - val_loss: 1.0951 - val_accuracy: 0.2897\n",
      "Epoch 70/200\n",
      "2553/2553 [==============================] - 0s 72us/sample - loss: 1.0983 - accuracy: 0.2844 - val_loss: 1.0951 - val_accuracy: 0.2897\n",
      "Epoch 71/200\n",
      "2553/2553 [==============================] - 0s 80us/sample - loss: 1.0981 - accuracy: 0.2910 - val_loss: 1.0950 - val_accuracy: 0.2897\n",
      "Epoch 72/200\n",
      "2553/2553 [==============================] - 0s 84us/sample - loss: 1.0985 - accuracy: 0.2852 - val_loss: 1.0951 - val_accuracy: 0.2897\n",
      "Epoch 73/200\n",
      "2553/2553 [==============================] - 0s 86us/sample - loss: 1.0985 - accuracy: 0.2855 - val_loss: 1.0951 - val_accuracy: 0.2897\n",
      "Epoch 74/200\n",
      "2553/2553 [==============================] - 0s 82us/sample - loss: 1.0982 - accuracy: 0.2871 - val_loss: 1.0951 - val_accuracy: 0.2897\n",
      "Epoch 75/200\n",
      "2553/2553 [==============================] - 0s 79us/sample - loss: 1.0983 - accuracy: 0.2855 - val_loss: 1.0951 - val_accuracy: 0.2897\n",
      "Epoch 76/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0982 - accuracy: 0.2910 - val_loss: 1.0951 - val_accuracy: 0.2897\n",
      "Epoch 77/200\n",
      "2553/2553 [==============================] - 0s 71us/sample - loss: 1.0985 - accuracy: 0.2867 - val_loss: 1.0950 - val_accuracy: 0.2897\n",
      "Epoch 78/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0983 - accuracy: 0.2902 - val_loss: 1.0950 - val_accuracy: 0.2897\n",
      "Epoch 79/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0984 - accuracy: 0.2855 - val_loss: 1.0950 - val_accuracy: 0.2897\n",
      "Epoch 80/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0987 - accuracy: 0.2910 - val_loss: 1.0951 - val_accuracy: 0.2897\n",
      "Epoch 81/200\n",
      "2553/2553 [==============================] - 0s 65us/sample - loss: 1.0987 - accuracy: 0.2895 - val_loss: 1.0951 - val_accuracy: 0.2897\n",
      "Epoch 82/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0980 - accuracy: 0.2922 - val_loss: 1.0951 - val_accuracy: 0.2897\n",
      "Epoch 83/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0983 - accuracy: 0.2895 - val_loss: 1.0951 - val_accuracy: 0.2897\n",
      "Epoch 84/200\n",
      "2553/2553 [==============================] - 0s 69us/sample - loss: 1.0983 - accuracy: 0.2891 - val_loss: 1.0951 - val_accuracy: 0.2897\n",
      "Epoch 85/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0985 - accuracy: 0.2883 - val_loss: 1.0950 - val_accuracy: 0.2897\n",
      "Epoch 86/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0987 - accuracy: 0.2887 - val_loss: 1.0950 - val_accuracy: 0.2897\n",
      "Epoch 87/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.0976 - accuracy: 0.2953 - val_loss: 1.0949 - val_accuracy: 0.2991\n",
      "Epoch 88/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0983 - accuracy: 0.2895 - val_loss: 1.0949 - val_accuracy: 0.2991\n",
      "Epoch 89/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0987 - accuracy: 0.2848 - val_loss: 1.0950 - val_accuracy: 0.2991\n",
      "Epoch 90/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0988 - accuracy: 0.2867 - val_loss: 1.0950 - val_accuracy: 0.2991\n",
      "Epoch 91/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0981 - accuracy: 0.2891 - val_loss: 1.0949 - val_accuracy: 0.2991\n",
      "Epoch 92/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.0983 - accuracy: 0.2899 - val_loss: 1.0949 - val_accuracy: 0.2991\n",
      "Epoch 93/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.0979 - accuracy: 0.3016 - val_loss: 1.0948 - val_accuracy: 0.2991\n",
      "Epoch 94/200\n",
      "2553/2553 [==============================] - 0s 66us/sample - loss: 1.0989 - accuracy: 0.2855 - val_loss: 1.0949 - val_accuracy: 0.2991\n",
      "Epoch 95/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0980 - accuracy: 0.2949 - val_loss: 1.0948 - val_accuracy: 0.2991\n",
      "Epoch 96/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0980 - accuracy: 0.2957 - val_loss: 1.0947 - val_accuracy: 0.2991\n",
      "Epoch 97/200\n",
      "2553/2553 [==============================] - 0s 65us/sample - loss: 1.0978 - accuracy: 0.2961 - val_loss: 1.0946 - val_accuracy: 0.2991\n",
      "Epoch 98/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.0986 - accuracy: 0.2906 - val_loss: 1.0947 - val_accuracy: 0.2991\n",
      "Epoch 99/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0979 - accuracy: 0.2934 - val_loss: 1.0946 - val_accuracy: 0.2991\n",
      "Epoch 100/200\n",
      "2553/2553 [==============================] - 0s 66us/sample - loss: 1.0978 - accuracy: 0.2957 - val_loss: 1.0946 - val_accuracy: 0.2991\n",
      "Epoch 101/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.0981 - accuracy: 0.2926 - val_loss: 1.0945 - val_accuracy: 0.2991\n",
      "Epoch 102/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0985 - accuracy: 0.2899 - val_loss: 1.0946 - val_accuracy: 0.2991\n",
      "Epoch 103/200\n",
      "2553/2553 [==============================] - 0s 70us/sample - loss: 1.0978 - accuracy: 0.2926 - val_loss: 1.0945 - val_accuracy: 0.2991\n",
      "Epoch 104/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.0979 - accuracy: 0.2957 - val_loss: 1.0944 - val_accuracy: 0.2991\n",
      "Epoch 105/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0982 - accuracy: 0.2930 - val_loss: 1.0944 - val_accuracy: 0.2991\n",
      "Epoch 106/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0984 - accuracy: 0.2895 - val_loss: 1.0944 - val_accuracy: 0.3084\n",
      "Epoch 107/200\n",
      "2553/2553 [==============================] - 0s 65us/sample - loss: 1.0976 - accuracy: 0.2934 - val_loss: 1.0944 - val_accuracy: 0.3084\n",
      "Epoch 108/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0981 - accuracy: 0.2914 - val_loss: 1.0943 - val_accuracy: 0.3084\n",
      "Epoch 109/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0978 - accuracy: 0.2934 - val_loss: 1.0943 - val_accuracy: 0.3084\n",
      "Epoch 110/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0977 - accuracy: 0.2902 - val_loss: 1.0943 - val_accuracy: 0.3084\n",
      "Epoch 111/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0981 - accuracy: 0.2930 - val_loss: 1.0943 - val_accuracy: 0.3178\n",
      "Epoch 112/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0975 - accuracy: 0.2981 - val_loss: 1.0942 - val_accuracy: 0.3178\n",
      "Epoch 113/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0980 - accuracy: 0.2942 - val_loss: 1.0942 - val_accuracy: 0.3084\n",
      "Epoch 114/200\n",
      "2553/2553 [==============================] - 0s 81us/sample - loss: 1.0981 - accuracy: 0.2973 - val_loss: 1.0942 - val_accuracy: 0.3084\n",
      "Epoch 115/200\n",
      "2553/2553 [==============================] - 0s 87us/sample - loss: 1.0978 - accuracy: 0.2922 - val_loss: 1.0942 - val_accuracy: 0.3084\n",
      "Epoch 116/200\n",
      "2553/2553 [==============================] - 0s 91us/sample - loss: 1.0976 - accuracy: 0.2973 - val_loss: 1.0941 - val_accuracy: 0.3084\n",
      "Epoch 117/200\n",
      "2553/2553 [==============================] - 0s 91us/sample - loss: 1.0975 - accuracy: 0.2934 - val_loss: 1.0941 - val_accuracy: 0.3084\n",
      "Epoch 118/200\n",
      "2553/2553 [==============================] - 0s 85us/sample - loss: 1.0983 - accuracy: 0.2879 - val_loss: 1.0941 - val_accuracy: 0.3084\n",
      "Epoch 119/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0977 - accuracy: 0.2934 - val_loss: 1.0941 - val_accuracy: 0.3084\n",
      "Epoch 120/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0971 - accuracy: 0.2977 - val_loss: 1.0940 - val_accuracy: 0.3084\n",
      "Epoch 121/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0971 - accuracy: 0.3004 - val_loss: 1.0940 - val_accuracy: 0.3084\n",
      "Epoch 122/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0971 - accuracy: 0.3024 - val_loss: 1.0939 - val_accuracy: 0.3178\n",
      "Epoch 123/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0978 - accuracy: 0.2934 - val_loss: 1.0939 - val_accuracy: 0.3084\n",
      "Epoch 124/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0972 - accuracy: 0.2981 - val_loss: 1.0939 - val_accuracy: 0.3084\n",
      "Epoch 125/200\n",
      "2553/2553 [==============================] - 0s 70us/sample - loss: 1.0974 - accuracy: 0.2922 - val_loss: 1.0939 - val_accuracy: 0.3084\n",
      "Epoch 126/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.0979 - accuracy: 0.2926 - val_loss: 1.0939 - val_accuracy: 0.3084\n",
      "Epoch 127/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.0968 - accuracy: 0.2949 - val_loss: 1.0939 - val_accuracy: 0.3084\n",
      "Epoch 128/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0970 - accuracy: 0.2993 - val_loss: 1.0938 - val_accuracy: 0.3084\n",
      "Epoch 129/200\n",
      "2553/2553 [==============================] - 0s 65us/sample - loss: 1.0977 - accuracy: 0.2910 - val_loss: 1.0938 - val_accuracy: 0.3178\n",
      "Epoch 130/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0976 - accuracy: 0.2934 - val_loss: 1.0937 - val_accuracy: 0.3084\n",
      "Epoch 131/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0971 - accuracy: 0.3008 - val_loss: 1.0936 - val_accuracy: 0.2991\n",
      "Epoch 132/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0974 - accuracy: 0.2973 - val_loss: 1.0936 - val_accuracy: 0.2991\n",
      "Epoch 133/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0979 - accuracy: 0.2879 - val_loss: 1.0937 - val_accuracy: 0.2991\n",
      "Epoch 134/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0975 - accuracy: 0.2965 - val_loss: 1.0937 - val_accuracy: 0.2991\n",
      "Epoch 135/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.0974 - accuracy: 0.2906 - val_loss: 1.0936 - val_accuracy: 0.2991\n",
      "Epoch 136/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.0974 - accuracy: 0.2965 - val_loss: 1.0936 - val_accuracy: 0.2991\n",
      "Epoch 137/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0980 - accuracy: 0.2859 - val_loss: 1.0937 - val_accuracy: 0.2991\n",
      "Epoch 138/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0967 - accuracy: 0.3004 - val_loss: 1.0936 - val_accuracy: 0.2991\n",
      "Epoch 139/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0978 - accuracy: 0.2906 - val_loss: 1.0937 - val_accuracy: 0.2991\n",
      "Epoch 140/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0972 - accuracy: 0.2981 - val_loss: 1.0937 - val_accuracy: 0.2991\n",
      "Epoch 141/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0975 - accuracy: 0.2934 - val_loss: 1.0936 - val_accuracy: 0.2991\n",
      "Epoch 142/200\n",
      "2553/2553 [==============================] - 0s 70us/sample - loss: 1.0974 - accuracy: 0.2934 - val_loss: 1.0937 - val_accuracy: 0.2991\n",
      "Epoch 143/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0964 - accuracy: 0.2996 - val_loss: 1.0936 - val_accuracy: 0.2897\n",
      "Epoch 144/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0978 - accuracy: 0.2918 - val_loss: 1.0936 - val_accuracy: 0.2897\n",
      "Epoch 145/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0973 - accuracy: 0.2930 - val_loss: 1.0936 - val_accuracy: 0.2897\n",
      "Epoch 146/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0976 - accuracy: 0.2906 - val_loss: 1.0935 - val_accuracy: 0.2897\n",
      "Epoch 147/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0977 - accuracy: 0.2938 - val_loss: 1.0936 - val_accuracy: 0.2897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 148/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0978 - accuracy: 0.2863 - val_loss: 1.0936 - val_accuracy: 0.2897\n",
      "Epoch 149/200\n",
      "2553/2553 [==============================] - 0s 66us/sample - loss: 1.0975 - accuracy: 0.2953 - val_loss: 1.0936 - val_accuracy: 0.2991\n",
      "Epoch 150/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0975 - accuracy: 0.2902 - val_loss: 1.0936 - val_accuracy: 0.2991\n",
      "Epoch 151/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0976 - accuracy: 0.2906 - val_loss: 1.0936 - val_accuracy: 0.2991\n",
      "Epoch 152/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0975 - accuracy: 0.2965 - val_loss: 1.0937 - val_accuracy: 0.3084\n",
      "Epoch 153/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.0976 - accuracy: 0.2965 - val_loss: 1.0937 - val_accuracy: 0.3084\n",
      "Epoch 154/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0972 - accuracy: 0.2969 - val_loss: 1.0937 - val_accuracy: 0.3084\n",
      "Epoch 155/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0977 - accuracy: 0.2934 - val_loss: 1.0937 - val_accuracy: 0.3084\n",
      "Epoch 156/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0973 - accuracy: 0.2969 - val_loss: 1.0936 - val_accuracy: 0.3084\n",
      "Epoch 157/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0972 - accuracy: 0.2993 - val_loss: 1.0936 - val_accuracy: 0.2991\n",
      "Epoch 158/200\n",
      "2553/2553 [==============================] - 0s 68us/sample - loss: 1.0977 - accuracy: 0.2930 - val_loss: 1.0935 - val_accuracy: 0.2991\n",
      "Epoch 159/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.0968 - accuracy: 0.2953 - val_loss: 1.0935 - val_accuracy: 0.2991\n",
      "Epoch 160/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0970 - accuracy: 0.2934 - val_loss: 1.0934 - val_accuracy: 0.2991\n",
      "Epoch 161/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0971 - accuracy: 0.2906 - val_loss: 1.0934 - val_accuracy: 0.2991\n",
      "Epoch 162/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0972 - accuracy: 0.2918 - val_loss: 1.0935 - val_accuracy: 0.2991\n",
      "Epoch 163/200\n",
      "2553/2553 [==============================] - 0s 65us/sample - loss: 1.0973 - accuracy: 0.2953 - val_loss: 1.0934 - val_accuracy: 0.2991\n",
      "Epoch 164/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0974 - accuracy: 0.2902 - val_loss: 1.0935 - val_accuracy: 0.2991\n",
      "Epoch 165/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0976 - accuracy: 0.2934 - val_loss: 1.0936 - val_accuracy: 0.3084\n",
      "Epoch 166/200\n",
      "2553/2553 [==============================] - 0s 68us/sample - loss: 1.0962 - accuracy: 0.3032 - val_loss: 1.0936 - val_accuracy: 0.2991\n",
      "Epoch 167/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0970 - accuracy: 0.2973 - val_loss: 1.0936 - val_accuracy: 0.2991\n",
      "Epoch 168/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0961 - accuracy: 0.2965 - val_loss: 1.0935 - val_accuracy: 0.3084\n",
      "Epoch 169/200\n",
      "2553/2553 [==============================] - 0s 65us/sample - loss: 1.0971 - accuracy: 0.2961 - val_loss: 1.0936 - val_accuracy: 0.3084\n",
      "Epoch 170/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0970 - accuracy: 0.2957 - val_loss: 1.0936 - val_accuracy: 0.3084\n",
      "Epoch 171/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.0970 - accuracy: 0.2934 - val_loss: 1.0936 - val_accuracy: 0.3084\n",
      "Epoch 172/200\n",
      "2553/2553 [==============================] - 0s 43us/sample - loss: 1.0970 - accuracy: 0.2902 - val_loss: 1.0936 - val_accuracy: 0.3084\n",
      "Epoch 173/200\n",
      "2553/2553 [==============================] - 0s 50us/sample - loss: 1.0968 - accuracy: 0.2977 - val_loss: 1.0936 - val_accuracy: 0.3084\n",
      "Epoch 174/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0957 - accuracy: 0.3024 - val_loss: 1.0934 - val_accuracy: 0.3084\n",
      "Epoch 175/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.0966 - accuracy: 0.2973 - val_loss: 1.0934 - val_accuracy: 0.3084\n",
      "Epoch 176/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0962 - accuracy: 0.2965 - val_loss: 1.0934 - val_accuracy: 0.3084\n",
      "Epoch 177/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0959 - accuracy: 0.2993 - val_loss: 1.0934 - val_accuracy: 0.2991\n",
      "Epoch 178/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0967 - accuracy: 0.2946 - val_loss: 1.0934 - val_accuracy: 0.3084\n",
      "Epoch 179/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0975 - accuracy: 0.2906 - val_loss: 1.0935 - val_accuracy: 0.3084\n",
      "Epoch 180/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0973 - accuracy: 0.2930 - val_loss: 1.0935 - val_accuracy: 0.3084\n",
      "Epoch 181/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0969 - accuracy: 0.2906 - val_loss: 1.0935 - val_accuracy: 0.3084\n",
      "Epoch 182/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0961 - accuracy: 0.3000 - val_loss: 1.0934 - val_accuracy: 0.3084\n",
      "Epoch 183/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0963 - accuracy: 0.2973 - val_loss: 1.0935 - val_accuracy: 0.3084\n",
      "Epoch 184/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0965 - accuracy: 0.3008 - val_loss: 1.0934 - val_accuracy: 0.3084\n",
      "Epoch 185/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0970 - accuracy: 0.2969 - val_loss: 1.0934 - val_accuracy: 0.3084\n",
      "Epoch 186/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0967 - accuracy: 0.2993 - val_loss: 1.0934 - val_accuracy: 0.3084\n",
      "Epoch 187/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0965 - accuracy: 0.2981 - val_loss: 1.0933 - val_accuracy: 0.3084\n",
      "Epoch 188/200\n",
      "2553/2553 [==============================] - ETA: 0s - loss: 1.0955 - accuracy: 0.30 - 0s 59us/sample - loss: 1.0959 - accuracy: 0.3047 - val_loss: 1.0933 - val_accuracy: 0.3178\n",
      "Epoch 189/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.0961 - accuracy: 0.2981 - val_loss: 1.0933 - val_accuracy: 0.3178\n",
      "Epoch 190/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0971 - accuracy: 0.2993 - val_loss: 1.0933 - val_accuracy: 0.3178\n",
      "Epoch 191/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.0955 - accuracy: 0.3059 - val_loss: 1.0932 - val_accuracy: 0.3271\n",
      "Epoch 192/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0966 - accuracy: 0.2985 - val_loss: 1.0931 - val_accuracy: 0.3271\n",
      "Epoch 193/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0974 - accuracy: 0.2926 - val_loss: 1.0932 - val_accuracy: 0.3271\n",
      "Epoch 194/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.0959 - accuracy: 0.3004 - val_loss: 1.0931 - val_accuracy: 0.3271\n",
      "Epoch 195/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0963 - accuracy: 0.2981 - val_loss: 1.0930 - val_accuracy: 0.3364\n",
      "Epoch 196/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.0947 - accuracy: 0.3106 - val_loss: 1.0929 - val_accuracy: 0.3364\n",
      "Epoch 197/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0958 - accuracy: 0.3059 - val_loss: 1.0928 - val_accuracy: 0.3364\n",
      "Epoch 198/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0964 - accuracy: 0.2965 - val_loss: 1.0929 - val_accuracy: 0.3364\n",
      "Epoch 199/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0963 - accuracy: 0.3024 - val_loss: 1.0929 - val_accuracy: 0.3364\n",
      "Epoch 200/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0960 - accuracy: 0.3004 - val_loss: 1.0930 - val_accuracy: 0.3364\n",
      "0.3364486 {'loss': 1.0959690783101346, 'accuracy': 0.30043086, 'val_loss': 1.0930207132179046, 'val_accuracy': 0.3364486}\n",
      "Model: \"model_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_15 (InputLayer)        [(None, 29)]              0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 41)                1230      \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 10)                420       \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 3)                 33        \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 1,903\n",
      "Trainable params: 1,903\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2553 samples, validate on 107 samples\n",
      "Epoch 1/200\n",
      "2553/2553 [==============================] - 1s 412us/sample - loss: 1.3062 - accuracy: 0.2769 - val_loss: 1.2309 - val_accuracy: 0.2243\n",
      "Epoch 2/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.2943 - accuracy: 0.2781 - val_loss: 1.2143 - val_accuracy: 0.2243\n",
      "Epoch 3/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.2501 - accuracy: 0.2758 - val_loss: 1.2020 - val_accuracy: 0.2243\n",
      "Epoch 4/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.2547 - accuracy: 0.2758 - val_loss: 1.1901 - val_accuracy: 0.2243\n",
      "Epoch 5/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.2327 - accuracy: 0.2789 - val_loss: 1.1801 - val_accuracy: 0.2243\n",
      "Epoch 6/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.2052 - accuracy: 0.2765 - val_loss: 1.1717 - val_accuracy: 0.2243\n",
      "Epoch 7/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.1988 - accuracy: 0.2683 - val_loss: 1.1646 - val_accuracy: 0.2243\n",
      "Epoch 8/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.1884 - accuracy: 0.2738 - val_loss: 1.1581 - val_accuracy: 0.2243\n",
      "Epoch 9/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.1786 - accuracy: 0.2718 - val_loss: 1.1519 - val_accuracy: 0.2243\n",
      "Epoch 10/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.1646 - accuracy: 0.2765 - val_loss: 1.1466 - val_accuracy: 0.2336\n",
      "Epoch 11/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.1596 - accuracy: 0.2746 - val_loss: 1.1418 - val_accuracy: 0.2336\n",
      "Epoch 12/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.1543 - accuracy: 0.2816 - val_loss: 1.1376 - val_accuracy: 0.2243\n",
      "Epoch 13/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.1483 - accuracy: 0.2754 - val_loss: 1.1339 - val_accuracy: 0.2243\n",
      "Epoch 14/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.1383 - accuracy: 0.2863 - val_loss: 1.1305 - val_accuracy: 0.2243\n",
      "Epoch 15/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.1372 - accuracy: 0.2887 - val_loss: 1.1274 - val_accuracy: 0.2243\n",
      "Epoch 16/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.1288 - accuracy: 0.2981 - val_loss: 1.1246 - val_accuracy: 0.2336\n",
      "Epoch 17/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.1281 - accuracy: 0.2957 - val_loss: 1.1221 - val_accuracy: 0.2336\n",
      "Epoch 18/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.1166 - accuracy: 0.2906 - val_loss: 1.1201 - val_accuracy: 0.2430\n",
      "Epoch 19/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.1229 - accuracy: 0.2820 - val_loss: 1.1178 - val_accuracy: 0.2523\n",
      "Epoch 20/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.1170 - accuracy: 0.2891 - val_loss: 1.1157 - val_accuracy: 0.2617\n",
      "Epoch 21/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.1113 - accuracy: 0.2883 - val_loss: 1.1141 - val_accuracy: 0.2617\n",
      "Epoch 22/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.1087 - accuracy: 0.3020 - val_loss: 1.1126 - val_accuracy: 0.2617\n",
      "Epoch 23/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.1107 - accuracy: 0.2895 - val_loss: 1.1111 - val_accuracy: 0.2710\n",
      "Epoch 24/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.1114 - accuracy: 0.2993 - val_loss: 1.1098 - val_accuracy: 0.2804\n",
      "Epoch 25/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 1.0994 - accuracy: 0.3016 - val_loss: 1.1090 - val_accuracy: 0.2710\n",
      "Epoch 26/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.1035 - accuracy: 0.3102 - val_loss: 1.1079 - val_accuracy: 0.2523\n",
      "Epoch 27/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.1009 - accuracy: 0.3032 - val_loss: 1.1068 - val_accuracy: 0.2617\n",
      "Epoch 28/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0979 - accuracy: 0.3079 - val_loss: 1.1057 - val_accuracy: 0.2430\n",
      "Epoch 29/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0999 - accuracy: 0.2981 - val_loss: 1.1047 - val_accuracy: 0.2617\n",
      "Epoch 30/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.1013 - accuracy: 0.3087 - val_loss: 1.1036 - val_accuracy: 0.2710\n",
      "Epoch 31/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0966 - accuracy: 0.3177 - val_loss: 1.1021 - val_accuracy: 0.2897\n",
      "Epoch 32/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.1005 - accuracy: 0.3028 - val_loss: 1.1007 - val_accuracy: 0.2991\n",
      "Epoch 33/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0973 - accuracy: 0.3149 - val_loss: 1.0996 - val_accuracy: 0.3084\n",
      "Epoch 34/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0974 - accuracy: 0.3235 - val_loss: 1.0986 - val_accuracy: 0.3271\n",
      "Epoch 35/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0901 - accuracy: 0.3357 - val_loss: 1.0977 - val_accuracy: 0.3364\n",
      "Epoch 36/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.0964 - accuracy: 0.3318 - val_loss: 1.0973 - val_accuracy: 0.3551\n",
      "Epoch 37/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0955 - accuracy: 0.3318 - val_loss: 1.0966 - val_accuracy: 0.3551\n",
      "Epoch 38/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.0917 - accuracy: 0.3282 - val_loss: 1.0958 - val_accuracy: 0.3738\n",
      "Epoch 39/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0917 - accuracy: 0.3235 - val_loss: 1.0949 - val_accuracy: 0.3832\n",
      "Epoch 40/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0921 - accuracy: 0.3310 - val_loss: 1.0941 - val_accuracy: 0.3832\n",
      "Epoch 41/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.0864 - accuracy: 0.3459 - val_loss: 1.0932 - val_accuracy: 0.4019\n",
      "Epoch 42/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.0901 - accuracy: 0.3447 - val_loss: 1.0925 - val_accuracy: 0.4299\n",
      "Epoch 43/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.0903 - accuracy: 0.3376 - val_loss: 1.0916 - val_accuracy: 0.4393\n",
      "Epoch 44/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.0910 - accuracy: 0.3459 - val_loss: 1.0909 - val_accuracy: 0.4579\n",
      "Epoch 45/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0896 - accuracy: 0.3420 - val_loss: 1.0904 - val_accuracy: 0.4579\n",
      "Epoch 46/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.0853 - accuracy: 0.3545 - val_loss: 1.0898 - val_accuracy: 0.4579\n",
      "Epoch 47/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0892 - accuracy: 0.3517 - val_loss: 1.0894 - val_accuracy: 0.4393\n",
      "Epoch 48/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0901 - accuracy: 0.3384 - val_loss: 1.0890 - val_accuracy: 0.4393\n",
      "Epoch 49/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0886 - accuracy: 0.3416 - val_loss: 1.0886 - val_accuracy: 0.4486\n",
      "Epoch 50/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.0858 - accuracy: 0.3478 - val_loss: 1.0881 - val_accuracy: 0.4486\n",
      "Epoch 51/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0866 - accuracy: 0.3290 - val_loss: 1.0877 - val_accuracy: 0.4393\n",
      "Epoch 52/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0879 - accuracy: 0.3490 - val_loss: 1.0873 - val_accuracy: 0.4393\n",
      "Epoch 53/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0861 - accuracy: 0.3561 - val_loss: 1.0869 - val_accuracy: 0.4579\n",
      "Epoch 54/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0838 - accuracy: 0.3545 - val_loss: 1.0864 - val_accuracy: 0.4673\n",
      "Epoch 55/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0829 - accuracy: 0.3506 - val_loss: 1.0859 - val_accuracy: 0.4673\n",
      "Epoch 56/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0857 - accuracy: 0.3514 - val_loss: 1.0855 - val_accuracy: 0.4579\n",
      "Epoch 57/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0840 - accuracy: 0.3537 - val_loss: 1.0850 - val_accuracy: 0.4579\n",
      "Epoch 58/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0879 - accuracy: 0.3314 - val_loss: 1.0846 - val_accuracy: 0.4766\n",
      "Epoch 59/200\n",
      "2553/2553 [==============================] - 0s 123us/sample - loss: 1.0845 - accuracy: 0.3322 - val_loss: 1.0842 - val_accuracy: 0.4766\n",
      "Epoch 60/200\n",
      "2553/2553 [==============================] - 0s 125us/sample - loss: 1.0804 - accuracy: 0.3576 - val_loss: 1.0837 - val_accuracy: 0.4766\n",
      "Epoch 61/200\n",
      "2553/2553 [==============================] - 0s 145us/sample - loss: 1.0816 - accuracy: 0.3380 - val_loss: 1.0832 - val_accuracy: 0.4860\n",
      "Epoch 62/200\n",
      "2553/2553 [==============================] - 0s 126us/sample - loss: 1.0832 - accuracy: 0.3561 - val_loss: 1.0827 - val_accuracy: 0.4860\n",
      "Epoch 63/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 1.0821 - accuracy: 0.3455 - val_loss: 1.0823 - val_accuracy: 0.4766\n",
      "Epoch 64/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0805 - accuracy: 0.3420 - val_loss: 1.0819 - val_accuracy: 0.4953\n",
      "Epoch 65/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0795 - accuracy: 0.3541 - val_loss: 1.0814 - val_accuracy: 0.4766\n",
      "Epoch 66/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.0855 - accuracy: 0.3400 - val_loss: 1.0811 - val_accuracy: 0.4860\n",
      "Epoch 67/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0804 - accuracy: 0.3376 - val_loss: 1.0807 - val_accuracy: 0.4860\n",
      "Epoch 68/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.0747 - accuracy: 0.3627 - val_loss: 1.0802 - val_accuracy: 0.4953\n",
      "Epoch 69/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0831 - accuracy: 0.3388 - val_loss: 1.0799 - val_accuracy: 0.4860\n",
      "Epoch 70/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.0806 - accuracy: 0.3541 - val_loss: 1.0795 - val_accuracy: 0.4953\n",
      "Epoch 71/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0811 - accuracy: 0.3467 - val_loss: 1.0790 - val_accuracy: 0.4953\n",
      "Epoch 72/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0833 - accuracy: 0.3341 - val_loss: 1.0787 - val_accuracy: 0.4953\n",
      "Epoch 73/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0786 - accuracy: 0.3498 - val_loss: 1.0782 - val_accuracy: 0.5047\n",
      "Epoch 74/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0791 - accuracy: 0.3494 - val_loss: 1.0778 - val_accuracy: 0.4953\n",
      "Epoch 75/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0767 - accuracy: 0.3623 - val_loss: 1.0774 - val_accuracy: 0.4953\n",
      "Epoch 76/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.0781 - accuracy: 0.3529 - val_loss: 1.0770 - val_accuracy: 0.4953\n",
      "Epoch 77/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0766 - accuracy: 0.3553 - val_loss: 1.0764 - val_accuracy: 0.4953\n",
      "Epoch 78/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0772 - accuracy: 0.3514 - val_loss: 1.0759 - val_accuracy: 0.4953\n",
      "Epoch 79/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.0747 - accuracy: 0.3619 - val_loss: 1.0753 - val_accuracy: 0.5047\n",
      "Epoch 80/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.0763 - accuracy: 0.3494 - val_loss: 1.0749 - val_accuracy: 0.5047\n",
      "Epoch 81/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0782 - accuracy: 0.3502 - val_loss: 1.0745 - val_accuracy: 0.5047\n",
      "Epoch 82/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.0830 - accuracy: 0.3423 - val_loss: 1.0742 - val_accuracy: 0.5047\n",
      "Epoch 83/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0832 - accuracy: 0.3427 - val_loss: 1.0739 - val_accuracy: 0.4953\n",
      "Epoch 84/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.0814 - accuracy: 0.3423 - val_loss: 1.0735 - val_accuracy: 0.4953\n",
      "Epoch 85/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0761 - accuracy: 0.3604 - val_loss: 1.0730 - val_accuracy: 0.4953\n",
      "Epoch 86/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0765 - accuracy: 0.3486 - val_loss: 1.0727 - val_accuracy: 0.5047\n",
      "Epoch 87/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0731 - accuracy: 0.3604 - val_loss: 1.0722 - val_accuracy: 0.5047\n",
      "Epoch 88/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0764 - accuracy: 0.3506 - val_loss: 1.0717 - val_accuracy: 0.5234\n",
      "Epoch 89/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0765 - accuracy: 0.3365 - val_loss: 1.0713 - val_accuracy: 0.5140\n",
      "Epoch 90/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0718 - accuracy: 0.3541 - val_loss: 1.0708 - val_accuracy: 0.5140\n",
      "Epoch 91/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0738 - accuracy: 0.3478 - val_loss: 1.0703 - val_accuracy: 0.5140\n",
      "Epoch 92/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0761 - accuracy: 0.3533 - val_loss: 1.0698 - val_accuracy: 0.5234\n",
      "Epoch 93/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0743 - accuracy: 0.3561 - val_loss: 1.0692 - val_accuracy: 0.5234\n",
      "Epoch 94/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0717 - accuracy: 0.3600 - val_loss: 1.0686 - val_accuracy: 0.5234\n",
      "Epoch 95/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0740 - accuracy: 0.3541 - val_loss: 1.0681 - val_accuracy: 0.5327\n",
      "Epoch 96/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0748 - accuracy: 0.3498 - val_loss: 1.0678 - val_accuracy: 0.5327\n",
      "Epoch 97/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0688 - accuracy: 0.3533 - val_loss: 1.0671 - val_accuracy: 0.5140\n",
      "Epoch 98/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0704 - accuracy: 0.3482 - val_loss: 1.0667 - val_accuracy: 0.5140\n",
      "Epoch 99/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.0731 - accuracy: 0.3439 - val_loss: 1.0663 - val_accuracy: 0.5140\n",
      "Epoch 100/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0654 - accuracy: 0.3698 - val_loss: 1.0656 - val_accuracy: 0.5140\n",
      "Epoch 101/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0698 - accuracy: 0.3584 - val_loss: 1.0651 - val_accuracy: 0.5327\n",
      "Epoch 102/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.0726 - accuracy: 0.3431 - val_loss: 1.0647 - val_accuracy: 0.5234\n",
      "Epoch 103/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0711 - accuracy: 0.3420 - val_loss: 1.0642 - val_accuracy: 0.4953\n",
      "Epoch 104/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.0716 - accuracy: 0.3576 - val_loss: 1.0638 - val_accuracy: 0.5327\n",
      "Epoch 105/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.0708 - accuracy: 0.3486 - val_loss: 1.0633 - val_accuracy: 0.5047\n",
      "Epoch 106/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0702 - accuracy: 0.3608 - val_loss: 1.0629 - val_accuracy: 0.5140\n",
      "Epoch 107/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0698 - accuracy: 0.3537 - val_loss: 1.0625 - val_accuracy: 0.5140\n",
      "Epoch 108/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0769 - accuracy: 0.3408 - val_loss: 1.0622 - val_accuracy: 0.5140\n",
      "Epoch 109/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0701 - accuracy: 0.3525 - val_loss: 1.0619 - val_accuracy: 0.5140\n",
      "Epoch 110/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.0651 - accuracy: 0.3580 - val_loss: 1.0615 - val_accuracy: 0.5047\n",
      "Epoch 111/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0698 - accuracy: 0.3451 - val_loss: 1.0611 - val_accuracy: 0.5140\n",
      "Epoch 112/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0646 - accuracy: 0.3623 - val_loss: 1.0607 - val_accuracy: 0.5140\n",
      "Epoch 113/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.0688 - accuracy: 0.3502 - val_loss: 1.0604 - val_accuracy: 0.5047\n",
      "Epoch 114/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0670 - accuracy: 0.3568 - val_loss: 1.0599 - val_accuracy: 0.5047\n",
      "Epoch 115/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.0671 - accuracy: 0.3502 - val_loss: 1.0594 - val_accuracy: 0.5047\n",
      "Epoch 116/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0648 - accuracy: 0.3592 - val_loss: 1.0589 - val_accuracy: 0.5140\n",
      "Epoch 117/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.0644 - accuracy: 0.3529 - val_loss: 1.0585 - val_accuracy: 0.5047\n",
      "Epoch 118/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0672 - accuracy: 0.3502 - val_loss: 1.0581 - val_accuracy: 0.5140\n",
      "Epoch 119/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0681 - accuracy: 0.3568 - val_loss: 1.0577 - val_accuracy: 0.5140\n",
      "Epoch 120/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0645 - accuracy: 0.3627 - val_loss: 1.0572 - val_accuracy: 0.5140\n",
      "Epoch 121/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.0631 - accuracy: 0.3639 - val_loss: 1.0567 - val_accuracy: 0.5140\n",
      "Epoch 122/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0689 - accuracy: 0.3525 - val_loss: 1.0562 - val_accuracy: 0.5234\n",
      "Epoch 123/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0652 - accuracy: 0.3498 - val_loss: 1.0557 - val_accuracy: 0.5234\n",
      "Epoch 124/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0622 - accuracy: 0.3662 - val_loss: 1.0552 - val_accuracy: 0.5234\n",
      "Epoch 125/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0626 - accuracy: 0.3611 - val_loss: 1.0546 - val_accuracy: 0.5234\n",
      "Epoch 126/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0684 - accuracy: 0.3533 - val_loss: 1.0543 - val_accuracy: 0.5234\n",
      "Epoch 127/200\n",
      "2553/2553 [==============================] - 0s 132us/sample - loss: 1.0688 - accuracy: 0.3447 - val_loss: 1.0540 - val_accuracy: 0.5234\n",
      "Epoch 128/200\n",
      "2553/2553 [==============================] - 0s 124us/sample - loss: 1.0604 - accuracy: 0.3608 - val_loss: 1.0534 - val_accuracy: 0.5234\n",
      "Epoch 129/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.0694 - accuracy: 0.3561 - val_loss: 1.0530 - val_accuracy: 0.5234\n",
      "Epoch 130/200\n",
      "2553/2553 [==============================] - 0s 160us/sample - loss: 1.0600 - accuracy: 0.3690 - val_loss: 1.0527 - val_accuracy: 0.5234\n",
      "Epoch 131/200\n",
      "2553/2553 [==============================] - 0s 118us/sample - loss: 1.0626 - accuracy: 0.3611 - val_loss: 1.0523 - val_accuracy: 0.5234\n",
      "Epoch 132/200\n",
      "2553/2553 [==============================] - 0s 137us/sample - loss: 1.0632 - accuracy: 0.3713 - val_loss: 1.0518 - val_accuracy: 0.5140\n",
      "Epoch 133/200\n",
      "2553/2553 [==============================] - 0s 164us/sample - loss: 1.0671 - accuracy: 0.3490 - val_loss: 1.0517 - val_accuracy: 0.5234\n",
      "Epoch 134/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.0670 - accuracy: 0.3498 - val_loss: 1.0513 - val_accuracy: 0.5234\n",
      "Epoch 135/200\n",
      "2553/2553 [==============================] - 0s 129us/sample - loss: 1.0625 - accuracy: 0.3525 - val_loss: 1.0509 - val_accuracy: 0.5140\n",
      "Epoch 136/200\n",
      "2553/2553 [==============================] - 0s 117us/sample - loss: 1.0631 - accuracy: 0.3639 - val_loss: 1.0506 - val_accuracy: 0.5140\n",
      "Epoch 137/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.0633 - accuracy: 0.3580 - val_loss: 1.0502 - val_accuracy: 0.5234\n",
      "Epoch 138/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.0625 - accuracy: 0.3514 - val_loss: 1.0498 - val_accuracy: 0.5234\n",
      "Epoch 139/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0623 - accuracy: 0.3647 - val_loss: 1.0496 - val_accuracy: 0.5234\n",
      "Epoch 140/200\n",
      "2553/2553 [==============================] - 0s 115us/sample - loss: 1.0640 - accuracy: 0.3615 - val_loss: 1.0493 - val_accuracy: 0.5234\n",
      "Epoch 141/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0647 - accuracy: 0.3537 - val_loss: 1.0492 - val_accuracy: 0.5234\n",
      "Epoch 142/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0645 - accuracy: 0.3572 - val_loss: 1.0488 - val_accuracy: 0.5234\n",
      "Epoch 143/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.0645 - accuracy: 0.3545 - val_loss: 1.0487 - val_accuracy: 0.5234\n",
      "Epoch 144/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.0681 - accuracy: 0.3533 - val_loss: 1.0485 - val_accuracy: 0.5234\n",
      "Epoch 145/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0656 - accuracy: 0.3463 - val_loss: 1.0482 - val_accuracy: 0.5234\n",
      "Epoch 146/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.0652 - accuracy: 0.3568 - val_loss: 1.0481 - val_accuracy: 0.5140\n",
      "Epoch 147/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0559 - accuracy: 0.3608 - val_loss: 1.0475 - val_accuracy: 0.5140\n",
      "Epoch 148/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 1.0651 - accuracy: 0.3545 - val_loss: 1.0471 - val_accuracy: 0.5047\n",
      "Epoch 149/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.0633 - accuracy: 0.3584 - val_loss: 1.0469 - val_accuracy: 0.5047\n",
      "Epoch 150/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0580 - accuracy: 0.3604 - val_loss: 1.0465 - val_accuracy: 0.5234\n",
      "Epoch 151/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0627 - accuracy: 0.3478 - val_loss: 1.0462 - val_accuracy: 0.5140\n",
      "Epoch 152/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0595 - accuracy: 0.3604 - val_loss: 1.0459 - val_accuracy: 0.5140\n",
      "Epoch 153/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0628 - accuracy: 0.3525 - val_loss: 1.0457 - val_accuracy: 0.5047\n",
      "Epoch 154/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.0536 - accuracy: 0.3682 - val_loss: 1.0453 - val_accuracy: 0.5047\n",
      "Epoch 155/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.0578 - accuracy: 0.3596 - val_loss: 1.0452 - val_accuracy: 0.5047\n",
      "Epoch 156/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0552 - accuracy: 0.3709 - val_loss: 1.0448 - val_accuracy: 0.5234\n",
      "Epoch 157/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0612 - accuracy: 0.3643 - val_loss: 1.0447 - val_accuracy: 0.5327\n",
      "Epoch 158/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0529 - accuracy: 0.3655 - val_loss: 1.0444 - val_accuracy: 0.5327\n",
      "Epoch 159/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.0612 - accuracy: 0.3564 - val_loss: 1.0443 - val_accuracy: 0.5234\n",
      "Epoch 160/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.0671 - accuracy: 0.3506 - val_loss: 1.0442 - val_accuracy: 0.5140\n",
      "Epoch 161/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0637 - accuracy: 0.3615 - val_loss: 1.0439 - val_accuracy: 0.5234\n",
      "Epoch 162/200\n",
      "2553/2553 [==============================] - 0s 133us/sample - loss: 1.0609 - accuracy: 0.3517 - val_loss: 1.0436 - val_accuracy: 0.5234\n",
      "Epoch 163/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 185us/sample - loss: 1.0674 - accuracy: 0.3435 - val_loss: 1.0435 - val_accuracy: 0.5234\n",
      "Epoch 164/200\n",
      "2553/2553 [==============================] - 0s 162us/sample - loss: 1.0606 - accuracy: 0.3705 - val_loss: 1.0433 - val_accuracy: 0.5234\n",
      "Epoch 165/200\n",
      "2553/2553 [==============================] - 0s 139us/sample - loss: 1.0563 - accuracy: 0.3615 - val_loss: 1.0431 - val_accuracy: 0.5327\n",
      "Epoch 166/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0608 - accuracy: 0.3572 - val_loss: 1.0430 - val_accuracy: 0.5140\n",
      "Epoch 167/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 1.0526 - accuracy: 0.3670 - val_loss: 1.0425 - val_accuracy: 0.5140\n",
      "Epoch 168/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0648 - accuracy: 0.3482 - val_loss: 1.0425 - val_accuracy: 0.5047\n",
      "Epoch 169/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0575 - accuracy: 0.3694 - val_loss: 1.0423 - val_accuracy: 0.5047\n",
      "Epoch 170/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0621 - accuracy: 0.3541 - val_loss: 1.0422 - val_accuracy: 0.5047\n",
      "Epoch 171/200\n",
      "2553/2553 [==============================] - 0s 119us/sample - loss: 1.0571 - accuracy: 0.3608 - val_loss: 1.0422 - val_accuracy: 0.5047\n",
      "Epoch 172/200\n",
      "2553/2553 [==============================] - 0s 115us/sample - loss: 1.0620 - accuracy: 0.3541 - val_loss: 1.0420 - val_accuracy: 0.4953\n",
      "Epoch 173/200\n",
      "2553/2553 [==============================] - 0s 119us/sample - loss: 1.0600 - accuracy: 0.3600 - val_loss: 1.0418 - val_accuracy: 0.5047\n",
      "Epoch 174/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0615 - accuracy: 0.3615 - val_loss: 1.0415 - val_accuracy: 0.5047\n",
      "Epoch 175/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0543 - accuracy: 0.3600 - val_loss: 1.0412 - val_accuracy: 0.5047\n",
      "Epoch 176/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0569 - accuracy: 0.3584 - val_loss: 1.0409 - val_accuracy: 0.4953\n",
      "Epoch 177/200\n",
      "2553/2553 [==============================] - 0s 118us/sample - loss: 1.0573 - accuracy: 0.3694 - val_loss: 1.0408 - val_accuracy: 0.4953\n",
      "Epoch 178/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0611 - accuracy: 0.3549 - val_loss: 1.0407 - val_accuracy: 0.4953\n",
      "Epoch 179/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0638 - accuracy: 0.3619 - val_loss: 1.0407 - val_accuracy: 0.4953\n",
      "Epoch 180/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.0648 - accuracy: 0.3506 - val_loss: 1.0407 - val_accuracy: 0.4953\n",
      "Epoch 181/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0548 - accuracy: 0.3674 - val_loss: 1.0404 - val_accuracy: 0.4953\n",
      "Epoch 182/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0595 - accuracy: 0.3537 - val_loss: 1.0404 - val_accuracy: 0.4953\n",
      "Epoch 183/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0618 - accuracy: 0.3498 - val_loss: 1.0403 - val_accuracy: 0.4953\n",
      "Epoch 184/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.0613 - accuracy: 0.3572 - val_loss: 1.0403 - val_accuracy: 0.4953\n",
      "Epoch 185/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0628 - accuracy: 0.3447 - val_loss: 1.0399 - val_accuracy: 0.4953\n",
      "Epoch 186/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.0570 - accuracy: 0.3733 - val_loss: 1.0398 - val_accuracy: 0.4953\n",
      "Epoch 187/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0590 - accuracy: 0.3541 - val_loss: 1.0398 - val_accuracy: 0.4953\n",
      "Epoch 188/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.0616 - accuracy: 0.3553 - val_loss: 1.0395 - val_accuracy: 0.4953\n",
      "Epoch 189/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0479 - accuracy: 0.3717 - val_loss: 1.0391 - val_accuracy: 0.4953\n",
      "Epoch 190/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0638 - accuracy: 0.3470 - val_loss: 1.0392 - val_accuracy: 0.4953\n",
      "Epoch 191/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0637 - accuracy: 0.3517 - val_loss: 1.0394 - val_accuracy: 0.4953\n",
      "Epoch 192/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.0572 - accuracy: 0.3576 - val_loss: 1.0394 - val_accuracy: 0.4953\n",
      "Epoch 193/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.0649 - accuracy: 0.3490 - val_loss: 1.0394 - val_accuracy: 0.4953\n",
      "Epoch 194/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0544 - accuracy: 0.3721 - val_loss: 1.0392 - val_accuracy: 0.4953\n",
      "Epoch 195/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.0607 - accuracy: 0.3572 - val_loss: 1.0391 - val_accuracy: 0.4953\n",
      "Epoch 196/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0583 - accuracy: 0.3525 - val_loss: 1.0392 - val_accuracy: 0.4953\n",
      "Epoch 197/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0604 - accuracy: 0.3514 - val_loss: 1.0391 - val_accuracy: 0.4953\n",
      "Epoch 198/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0637 - accuracy: 0.3537 - val_loss: 1.0390 - val_accuracy: 0.4953\n",
      "Epoch 199/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0611 - accuracy: 0.3572 - val_loss: 1.0388 - val_accuracy: 0.5047\n",
      "Epoch 200/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0556 - accuracy: 0.3639 - val_loss: 1.0388 - val_accuracy: 0.4953\n",
      "0.49532712 {'loss': 1.0555994956109556, 'accuracy': 0.3638856, 'val_loss': 1.0387764032756057, 'val_accuracy': 0.49532712}\n",
      "Model: \"model_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_16 (InputLayer)        [(None, 29)]              0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 41)                1230      \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 10)                420       \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 3)                 33        \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 1,903\n",
      "Trainable params: 1,903\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2553 samples, validate on 107 samples\n",
      "Epoch 1/200\n",
      "2553/2553 [==============================] - 1s 294us/sample - loss: 1.1798 - accuracy: 0.3259 - val_loss: 1.0940 - val_accuracy: 0.4019\n",
      "Epoch 2/200\n",
      "2553/2553 [==============================] - 0s 49us/sample - loss: 1.1751 - accuracy: 0.3192 - val_loss: 1.0913 - val_accuracy: 0.3925\n",
      "Epoch 3/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1702 - accuracy: 0.3212 - val_loss: 1.0890 - val_accuracy: 0.4112\n",
      "Epoch 4/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.1677 - accuracy: 0.3040 - val_loss: 1.0872 - val_accuracy: 0.4393\n",
      "Epoch 5/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1540 - accuracy: 0.3286 - val_loss: 1.0854 - val_accuracy: 0.4486\n",
      "Epoch 6/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.1476 - accuracy: 0.3290 - val_loss: 1.0840 - val_accuracy: 0.4579\n",
      "Epoch 7/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1305 - accuracy: 0.3439 - val_loss: 1.0824 - val_accuracy: 0.4766\n",
      "Epoch 8/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.1356 - accuracy: 0.3333 - val_loss: 1.0807 - val_accuracy: 0.4673\n",
      "Epoch 9/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1307 - accuracy: 0.3396 - val_loss: 1.0789 - val_accuracy: 0.4486\n",
      "Epoch 10/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1293 - accuracy: 0.3290 - val_loss: 1.0772 - val_accuracy: 0.4579\n",
      "Epoch 11/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.1365 - accuracy: 0.3235 - val_loss: 1.0760 - val_accuracy: 0.4673\n",
      "Epoch 12/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1234 - accuracy: 0.3173 - val_loss: 1.0750 - val_accuracy: 0.4766\n",
      "Epoch 13/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1171 - accuracy: 0.3502 - val_loss: 1.0737 - val_accuracy: 0.4860\n",
      "Epoch 14/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1208 - accuracy: 0.3318 - val_loss: 1.0728 - val_accuracy: 0.4953\n",
      "Epoch 15/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.1117 - accuracy: 0.3416 - val_loss: 1.0720 - val_accuracy: 0.4953\n",
      "Epoch 16/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1175 - accuracy: 0.3231 - val_loss: 1.0711 - val_accuracy: 0.4953\n",
      "Epoch 17/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.1040 - accuracy: 0.3400 - val_loss: 1.0703 - val_accuracy: 0.4953\n",
      "Epoch 18/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0945 - accuracy: 0.3490 - val_loss: 1.0696 - val_accuracy: 0.5047\n",
      "Epoch 19/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.1003 - accuracy: 0.3392 - val_loss: 1.0687 - val_accuracy: 0.5047\n",
      "Epoch 20/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0981 - accuracy: 0.3361 - val_loss: 1.0677 - val_accuracy: 0.5047\n",
      "Epoch 21/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1020 - accuracy: 0.3263 - val_loss: 1.0670 - val_accuracy: 0.5047\n",
      "Epoch 22/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.0923 - accuracy: 0.3447 - val_loss: 1.0660 - val_accuracy: 0.4953\n",
      "Epoch 23/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1002 - accuracy: 0.3251 - val_loss: 1.0652 - val_accuracy: 0.4953\n",
      "Epoch 24/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1009 - accuracy: 0.3341 - val_loss: 1.0645 - val_accuracy: 0.4953\n",
      "Epoch 25/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0932 - accuracy: 0.3329 - val_loss: 1.0638 - val_accuracy: 0.5047\n",
      "Epoch 26/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0892 - accuracy: 0.3423 - val_loss: 1.0632 - val_accuracy: 0.5047\n",
      "Epoch 27/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0926 - accuracy: 0.3384 - val_loss: 1.0623 - val_accuracy: 0.5047\n",
      "Epoch 28/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.0920 - accuracy: 0.3255 - val_loss: 1.0617 - val_accuracy: 0.5140\n",
      "Epoch 29/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.0908 - accuracy: 0.3365 - val_loss: 1.0610 - val_accuracy: 0.5140\n",
      "Epoch 30/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0853 - accuracy: 0.3447 - val_loss: 1.0601 - val_accuracy: 0.5140\n",
      "Epoch 31/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.0884 - accuracy: 0.3357 - val_loss: 1.0594 - val_accuracy: 0.5140\n",
      "Epoch 32/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0854 - accuracy: 0.3408 - val_loss: 1.0588 - val_accuracy: 0.5140\n",
      "Epoch 33/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0817 - accuracy: 0.3416 - val_loss: 1.0582 - val_accuracy: 0.5140\n",
      "Epoch 34/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0869 - accuracy: 0.3443 - val_loss: 1.0576 - val_accuracy: 0.5140\n",
      "Epoch 35/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.0832 - accuracy: 0.3416 - val_loss: 1.0570 - val_accuracy: 0.5140\n",
      "Epoch 36/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0849 - accuracy: 0.3278 - val_loss: 1.0566 - val_accuracy: 0.5140\n",
      "Epoch 37/200\n",
      "2553/2553 [==============================] - 0s 68us/sample - loss: 1.0753 - accuracy: 0.3451 - val_loss: 1.0560 - val_accuracy: 0.5140\n",
      "Epoch 38/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0907 - accuracy: 0.3302 - val_loss: 1.0556 - val_accuracy: 0.5140\n",
      "Epoch 39/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.0828 - accuracy: 0.3443 - val_loss: 1.0550 - val_accuracy: 0.5140\n",
      "Epoch 40/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0844 - accuracy: 0.3420 - val_loss: 1.0546 - val_accuracy: 0.5140\n",
      "Epoch 41/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0786 - accuracy: 0.3529 - val_loss: 1.0541 - val_accuracy: 0.5140\n",
      "Epoch 42/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0849 - accuracy: 0.3380 - val_loss: 1.0536 - val_accuracy: 0.5140\n",
      "Epoch 43/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.0777 - accuracy: 0.3470 - val_loss: 1.0531 - val_accuracy: 0.5140\n",
      "Epoch 44/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0799 - accuracy: 0.3384 - val_loss: 1.0527 - val_accuracy: 0.5140\n",
      "Epoch 45/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0825 - accuracy: 0.3380 - val_loss: 1.0523 - val_accuracy: 0.5140\n",
      "Epoch 46/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0733 - accuracy: 0.3521 - val_loss: 1.0519 - val_accuracy: 0.5140\n",
      "Epoch 47/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.0737 - accuracy: 0.3439 - val_loss: 1.0513 - val_accuracy: 0.5140\n",
      "Epoch 48/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.0705 - accuracy: 0.3572 - val_loss: 1.0509 - val_accuracy: 0.5140\n",
      "Epoch 49/200\n",
      "2553/2553 [==============================] - 0s 51us/sample - loss: 1.0846 - accuracy: 0.3290 - val_loss: 1.0506 - val_accuracy: 0.5140\n",
      "Epoch 50/200\n",
      "2553/2553 [==============================] - 0s 50us/sample - loss: 1.0752 - accuracy: 0.3392 - val_loss: 1.0502 - val_accuracy: 0.5047\n",
      "Epoch 51/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.0794 - accuracy: 0.3470 - val_loss: 1.0499 - val_accuracy: 0.4953\n",
      "Epoch 52/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0800 - accuracy: 0.3369 - val_loss: 1.0497 - val_accuracy: 0.5140\n",
      "Epoch 53/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.0802 - accuracy: 0.3376 - val_loss: 1.0493 - val_accuracy: 0.5140\n",
      "Epoch 54/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.0752 - accuracy: 0.3498 - val_loss: 1.0489 - val_accuracy: 0.5140\n",
      "Epoch 55/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0675 - accuracy: 0.3545 - val_loss: 1.0483 - val_accuracy: 0.5140\n",
      "Epoch 56/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0755 - accuracy: 0.3482 - val_loss: 1.0480 - val_accuracy: 0.5140\n",
      "Epoch 57/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.0765 - accuracy: 0.3380 - val_loss: 1.0478 - val_accuracy: 0.5140\n",
      "Epoch 58/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.0774 - accuracy: 0.3467 - val_loss: 1.0476 - val_accuracy: 0.5140\n",
      "Epoch 59/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0779 - accuracy: 0.3494 - val_loss: 1.0475 - val_accuracy: 0.5140\n",
      "Epoch 60/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0637 - accuracy: 0.3506 - val_loss: 1.0472 - val_accuracy: 0.5140\n",
      "Epoch 61/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0669 - accuracy: 0.3564 - val_loss: 1.0468 - val_accuracy: 0.5140\n",
      "Epoch 62/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.0642 - accuracy: 0.3627 - val_loss: 1.0463 - val_accuracy: 0.5140\n",
      "Epoch 63/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0728 - accuracy: 0.3510 - val_loss: 1.0460 - val_accuracy: 0.5140\n",
      "Epoch 64/200\n",
      "2553/2553 [==============================] - 0s 51us/sample - loss: 1.0681 - accuracy: 0.3439 - val_loss: 1.0458 - val_accuracy: 0.5140\n",
      "Epoch 65/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0662 - accuracy: 0.3655 - val_loss: 1.0455 - val_accuracy: 0.5140\n",
      "Epoch 66/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0709 - accuracy: 0.3482 - val_loss: 1.0452 - val_accuracy: 0.5140\n",
      "Epoch 67/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0675 - accuracy: 0.3517 - val_loss: 1.0450 - val_accuracy: 0.5140\n",
      "Epoch 68/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0613 - accuracy: 0.3604 - val_loss: 1.0445 - val_accuracy: 0.5140\n",
      "Epoch 69/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0552 - accuracy: 0.3662 - val_loss: 1.0440 - val_accuracy: 0.5140\n",
      "Epoch 70/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0672 - accuracy: 0.3545 - val_loss: 1.0438 - val_accuracy: 0.5140\n",
      "Epoch 71/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0615 - accuracy: 0.3545 - val_loss: 1.0435 - val_accuracy: 0.5140\n",
      "Epoch 72/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0654 - accuracy: 0.3647 - val_loss: 1.0431 - val_accuracy: 0.5140\n",
      "Epoch 73/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0677 - accuracy: 0.3553 - val_loss: 1.0430 - val_accuracy: 0.5140\n",
      "Epoch 74/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0629 - accuracy: 0.3619 - val_loss: 1.0427 - val_accuracy: 0.5140\n",
      "Epoch 75/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0647 - accuracy: 0.3604 - val_loss: 1.0425 - val_accuracy: 0.5140\n",
      "Epoch 76/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0716 - accuracy: 0.3514 - val_loss: 1.0423 - val_accuracy: 0.5140\n",
      "Epoch 77/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0685 - accuracy: 0.3537 - val_loss: 1.0423 - val_accuracy: 0.5140\n",
      "Epoch 78/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0757 - accuracy: 0.3380 - val_loss: 1.0423 - val_accuracy: 0.5140\n",
      "Epoch 79/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0688 - accuracy: 0.3502 - val_loss: 1.0422 - val_accuracy: 0.5140\n",
      "Epoch 80/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.0679 - accuracy: 0.3494 - val_loss: 1.0420 - val_accuracy: 0.5140\n",
      "Epoch 81/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.0643 - accuracy: 0.3506 - val_loss: 1.0418 - val_accuracy: 0.5140\n",
      "Epoch 82/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0639 - accuracy: 0.3553 - val_loss: 1.0415 - val_accuracy: 0.5140\n",
      "Epoch 83/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0669 - accuracy: 0.3568 - val_loss: 1.0414 - val_accuracy: 0.5140\n",
      "Epoch 84/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.0653 - accuracy: 0.3600 - val_loss: 1.0411 - val_accuracy: 0.5234\n",
      "Epoch 85/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.0675 - accuracy: 0.3506 - val_loss: 1.0410 - val_accuracy: 0.5140\n",
      "Epoch 86/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0658 - accuracy: 0.3486 - val_loss: 1.0409 - val_accuracy: 0.5140\n",
      "Epoch 87/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0651 - accuracy: 0.3568 - val_loss: 1.0407 - val_accuracy: 0.5140\n",
      "Epoch 88/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.0650 - accuracy: 0.3537 - val_loss: 1.0405 - val_accuracy: 0.5234\n",
      "Epoch 89/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0635 - accuracy: 0.3600 - val_loss: 1.0403 - val_accuracy: 0.5140\n",
      "Epoch 90/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.0649 - accuracy: 0.3545 - val_loss: 1.0402 - val_accuracy: 0.5234\n",
      "Epoch 91/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.0667 - accuracy: 0.3494 - val_loss: 1.0402 - val_accuracy: 0.5140\n",
      "Epoch 92/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.0702 - accuracy: 0.3470 - val_loss: 1.0400 - val_accuracy: 0.5234\n",
      "Epoch 93/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0680 - accuracy: 0.3502 - val_loss: 1.0399 - val_accuracy: 0.5327\n",
      "Epoch 94/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0612 - accuracy: 0.3502 - val_loss: 1.0398 - val_accuracy: 0.5234\n",
      "Epoch 95/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.0629 - accuracy: 0.3537 - val_loss: 1.0395 - val_accuracy: 0.5140\n",
      "Epoch 96/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.0664 - accuracy: 0.3623 - val_loss: 1.0393 - val_accuracy: 0.5327\n",
      "Epoch 97/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0605 - accuracy: 0.3631 - val_loss: 1.0389 - val_accuracy: 0.5327\n",
      "Epoch 98/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0679 - accuracy: 0.3443 - val_loss: 1.0388 - val_accuracy: 0.5327\n",
      "Epoch 99/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0664 - accuracy: 0.3541 - val_loss: 1.0387 - val_accuracy: 0.5327\n",
      "Epoch 100/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0697 - accuracy: 0.3502 - val_loss: 1.0388 - val_accuracy: 0.5327\n",
      "Epoch 101/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0703 - accuracy: 0.3470 - val_loss: 1.0389 - val_accuracy: 0.5327\n",
      "Epoch 102/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.0600 - accuracy: 0.3662 - val_loss: 1.0384 - val_accuracy: 0.5327\n",
      "Epoch 103/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.0672 - accuracy: 0.3459 - val_loss: 1.0382 - val_accuracy: 0.5327\n",
      "Epoch 104/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0605 - accuracy: 0.3627 - val_loss: 1.0379 - val_accuracy: 0.5327\n",
      "Epoch 105/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0604 - accuracy: 0.3596 - val_loss: 1.0378 - val_accuracy: 0.5327\n",
      "Epoch 106/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.0580 - accuracy: 0.3580 - val_loss: 1.0375 - val_accuracy: 0.5327\n",
      "Epoch 107/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0595 - accuracy: 0.3514 - val_loss: 1.0373 - val_accuracy: 0.5327\n",
      "Epoch 108/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0599 - accuracy: 0.3702 - val_loss: 1.0372 - val_accuracy: 0.5327\n",
      "Epoch 109/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0618 - accuracy: 0.3619 - val_loss: 1.0369 - val_accuracy: 0.5327\n",
      "Epoch 110/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.0565 - accuracy: 0.3545 - val_loss: 1.0370 - val_accuracy: 0.5327\n",
      "Epoch 111/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.0639 - accuracy: 0.3592 - val_loss: 1.0367 - val_accuracy: 0.5327\n",
      "Epoch 112/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0640 - accuracy: 0.3572 - val_loss: 1.0367 - val_accuracy: 0.5421\n",
      "Epoch 113/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.0668 - accuracy: 0.3545 - val_loss: 1.0366 - val_accuracy: 0.5421\n",
      "Epoch 114/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0671 - accuracy: 0.3478 - val_loss: 1.0367 - val_accuracy: 0.5421\n",
      "Epoch 115/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0681 - accuracy: 0.3467 - val_loss: 1.0368 - val_accuracy: 0.5421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0688 - accuracy: 0.3525 - val_loss: 1.0367 - val_accuracy: 0.5421\n",
      "Epoch 117/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.0679 - accuracy: 0.3506 - val_loss: 1.0369 - val_accuracy: 0.5421\n",
      "Epoch 118/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0654 - accuracy: 0.3541 - val_loss: 1.0368 - val_accuracy: 0.5421\n",
      "Epoch 119/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0633 - accuracy: 0.3588 - val_loss: 1.0367 - val_accuracy: 0.5421\n",
      "Epoch 120/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0649 - accuracy: 0.3541 - val_loss: 1.0369 - val_accuracy: 0.5421\n",
      "Epoch 121/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.0578 - accuracy: 0.3666 - val_loss: 1.0368 - val_accuracy: 0.5234\n",
      "Epoch 122/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0581 - accuracy: 0.3592 - val_loss: 1.0366 - val_accuracy: 0.5234\n",
      "Epoch 123/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0587 - accuracy: 0.3592 - val_loss: 1.0366 - val_accuracy: 0.5234\n",
      "Epoch 124/200\n",
      "2553/2553 [==============================] - 0s 51us/sample - loss: 1.0591 - accuracy: 0.3572 - val_loss: 1.0364 - val_accuracy: 0.5234\n",
      "Epoch 125/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0731 - accuracy: 0.3494 - val_loss: 1.0367 - val_accuracy: 0.5234\n",
      "Epoch 126/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.0664 - accuracy: 0.3533 - val_loss: 1.0368 - val_accuracy: 0.5234\n",
      "Epoch 127/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0651 - accuracy: 0.3619 - val_loss: 1.0364 - val_accuracy: 0.5327\n",
      "Epoch 128/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0666 - accuracy: 0.3463 - val_loss: 1.0366 - val_accuracy: 0.5327\n",
      "Epoch 129/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0500 - accuracy: 0.3623 - val_loss: 1.0363 - val_accuracy: 0.5327\n",
      "Epoch 130/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0681 - accuracy: 0.3467 - val_loss: 1.0362 - val_accuracy: 0.5327\n",
      "Epoch 131/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0593 - accuracy: 0.3694 - val_loss: 1.0359 - val_accuracy: 0.5327\n",
      "Epoch 132/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0713 - accuracy: 0.3420 - val_loss: 1.0363 - val_accuracy: 0.5327\n",
      "Epoch 133/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0670 - accuracy: 0.3545 - val_loss: 1.0363 - val_accuracy: 0.5327\n",
      "Epoch 134/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0634 - accuracy: 0.3447 - val_loss: 1.0364 - val_accuracy: 0.5327\n",
      "Epoch 135/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0652 - accuracy: 0.3549 - val_loss: 1.0365 - val_accuracy: 0.5327\n",
      "Epoch 136/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0631 - accuracy: 0.3510 - val_loss: 1.0364 - val_accuracy: 0.5327\n",
      "Epoch 137/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0641 - accuracy: 0.3498 - val_loss: 1.0361 - val_accuracy: 0.5327\n",
      "Epoch 138/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.0653 - accuracy: 0.3435 - val_loss: 1.0361 - val_accuracy: 0.5327\n",
      "Epoch 139/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.0616 - accuracy: 0.3564 - val_loss: 1.0359 - val_accuracy: 0.5327\n",
      "Epoch 140/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.0589 - accuracy: 0.3572 - val_loss: 1.0359 - val_accuracy: 0.5327\n",
      "Epoch 141/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.0676 - accuracy: 0.3510 - val_loss: 1.0360 - val_accuracy: 0.5327\n",
      "Epoch 142/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0641 - accuracy: 0.3525 - val_loss: 1.0359 - val_accuracy: 0.5327\n",
      "Epoch 143/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0604 - accuracy: 0.3604 - val_loss: 1.0357 - val_accuracy: 0.5327\n",
      "Epoch 144/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0640 - accuracy: 0.3506 - val_loss: 1.0357 - val_accuracy: 0.5327\n",
      "Epoch 145/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.0528 - accuracy: 0.3611 - val_loss: 1.0352 - val_accuracy: 0.5327\n",
      "Epoch 146/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0698 - accuracy: 0.3447 - val_loss: 1.0352 - val_accuracy: 0.5327\n",
      "Epoch 147/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0627 - accuracy: 0.3537 - val_loss: 1.0351 - val_accuracy: 0.5327\n",
      "Epoch 148/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0653 - accuracy: 0.3459 - val_loss: 1.0351 - val_accuracy: 0.5327\n",
      "Epoch 149/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0639 - accuracy: 0.3478 - val_loss: 1.0352 - val_accuracy: 0.5327\n",
      "Epoch 150/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.0562 - accuracy: 0.3635 - val_loss: 1.0349 - val_accuracy: 0.5327\n",
      "Epoch 151/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.0633 - accuracy: 0.3521 - val_loss: 1.0349 - val_accuracy: 0.5327\n",
      "Epoch 152/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.0592 - accuracy: 0.3576 - val_loss: 1.0348 - val_accuracy: 0.5327\n",
      "Epoch 153/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0622 - accuracy: 0.3557 - val_loss: 1.0349 - val_accuracy: 0.5327\n",
      "Epoch 154/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0596 - accuracy: 0.3498 - val_loss: 1.0347 - val_accuracy: 0.5327\n",
      "Epoch 155/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.0621 - accuracy: 0.3459 - val_loss: 1.0347 - val_accuracy: 0.5327\n",
      "Epoch 156/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0694 - accuracy: 0.3455 - val_loss: 1.0347 - val_accuracy: 0.5327\n",
      "Epoch 157/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0624 - accuracy: 0.3549 - val_loss: 1.0346 - val_accuracy: 0.5327\n",
      "Epoch 158/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0574 - accuracy: 0.3604 - val_loss: 1.0345 - val_accuracy: 0.5327\n",
      "Epoch 159/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.0561 - accuracy: 0.3611 - val_loss: 1.0343 - val_accuracy: 0.5327\n",
      "Epoch 160/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0627 - accuracy: 0.3533 - val_loss: 1.0345 - val_accuracy: 0.5421\n",
      "Epoch 161/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0579 - accuracy: 0.3549 - val_loss: 1.0343 - val_accuracy: 0.5421\n",
      "Epoch 162/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0540 - accuracy: 0.3631 - val_loss: 1.0341 - val_accuracy: 0.5421\n",
      "Epoch 163/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.0617 - accuracy: 0.3451 - val_loss: 1.0340 - val_accuracy: 0.5421\n",
      "Epoch 164/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0600 - accuracy: 0.3561 - val_loss: 1.0339 - val_accuracy: 0.5421\n",
      "Epoch 165/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0602 - accuracy: 0.3474 - val_loss: 1.0339 - val_accuracy: 0.5421\n",
      "Epoch 166/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.0585 - accuracy: 0.3521 - val_loss: 1.0338 - val_accuracy: 0.5421\n",
      "Epoch 167/200\n",
      "2553/2553 [==============================] - 0s 51us/sample - loss: 1.0567 - accuracy: 0.3549 - val_loss: 1.0339 - val_accuracy: 0.5421\n",
      "Epoch 168/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0624 - accuracy: 0.3596 - val_loss: 1.0340 - val_accuracy: 0.5421\n",
      "Epoch 169/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0594 - accuracy: 0.3455 - val_loss: 1.0338 - val_accuracy: 0.5327\n",
      "Epoch 170/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.0560 - accuracy: 0.3584 - val_loss: 1.0336 - val_accuracy: 0.5327\n",
      "Epoch 171/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0473 - accuracy: 0.3651 - val_loss: 1.0333 - val_accuracy: 0.5327\n",
      "Epoch 172/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0659 - accuracy: 0.3517 - val_loss: 1.0336 - val_accuracy: 0.5327\n",
      "Epoch 173/200\n",
      "2553/2553 [==============================] - 0s 46us/sample - loss: 1.0635 - accuracy: 0.3576 - val_loss: 1.0335 - val_accuracy: 0.5327\n",
      "Epoch 174/200\n",
      "2553/2553 [==============================] - 0s 45us/sample - loss: 1.0575 - accuracy: 0.3631 - val_loss: 1.0336 - val_accuracy: 0.5327\n",
      "Epoch 175/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0630 - accuracy: 0.3549 - val_loss: 1.0336 - val_accuracy: 0.5327\n",
      "Epoch 176/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0673 - accuracy: 0.3482 - val_loss: 1.0339 - val_accuracy: 0.5327\n",
      "Epoch 177/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0583 - accuracy: 0.3564 - val_loss: 1.0339 - val_accuracy: 0.5327\n",
      "Epoch 178/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0635 - accuracy: 0.3549 - val_loss: 1.0342 - val_accuracy: 0.5327\n",
      "Epoch 179/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0711 - accuracy: 0.3474 - val_loss: 1.0343 - val_accuracy: 0.5327\n",
      "Epoch 180/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0601 - accuracy: 0.3572 - val_loss: 1.0345 - val_accuracy: 0.5327\n",
      "Epoch 181/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.0494 - accuracy: 0.3608 - val_loss: 1.0340 - val_accuracy: 0.5327\n",
      "Epoch 182/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0622 - accuracy: 0.3498 - val_loss: 1.0341 - val_accuracy: 0.5327\n",
      "Epoch 183/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0620 - accuracy: 0.3435 - val_loss: 1.0341 - val_accuracy: 0.5327\n",
      "Epoch 184/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.0608 - accuracy: 0.3514 - val_loss: 1.0341 - val_accuracy: 0.5327\n",
      "Epoch 185/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0608 - accuracy: 0.3576 - val_loss: 1.0339 - val_accuracy: 0.5327\n",
      "Epoch 186/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0567 - accuracy: 0.3592 - val_loss: 1.0339 - val_accuracy: 0.5327\n",
      "Epoch 187/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0592 - accuracy: 0.3557 - val_loss: 1.0338 - val_accuracy: 0.5327\n",
      "Epoch 188/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0620 - accuracy: 0.3498 - val_loss: 1.0338 - val_accuracy: 0.5327\n",
      "Epoch 189/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0615 - accuracy: 0.3470 - val_loss: 1.0338 - val_accuracy: 0.5327\n",
      "Epoch 190/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0512 - accuracy: 0.3662 - val_loss: 1.0337 - val_accuracy: 0.5327\n",
      "Epoch 191/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0558 - accuracy: 0.3584 - val_loss: 1.0334 - val_accuracy: 0.5327\n",
      "Epoch 192/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0631 - accuracy: 0.3502 - val_loss: 1.0334 - val_accuracy: 0.5327\n",
      "Epoch 193/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0621 - accuracy: 0.3608 - val_loss: 1.0334 - val_accuracy: 0.5327\n",
      "Epoch 194/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0632 - accuracy: 0.3443 - val_loss: 1.0336 - val_accuracy: 0.5327\n",
      "Epoch 195/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0574 - accuracy: 0.3588 - val_loss: 1.0337 - val_accuracy: 0.5327\n",
      "Epoch 196/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0619 - accuracy: 0.3615 - val_loss: 1.0338 - val_accuracy: 0.5327\n",
      "Epoch 197/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0642 - accuracy: 0.3451 - val_loss: 1.0341 - val_accuracy: 0.5327\n",
      "Epoch 198/200\n",
      "2553/2553 [==============================] - 0s 71us/sample - loss: 1.0549 - accuracy: 0.3717 - val_loss: 1.0340 - val_accuracy: 0.5327\n",
      "Epoch 199/200\n",
      "2553/2553 [==============================] - 0s 66us/sample - loss: 1.0608 - accuracy: 0.3564 - val_loss: 1.0339 - val_accuracy: 0.5327\n",
      "Epoch 200/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0601 - accuracy: 0.3611 - val_loss: 1.0336 - val_accuracy: 0.5327\n",
      "0.53271025 {'loss': 1.0600600109537395, 'accuracy': 0.36114374, 'val_loss': 1.033629916538702, 'val_accuracy': 0.53271025}\n",
      "Model: \"model_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_17 (InputLayer)        [(None, 29)]              0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 41)                1230      \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 75)                3150      \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 3)                 228       \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 4,608\n",
      "Trainable params: 4,608\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2553 samples, validate on 107 samples\n",
      "Epoch 1/200\n",
      "2553/2553 [==============================] - 1s 293us/sample - loss: 1.1995 - accuracy: 0.4277 - val_loss: 1.1361 - val_accuracy: 0.4486\n",
      "Epoch 2/200\n",
      "2553/2553 [==============================] - 0s 93us/sample - loss: 1.1925 - accuracy: 0.4289 - val_loss: 1.1317 - val_accuracy: 0.4579\n",
      "Epoch 3/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.1857 - accuracy: 0.4285 - val_loss: 1.1274 - val_accuracy: 0.4579\n",
      "Epoch 4/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.1791 - accuracy: 0.4309 - val_loss: 1.1233 - val_accuracy: 0.4766\n",
      "Epoch 5/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.1726 - accuracy: 0.4309 - val_loss: 1.1195 - val_accuracy: 0.4766\n",
      "Epoch 6/200\n",
      "2553/2553 [==============================] - 0s 98us/sample - loss: 1.1664 - accuracy: 0.4320 - val_loss: 1.1157 - val_accuracy: 0.4860\n",
      "Epoch 7/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.1604 - accuracy: 0.4332 - val_loss: 1.1121 - val_accuracy: 0.4860\n",
      "Epoch 8/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.1545 - accuracy: 0.4352 - val_loss: 1.1087 - val_accuracy: 0.4953\n",
      "Epoch 9/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.1488 - accuracy: 0.4363 - val_loss: 1.1053 - val_accuracy: 0.4953\n",
      "Epoch 10/200\n",
      "2553/2553 [==============================] - 0s 97us/sample - loss: 1.1432 - accuracy: 0.4367 - val_loss: 1.1020 - val_accuracy: 0.4953\n",
      "Epoch 11/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.1378 - accuracy: 0.4379 - val_loss: 1.0988 - val_accuracy: 0.4860\n",
      "Epoch 12/200\n",
      "2553/2553 [==============================] - 0s 98us/sample - loss: 1.1325 - accuracy: 0.4383 - val_loss: 1.0957 - val_accuracy: 0.4860\n",
      "Epoch 13/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.1274 - accuracy: 0.4391 - val_loss: 1.0928 - val_accuracy: 0.4860\n",
      "Epoch 14/200\n",
      "2553/2553 [==============================] - 0s 98us/sample - loss: 1.1224 - accuracy: 0.4379 - val_loss: 1.0900 - val_accuracy: 0.4860\n",
      "Epoch 15/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.1175 - accuracy: 0.4391 - val_loss: 1.0874 - val_accuracy: 0.4860\n",
      "Epoch 16/200\n",
      "2553/2553 [==============================] - 0s 96us/sample - loss: 1.1128 - accuracy: 0.4403 - val_loss: 1.0848 - val_accuracy: 0.4860\n",
      "Epoch 17/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.1082 - accuracy: 0.4410 - val_loss: 1.0825 - val_accuracy: 0.4860\n",
      "Epoch 18/200\n",
      "2553/2553 [==============================] - 0s 98us/sample - loss: 1.1038 - accuracy: 0.4410 - val_loss: 1.0802 - val_accuracy: 0.4860\n",
      "Epoch 19/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.0995 - accuracy: 0.4395 - val_loss: 1.0780 - val_accuracy: 0.4860\n",
      "Epoch 20/200\n",
      "2553/2553 [==============================] - 0s 96us/sample - loss: 1.0953 - accuracy: 0.4387 - val_loss: 1.0757 - val_accuracy: 0.4766\n",
      "Epoch 21/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0913 - accuracy: 0.4391 - val_loss: 1.0735 - val_accuracy: 0.4766\n",
      "Epoch 22/200\n",
      "2553/2553 [==============================] - 0s 94us/sample - loss: 1.0874 - accuracy: 0.4387 - val_loss: 1.0714 - val_accuracy: 0.4766\n",
      "Epoch 23/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.0837 - accuracy: 0.4399 - val_loss: 1.0694 - val_accuracy: 0.4766\n",
      "Epoch 24/200\n",
      "2553/2553 [==============================] - 0s 97us/sample - loss: 1.0801 - accuracy: 0.4407 - val_loss: 1.0675 - val_accuracy: 0.4673\n",
      "Epoch 25/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0767 - accuracy: 0.4442 - val_loss: 1.0657 - val_accuracy: 0.4579\n",
      "Epoch 26/200\n",
      "2553/2553 [==============================] - 0s 96us/sample - loss: 1.0733 - accuracy: 0.4450 - val_loss: 1.0641 - val_accuracy: 0.4579\n",
      "Epoch 27/200\n",
      "2553/2553 [==============================] - 0s 96us/sample - loss: 1.0701 - accuracy: 0.4461 - val_loss: 1.0623 - val_accuracy: 0.4579\n",
      "Epoch 28/200\n",
      "2553/2553 [==============================] - 0s 99us/sample - loss: 1.0670 - accuracy: 0.4465 - val_loss: 1.0607 - val_accuracy: 0.4673\n",
      "Epoch 29/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0641 - accuracy: 0.4469 - val_loss: 1.0592 - val_accuracy: 0.4766\n",
      "Epoch 30/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.0612 - accuracy: 0.4473 - val_loss: 1.0578 - val_accuracy: 0.4673\n",
      "Epoch 31/200\n",
      "2553/2553 [==============================] - 0s 97us/sample - loss: 1.0585 - accuracy: 0.4485 - val_loss: 1.0564 - val_accuracy: 0.4579\n",
      "Epoch 32/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0559 - accuracy: 0.4485 - val_loss: 1.0551 - val_accuracy: 0.4486\n",
      "Epoch 33/200\n",
      "2553/2553 [==============================] - 0s 96us/sample - loss: 1.0534 - accuracy: 0.4508 - val_loss: 1.0540 - val_accuracy: 0.4486\n",
      "Epoch 34/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.0510 - accuracy: 0.4544 - val_loss: 1.0529 - val_accuracy: 0.4393\n",
      "Epoch 35/200\n",
      "2553/2553 [==============================] - 0s 95us/sample - loss: 1.0486 - accuracy: 0.4536 - val_loss: 1.0517 - val_accuracy: 0.4393\n",
      "Epoch 36/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0464 - accuracy: 0.4505 - val_loss: 1.0506 - val_accuracy: 0.4486\n",
      "Epoch 37/200\n",
      "2553/2553 [==============================] - 0s 99us/sample - loss: 1.0442 - accuracy: 0.4524 - val_loss: 1.0495 - val_accuracy: 0.4486\n",
      "Epoch 38/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0422 - accuracy: 0.4544 - val_loss: 1.0486 - val_accuracy: 0.4486\n",
      "Epoch 39/200\n",
      "2553/2553 [==============================] - 0s 98us/sample - loss: 1.0402 - accuracy: 0.4555 - val_loss: 1.0476 - val_accuracy: 0.4486\n",
      "Epoch 40/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0383 - accuracy: 0.4559 - val_loss: 1.0467 - val_accuracy: 0.4393\n",
      "Epoch 41/200\n",
      "2553/2553 [==============================] - 0s 96us/sample - loss: 1.0365 - accuracy: 0.4575 - val_loss: 1.0459 - val_accuracy: 0.4486\n",
      "Epoch 42/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0348 - accuracy: 0.4595 - val_loss: 1.0452 - val_accuracy: 0.4486\n",
      "Epoch 43/200\n",
      "2553/2553 [==============================] - 0s 95us/sample - loss: 1.0331 - accuracy: 0.4587 - val_loss: 1.0445 - val_accuracy: 0.4486\n",
      "Epoch 44/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0316 - accuracy: 0.4591 - val_loss: 1.0438 - val_accuracy: 0.4486\n",
      "Epoch 45/200\n",
      "2553/2553 [==============================] - 0s 97us/sample - loss: 1.0301 - accuracy: 0.4595 - val_loss: 1.0432 - val_accuracy: 0.4579\n",
      "Epoch 46/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.0287 - accuracy: 0.4630 - val_loss: 1.0426 - val_accuracy: 0.4486\n",
      "Epoch 47/200\n",
      "2553/2553 [==============================] - 0s 95us/sample - loss: 1.0274 - accuracy: 0.4646 - val_loss: 1.0420 - val_accuracy: 0.4486\n",
      "Epoch 48/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0261 - accuracy: 0.4657 - val_loss: 1.0414 - val_accuracy: 0.4486\n",
      "Epoch 49/200\n",
      "2553/2553 [==============================] - 0s 95us/sample - loss: 1.0248 - accuracy: 0.4685 - val_loss: 1.0409 - val_accuracy: 0.4486\n",
      "Epoch 50/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0237 - accuracy: 0.4704 - val_loss: 1.0404 - val_accuracy: 0.4486\n",
      "Epoch 51/200\n",
      "2553/2553 [==============================] - 0s 97us/sample - loss: 1.0226 - accuracy: 0.4693 - val_loss: 1.0399 - val_accuracy: 0.4486\n",
      "Epoch 52/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.0215 - accuracy: 0.4720 - val_loss: 1.0394 - val_accuracy: 0.4486\n",
      "Epoch 53/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0205 - accuracy: 0.4736 - val_loss: 1.0390 - val_accuracy: 0.4486\n",
      "Epoch 54/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0195 - accuracy: 0.4755 - val_loss: 1.0386 - val_accuracy: 0.4486\n",
      "Epoch 55/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.0186 - accuracy: 0.4747 - val_loss: 1.0382 - val_accuracy: 0.4486\n",
      "Epoch 56/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0177 - accuracy: 0.4759 - val_loss: 1.0377 - val_accuracy: 0.4486\n",
      "Epoch 57/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.0168 - accuracy: 0.4783 - val_loss: 1.0373 - val_accuracy: 0.4579\n",
      "Epoch 58/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0160 - accuracy: 0.4806 - val_loss: 1.0368 - val_accuracy: 0.4579\n",
      "Epoch 59/200\n",
      "2553/2553 [==============================] - 0s 96us/sample - loss: 1.0153 - accuracy: 0.4822 - val_loss: 1.0364 - val_accuracy: 0.4673\n",
      "Epoch 60/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.0145 - accuracy: 0.4814 - val_loss: 1.0360 - val_accuracy: 0.4766\n",
      "Epoch 61/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0139 - accuracy: 0.4826 - val_loss: 1.0356 - val_accuracy: 0.4766\n",
      "Epoch 62/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0132 - accuracy: 0.4834 - val_loss: 1.0351 - val_accuracy: 0.4766\n",
      "Epoch 63/200\n",
      "2553/2553 [==============================] - 0s 98us/sample - loss: 1.0125 - accuracy: 0.4834 - val_loss: 1.0347 - val_accuracy: 0.4766\n",
      "Epoch 64/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.0119 - accuracy: 0.4857 - val_loss: 1.0343 - val_accuracy: 0.4766\n",
      "Epoch 65/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0113 - accuracy: 0.4869 - val_loss: 1.0339 - val_accuracy: 0.4766\n",
      "Epoch 66/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.0107 - accuracy: 0.4865 - val_loss: 1.0335 - val_accuracy: 0.4860\n",
      "Epoch 67/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0101 - accuracy: 0.4877 - val_loss: 1.0331 - val_accuracy: 0.4766\n",
      "Epoch 68/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.0096 - accuracy: 0.4896 - val_loss: 1.0328 - val_accuracy: 0.4766\n",
      "Epoch 69/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0091 - accuracy: 0.4892 - val_loss: 1.0324 - val_accuracy: 0.4766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0085 - accuracy: 0.4908 - val_loss: 1.0320 - val_accuracy: 0.4766\n",
      "Epoch 71/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.0081 - accuracy: 0.4908 - val_loss: 1.0317 - val_accuracy: 0.4766\n",
      "Epoch 72/200\n",
      "2553/2553 [==============================] - 0s 99us/sample - loss: 1.0076 - accuracy: 0.4904 - val_loss: 1.0313 - val_accuracy: 0.4766\n",
      "Epoch 73/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0071 - accuracy: 0.4908 - val_loss: 1.0309 - val_accuracy: 0.4953\n",
      "Epoch 74/200\n",
      "2553/2553 [==============================] - 0s 133us/sample - loss: 1.0067 - accuracy: 0.4912 - val_loss: 1.0306 - val_accuracy: 0.4953\n",
      "Epoch 75/200\n",
      "2553/2553 [==============================] - 0s 143us/sample - loss: 1.0062 - accuracy: 0.4916 - val_loss: 1.0303 - val_accuracy: 0.4953\n",
      "Epoch 76/200\n",
      "2553/2553 [==============================] - 0s 154us/sample - loss: 1.0058 - accuracy: 0.4904 - val_loss: 1.0299 - val_accuracy: 0.4953\n",
      "Epoch 77/200\n",
      "2553/2553 [==============================] - 0s 120us/sample - loss: 1.0054 - accuracy: 0.4908 - val_loss: 1.0296 - val_accuracy: 0.5047\n",
      "Epoch 78/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.0050 - accuracy: 0.4920 - val_loss: 1.0292 - val_accuracy: 0.5047\n",
      "Epoch 79/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.0046 - accuracy: 0.4931 - val_loss: 1.0289 - val_accuracy: 0.5047\n",
      "Epoch 80/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0043 - accuracy: 0.4928 - val_loss: 1.0285 - val_accuracy: 0.5047\n",
      "Epoch 81/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0040 - accuracy: 0.4920 - val_loss: 1.0282 - val_accuracy: 0.5047\n",
      "Epoch 82/200\n",
      "2553/2553 [==============================] - 0s 99us/sample - loss: 1.0036 - accuracy: 0.4943 - val_loss: 1.0279 - val_accuracy: 0.5047\n",
      "Epoch 83/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.0033 - accuracy: 0.4951 - val_loss: 1.0276 - val_accuracy: 0.5047\n",
      "Epoch 84/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0030 - accuracy: 0.4955 - val_loss: 1.0273 - val_accuracy: 0.5047\n",
      "Epoch 85/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0027 - accuracy: 0.4959 - val_loss: 1.0270 - val_accuracy: 0.5047\n",
      "Epoch 86/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.0024 - accuracy: 0.4967 - val_loss: 1.0267 - val_accuracy: 0.5047\n",
      "Epoch 87/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.0021 - accuracy: 0.4978 - val_loss: 1.0264 - val_accuracy: 0.5047\n",
      "Epoch 88/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0018 - accuracy: 0.4978 - val_loss: 1.0262 - val_accuracy: 0.5047\n",
      "Epoch 89/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0015 - accuracy: 0.4990 - val_loss: 1.0259 - val_accuracy: 0.5047\n",
      "Epoch 90/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0012 - accuracy: 0.4994 - val_loss: 1.0256 - val_accuracy: 0.5047\n",
      "Epoch 91/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.0009 - accuracy: 0.4994 - val_loss: 1.0253 - val_accuracy: 0.5047\n",
      "Epoch 92/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0007 - accuracy: 0.4990 - val_loss: 1.0251 - val_accuracy: 0.4953\n",
      "Epoch 93/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0004 - accuracy: 0.4994 - val_loss: 1.0247 - val_accuracy: 0.4953\n",
      "Epoch 94/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0002 - accuracy: 0.4990 - val_loss: 1.0245 - val_accuracy: 0.4953\n",
      "Epoch 95/200\n",
      "2553/2553 [==============================] - 0s 97us/sample - loss: 0.9999 - accuracy: 0.5002 - val_loss: 1.0243 - val_accuracy: 0.4953\n",
      "Epoch 96/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 0.9996 - accuracy: 0.5018 - val_loss: 1.0240 - val_accuracy: 0.4953\n",
      "Epoch 97/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 0.9994 - accuracy: 0.5018 - val_loss: 1.0237 - val_accuracy: 0.4953\n",
      "Epoch 98/200\n",
      "2553/2553 [==============================] - 0s 98us/sample - loss: 0.9991 - accuracy: 0.5025 - val_loss: 1.0235 - val_accuracy: 0.4953\n",
      "Epoch 99/200\n",
      "2553/2553 [==============================] - 0s 94us/sample - loss: 0.9989 - accuracy: 0.5029 - val_loss: 1.0232 - val_accuracy: 0.4953\n",
      "Epoch 100/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 0.9987 - accuracy: 0.5025 - val_loss: 1.0229 - val_accuracy: 0.4953\n",
      "Epoch 101/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 0.9984 - accuracy: 0.5025 - val_loss: 1.0226 - val_accuracy: 0.4953\n",
      "Epoch 102/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 0.9982 - accuracy: 0.5025 - val_loss: 1.0224 - val_accuracy: 0.4953\n",
      "Epoch 103/200\n",
      "2553/2553 [==============================] - 0s 96us/sample - loss: 0.9980 - accuracy: 0.5018 - val_loss: 1.0222 - val_accuracy: 0.4953\n",
      "Epoch 104/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 0.9977 - accuracy: 0.5018 - val_loss: 1.0219 - val_accuracy: 0.4953\n",
      "Epoch 105/200\n",
      "2553/2553 [==============================] - 0s 96us/sample - loss: 0.9975 - accuracy: 0.5025 - val_loss: 1.0216 - val_accuracy: 0.4953\n",
      "Epoch 106/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 0.9973 - accuracy: 0.5033 - val_loss: 1.0214 - val_accuracy: 0.5047\n",
      "Epoch 107/200\n",
      "2553/2553 [==============================] - 0s 96us/sample - loss: 0.9970 - accuracy: 0.5029 - val_loss: 1.0211 - val_accuracy: 0.5047\n",
      "Epoch 108/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 0.9968 - accuracy: 0.5029 - val_loss: 1.0209 - val_accuracy: 0.5047\n",
      "Epoch 109/200\n",
      "2553/2553 [==============================] - 0s 97us/sample - loss: 0.9966 - accuracy: 0.5025 - val_loss: 1.0206 - val_accuracy: 0.5047\n",
      "Epoch 110/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 0.9964 - accuracy: 0.5029 - val_loss: 1.0204 - val_accuracy: 0.5047\n",
      "Epoch 111/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 0.9962 - accuracy: 0.5033 - val_loss: 1.0201 - val_accuracy: 0.5047\n",
      "Epoch 112/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 0.9960 - accuracy: 0.5037 - val_loss: 1.0199 - val_accuracy: 0.5047\n",
      "Epoch 113/200\n",
      "2553/2553 [==============================] - 0s 97us/sample - loss: 0.9958 - accuracy: 0.5037 - val_loss: 1.0196 - val_accuracy: 0.5047\n",
      "Epoch 114/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 0.9956 - accuracy: 0.5037 - val_loss: 1.0194 - val_accuracy: 0.5047\n",
      "Epoch 115/200\n",
      "2553/2553 [==============================] - 0s 98us/sample - loss: 0.9954 - accuracy: 0.5041 - val_loss: 1.0191 - val_accuracy: 0.5047\n",
      "Epoch 116/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 0.9952 - accuracy: 0.5049 - val_loss: 1.0189 - val_accuracy: 0.5047\n",
      "Epoch 117/200\n",
      "2553/2553 [==============================] - 0s 98us/sample - loss: 0.9950 - accuracy: 0.5057 - val_loss: 1.0187 - val_accuracy: 0.5047\n",
      "Epoch 118/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 0.9948 - accuracy: 0.5065 - val_loss: 1.0184 - val_accuracy: 0.5047\n",
      "Epoch 119/200\n",
      "2553/2553 [==============================] - 0s 98us/sample - loss: 0.9946 - accuracy: 0.5065 - val_loss: 1.0182 - val_accuracy: 0.5047\n",
      "Epoch 120/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 0.9944 - accuracy: 0.5065 - val_loss: 1.0179 - val_accuracy: 0.5047\n",
      "Epoch 121/200\n",
      "2553/2553 [==============================] - 0s 98us/sample - loss: 0.9942 - accuracy: 0.5069 - val_loss: 1.0176 - val_accuracy: 0.5047\n",
      "Epoch 122/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 0.9941 - accuracy: 0.5065 - val_loss: 1.0174 - val_accuracy: 0.5047\n",
      "Epoch 123/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 0.9939 - accuracy: 0.5072 - val_loss: 1.0172 - val_accuracy: 0.5047\n",
      "Epoch 124/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 103us/sample - loss: 0.9937 - accuracy: 0.5069 - val_loss: 1.0169 - val_accuracy: 0.5047\n",
      "Epoch 125/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 0.9935 - accuracy: 0.5065 - val_loss: 1.0167 - val_accuracy: 0.4953\n",
      "Epoch 126/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 0.9933 - accuracy: 0.5061 - val_loss: 1.0164 - val_accuracy: 0.4953\n",
      "Epoch 127/200\n",
      "2553/2553 [==============================] - 0s 99us/sample - loss: 0.9932 - accuracy: 0.5065 - val_loss: 1.0162 - val_accuracy: 0.4953\n",
      "Epoch 128/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 0.9930 - accuracy: 0.5072 - val_loss: 1.0159 - val_accuracy: 0.4953\n",
      "Epoch 129/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 0.9928 - accuracy: 0.5069 - val_loss: 1.0157 - val_accuracy: 0.4953\n",
      "Epoch 130/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 0.9926 - accuracy: 0.5076 - val_loss: 1.0154 - val_accuracy: 0.4953\n",
      "Epoch 131/200\n",
      "2553/2553 [==============================] - 0s 99us/sample - loss: 0.9925 - accuracy: 0.5076 - val_loss: 1.0152 - val_accuracy: 0.4953\n",
      "Epoch 132/200\n",
      "2553/2553 [==============================] - 0s 98us/sample - loss: 0.9923 - accuracy: 0.5072 - val_loss: 1.0149 - val_accuracy: 0.4953\n",
      "Epoch 133/200\n",
      "2553/2553 [==============================] - 0s 120us/sample - loss: 0.9921 - accuracy: 0.5072 - val_loss: 1.0147 - val_accuracy: 0.4953\n",
      "Epoch 134/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 0.9920 - accuracy: 0.5072 - val_loss: 1.0144 - val_accuracy: 0.4953\n",
      "Epoch 135/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 0.9918 - accuracy: 0.5072 - val_loss: 1.0141 - val_accuracy: 0.4953\n",
      "Epoch 136/200\n",
      "2553/2553 [==============================] - 0s 99us/sample - loss: 0.9916 - accuracy: 0.5072 - val_loss: 1.0139 - val_accuracy: 0.4953\n",
      "Epoch 137/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 0.9915 - accuracy: 0.5080 - val_loss: 1.0137 - val_accuracy: 0.4953\n",
      "Epoch 138/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 0.9913 - accuracy: 0.5084 - val_loss: 1.0134 - val_accuracy: 0.4953\n",
      "Epoch 139/200\n",
      "2553/2553 [==============================] - 0s 96us/sample - loss: 0.9912 - accuracy: 0.5084 - val_loss: 1.0132 - val_accuracy: 0.4953\n",
      "Epoch 140/200\n",
      "2553/2553 [==============================] - 0s 98us/sample - loss: 0.9910 - accuracy: 0.5084 - val_loss: 1.0129 - val_accuracy: 0.4953\n",
      "Epoch 141/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 0.9908 - accuracy: 0.5088 - val_loss: 1.0126 - val_accuracy: 0.4953\n",
      "Epoch 142/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 0.9907 - accuracy: 0.5088 - val_loss: 1.0124 - val_accuracy: 0.4953\n",
      "Epoch 143/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 0.9905 - accuracy: 0.5084 - val_loss: 1.0121 - val_accuracy: 0.4953\n",
      "Epoch 144/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 0.9904 - accuracy: 0.5092 - val_loss: 1.0119 - val_accuracy: 0.4953\n",
      "Epoch 145/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 0.9902 - accuracy: 0.5096 - val_loss: 1.0117 - val_accuracy: 0.4953\n",
      "Epoch 146/200\n",
      "2553/2553 [==============================] - 0s 96us/sample - loss: 0.9901 - accuracy: 0.5100 - val_loss: 1.0114 - val_accuracy: 0.4953\n",
      "Epoch 147/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 0.9899 - accuracy: 0.5104 - val_loss: 1.0112 - val_accuracy: 0.4953\n",
      "Epoch 148/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 0.9898 - accuracy: 0.5116 - val_loss: 1.0110 - val_accuracy: 0.4953\n",
      "Epoch 149/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 0.9896 - accuracy: 0.5112 - val_loss: 1.0107 - val_accuracy: 0.4953\n",
      "Epoch 150/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 0.9895 - accuracy: 0.5108 - val_loss: 1.0105 - val_accuracy: 0.4953\n",
      "Epoch 151/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 0.9893 - accuracy: 0.5112 - val_loss: 1.0102 - val_accuracy: 0.4953\n",
      "Epoch 152/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 0.9892 - accuracy: 0.5112 - val_loss: 1.0101 - val_accuracy: 0.4953\n",
      "Epoch 153/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 0.9890 - accuracy: 0.5116 - val_loss: 1.0098 - val_accuracy: 0.4953\n",
      "Epoch 154/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 0.9889 - accuracy: 0.5116 - val_loss: 1.0096 - val_accuracy: 0.4953\n",
      "Epoch 155/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 0.9888 - accuracy: 0.5112 - val_loss: 1.0094 - val_accuracy: 0.4953\n",
      "Epoch 156/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 0.9886 - accuracy: 0.5108 - val_loss: 1.0092 - val_accuracy: 0.4953\n",
      "Epoch 157/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 0.9885 - accuracy: 0.5100 - val_loss: 1.0090 - val_accuracy: 0.4953\n",
      "Epoch 158/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 0.9883 - accuracy: 0.5100 - val_loss: 1.0087 - val_accuracy: 0.4953\n",
      "Epoch 159/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 0.9882 - accuracy: 0.5104 - val_loss: 1.0085 - val_accuracy: 0.4860\n",
      "Epoch 160/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 0.9881 - accuracy: 0.5100 - val_loss: 1.0083 - val_accuracy: 0.4860\n",
      "Epoch 161/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 0.9879 - accuracy: 0.5112 - val_loss: 1.0081 - val_accuracy: 0.4860\n",
      "Epoch 162/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 0.9878 - accuracy: 0.5119 - val_loss: 1.0078 - val_accuracy: 0.4860\n",
      "Epoch 163/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 0.9877 - accuracy: 0.5119 - val_loss: 1.0076 - val_accuracy: 0.4860\n",
      "Epoch 164/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 0.9875 - accuracy: 0.5123 - val_loss: 1.0074 - val_accuracy: 0.4860\n",
      "Epoch 165/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 0.9874 - accuracy: 0.5123 - val_loss: 1.0072 - val_accuracy: 0.4860\n",
      "Epoch 166/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 0.9873 - accuracy: 0.5127 - val_loss: 1.0070 - val_accuracy: 0.4860\n",
      "Epoch 167/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 0.9872 - accuracy: 0.5127 - val_loss: 1.0068 - val_accuracy: 0.4860\n",
      "Epoch 168/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 0.9870 - accuracy: 0.5123 - val_loss: 1.0066 - val_accuracy: 0.4860\n",
      "Epoch 169/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 0.9869 - accuracy: 0.5127 - val_loss: 1.0064 - val_accuracy: 0.4860\n",
      "Epoch 170/200\n",
      "2553/2553 [==============================] - 0s 97us/sample - loss: 0.9868 - accuracy: 0.5127 - val_loss: 1.0062 - val_accuracy: 0.4860\n",
      "Epoch 171/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 0.9866 - accuracy: 0.5127 - val_loss: 1.0060 - val_accuracy: 0.4860\n",
      "Epoch 172/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 0.9865 - accuracy: 0.5123 - val_loss: 1.0058 - val_accuracy: 0.4860\n",
      "Epoch 173/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 0.9864 - accuracy: 0.5123 - val_loss: 1.0056 - val_accuracy: 0.4953\n",
      "Epoch 174/200\n",
      "2553/2553 [==============================] - 0s 99us/sample - loss: 0.9863 - accuracy: 0.5127 - val_loss: 1.0054 - val_accuracy: 0.4953\n",
      "Epoch 175/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 0.9861 - accuracy: 0.5127 - val_loss: 1.0052 - val_accuracy: 0.4953\n",
      "Epoch 176/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 0.9860 - accuracy: 0.5131 - val_loss: 1.0050 - val_accuracy: 0.4953\n",
      "Epoch 177/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 0.9859 - accuracy: 0.5143 - val_loss: 1.0048 - val_accuracy: 0.4953\n",
      "Epoch 178/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 98us/sample - loss: 0.9858 - accuracy: 0.5147 - val_loss: 1.0046 - val_accuracy: 0.4953\n",
      "Epoch 179/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 0.9856 - accuracy: 0.5159 - val_loss: 1.0044 - val_accuracy: 0.4953\n",
      "Epoch 180/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 0.9855 - accuracy: 0.5159 - val_loss: 1.0042 - val_accuracy: 0.4953\n",
      "Epoch 181/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 0.9854 - accuracy: 0.5159 - val_loss: 1.0039 - val_accuracy: 0.4953\n",
      "Epoch 182/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 0.9852 - accuracy: 0.5151 - val_loss: 1.0038 - val_accuracy: 0.5047\n",
      "Epoch 183/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 0.9851 - accuracy: 0.5151 - val_loss: 1.0036 - val_accuracy: 0.5047\n",
      "Epoch 184/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 0.9850 - accuracy: 0.5159 - val_loss: 1.0034 - val_accuracy: 0.5047\n",
      "Epoch 185/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 0.9849 - accuracy: 0.5155 - val_loss: 1.0032 - val_accuracy: 0.5047\n",
      "Epoch 186/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 0.9847 - accuracy: 0.5155 - val_loss: 1.0029 - val_accuracy: 0.5047\n",
      "Epoch 187/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 0.9846 - accuracy: 0.5159 - val_loss: 1.0027 - val_accuracy: 0.5047\n",
      "Epoch 188/200\n",
      "2553/2553 [==============================] - 0s 99us/sample - loss: 0.9845 - accuracy: 0.5147 - val_loss: 1.0026 - val_accuracy: 0.5047\n",
      "Epoch 189/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 0.9844 - accuracy: 0.5151 - val_loss: 1.0024 - val_accuracy: 0.5047\n",
      "Epoch 190/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 0.9842 - accuracy: 0.5155 - val_loss: 1.0022 - val_accuracy: 0.5047\n",
      "Epoch 191/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 0.9841 - accuracy: 0.5151 - val_loss: 1.0019 - val_accuracy: 0.5047\n",
      "Epoch 192/200\n",
      "2553/2553 [==============================] - 0s 98us/sample - loss: 0.9840 - accuracy: 0.5151 - val_loss: 1.0018 - val_accuracy: 0.5047\n",
      "Epoch 193/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 0.9839 - accuracy: 0.5155 - val_loss: 1.0016 - val_accuracy: 0.5047\n",
      "Epoch 194/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 0.9837 - accuracy: 0.5163 - val_loss: 1.0014 - val_accuracy: 0.5047\n",
      "Epoch 195/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 0.9836 - accuracy: 0.5170 - val_loss: 1.0012 - val_accuracy: 0.5047\n",
      "Epoch 196/200\n",
      "2553/2553 [==============================] - 0s 99us/sample - loss: 0.9835 - accuracy: 0.5178 - val_loss: 1.0010 - val_accuracy: 0.5047\n",
      "Epoch 197/200\n",
      "2553/2553 [==============================] - 0s 99us/sample - loss: 0.9834 - accuracy: 0.5174 - val_loss: 1.0009 - val_accuracy: 0.5047\n",
      "Epoch 198/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 0.9833 - accuracy: 0.5178 - val_loss: 1.0007 - val_accuracy: 0.5047\n",
      "Epoch 199/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 0.9831 - accuracy: 0.5178 - val_loss: 1.0006 - val_accuracy: 0.5047\n",
      "Epoch 200/200\n",
      "2553/2553 [==============================] - 0s 96us/sample - loss: 0.9830 - accuracy: 0.5182 - val_loss: 1.0004 - val_accuracy: 0.5047\n",
      "0.5046729 {'loss': 0.9830159241435017, 'accuracy': 0.51821387, 'val_loss': 1.000368595123291, 'val_accuracy': 0.5046729}\n",
      "Model: \"model_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_18 (InputLayer)        [(None, 29)]              0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 41)                1230      \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 75)                3150      \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 3)                 228       \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 4,608\n",
      "Trainable params: 4,608\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2553 samples, validate on 107 samples\n",
      "Epoch 1/200\n",
      "2553/2553 [==============================] - 1s 253us/sample - loss: 1.0124 - accuracy: 0.4975 - val_loss: 1.0304 - val_accuracy: 0.4393\n",
      "Epoch 2/200\n",
      "2553/2553 [==============================] - 0s 48us/sample - loss: 1.0120 - accuracy: 0.4990 - val_loss: 1.0300 - val_accuracy: 0.4393\n",
      "Epoch 3/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0116 - accuracy: 0.5002 - val_loss: 1.0295 - val_accuracy: 0.4393\n",
      "Epoch 4/200\n",
      "2553/2553 [==============================] - 0s 49us/sample - loss: 1.0112 - accuracy: 0.4994 - val_loss: 1.0290 - val_accuracy: 0.4393\n",
      "Epoch 5/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.0108 - accuracy: 0.5002 - val_loss: 1.0286 - val_accuracy: 0.4393\n",
      "Epoch 6/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0104 - accuracy: 0.4994 - val_loss: 1.0282 - val_accuracy: 0.4486\n",
      "Epoch 7/200\n",
      "2553/2553 [==============================] - 0s 48us/sample - loss: 1.0101 - accuracy: 0.4998 - val_loss: 1.0278 - val_accuracy: 0.4486\n",
      "Epoch 8/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.0097 - accuracy: 0.4986 - val_loss: 1.0273 - val_accuracy: 0.4486\n",
      "Epoch 9/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0094 - accuracy: 0.4986 - val_loss: 1.0269 - val_accuracy: 0.4486\n",
      "Epoch 10/200\n",
      "2553/2553 [==============================] - 0s 50us/sample - loss: 1.0091 - accuracy: 0.4994 - val_loss: 1.0266 - val_accuracy: 0.4486\n",
      "Epoch 11/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.0088 - accuracy: 0.4994 - val_loss: 1.0262 - val_accuracy: 0.4579\n",
      "Epoch 12/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.0085 - accuracy: 0.5014 - val_loss: 1.0258 - val_accuracy: 0.4579\n",
      "Epoch 13/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0082 - accuracy: 0.5014 - val_loss: 1.0254 - val_accuracy: 0.4579\n",
      "Epoch 14/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.0079 - accuracy: 0.5018 - val_loss: 1.0250 - val_accuracy: 0.4579\n",
      "Epoch 15/200\n",
      "2553/2553 [==============================] - 0s 50us/sample - loss: 1.0076 - accuracy: 0.5022 - val_loss: 1.0246 - val_accuracy: 0.4579\n",
      "Epoch 16/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0073 - accuracy: 0.5025 - val_loss: 1.0243 - val_accuracy: 0.4579\n",
      "Epoch 17/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0071 - accuracy: 0.5025 - val_loss: 1.0239 - val_accuracy: 0.4579\n",
      "Epoch 18/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.0068 - accuracy: 0.5025 - val_loss: 1.0236 - val_accuracy: 0.4579\n",
      "Epoch 19/200\n",
      "2553/2553 [==============================] - 0s 50us/sample - loss: 1.0065 - accuracy: 0.5010 - val_loss: 1.0233 - val_accuracy: 0.4579\n",
      "Epoch 20/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.0063 - accuracy: 0.5006 - val_loss: 1.0230 - val_accuracy: 0.4579\n",
      "Epoch 21/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.0061 - accuracy: 0.5002 - val_loss: 1.0227 - val_accuracy: 0.4579\n",
      "Epoch 22/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.0059 - accuracy: 0.4998 - val_loss: 1.0224 - val_accuracy: 0.4673\n",
      "Epoch 23/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.0056 - accuracy: 0.4994 - val_loss: 1.0221 - val_accuracy: 0.4673\n",
      "Epoch 24/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.0054 - accuracy: 0.4998 - val_loss: 1.0218 - val_accuracy: 0.4673\n",
      "Epoch 25/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0052 - accuracy: 0.4990 - val_loss: 1.0215 - val_accuracy: 0.4673\n",
      "Epoch 26/200\n",
      "2553/2553 [==============================] - 0s 50us/sample - loss: 1.0051 - accuracy: 0.4982 - val_loss: 1.0212 - val_accuracy: 0.4673\n",
      "Epoch 27/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.0049 - accuracy: 0.4982 - val_loss: 1.0210 - val_accuracy: 0.4673\n",
      "Epoch 28/200\n",
      "2553/2553 [==============================] - 0s 51us/sample - loss: 1.0047 - accuracy: 0.4986 - val_loss: 1.0207 - val_accuracy: 0.4673\n",
      "Epoch 29/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0045 - accuracy: 0.4990 - val_loss: 1.0205 - val_accuracy: 0.4766\n",
      "Epoch 30/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0044 - accuracy: 0.4990 - val_loss: 1.0202 - val_accuracy: 0.4860\n",
      "Epoch 31/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0042 - accuracy: 0.4990 - val_loss: 1.0199 - val_accuracy: 0.4766\n",
      "Epoch 32/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0041 - accuracy: 0.4998 - val_loss: 1.0196 - val_accuracy: 0.4766\n",
      "Epoch 33/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0039 - accuracy: 0.5010 - val_loss: 1.0193 - val_accuracy: 0.4766\n",
      "Epoch 34/200\n",
      "2553/2553 [==============================] - 0s 51us/sample - loss: 1.0038 - accuracy: 0.5014 - val_loss: 1.0191 - val_accuracy: 0.4766\n",
      "Epoch 35/200\n",
      "2553/2553 [==============================] - 0s 50us/sample - loss: 1.0036 - accuracy: 0.5018 - val_loss: 1.0188 - val_accuracy: 0.4766\n",
      "Epoch 36/200\n",
      "2553/2553 [==============================] - 0s 51us/sample - loss: 1.0035 - accuracy: 0.5010 - val_loss: 1.0186 - val_accuracy: 0.4766\n",
      "Epoch 37/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0033 - accuracy: 0.5018 - val_loss: 1.0183 - val_accuracy: 0.4766\n",
      "Epoch 38/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.0032 - accuracy: 0.5025 - val_loss: 1.0180 - val_accuracy: 0.4860\n",
      "Epoch 39/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0031 - accuracy: 0.5033 - val_loss: 1.0178 - val_accuracy: 0.4860\n",
      "Epoch 40/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.0029 - accuracy: 0.5033 - val_loss: 1.0175 - val_accuracy: 0.4860\n",
      "Epoch 41/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.0028 - accuracy: 0.5033 - val_loss: 1.0173 - val_accuracy: 0.4860\n",
      "Epoch 42/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.0027 - accuracy: 0.5041 - val_loss: 1.0170 - val_accuracy: 0.4860\n",
      "Epoch 43/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.0026 - accuracy: 0.5049 - val_loss: 1.0168 - val_accuracy: 0.4860\n",
      "Epoch 44/200\n",
      "2553/2553 [==============================] - 0s 51us/sample - loss: 1.0024 - accuracy: 0.5049 - val_loss: 1.0165 - val_accuracy: 0.4860\n",
      "Epoch 45/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0023 - accuracy: 0.5057 - val_loss: 1.0163 - val_accuracy: 0.4860\n",
      "Epoch 46/200\n",
      "2553/2553 [==============================] - 0s 51us/sample - loss: 1.0022 - accuracy: 0.5057 - val_loss: 1.0161 - val_accuracy: 0.4860\n",
      "Epoch 47/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.0021 - accuracy: 0.5061 - val_loss: 1.0158 - val_accuracy: 0.4860\n",
      "Epoch 48/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0020 - accuracy: 0.5061 - val_loss: 1.0156 - val_accuracy: 0.4860\n",
      "Epoch 49/200\n",
      "2553/2553 [==============================] - 0s 51us/sample - loss: 1.0019 - accuracy: 0.5065 - val_loss: 1.0154 - val_accuracy: 0.4860\n",
      "Epoch 50/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.0018 - accuracy: 0.5057 - val_loss: 1.0151 - val_accuracy: 0.4860\n",
      "Epoch 51/200\n",
      "2553/2553 [==============================] - 0s 50us/sample - loss: 1.0017 - accuracy: 0.5057 - val_loss: 1.0149 - val_accuracy: 0.4860\n",
      "Epoch 52/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0016 - accuracy: 0.5061 - val_loss: 1.0147 - val_accuracy: 0.4953\n",
      "Epoch 53/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0015 - accuracy: 0.5061 - val_loss: 1.0145 - val_accuracy: 0.4953\n",
      "Epoch 54/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.0014 - accuracy: 0.5061 - val_loss: 1.0143 - val_accuracy: 0.4953\n",
      "Epoch 55/200\n",
      "2553/2553 [==============================] - 0s 50us/sample - loss: 1.0013 - accuracy: 0.5057 - val_loss: 1.0141 - val_accuracy: 0.4953\n",
      "Epoch 56/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0012 - accuracy: 0.5057 - val_loss: 1.0139 - val_accuracy: 0.4953\n",
      "Epoch 57/200\n",
      "2553/2553 [==============================] - 0s 51us/sample - loss: 1.0011 - accuracy: 0.5061 - val_loss: 1.0136 - val_accuracy: 0.4953\n",
      "Epoch 58/200\n",
      "2553/2553 [==============================] - 0s 51us/sample - loss: 1.0010 - accuracy: 0.5065 - val_loss: 1.0135 - val_accuracy: 0.4953\n",
      "Epoch 59/200\n",
      "2553/2553 [==============================] - 0s 50us/sample - loss: 1.0009 - accuracy: 0.5061 - val_loss: 1.0133 - val_accuracy: 0.4953\n",
      "Epoch 60/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0008 - accuracy: 0.5065 - val_loss: 1.0130 - val_accuracy: 0.4953\n",
      "Epoch 61/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.0008 - accuracy: 0.5072 - val_loss: 1.0129 - val_accuracy: 0.4953\n",
      "Epoch 62/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0007 - accuracy: 0.5069 - val_loss: 1.0127 - val_accuracy: 0.4953\n",
      "Epoch 63/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.0006 - accuracy: 0.5069 - val_loss: 1.0125 - val_accuracy: 0.4953\n",
      "Epoch 64/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0005 - accuracy: 0.5069 - val_loss: 1.0123 - val_accuracy: 0.4953\n",
      "Epoch 65/200\n",
      "2553/2553 [==============================] - 0s 50us/sample - loss: 1.0004 - accuracy: 0.5069 - val_loss: 1.0121 - val_accuracy: 0.4953\n",
      "Epoch 66/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.0004 - accuracy: 0.5069 - val_loss: 1.0120 - val_accuracy: 0.4953\n",
      "Epoch 67/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.0003 - accuracy: 0.5069 - val_loss: 1.0118 - val_accuracy: 0.4953\n",
      "Epoch 68/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0002 - accuracy: 0.5072 - val_loss: 1.0116 - val_accuracy: 0.4953\n",
      "Epoch 69/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.0001 - accuracy: 0.5072 - val_loss: 1.0115 - val_accuracy: 0.4953\n",
      "Epoch 70/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.0001 - accuracy: 0.5069 - val_loss: 1.0113 - val_accuracy: 0.4953\n",
      "Epoch 71/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.0000 - accuracy: 0.5069 - val_loss: 1.0111 - val_accuracy: 0.4953\n",
      "Epoch 72/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 0.9999 - accuracy: 0.5069 - val_loss: 1.0110 - val_accuracy: 0.4953\n",
      "Epoch 73/200\n",
      "2553/2553 [==============================] - 0s 50us/sample - loss: 0.9999 - accuracy: 0.5076 - val_loss: 1.0108 - val_accuracy: 0.4953\n",
      "Epoch 74/200\n",
      "2553/2553 [==============================] - 0s 50us/sample - loss: 0.9998 - accuracy: 0.5076 - val_loss: 1.0107 - val_accuracy: 0.4953\n",
      "Epoch 75/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 0.9997 - accuracy: 0.5076 - val_loss: 1.0105 - val_accuracy: 0.4953\n",
      "Epoch 76/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 0.9997 - accuracy: 0.5076 - val_loss: 1.0104 - val_accuracy: 0.4953\n",
      "Epoch 77/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 0.9996 - accuracy: 0.5072 - val_loss: 1.0102 - val_accuracy: 0.4953\n",
      "Epoch 78/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 52us/sample - loss: 0.9996 - accuracy: 0.5072 - val_loss: 1.0101 - val_accuracy: 0.4953\n",
      "Epoch 79/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 0.9995 - accuracy: 0.5072 - val_loss: 1.0099 - val_accuracy: 0.4953\n",
      "Epoch 80/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 0.9994 - accuracy: 0.5072 - val_loss: 1.0098 - val_accuracy: 0.4953\n",
      "Epoch 81/200\n",
      "2553/2553 [==============================] - 0s 48us/sample - loss: 0.9994 - accuracy: 0.5072 - val_loss: 1.0096 - val_accuracy: 0.4953\n",
      "Epoch 82/200\n",
      "2553/2553 [==============================] - 0s 51us/sample - loss: 0.9993 - accuracy: 0.5088 - val_loss: 1.0095 - val_accuracy: 0.4953\n",
      "Epoch 83/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 0.9992 - accuracy: 0.5092 - val_loss: 1.0093 - val_accuracy: 0.5047\n",
      "Epoch 84/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 0.9992 - accuracy: 0.5092 - val_loss: 1.0092 - val_accuracy: 0.5047\n",
      "Epoch 85/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 0.9991 - accuracy: 0.5092 - val_loss: 1.0091 - val_accuracy: 0.5047\n",
      "Epoch 86/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 0.9990 - accuracy: 0.5096 - val_loss: 1.0089 - val_accuracy: 0.5047\n",
      "Epoch 87/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 0.9990 - accuracy: 0.5096 - val_loss: 1.0088 - val_accuracy: 0.5047\n",
      "Epoch 88/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 0.9989 - accuracy: 0.5104 - val_loss: 1.0086 - val_accuracy: 0.5047\n",
      "Epoch 89/200\n",
      "2553/2553 [==============================] - 0s 51us/sample - loss: 0.9989 - accuracy: 0.5104 - val_loss: 1.0085 - val_accuracy: 0.5047\n",
      "Epoch 90/200\n",
      "2553/2553 [==============================] - 0s 51us/sample - loss: 0.9988 - accuracy: 0.5104 - val_loss: 1.0084 - val_accuracy: 0.5047\n",
      "Epoch 91/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 0.9987 - accuracy: 0.5104 - val_loss: 1.0082 - val_accuracy: 0.5047\n",
      "Epoch 92/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 0.9987 - accuracy: 0.5104 - val_loss: 1.0081 - val_accuracy: 0.5047\n",
      "Epoch 93/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 0.9986 - accuracy: 0.5104 - val_loss: 1.0080 - val_accuracy: 0.5047\n",
      "Epoch 94/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 0.9986 - accuracy: 0.5112 - val_loss: 1.0078 - val_accuracy: 0.5047\n",
      "Epoch 95/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 0.9985 - accuracy: 0.5112 - val_loss: 1.0077 - val_accuracy: 0.5047\n",
      "Epoch 96/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 0.9985 - accuracy: 0.5108 - val_loss: 1.0076 - val_accuracy: 0.5047\n",
      "Epoch 97/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 0.9984 - accuracy: 0.5108 - val_loss: 1.0074 - val_accuracy: 0.5047\n",
      "Epoch 98/200\n",
      "2553/2553 [==============================] - 0s 51us/sample - loss: 0.9983 - accuracy: 0.5108 - val_loss: 1.0073 - val_accuracy: 0.5047\n",
      "Epoch 99/200\n",
      "2553/2553 [==============================] - 0s 50us/sample - loss: 0.9983 - accuracy: 0.5108 - val_loss: 1.0072 - val_accuracy: 0.5047\n",
      "Epoch 100/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 0.9982 - accuracy: 0.5112 - val_loss: 1.0070 - val_accuracy: 0.5047\n",
      "Epoch 101/200\n",
      "2553/2553 [==============================] - 0s 50us/sample - loss: 0.9982 - accuracy: 0.5116 - val_loss: 1.0069 - val_accuracy: 0.5047\n",
      "Epoch 102/200\n",
      "2553/2553 [==============================] - 0s 51us/sample - loss: 0.9981 - accuracy: 0.5116 - val_loss: 1.0068 - val_accuracy: 0.5047\n",
      "Epoch 103/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 0.9981 - accuracy: 0.5119 - val_loss: 1.0067 - val_accuracy: 0.5047\n",
      "Epoch 104/200\n",
      "2553/2553 [==============================] - 0s 49us/sample - loss: 0.9980 - accuracy: 0.5119 - val_loss: 1.0065 - val_accuracy: 0.5047\n",
      "Epoch 105/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 0.9980 - accuracy: 0.5123 - val_loss: 1.0064 - val_accuracy: 0.5047\n",
      "Epoch 106/200\n",
      "2553/2553 [==============================] - 0s 51us/sample - loss: 0.9979 - accuracy: 0.5123 - val_loss: 1.0063 - val_accuracy: 0.4953\n",
      "Epoch 107/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 0.9979 - accuracy: 0.5119 - val_loss: 1.0062 - val_accuracy: 0.4953\n",
      "Epoch 108/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 0.9978 - accuracy: 0.5119 - val_loss: 1.0061 - val_accuracy: 0.4953\n",
      "Epoch 109/200\n",
      "2553/2553 [==============================] - 0s 51us/sample - loss: 0.9978 - accuracy: 0.5127 - val_loss: 1.0060 - val_accuracy: 0.4953\n",
      "Epoch 110/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 0.9977 - accuracy: 0.5127 - val_loss: 1.0059 - val_accuracy: 0.4953\n",
      "Epoch 111/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 0.9977 - accuracy: 0.5127 - val_loss: 1.0058 - val_accuracy: 0.4953\n",
      "Epoch 112/200\n",
      "2553/2553 [==============================] - 0s 51us/sample - loss: 0.9976 - accuracy: 0.5127 - val_loss: 1.0057 - val_accuracy: 0.4953\n",
      "Epoch 113/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 0.9976 - accuracy: 0.5127 - val_loss: 1.0056 - val_accuracy: 0.4953\n",
      "Epoch 114/200\n",
      "2553/2553 [==============================] - 0s 49us/sample - loss: 0.9975 - accuracy: 0.5135 - val_loss: 1.0055 - val_accuracy: 0.4953\n",
      "Epoch 115/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 0.9975 - accuracy: 0.5131 - val_loss: 1.0053 - val_accuracy: 0.4953\n",
      "Epoch 116/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 0.9974 - accuracy: 0.5131 - val_loss: 1.0053 - val_accuracy: 0.4953\n",
      "Epoch 117/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 0.9974 - accuracy: 0.5131 - val_loss: 1.0052 - val_accuracy: 0.4953\n",
      "Epoch 118/200\n",
      "2553/2553 [==============================] - 0s 51us/sample - loss: 0.9973 - accuracy: 0.5131 - val_loss: 1.0051 - val_accuracy: 0.4953\n",
      "Epoch 119/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 0.9973 - accuracy: 0.5143 - val_loss: 1.0049 - val_accuracy: 0.4953\n",
      "Epoch 120/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 0.9972 - accuracy: 0.5143 - val_loss: 1.0049 - val_accuracy: 0.4953\n",
      "Epoch 121/200\n",
      "2553/2553 [==============================] - 0s 51us/sample - loss: 0.9972 - accuracy: 0.5139 - val_loss: 1.0047 - val_accuracy: 0.4953\n",
      "Epoch 122/200\n",
      "2553/2553 [==============================] - 0s 50us/sample - loss: 0.9971 - accuracy: 0.5139 - val_loss: 1.0047 - val_accuracy: 0.4953\n",
      "Epoch 123/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 0.9971 - accuracy: 0.5143 - val_loss: 1.0045 - val_accuracy: 0.4953\n",
      "Epoch 124/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 0.9970 - accuracy: 0.5139 - val_loss: 1.0045 - val_accuracy: 0.4953\n",
      "Epoch 125/200\n",
      "2553/2553 [==============================] - 0s 51us/sample - loss: 0.9970 - accuracy: 0.5139 - val_loss: 1.0044 - val_accuracy: 0.4953\n",
      "Epoch 126/200\n",
      "2553/2553 [==============================] - 0s 51us/sample - loss: 0.9970 - accuracy: 0.5139 - val_loss: 1.0043 - val_accuracy: 0.4953\n",
      "Epoch 127/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 0.9969 - accuracy: 0.5135 - val_loss: 1.0042 - val_accuracy: 0.4953\n",
      "Epoch 128/200\n",
      "2553/2553 [==============================] - 0s 51us/sample - loss: 0.9969 - accuracy: 0.5135 - val_loss: 1.0041 - val_accuracy: 0.4953\n",
      "Epoch 129/200\n",
      "2553/2553 [==============================] - 0s 51us/sample - loss: 0.9968 - accuracy: 0.5139 - val_loss: 1.0040 - val_accuracy: 0.4953\n",
      "Epoch 130/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 0.9968 - accuracy: 0.5147 - val_loss: 1.0039 - val_accuracy: 0.4953\n",
      "Epoch 131/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 0.9967 - accuracy: 0.5143 - val_loss: 1.0038 - val_accuracy: 0.4953\n",
      "Epoch 132/200\n",
      "2553/2553 [==============================] - 0s 50us/sample - loss: 0.9967 - accuracy: 0.5143 - val_loss: 1.0037 - val_accuracy: 0.4953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 133/200\n",
      "2553/2553 [==============================] - 0s 50us/sample - loss: 0.9966 - accuracy: 0.5139 - val_loss: 1.0036 - val_accuracy: 0.4953\n",
      "Epoch 134/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 0.9966 - accuracy: 0.5139 - val_loss: 1.0035 - val_accuracy: 0.4953\n",
      "Epoch 135/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 0.9965 - accuracy: 0.5135 - val_loss: 1.0034 - val_accuracy: 0.4953\n",
      "Epoch 136/200\n",
      "2553/2553 [==============================] - 0s 50us/sample - loss: 0.9965 - accuracy: 0.5135 - val_loss: 1.0033 - val_accuracy: 0.4953\n",
      "Epoch 137/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 0.9965 - accuracy: 0.5131 - val_loss: 1.0033 - val_accuracy: 0.5047\n",
      "Epoch 138/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 0.9964 - accuracy: 0.5131 - val_loss: 1.0032 - val_accuracy: 0.5047\n",
      "Epoch 139/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 0.9964 - accuracy: 0.5131 - val_loss: 1.0031 - val_accuracy: 0.5047\n",
      "Epoch 140/200\n",
      "2553/2553 [==============================] - 0s 49us/sample - loss: 0.9963 - accuracy: 0.5131 - val_loss: 1.0030 - val_accuracy: 0.5047\n",
      "Epoch 141/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 0.9963 - accuracy: 0.5131 - val_loss: 1.0029 - val_accuracy: 0.5047\n",
      "Epoch 142/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 0.9962 - accuracy: 0.5131 - val_loss: 1.0028 - val_accuracy: 0.5047\n",
      "Epoch 143/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 0.9962 - accuracy: 0.5127 - val_loss: 1.0027 - val_accuracy: 0.4953\n",
      "Epoch 144/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 0.9962 - accuracy: 0.5123 - val_loss: 1.0026 - val_accuracy: 0.4953\n",
      "Epoch 145/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 0.9961 - accuracy: 0.5123 - val_loss: 1.0025 - val_accuracy: 0.4953\n",
      "Epoch 146/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 0.9961 - accuracy: 0.5123 - val_loss: 1.0025 - val_accuracy: 0.4953\n",
      "Epoch 147/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 0.9960 - accuracy: 0.5123 - val_loss: 1.0024 - val_accuracy: 0.4953\n",
      "Epoch 148/200\n",
      "2553/2553 [==============================] - 0s 49us/sample - loss: 0.9960 - accuracy: 0.5123 - val_loss: 1.0023 - val_accuracy: 0.4953\n",
      "Epoch 149/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 0.9960 - accuracy: 0.5123 - val_loss: 1.0022 - val_accuracy: 0.4953\n",
      "Epoch 150/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 0.9959 - accuracy: 0.5123 - val_loss: 1.0021 - val_accuracy: 0.4953\n",
      "Epoch 151/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 0.9959 - accuracy: 0.5127 - val_loss: 1.0020 - val_accuracy: 0.4953\n",
      "Epoch 152/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 0.9958 - accuracy: 0.5131 - val_loss: 1.0020 - val_accuracy: 0.4953\n",
      "Epoch 153/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 0.9958 - accuracy: 0.5123 - val_loss: 1.0019 - val_accuracy: 0.4953\n",
      "Epoch 154/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 0.9958 - accuracy: 0.5123 - val_loss: 1.0018 - val_accuracy: 0.4953\n",
      "Epoch 155/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 0.9957 - accuracy: 0.5123 - val_loss: 1.0017 - val_accuracy: 0.4953\n",
      "Epoch 156/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 0.9957 - accuracy: 0.5123 - val_loss: 1.0017 - val_accuracy: 0.4953\n",
      "Epoch 157/200\n",
      "2553/2553 [==============================] - 0s 51us/sample - loss: 0.9956 - accuracy: 0.5127 - val_loss: 1.0016 - val_accuracy: 0.4953\n",
      "Epoch 158/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 0.9956 - accuracy: 0.5127 - val_loss: 1.0015 - val_accuracy: 0.4860\n",
      "Epoch 159/200\n",
      "2553/2553 [==============================] - 0s 50us/sample - loss: 0.9956 - accuracy: 0.5131 - val_loss: 1.0014 - val_accuracy: 0.4860\n",
      "Epoch 160/200\n",
      "2553/2553 [==============================] - 0s 51us/sample - loss: 0.9955 - accuracy: 0.5127 - val_loss: 1.0013 - val_accuracy: 0.4860\n",
      "Epoch 161/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 0.9955 - accuracy: 0.5131 - val_loss: 1.0013 - val_accuracy: 0.4860\n",
      "Epoch 162/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 0.9954 - accuracy: 0.5131 - val_loss: 1.0012 - val_accuracy: 0.4860\n",
      "Epoch 163/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 0.9954 - accuracy: 0.5131 - val_loss: 1.0011 - val_accuracy: 0.4860\n",
      "Epoch 164/200\n",
      "2553/2553 [==============================] - 0s 51us/sample - loss: 0.9954 - accuracy: 0.5131 - val_loss: 1.0010 - val_accuracy: 0.4860\n",
      "Epoch 165/200\n",
      "2553/2553 [==============================] - 0s 49us/sample - loss: 0.9953 - accuracy: 0.5131 - val_loss: 1.0009 - val_accuracy: 0.4860\n",
      "Epoch 166/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 0.9953 - accuracy: 0.5131 - val_loss: 1.0009 - val_accuracy: 0.4860\n",
      "Epoch 167/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 0.9952 - accuracy: 0.5131 - val_loss: 1.0008 - val_accuracy: 0.4860\n",
      "Epoch 168/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 0.9952 - accuracy: 0.5131 - val_loss: 1.0007 - val_accuracy: 0.4860\n",
      "Epoch 169/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 0.9952 - accuracy: 0.5135 - val_loss: 1.0006 - val_accuracy: 0.4860\n",
      "Epoch 170/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 0.9951 - accuracy: 0.5135 - val_loss: 1.0006 - val_accuracy: 0.4860\n",
      "Epoch 171/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 0.9951 - accuracy: 0.5135 - val_loss: 1.0005 - val_accuracy: 0.4860\n",
      "Epoch 172/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 0.9951 - accuracy: 0.5135 - val_loss: 1.0004 - val_accuracy: 0.4860\n",
      "Epoch 173/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 0.9950 - accuracy: 0.5135 - val_loss: 1.0004 - val_accuracy: 0.4860\n",
      "Epoch 174/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 0.9950 - accuracy: 0.5135 - val_loss: 1.0003 - val_accuracy: 0.4860\n",
      "Epoch 175/200\n",
      "2553/2553 [==============================] - 0s 50us/sample - loss: 0.9949 - accuracy: 0.5135 - val_loss: 1.0002 - val_accuracy: 0.4860\n",
      "Epoch 176/200\n",
      "2553/2553 [==============================] - 0s 51us/sample - loss: 0.9949 - accuracy: 0.5135 - val_loss: 1.0002 - val_accuracy: 0.4860\n",
      "Epoch 177/200\n",
      "2553/2553 [==============================] - 0s 51us/sample - loss: 0.9949 - accuracy: 0.5135 - val_loss: 1.0001 - val_accuracy: 0.4860\n",
      "Epoch 178/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 0.9948 - accuracy: 0.5135 - val_loss: 1.0000 - val_accuracy: 0.4860\n",
      "Epoch 179/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 0.9948 - accuracy: 0.5135 - val_loss: 1.0000 - val_accuracy: 0.4860\n",
      "Epoch 180/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 0.9948 - accuracy: 0.5135 - val_loss: 0.9999 - val_accuracy: 0.4860\n",
      "Epoch 181/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 0.9947 - accuracy: 0.5135 - val_loss: 0.9998 - val_accuracy: 0.4860\n",
      "Epoch 182/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 0.9947 - accuracy: 0.5135 - val_loss: 0.9997 - val_accuracy: 0.4860\n",
      "Epoch 183/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 0.9947 - accuracy: 0.5131 - val_loss: 0.9997 - val_accuracy: 0.4860\n",
      "Epoch 184/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 0.9946 - accuracy: 0.5131 - val_loss: 0.9996 - val_accuracy: 0.4860\n",
      "Epoch 185/200\n",
      "2553/2553 [==============================] - 0s 51us/sample - loss: 0.9946 - accuracy: 0.5131 - val_loss: 0.9995 - val_accuracy: 0.4860\n",
      "Epoch 186/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 0.9945 - accuracy: 0.5131 - val_loss: 0.9995 - val_accuracy: 0.4860\n",
      "Epoch 187/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 49us/sample - loss: 0.9945 - accuracy: 0.5131 - val_loss: 0.9994 - val_accuracy: 0.4860\n",
      "Epoch 188/200\n",
      "2553/2553 [==============================] - 0s 44us/sample - loss: 0.9945 - accuracy: 0.5131 - val_loss: 0.9993 - val_accuracy: 0.4860\n",
      "Epoch 189/200\n",
      "2553/2553 [==============================] - 0s 41us/sample - loss: 0.9944 - accuracy: 0.5131 - val_loss: 0.9993 - val_accuracy: 0.4860\n",
      "Epoch 190/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 0.9944 - accuracy: 0.5127 - val_loss: 0.9992 - val_accuracy: 0.4860\n",
      "Epoch 191/200\n",
      "2553/2553 [==============================] - 0s 51us/sample - loss: 0.9944 - accuracy: 0.5127 - val_loss: 0.9992 - val_accuracy: 0.4860\n",
      "Epoch 192/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 0.9943 - accuracy: 0.5127 - val_loss: 0.9991 - val_accuracy: 0.4860\n",
      "Epoch 193/200\n",
      "2553/2553 [==============================] - 0s 82us/sample - loss: 0.9943 - accuracy: 0.5131 - val_loss: 0.9990 - val_accuracy: 0.4860\n",
      "Epoch 194/200\n",
      "2553/2553 [==============================] - 0s 71us/sample - loss: 0.9943 - accuracy: 0.5135 - val_loss: 0.9990 - val_accuracy: 0.4860\n",
      "Epoch 195/200\n",
      "2553/2553 [==============================] - 0s 80us/sample - loss: 0.9942 - accuracy: 0.5135 - val_loss: 0.9989 - val_accuracy: 0.4860\n",
      "Epoch 196/200\n",
      "2553/2553 [==============================] - 0s 99us/sample - loss: 0.9942 - accuracy: 0.5135 - val_loss: 0.9988 - val_accuracy: 0.4860\n",
      "Epoch 197/200\n",
      "2553/2553 [==============================] - 0s 87us/sample - loss: 0.9942 - accuracy: 0.5135 - val_loss: 0.9988 - val_accuracy: 0.4860\n",
      "Epoch 198/200\n",
      "2553/2553 [==============================] - 0s 68us/sample - loss: 0.9941 - accuracy: 0.5135 - val_loss: 0.9987 - val_accuracy: 0.4860\n",
      "Epoch 199/200\n",
      "2553/2553 [==============================] - 0s 81us/sample - loss: 0.9941 - accuracy: 0.5135 - val_loss: 0.9986 - val_accuracy: 0.4860\n",
      "Epoch 200/200\n",
      "2553/2553 [==============================] - 0s 68us/sample - loss: 0.9941 - accuracy: 0.5135 - val_loss: 0.9986 - val_accuracy: 0.4860\n",
      "0.48598132 {'loss': 0.994055931679277, 'accuracy': 0.5135135, 'val_loss': 0.9985859082123943, 'val_accuracy': 0.48598132}\n",
      "Model: \"model_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_19 (InputLayer)        [(None, 29)]              0         \n",
      "_________________________________________________________________\n",
      "flatten_18 (Flatten)         (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 41)                1230      \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 75)                3150      \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 3)                 228       \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 4,608\n",
      "Trainable params: 4,608\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2553 samples, validate on 107 samples\n",
      "Epoch 1/200\n",
      "2553/2553 [==============================] - 1s 518us/sample - loss: 1.0769 - accuracy: 0.4132 - val_loss: 1.0598 - val_accuracy: 0.3925\n",
      "Epoch 2/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0915 - accuracy: 0.4093 - val_loss: 1.0575 - val_accuracy: 0.3925\n",
      "Epoch 3/200\n",
      "2553/2553 [==============================] - 0s 133us/sample - loss: 1.0829 - accuracy: 0.4031 - val_loss: 1.0555 - val_accuracy: 0.3925\n",
      "Epoch 4/200\n",
      "2553/2553 [==============================] - 0s 120us/sample - loss: 1.0839 - accuracy: 0.4113 - val_loss: 1.0533 - val_accuracy: 0.3925\n",
      "Epoch 5/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0701 - accuracy: 0.4313 - val_loss: 1.0514 - val_accuracy: 0.3925\n",
      "Epoch 6/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0767 - accuracy: 0.4144 - val_loss: 1.0495 - val_accuracy: 0.3925\n",
      "Epoch 7/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.0712 - accuracy: 0.4242 - val_loss: 1.0477 - val_accuracy: 0.4019\n",
      "Epoch 8/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0739 - accuracy: 0.4168 - val_loss: 1.0459 - val_accuracy: 0.4019\n",
      "Epoch 9/200\n",
      "2553/2553 [==============================] - 0s 88us/sample - loss: 1.0681 - accuracy: 0.4207 - val_loss: 1.0442 - val_accuracy: 0.4019\n",
      "Epoch 10/200\n",
      "2553/2553 [==============================] - 0s 92us/sample - loss: 1.0596 - accuracy: 0.4273 - val_loss: 1.0427 - val_accuracy: 0.4019\n",
      "Epoch 11/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0693 - accuracy: 0.4156 - val_loss: 1.0412 - val_accuracy: 0.4206\n",
      "Epoch 12/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.0762 - accuracy: 0.3960 - val_loss: 1.0398 - val_accuracy: 0.4206\n",
      "Epoch 13/200\n",
      "2553/2553 [==============================] - 0s 99us/sample - loss: 1.0703 - accuracy: 0.4230 - val_loss: 1.0386 - val_accuracy: 0.4206\n",
      "Epoch 14/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.0559 - accuracy: 0.4297 - val_loss: 1.0373 - val_accuracy: 0.4206\n",
      "Epoch 15/200\n",
      "2553/2553 [==============================] - 1s 220us/sample - loss: 1.0633 - accuracy: 0.4203 - val_loss: 1.0361 - val_accuracy: 0.4206\n",
      "Epoch 16/200\n",
      "2553/2553 [==============================] - 1s 261us/sample - loss: 1.0612 - accuracy: 0.4175 - val_loss: 1.0351 - val_accuracy: 0.4206\n",
      "Epoch 17/200\n",
      "2553/2553 [==============================] - 1s 251us/sample - loss: 1.0551 - accuracy: 0.4313 - val_loss: 1.0339 - val_accuracy: 0.4206\n",
      "Epoch 18/200\n",
      "2553/2553 [==============================] - 1s 248us/sample - loss: 1.0652 - accuracy: 0.4152 - val_loss: 1.0329 - val_accuracy: 0.4206\n",
      "Epoch 19/200\n",
      "2553/2553 [==============================] - 1s 221us/sample - loss: 1.0545 - accuracy: 0.4305 - val_loss: 1.0318 - val_accuracy: 0.4206\n",
      "Epoch 20/200\n",
      "2553/2553 [==============================] - ETA: 0s - loss: 1.0526 - accuracy: 0.43 - 0s 194us/sample - loss: 1.0530 - accuracy: 0.4348 - val_loss: 1.0308 - val_accuracy: 0.4299\n",
      "Epoch 21/200\n",
      "2553/2553 [==============================] - 0s 164us/sample - loss: 1.0555 - accuracy: 0.4250 - val_loss: 1.0299 - val_accuracy: 0.4299\n",
      "Epoch 22/200\n",
      "2553/2553 [==============================] - 0s 157us/sample - loss: 1.0444 - accuracy: 0.4285 - val_loss: 1.0291 - val_accuracy: 0.4299\n",
      "Epoch 23/200\n",
      "2553/2553 [==============================] - 0s 160us/sample - loss: 1.0522 - accuracy: 0.4309 - val_loss: 1.0282 - val_accuracy: 0.4299\n",
      "Epoch 24/200\n",
      "2553/2553 [==============================] - 0s 166us/sample - loss: 1.0447 - accuracy: 0.4395 - val_loss: 1.0273 - val_accuracy: 0.4299\n",
      "Epoch 25/200\n",
      "2553/2553 [==============================] - 0s 180us/sample - loss: 1.0445 - accuracy: 0.4320 - val_loss: 1.0264 - val_accuracy: 0.4299\n",
      "Epoch 26/200\n",
      "2553/2553 [==============================] - 0s 168us/sample - loss: 1.0564 - accuracy: 0.4234 - val_loss: 1.0257 - val_accuracy: 0.4299\n",
      "Epoch 27/200\n",
      "2553/2553 [==============================] - 0s 164us/sample - loss: 1.0423 - accuracy: 0.4242 - val_loss: 1.0248 - val_accuracy: 0.4299\n",
      "Epoch 28/200\n",
      "2553/2553 [==============================] - 1s 223us/sample - loss: 1.0451 - accuracy: 0.4332 - val_loss: 1.0241 - val_accuracy: 0.4299\n",
      "Epoch 29/200\n",
      "2553/2553 [==============================] - 0s 184us/sample - loss: 1.0418 - accuracy: 0.4246 - val_loss: 1.0234 - val_accuracy: 0.4299\n",
      "Epoch 30/200\n",
      "2553/2553 [==============================] - 0s 174us/sample - loss: 1.0370 - accuracy: 0.4450 - val_loss: 1.0228 - val_accuracy: 0.4299\n",
      "Epoch 31/200\n",
      "2553/2553 [==============================] - 0s 190us/sample - loss: 1.0452 - accuracy: 0.4391 - val_loss: 1.0221 - val_accuracy: 0.4299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/200\n",
      "2553/2553 [==============================] - 0s 149us/sample - loss: 1.0377 - accuracy: 0.4383 - val_loss: 1.0214 - val_accuracy: 0.4393\n",
      "Epoch 33/200\n",
      "2553/2553 [==============================] - 0s 139us/sample - loss: 1.0489 - accuracy: 0.4195 - val_loss: 1.0208 - val_accuracy: 0.4393\n",
      "Epoch 34/200\n",
      "2553/2553 [==============================] - 0s 145us/sample - loss: 1.0378 - accuracy: 0.4348 - val_loss: 1.0202 - val_accuracy: 0.4393\n",
      "Epoch 35/200\n",
      "2553/2553 [==============================] - 0s 156us/sample - loss: 1.0377 - accuracy: 0.4360 - val_loss: 1.0197 - val_accuracy: 0.4393\n",
      "Epoch 36/200\n",
      "2553/2553 [==============================] - 0s 142us/sample - loss: 1.0410 - accuracy: 0.4316 - val_loss: 1.0191 - val_accuracy: 0.4393\n",
      "Epoch 37/200\n",
      "2553/2553 [==============================] - 0s 115us/sample - loss: 1.0318 - accuracy: 0.4273 - val_loss: 1.0186 - val_accuracy: 0.4299\n",
      "Epoch 38/200\n",
      "2553/2553 [==============================] - 0s 122us/sample - loss: 1.0303 - accuracy: 0.4552 - val_loss: 1.0181 - val_accuracy: 0.4299\n",
      "Epoch 39/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.0359 - accuracy: 0.4289 - val_loss: 1.0176 - val_accuracy: 0.4393\n",
      "Epoch 40/200\n",
      "2553/2553 [==============================] - 0s 115us/sample - loss: 1.0373 - accuracy: 0.4316 - val_loss: 1.0172 - val_accuracy: 0.4393\n",
      "Epoch 41/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 1.0351 - accuracy: 0.4352 - val_loss: 1.0169 - val_accuracy: 0.4393\n",
      "Epoch 42/200\n",
      "2553/2553 [==============================] - 0s 119us/sample - loss: 1.0361 - accuracy: 0.4242 - val_loss: 1.0166 - val_accuracy: 0.4393\n",
      "Epoch 43/200\n",
      "2553/2553 [==============================] - 0s 140us/sample - loss: 1.0385 - accuracy: 0.4293 - val_loss: 1.0163 - val_accuracy: 0.4486\n",
      "Epoch 44/200\n",
      "2553/2553 [==============================] - 0s 99us/sample - loss: 1.0326 - accuracy: 0.4336 - val_loss: 1.0160 - val_accuracy: 0.4486\n",
      "Epoch 45/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0329 - accuracy: 0.4438 - val_loss: 1.0156 - val_accuracy: 0.4393\n",
      "Epoch 46/200\n",
      "2553/2553 [==============================] - 0s 125us/sample - loss: 1.0320 - accuracy: 0.4375 - val_loss: 1.0152 - val_accuracy: 0.4393\n",
      "Epoch 47/200\n",
      "2553/2553 [==============================] - 0s 99us/sample - loss: 1.0321 - accuracy: 0.4332 - val_loss: 1.0147 - val_accuracy: 0.4393\n",
      "Epoch 48/200\n",
      "2553/2553 [==============================] - 0s 97us/sample - loss: 1.0282 - accuracy: 0.4426 - val_loss: 1.0143 - val_accuracy: 0.4393\n",
      "Epoch 49/200\n",
      "2553/2553 [==============================] - 0s 99us/sample - loss: 1.0278 - accuracy: 0.4477 - val_loss: 1.0139 - val_accuracy: 0.4393\n",
      "Epoch 50/200\n",
      "2553/2553 [==============================] - 0s 98us/sample - loss: 1.0295 - accuracy: 0.4352 - val_loss: 1.0135 - val_accuracy: 0.4393\n",
      "Epoch 51/200\n",
      "2553/2553 [==============================] - 0s 97us/sample - loss: 1.0289 - accuracy: 0.4332 - val_loss: 1.0130 - val_accuracy: 0.4393\n",
      "Epoch 52/200\n",
      "2553/2553 [==============================] - 0s 97us/sample - loss: 1.0191 - accuracy: 0.4481 - val_loss: 1.0126 - val_accuracy: 0.4393\n",
      "Epoch 53/200\n",
      "2553/2553 [==============================] - 0s 99us/sample - loss: 1.0277 - accuracy: 0.4387 - val_loss: 1.0123 - val_accuracy: 0.4393\n",
      "Epoch 54/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0344 - accuracy: 0.4340 - val_loss: 1.0120 - val_accuracy: 0.4299\n",
      "Epoch 55/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0243 - accuracy: 0.4465 - val_loss: 1.0116 - val_accuracy: 0.4299\n",
      "Epoch 56/200\n",
      "2553/2553 [==============================] - 0s 117us/sample - loss: 1.0218 - accuracy: 0.4454 - val_loss: 1.0113 - val_accuracy: 0.4393\n",
      "Epoch 57/200\n",
      "2553/2553 [==============================] - 0s 129us/sample - loss: 1.0350 - accuracy: 0.4301 - val_loss: 1.0110 - val_accuracy: 0.4393\n",
      "Epoch 58/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.0171 - accuracy: 0.4501 - val_loss: 1.0106 - val_accuracy: 0.4486\n",
      "Epoch 59/200\n",
      "2553/2553 [==============================] - 0s 122us/sample - loss: 1.0234 - accuracy: 0.4489 - val_loss: 1.0103 - val_accuracy: 0.4486\n",
      "Epoch 60/200\n",
      "2553/2553 [==============================] - 0s 133us/sample - loss: 1.0276 - accuracy: 0.4367 - val_loss: 1.0100 - val_accuracy: 0.4486\n",
      "Epoch 61/200\n",
      "2553/2553 [==============================] - 0s 98us/sample - loss: 1.0272 - accuracy: 0.4410 - val_loss: 1.0096 - val_accuracy: 0.4486\n",
      "Epoch 62/200\n",
      "2553/2553 [==============================] - 0s 99us/sample - loss: 1.0200 - accuracy: 0.4505 - val_loss: 1.0092 - val_accuracy: 0.4486\n",
      "Epoch 63/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0228 - accuracy: 0.4430 - val_loss: 1.0087 - val_accuracy: 0.4486\n",
      "Epoch 64/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.0378 - accuracy: 0.4258 - val_loss: 1.0084 - val_accuracy: 0.4486\n",
      "Epoch 65/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0222 - accuracy: 0.4422 - val_loss: 1.0079 - val_accuracy: 0.4486\n",
      "Epoch 66/200\n",
      "2553/2553 [==============================] - 0s 98us/sample - loss: 1.0218 - accuracy: 0.4512 - val_loss: 1.0077 - val_accuracy: 0.4393\n",
      "Epoch 67/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0225 - accuracy: 0.4481 - val_loss: 1.0074 - val_accuracy: 0.4393\n",
      "Epoch 68/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0161 - accuracy: 0.4512 - val_loss: 1.0070 - val_accuracy: 0.4299\n",
      "Epoch 69/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0205 - accuracy: 0.4450 - val_loss: 1.0067 - val_accuracy: 0.4393\n",
      "Epoch 70/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.0243 - accuracy: 0.4367 - val_loss: 1.0063 - val_accuracy: 0.4393\n",
      "Epoch 71/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0275 - accuracy: 0.4434 - val_loss: 1.0061 - val_accuracy: 0.4393\n",
      "Epoch 72/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0227 - accuracy: 0.4469 - val_loss: 1.0057 - val_accuracy: 0.4393\n",
      "Epoch 73/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0218 - accuracy: 0.4461 - val_loss: 1.0054 - val_accuracy: 0.4393\n",
      "Epoch 74/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0265 - accuracy: 0.4360 - val_loss: 1.0052 - val_accuracy: 0.4393\n",
      "Epoch 75/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.0231 - accuracy: 0.4407 - val_loss: 1.0048 - val_accuracy: 0.4393\n",
      "Epoch 76/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0257 - accuracy: 0.4297 - val_loss: 1.0046 - val_accuracy: 0.4393\n",
      "Epoch 77/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0235 - accuracy: 0.4454 - val_loss: 1.0044 - val_accuracy: 0.4393\n",
      "Epoch 78/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0179 - accuracy: 0.4544 - val_loss: 1.0041 - val_accuracy: 0.4393\n",
      "Epoch 79/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.0180 - accuracy: 0.4422 - val_loss: 1.0038 - val_accuracy: 0.4393\n",
      "Epoch 80/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0173 - accuracy: 0.4540 - val_loss: 1.0035 - val_accuracy: 0.4393\n",
      "Epoch 81/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0296 - accuracy: 0.4399 - val_loss: 1.0033 - val_accuracy: 0.4393\n",
      "Epoch 82/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0143 - accuracy: 0.4461 - val_loss: 1.0031 - val_accuracy: 0.4393\n",
      "Epoch 83/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0158 - accuracy: 0.4426 - val_loss: 1.0029 - val_accuracy: 0.4393\n",
      "Epoch 84/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0249 - accuracy: 0.4320 - val_loss: 1.0027 - val_accuracy: 0.4393\n",
      "Epoch 85/200\n",
      "2553/2553 [==============================] - 0s 98us/sample - loss: 1.0172 - accuracy: 0.4410 - val_loss: 1.0025 - val_accuracy: 0.4393\n",
      "Epoch 86/200\n",
      "2553/2553 [==============================] - 0s 96us/sample - loss: 1.0143 - accuracy: 0.4493 - val_loss: 1.0022 - val_accuracy: 0.4486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.0272 - accuracy: 0.4328 - val_loss: 1.0021 - val_accuracy: 0.4486\n",
      "Epoch 88/200\n",
      "2553/2553 [==============================] - 0s 97us/sample - loss: 1.0161 - accuracy: 0.4469 - val_loss: 1.0019 - val_accuracy: 0.4486\n",
      "Epoch 89/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0217 - accuracy: 0.4332 - val_loss: 1.0017 - val_accuracy: 0.4486\n",
      "Epoch 90/200\n",
      "2553/2553 [==============================] - ETA: 0s - loss: 1.0202 - accuracy: 0.45 - 0s 94us/sample - loss: 1.0181 - accuracy: 0.4508 - val_loss: 1.0014 - val_accuracy: 0.4486\n",
      "Epoch 91/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0169 - accuracy: 0.4505 - val_loss: 1.0012 - val_accuracy: 0.4486\n",
      "Epoch 92/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.0125 - accuracy: 0.4473 - val_loss: 1.0010 - val_accuracy: 0.4486\n",
      "Epoch 93/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.0183 - accuracy: 0.4469 - val_loss: 1.0008 - val_accuracy: 0.4486\n",
      "Epoch 94/200\n",
      "2553/2553 [==============================] - 0s 98us/sample - loss: 1.0086 - accuracy: 0.4579 - val_loss: 1.0007 - val_accuracy: 0.4486\n",
      "Epoch 95/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0169 - accuracy: 0.4461 - val_loss: 1.0005 - val_accuracy: 0.4486\n",
      "Epoch 96/200\n",
      "2553/2553 [==============================] - 0s 99us/sample - loss: 1.0177 - accuracy: 0.4450 - val_loss: 1.0002 - val_accuracy: 0.4486\n",
      "Epoch 97/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0170 - accuracy: 0.4497 - val_loss: 1.0001 - val_accuracy: 0.4486\n",
      "Epoch 98/200\n",
      "2553/2553 [==============================] - 0s 99us/sample - loss: 1.0189 - accuracy: 0.4454 - val_loss: 0.9999 - val_accuracy: 0.4486\n",
      "Epoch 99/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0095 - accuracy: 0.4477 - val_loss: 0.9997 - val_accuracy: 0.4486\n",
      "Epoch 100/200\n",
      "2553/2553 [==============================] - 0s 98us/sample - loss: 1.0211 - accuracy: 0.4426 - val_loss: 0.9995 - val_accuracy: 0.4579\n",
      "Epoch 101/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0284 - accuracy: 0.4383 - val_loss: 0.9995 - val_accuracy: 0.4579\n",
      "Epoch 102/200\n",
      "2553/2553 [==============================] - 0s 98us/sample - loss: 1.0160 - accuracy: 0.4414 - val_loss: 0.9993 - val_accuracy: 0.4579\n",
      "Epoch 103/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.0169 - accuracy: 0.4418 - val_loss: 0.9991 - val_accuracy: 0.4579\n",
      "Epoch 104/200\n",
      "2553/2553 [==============================] - 0s 99us/sample - loss: 1.0213 - accuracy: 0.4395 - val_loss: 0.9990 - val_accuracy: 0.4579\n",
      "Epoch 105/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0156 - accuracy: 0.4473 - val_loss: 0.9989 - val_accuracy: 0.4579\n",
      "Epoch 106/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.0173 - accuracy: 0.4505 - val_loss: 0.9988 - val_accuracy: 0.4579\n",
      "Epoch 107/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0103 - accuracy: 0.4434 - val_loss: 0.9986 - val_accuracy: 0.4579\n",
      "Epoch 108/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0131 - accuracy: 0.4320 - val_loss: 0.9984 - val_accuracy: 0.4579\n",
      "Epoch 109/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0113 - accuracy: 0.4477 - val_loss: 0.9982 - val_accuracy: 0.4579\n",
      "Epoch 110/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0111 - accuracy: 0.4497 - val_loss: 0.9980 - val_accuracy: 0.4579\n",
      "Epoch 111/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0121 - accuracy: 0.4536 - val_loss: 0.9978 - val_accuracy: 0.4579\n",
      "Epoch 112/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0139 - accuracy: 0.4450 - val_loss: 0.9976 - val_accuracy: 0.4579\n",
      "Epoch 113/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.0044 - accuracy: 0.4571 - val_loss: 0.9974 - val_accuracy: 0.4579\n",
      "Epoch 114/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0161 - accuracy: 0.4469 - val_loss: 0.9973 - val_accuracy: 0.4579\n",
      "Epoch 115/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.0124 - accuracy: 0.4450 - val_loss: 0.9972 - val_accuracy: 0.4579\n",
      "Epoch 116/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.0105 - accuracy: 0.4520 - val_loss: 0.9971 - val_accuracy: 0.4579\n",
      "Epoch 117/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0160 - accuracy: 0.4410 - val_loss: 0.9970 - val_accuracy: 0.4579\n",
      "Epoch 118/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0142 - accuracy: 0.4465 - val_loss: 0.9969 - val_accuracy: 0.4579\n",
      "Epoch 119/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.0196 - accuracy: 0.4367 - val_loss: 0.9968 - val_accuracy: 0.4579\n",
      "Epoch 120/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0074 - accuracy: 0.4512 - val_loss: 0.9966 - val_accuracy: 0.4579\n",
      "Epoch 121/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.0057 - accuracy: 0.4579 - val_loss: 0.9964 - val_accuracy: 0.4579\n",
      "Epoch 122/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0021 - accuracy: 0.4528 - val_loss: 0.9963 - val_accuracy: 0.4579\n",
      "Epoch 123/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.0152 - accuracy: 0.4450 - val_loss: 0.9962 - val_accuracy: 0.4579\n",
      "Epoch 124/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0156 - accuracy: 0.4426 - val_loss: 0.9961 - val_accuracy: 0.4579\n",
      "Epoch 125/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.0194 - accuracy: 0.4383 - val_loss: 0.9961 - val_accuracy: 0.4579\n",
      "Epoch 126/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0096 - accuracy: 0.4544 - val_loss: 0.9960 - val_accuracy: 0.4579\n",
      "Epoch 127/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0102 - accuracy: 0.4552 - val_loss: 0.9958 - val_accuracy: 0.4579\n",
      "Epoch 128/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0155 - accuracy: 0.4501 - val_loss: 0.9958 - val_accuracy: 0.4579\n",
      "Epoch 129/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0107 - accuracy: 0.4461 - val_loss: 0.9957 - val_accuracy: 0.4579\n",
      "Epoch 130/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0046 - accuracy: 0.4469 - val_loss: 0.9956 - val_accuracy: 0.4579\n",
      "Epoch 131/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0133 - accuracy: 0.4508 - val_loss: 0.9954 - val_accuracy: 0.4579\n",
      "Epoch 132/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0135 - accuracy: 0.4391 - val_loss: 0.9954 - val_accuracy: 0.4579\n",
      "Epoch 133/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0134 - accuracy: 0.4426 - val_loss: 0.9954 - val_accuracy: 0.4579\n",
      "Epoch 134/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0149 - accuracy: 0.4438 - val_loss: 0.9953 - val_accuracy: 0.4579\n",
      "Epoch 135/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.0180 - accuracy: 0.4430 - val_loss: 0.9952 - val_accuracy: 0.4579\n",
      "Epoch 136/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0129 - accuracy: 0.4442 - val_loss: 0.9951 - val_accuracy: 0.4579\n",
      "Epoch 137/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.0170 - accuracy: 0.4465 - val_loss: 0.9951 - val_accuracy: 0.4579\n",
      "Epoch 138/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.0112 - accuracy: 0.4454 - val_loss: 0.9951 - val_accuracy: 0.4579\n",
      "Epoch 139/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0050 - accuracy: 0.4512 - val_loss: 0.9948 - val_accuracy: 0.4579\n",
      "Epoch 140/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0125 - accuracy: 0.4473 - val_loss: 0.9948 - val_accuracy: 0.4579\n",
      "Epoch 141/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0191 - accuracy: 0.4379 - val_loss: 0.9949 - val_accuracy: 0.4579\n",
      "Epoch 142/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0105 - accuracy: 0.4446 - val_loss: 0.9948 - val_accuracy: 0.4579\n",
      "Epoch 143/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.0132 - accuracy: 0.4473 - val_loss: 0.9948 - val_accuracy: 0.4579\n",
      "Epoch 144/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0155 - accuracy: 0.4395 - val_loss: 0.9948 - val_accuracy: 0.4579\n",
      "Epoch 145/200\n",
      "2553/2553 [==============================] - 0s 99us/sample - loss: 1.0086 - accuracy: 0.4438 - val_loss: 0.9947 - val_accuracy: 0.4579\n",
      "Epoch 146/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.0147 - accuracy: 0.4375 - val_loss: 0.9947 - val_accuracy: 0.4579\n",
      "Epoch 147/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.0059 - accuracy: 0.4524 - val_loss: 0.9946 - val_accuracy: 0.4579\n",
      "Epoch 148/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0169 - accuracy: 0.4410 - val_loss: 0.9945 - val_accuracy: 0.4579\n",
      "Epoch 149/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.0006 - accuracy: 0.4646 - val_loss: 0.9944 - val_accuracy: 0.4579\n",
      "Epoch 150/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.0118 - accuracy: 0.4461 - val_loss: 0.9943 - val_accuracy: 0.4579\n",
      "Epoch 151/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.0127 - accuracy: 0.4528 - val_loss: 0.9943 - val_accuracy: 0.4579\n",
      "Epoch 152/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.0127 - accuracy: 0.4501 - val_loss: 0.9942 - val_accuracy: 0.4579\n",
      "Epoch 153/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.0191 - accuracy: 0.4379 - val_loss: 0.9942 - val_accuracy: 0.4579\n",
      "Epoch 154/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.0152 - accuracy: 0.4403 - val_loss: 0.9942 - val_accuracy: 0.4579\n",
      "Epoch 155/200\n",
      "2553/2553 [==============================] - 0s 98us/sample - loss: 1.0171 - accuracy: 0.4403 - val_loss: 0.9942 - val_accuracy: 0.4579\n",
      "Epoch 156/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0103 - accuracy: 0.4454 - val_loss: 0.9941 - val_accuracy: 0.4579\n",
      "Epoch 157/200\n",
      "2553/2553 [==============================] - 0s 99us/sample - loss: 1.0091 - accuracy: 0.4508 - val_loss: 0.9941 - val_accuracy: 0.4579\n",
      "Epoch 158/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0093 - accuracy: 0.4493 - val_loss: 0.9940 - val_accuracy: 0.4579\n",
      "Epoch 159/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.0037 - accuracy: 0.4606 - val_loss: 0.9939 - val_accuracy: 0.4579\n",
      "Epoch 160/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0214 - accuracy: 0.4301 - val_loss: 0.9939 - val_accuracy: 0.4579\n",
      "Epoch 161/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.0113 - accuracy: 0.4501 - val_loss: 0.9937 - val_accuracy: 0.4486\n",
      "Epoch 162/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0213 - accuracy: 0.4371 - val_loss: 0.9938 - val_accuracy: 0.4579\n",
      "Epoch 163/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.0134 - accuracy: 0.4430 - val_loss: 0.9937 - val_accuracy: 0.4579\n",
      "Epoch 164/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.0034 - accuracy: 0.4516 - val_loss: 0.9936 - val_accuracy: 0.4486\n",
      "Epoch 165/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.0069 - accuracy: 0.4563 - val_loss: 0.9935 - val_accuracy: 0.4486\n",
      "Epoch 166/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0088 - accuracy: 0.4465 - val_loss: 0.9934 - val_accuracy: 0.4486\n",
      "Epoch 167/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0110 - accuracy: 0.4493 - val_loss: 0.9933 - val_accuracy: 0.4486\n",
      "Epoch 168/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0035 - accuracy: 0.4512 - val_loss: 0.9932 - val_accuracy: 0.4486\n",
      "Epoch 169/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0114 - accuracy: 0.4477 - val_loss: 0.9931 - val_accuracy: 0.4486\n",
      "Epoch 170/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0102 - accuracy: 0.4450 - val_loss: 0.9930 - val_accuracy: 0.4486\n",
      "Epoch 171/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0109 - accuracy: 0.4497 - val_loss: 0.9930 - val_accuracy: 0.4486\n",
      "Epoch 172/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.0044 - accuracy: 0.4555 - val_loss: 0.9929 - val_accuracy: 0.4486\n",
      "Epoch 173/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 0.9985 - accuracy: 0.4602 - val_loss: 0.9926 - val_accuracy: 0.4486\n",
      "Epoch 174/200\n",
      "2553/2553 [==============================] - 0s 115us/sample - loss: 1.0140 - accuracy: 0.4485 - val_loss: 0.9926 - val_accuracy: 0.4486\n",
      "Epoch 175/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.0055 - accuracy: 0.4508 - val_loss: 0.9925 - val_accuracy: 0.4486\n",
      "Epoch 176/200\n",
      "2553/2553 [==============================] - 0s 117us/sample - loss: 1.0103 - accuracy: 0.4477 - val_loss: 0.9924 - val_accuracy: 0.4486\n",
      "Epoch 177/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0115 - accuracy: 0.4403 - val_loss: 0.9923 - val_accuracy: 0.4486\n",
      "Epoch 178/200\n",
      "2553/2553 [==============================] - 0s 129us/sample - loss: 1.0054 - accuracy: 0.4548 - val_loss: 0.9922 - val_accuracy: 0.4486\n",
      "Epoch 179/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.0128 - accuracy: 0.4524 - val_loss: 0.9922 - val_accuracy: 0.4486\n",
      "Epoch 180/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.0062 - accuracy: 0.4450 - val_loss: 0.9921 - val_accuracy: 0.4579\n",
      "Epoch 181/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0048 - accuracy: 0.4497 - val_loss: 0.9920 - val_accuracy: 0.4579\n",
      "Epoch 182/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0109 - accuracy: 0.4501 - val_loss: 0.9920 - val_accuracy: 0.4579\n",
      "Epoch 183/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0128 - accuracy: 0.4485 - val_loss: 0.9920 - val_accuracy: 0.4579\n",
      "Epoch 184/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0090 - accuracy: 0.4497 - val_loss: 0.9919 - val_accuracy: 0.4579\n",
      "Epoch 185/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0140 - accuracy: 0.4512 - val_loss: 0.9919 - val_accuracy: 0.4579\n",
      "Epoch 186/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0029 - accuracy: 0.4591 - val_loss: 0.9918 - val_accuracy: 0.4579\n",
      "Epoch 187/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0133 - accuracy: 0.4403 - val_loss: 0.9918 - val_accuracy: 0.4579\n",
      "Epoch 188/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0017 - accuracy: 0.4552 - val_loss: 0.9916 - val_accuracy: 0.4579\n",
      "Epoch 189/200\n",
      "2553/2553 [==============================] - 0s 119us/sample - loss: 1.0055 - accuracy: 0.4520 - val_loss: 0.9916 - val_accuracy: 0.4579\n",
      "Epoch 190/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0163 - accuracy: 0.4309 - val_loss: 0.9916 - val_accuracy: 0.4579\n",
      "Epoch 191/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0095 - accuracy: 0.4438 - val_loss: 0.9915 - val_accuracy: 0.4579\n",
      "Epoch 192/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0091 - accuracy: 0.4505 - val_loss: 0.9914 - val_accuracy: 0.4579\n",
      "Epoch 193/200\n",
      "2553/2553 [==============================] - 0s 130us/sample - loss: 1.0072 - accuracy: 0.4367 - val_loss: 0.9914 - val_accuracy: 0.4579\n",
      "Epoch 194/200\n",
      "2553/2553 [==============================] - 0s 168us/sample - loss: 1.0067 - accuracy: 0.4481 - val_loss: 0.9913 - val_accuracy: 0.4579\n",
      "Epoch 195/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 158us/sample - loss: 1.0029 - accuracy: 0.4552 - val_loss: 0.9912 - val_accuracy: 0.4579\n",
      "Epoch 196/200\n",
      "2553/2553 [==============================] - 0s 134us/sample - loss: 1.0086 - accuracy: 0.4548 - val_loss: 0.9911 - val_accuracy: 0.4579\n",
      "Epoch 197/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 0.9987 - accuracy: 0.4618 - val_loss: 0.9910 - val_accuracy: 0.4579\n",
      "Epoch 198/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.0153 - accuracy: 0.4434 - val_loss: 0.9910 - val_accuracy: 0.4579\n",
      "Epoch 199/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.0080 - accuracy: 0.4493 - val_loss: 0.9910 - val_accuracy: 0.4579\n",
      "Epoch 200/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.0100 - accuracy: 0.4458 - val_loss: 0.9909 - val_accuracy: 0.4579\n",
      "0.45794392 {'loss': 1.0100229045619136, 'accuracy': 0.4457501, 'val_loss': 0.9908906811865691, 'val_accuracy': 0.45794392}\n",
      "Model: \"model_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_20 (InputLayer)        [(None, 29)]              0         \n",
      "_________________________________________________________________\n",
      "flatten_19 (Flatten)         (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 41)                1230      \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 75)                3150      \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 3)                 228       \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 4,608\n",
      "Trainable params: 4,608\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2553 samples, validate on 107 samples\n",
      "Epoch 1/200\n",
      "2553/2553 [==============================] - 1s 284us/sample - loss: 1.3103 - accuracy: 0.2609 - val_loss: 1.2298 - val_accuracy: 0.2617\n",
      "Epoch 2/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.3221 - accuracy: 0.2468 - val_loss: 1.2262 - val_accuracy: 0.2617\n",
      "Epoch 3/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.2968 - accuracy: 0.2585 - val_loss: 1.2229 - val_accuracy: 0.2617\n",
      "Epoch 4/200\n",
      "2553/2553 [==============================] - 0s 68us/sample - loss: 1.3085 - accuracy: 0.2476 - val_loss: 1.2196 - val_accuracy: 0.2617\n",
      "Epoch 5/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.3010 - accuracy: 0.2499 - val_loss: 1.2164 - val_accuracy: 0.2523\n",
      "Epoch 6/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.3021 - accuracy: 0.2483 - val_loss: 1.2131 - val_accuracy: 0.2523\n",
      "Epoch 7/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.2893 - accuracy: 0.2550 - val_loss: 1.2099 - val_accuracy: 0.2523\n",
      "Epoch 8/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.2901 - accuracy: 0.2526 - val_loss: 1.2068 - val_accuracy: 0.2523\n",
      "Epoch 9/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.2822 - accuracy: 0.2546 - val_loss: 1.2039 - val_accuracy: 0.2523\n",
      "Epoch 10/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.2887 - accuracy: 0.2421 - val_loss: 1.2008 - val_accuracy: 0.2617\n",
      "Epoch 11/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.2766 - accuracy: 0.2429 - val_loss: 1.1980 - val_accuracy: 0.2617\n",
      "Epoch 12/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.2696 - accuracy: 0.2550 - val_loss: 1.1952 - val_accuracy: 0.2617\n",
      "Epoch 13/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.2720 - accuracy: 0.2444 - val_loss: 1.1923 - val_accuracy: 0.2617\n",
      "Epoch 14/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.2572 - accuracy: 0.2550 - val_loss: 1.1897 - val_accuracy: 0.2617\n",
      "Epoch 15/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.2431 - accuracy: 0.2648 - val_loss: 1.1873 - val_accuracy: 0.2710\n",
      "Epoch 16/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.2509 - accuracy: 0.2573 - val_loss: 1.1848 - val_accuracy: 0.2710\n",
      "Epoch 17/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.2529 - accuracy: 0.2472 - val_loss: 1.1823 - val_accuracy: 0.2710\n",
      "Epoch 18/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.2430 - accuracy: 0.2526 - val_loss: 1.1798 - val_accuracy: 0.2804\n",
      "Epoch 19/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.2441 - accuracy: 0.2503 - val_loss: 1.1774 - val_accuracy: 0.2804\n",
      "Epoch 20/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.2335 - accuracy: 0.2593 - val_loss: 1.1751 - val_accuracy: 0.2804\n",
      "Epoch 21/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.2320 - accuracy: 0.2499 - val_loss: 1.1729 - val_accuracy: 0.2804\n",
      "Epoch 22/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.2250 - accuracy: 0.2593 - val_loss: 1.1707 - val_accuracy: 0.2804\n",
      "Epoch 23/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.2320 - accuracy: 0.2464 - val_loss: 1.1685 - val_accuracy: 0.2804\n",
      "Epoch 24/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.2288 - accuracy: 0.2385 - val_loss: 1.1664 - val_accuracy: 0.2897\n",
      "Epoch 25/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.2175 - accuracy: 0.2589 - val_loss: 1.1642 - val_accuracy: 0.3084\n",
      "Epoch 26/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.2208 - accuracy: 0.2452 - val_loss: 1.1623 - val_accuracy: 0.3084\n",
      "Epoch 27/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.2127 - accuracy: 0.2468 - val_loss: 1.1604 - val_accuracy: 0.3084\n",
      "Epoch 28/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.2138 - accuracy: 0.2464 - val_loss: 1.1585 - val_accuracy: 0.3084\n",
      "Epoch 29/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.2176 - accuracy: 0.2358 - val_loss: 1.1566 - val_accuracy: 0.3084\n",
      "Epoch 30/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.2052 - accuracy: 0.2632 - val_loss: 1.1549 - val_accuracy: 0.3084\n",
      "Epoch 31/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.2020 - accuracy: 0.2515 - val_loss: 1.1532 - val_accuracy: 0.3084\n",
      "Epoch 32/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.2022 - accuracy: 0.2491 - val_loss: 1.1516 - val_accuracy: 0.2991\n",
      "Epoch 33/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1984 - accuracy: 0.2644 - val_loss: 1.1502 - val_accuracy: 0.2991\n",
      "Epoch 34/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.1933 - accuracy: 0.2581 - val_loss: 1.1487 - val_accuracy: 0.3084\n",
      "Epoch 35/200\n",
      "2553/2553 [==============================] - 0s 67us/sample - loss: 1.1923 - accuracy: 0.2593 - val_loss: 1.1474 - val_accuracy: 0.3084\n",
      "Epoch 36/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1883 - accuracy: 0.2679 - val_loss: 1.1461 - val_accuracy: 0.3084\n",
      "Epoch 37/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.1858 - accuracy: 0.2570 - val_loss: 1.1450 - val_accuracy: 0.2991\n",
      "Epoch 38/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.1830 - accuracy: 0.2683 - val_loss: 1.1439 - val_accuracy: 0.2991\n",
      "Epoch 39/200\n",
      "2553/2553 [==============================] - 0s 71us/sample - loss: 1.1871 - accuracy: 0.2570 - val_loss: 1.1429 - val_accuracy: 0.2991\n",
      "Epoch 40/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1840 - accuracy: 0.2452 - val_loss: 1.1418 - val_accuracy: 0.2991\n",
      "Epoch 41/200\n",
      "2553/2553 [==============================] - 0s 74us/sample - loss: 1.1744 - accuracy: 0.2534 - val_loss: 1.1408 - val_accuracy: 0.2991\n",
      "Epoch 42/200\n",
      "2553/2553 [==============================] - 0s 70us/sample - loss: 1.1732 - accuracy: 0.2648 - val_loss: 1.1398 - val_accuracy: 0.2991\n",
      "Epoch 43/200\n",
      "2553/2553 [==============================] - 0s 65us/sample - loss: 1.1752 - accuracy: 0.2546 - val_loss: 1.1389 - val_accuracy: 0.3084\n",
      "Epoch 44/200\n",
      "2553/2553 [==============================] - 0s 72us/sample - loss: 1.1715 - accuracy: 0.2648 - val_loss: 1.1380 - val_accuracy: 0.2991\n",
      "Epoch 45/200\n",
      "2553/2553 [==============================] - 0s 70us/sample - loss: 1.1688 - accuracy: 0.2636 - val_loss: 1.1372 - val_accuracy: 0.2991\n",
      "Epoch 46/200\n",
      "2553/2553 [==============================] - 0s 68us/sample - loss: 1.1674 - accuracy: 0.2581 - val_loss: 1.1363 - val_accuracy: 0.2991\n",
      "Epoch 47/200\n",
      "2553/2553 [==============================] - 0s 74us/sample - loss: 1.1660 - accuracy: 0.2652 - val_loss: 1.1355 - val_accuracy: 0.2991\n",
      "Epoch 48/200\n",
      "2553/2553 [==============================] - 0s 79us/sample - loss: 1.1621 - accuracy: 0.2562 - val_loss: 1.1347 - val_accuracy: 0.2897\n",
      "Epoch 49/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.1665 - accuracy: 0.2495 - val_loss: 1.1339 - val_accuracy: 0.2804\n",
      "Epoch 50/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.1602 - accuracy: 0.2472 - val_loss: 1.1332 - val_accuracy: 0.2897\n",
      "Epoch 51/200\n",
      "2553/2553 [==============================] - 0s 73us/sample - loss: 1.1592 - accuracy: 0.2601 - val_loss: 1.1324 - val_accuracy: 0.2897\n",
      "Epoch 52/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1593 - accuracy: 0.2550 - val_loss: 1.1317 - val_accuracy: 0.2804\n",
      "Epoch 53/200\n",
      "2553/2553 [==============================] - 0s 73us/sample - loss: 1.1543 - accuracy: 0.2656 - val_loss: 1.1310 - val_accuracy: 0.2897\n",
      "Epoch 54/200\n",
      "2553/2553 [==============================] - 0s 75us/sample - loss: 1.1520 - accuracy: 0.2687 - val_loss: 1.1303 - val_accuracy: 0.2897\n",
      "Epoch 55/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.1561 - accuracy: 0.2601 - val_loss: 1.1295 - val_accuracy: 0.2897\n",
      "Epoch 56/200\n",
      "2553/2553 [==============================] - 0s 70us/sample - loss: 1.1505 - accuracy: 0.2652 - val_loss: 1.1288 - val_accuracy: 0.2897\n",
      "Epoch 57/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.1518 - accuracy: 0.2573 - val_loss: 1.1281 - val_accuracy: 0.2897\n",
      "Epoch 58/200\n",
      "2553/2553 [==============================] - 0s 81us/sample - loss: 1.1486 - accuracy: 0.2613 - val_loss: 1.1276 - val_accuracy: 0.2897\n",
      "Epoch 59/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.1435 - accuracy: 0.2703 - val_loss: 1.1270 - val_accuracy: 0.2897\n",
      "Epoch 60/200\n",
      "2553/2553 [==============================] - 0s 129us/sample - loss: 1.1468 - accuracy: 0.2624 - val_loss: 1.1265 - val_accuracy: 0.2897\n",
      "Epoch 61/200\n",
      "2553/2553 [==============================] - 0s 148us/sample - loss: 1.1426 - accuracy: 0.2656 - val_loss: 1.1260 - val_accuracy: 0.2897\n",
      "Epoch 62/200\n",
      "2553/2553 [==============================] - 0s 127us/sample - loss: 1.1447 - accuracy: 0.2581 - val_loss: 1.1256 - val_accuracy: 0.2897\n",
      "Epoch 63/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.1410 - accuracy: 0.2664 - val_loss: 1.1252 - val_accuracy: 0.2897\n",
      "Epoch 64/200\n",
      "2553/2553 [==============================] - 0s 79us/sample - loss: 1.1435 - accuracy: 0.2628 - val_loss: 1.1247 - val_accuracy: 0.2897\n",
      "Epoch 65/200\n",
      "2553/2553 [==============================] - 0s 86us/sample - loss: 1.1423 - accuracy: 0.2605 - val_loss: 1.1243 - val_accuracy: 0.2991\n",
      "Epoch 66/200\n",
      "2553/2553 [==============================] - 0s 79us/sample - loss: 1.1380 - accuracy: 0.2675 - val_loss: 1.1238 - val_accuracy: 0.2991\n",
      "Epoch 67/200\n",
      "2553/2553 [==============================] - 0s 75us/sample - loss: 1.1390 - accuracy: 0.2601 - val_loss: 1.1234 - val_accuracy: 0.3084\n",
      "Epoch 68/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.1369 - accuracy: 0.2648 - val_loss: 1.1230 - val_accuracy: 0.2991\n",
      "Epoch 69/200\n",
      "2553/2553 [==============================] - 0s 94us/sample - loss: 1.1352 - accuracy: 0.2620 - val_loss: 1.1225 - val_accuracy: 0.3084\n",
      "Epoch 70/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.1359 - accuracy: 0.2660 - val_loss: 1.1220 - val_accuracy: 0.3084\n",
      "Epoch 71/200\n",
      "2553/2553 [==============================] - 0s 83us/sample - loss: 1.1295 - accuracy: 0.2797 - val_loss: 1.1216 - val_accuracy: 0.3084\n",
      "Epoch 72/200\n",
      "2553/2553 [==============================] - 0s 92us/sample - loss: 1.1366 - accuracy: 0.2526 - val_loss: 1.1212 - val_accuracy: 0.3084\n",
      "Epoch 73/200\n",
      "2553/2553 [==============================] - 0s 77us/sample - loss: 1.1324 - accuracy: 0.2703 - val_loss: 1.1207 - val_accuracy: 0.3178\n",
      "Epoch 74/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.1303 - accuracy: 0.2726 - val_loss: 1.1202 - val_accuracy: 0.3178\n",
      "Epoch 75/200\n",
      "2553/2553 [==============================] - 0s 66us/sample - loss: 1.1295 - accuracy: 0.2789 - val_loss: 1.1198 - val_accuracy: 0.3178\n",
      "Epoch 76/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.1273 - accuracy: 0.2726 - val_loss: 1.1194 - val_accuracy: 0.3178\n",
      "Epoch 77/200\n",
      "2553/2553 [==============================] - 0s 50us/sample - loss: 1.1283 - accuracy: 0.2777 - val_loss: 1.1190 - val_accuracy: 0.3084\n",
      "Epoch 78/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.1263 - accuracy: 0.2840 - val_loss: 1.1186 - val_accuracy: 0.3084\n",
      "Epoch 79/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1233 - accuracy: 0.2656 - val_loss: 1.1182 - val_accuracy: 0.3084\n",
      "Epoch 80/200\n",
      "2553/2553 [==============================] - 0s 51us/sample - loss: 1.1262 - accuracy: 0.2687 - val_loss: 1.1178 - val_accuracy: 0.3084\n",
      "Epoch 81/200\n",
      "2553/2553 [==============================] - 0s 51us/sample - loss: 1.1262 - accuracy: 0.2738 - val_loss: 1.1174 - val_accuracy: 0.3084\n",
      "Epoch 82/200\n",
      "2553/2553 [==============================] - 0s 50us/sample - loss: 1.1223 - accuracy: 0.2785 - val_loss: 1.1169 - val_accuracy: 0.3084\n",
      "Epoch 83/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.1200 - accuracy: 0.2773 - val_loss: 1.1166 - val_accuracy: 0.3084\n",
      "Epoch 84/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.1203 - accuracy: 0.2828 - val_loss: 1.1162 - val_accuracy: 0.2991\n",
      "Epoch 85/200\n",
      "2553/2553 [==============================] - 0s 171us/sample - loss: 1.1212 - accuracy: 0.2797 - val_loss: 1.1158 - val_accuracy: 0.2991\n",
      "Epoch 86/200\n",
      "2553/2553 [==============================] - 0s 145us/sample - loss: 1.1174 - accuracy: 0.2816 - val_loss: 1.1154 - val_accuracy: 0.3084\n",
      "Epoch 87/200\n",
      "2553/2553 [==============================] - 0s 115us/sample - loss: 1.1171 - accuracy: 0.2867 - val_loss: 1.1149 - val_accuracy: 0.3084\n",
      "Epoch 88/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.1189 - accuracy: 0.2777 - val_loss: 1.1144 - val_accuracy: 0.3084\n",
      "Epoch 89/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.1129 - accuracy: 0.2895 - val_loss: 1.1139 - val_accuracy: 0.3084\n",
      "Epoch 90/200\n",
      "2553/2553 [==============================] - 0s 77us/sample - loss: 1.1151 - accuracy: 0.2852 - val_loss: 1.1135 - val_accuracy: 0.3084\n",
      "Epoch 91/200\n",
      "2553/2553 [==============================] - 0s 65us/sample - loss: 1.1155 - accuracy: 0.2871 - val_loss: 1.1130 - val_accuracy: 0.2991\n",
      "Epoch 92/200\n",
      "2553/2553 [==============================] - 0s 70us/sample - loss: 1.1126 - accuracy: 0.2906 - val_loss: 1.1126 - val_accuracy: 0.2991\n",
      "Epoch 93/200\n",
      "2553/2553 [==============================] - 0s 73us/sample - loss: 1.1148 - accuracy: 0.2891 - val_loss: 1.1122 - val_accuracy: 0.2991\n",
      "Epoch 94/200\n",
      "2553/2553 [==============================] - 0s 86us/sample - loss: 1.1103 - accuracy: 0.3024 - val_loss: 1.1118 - val_accuracy: 0.2991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/200\n",
      "2553/2553 [==============================] - 0s 66us/sample - loss: 1.1102 - accuracy: 0.3020 - val_loss: 1.1113 - val_accuracy: 0.3084\n",
      "Epoch 96/200\n",
      "2553/2553 [==============================] - 0s 65us/sample - loss: 1.1066 - accuracy: 0.3141 - val_loss: 1.1108 - val_accuracy: 0.3084\n",
      "Epoch 97/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.1096 - accuracy: 0.2942 - val_loss: 1.1103 - val_accuracy: 0.3178\n",
      "Epoch 98/200\n",
      "2553/2553 [==============================] - 0s 66us/sample - loss: 1.1056 - accuracy: 0.3251 - val_loss: 1.1096 - val_accuracy: 0.3178\n",
      "Epoch 99/200\n",
      "2553/2553 [==============================] - 0s 65us/sample - loss: 1.1105 - accuracy: 0.2989 - val_loss: 1.1091 - val_accuracy: 0.3178\n",
      "Epoch 100/200\n",
      "2553/2553 [==============================] - 0s 72us/sample - loss: 1.1102 - accuracy: 0.3071 - val_loss: 1.1086 - val_accuracy: 0.3178\n",
      "Epoch 101/200\n",
      "2553/2553 [==============================] - 0s 71us/sample - loss: 1.1081 - accuracy: 0.3102 - val_loss: 1.1080 - val_accuracy: 0.3178\n",
      "Epoch 102/200\n",
      "2553/2553 [==============================] - 0s 65us/sample - loss: 1.1039 - accuracy: 0.3212 - val_loss: 1.1074 - val_accuracy: 0.3178\n",
      "Epoch 103/200\n",
      "2553/2553 [==============================] - 0s 66us/sample - loss: 1.1049 - accuracy: 0.3212 - val_loss: 1.1066 - val_accuracy: 0.3364\n",
      "Epoch 104/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1036 - accuracy: 0.3204 - val_loss: 1.1059 - val_accuracy: 0.3271\n",
      "Epoch 105/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1026 - accuracy: 0.3251 - val_loss: 1.1053 - val_accuracy: 0.3271\n",
      "Epoch 106/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.1002 - accuracy: 0.3396 - val_loss: 1.1046 - val_accuracy: 0.3364\n",
      "Epoch 107/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.0987 - accuracy: 0.3298 - val_loss: 1.1041 - val_accuracy: 0.3364\n",
      "Epoch 108/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0987 - accuracy: 0.3271 - val_loss: 1.1035 - val_accuracy: 0.3364\n",
      "Epoch 109/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0939 - accuracy: 0.3369 - val_loss: 1.1027 - val_accuracy: 0.3551\n",
      "Epoch 110/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0912 - accuracy: 0.3529 - val_loss: 1.1019 - val_accuracy: 0.3551\n",
      "Epoch 111/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0938 - accuracy: 0.3412 - val_loss: 1.1010 - val_accuracy: 0.3551\n",
      "Epoch 112/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0955 - accuracy: 0.3439 - val_loss: 1.1001 - val_accuracy: 0.3645\n",
      "Epoch 113/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0910 - accuracy: 0.3498 - val_loss: 1.0991 - val_accuracy: 0.3645\n",
      "Epoch 114/200\n",
      "2553/2553 [==============================] - 0s 68us/sample - loss: 1.0895 - accuracy: 0.3498 - val_loss: 1.0982 - val_accuracy: 0.3551\n",
      "Epoch 115/200\n",
      "2553/2553 [==============================] - 0s 70us/sample - loss: 1.0893 - accuracy: 0.3561 - val_loss: 1.0973 - val_accuracy: 0.3738\n",
      "Epoch 116/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0876 - accuracy: 0.3615 - val_loss: 1.0961 - val_accuracy: 0.3832\n",
      "Epoch 117/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0854 - accuracy: 0.3600 - val_loss: 1.0950 - val_accuracy: 0.3832\n",
      "Epoch 118/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0836 - accuracy: 0.3678 - val_loss: 1.0938 - val_accuracy: 0.3832\n",
      "Epoch 119/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0827 - accuracy: 0.3709 - val_loss: 1.0924 - val_accuracy: 0.4019\n",
      "Epoch 120/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0790 - accuracy: 0.3752 - val_loss: 1.0908 - val_accuracy: 0.4019\n",
      "Epoch 121/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0761 - accuracy: 0.3874 - val_loss: 1.0892 - val_accuracy: 0.4019\n",
      "Epoch 122/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.0745 - accuracy: 0.3870 - val_loss: 1.0877 - val_accuracy: 0.4019\n",
      "Epoch 123/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0819 - accuracy: 0.3729 - val_loss: 1.0865 - val_accuracy: 0.4019\n",
      "Epoch 124/200\n",
      "2553/2553 [==============================] - 0s 70us/sample - loss: 1.0733 - accuracy: 0.3850 - val_loss: 1.0850 - val_accuracy: 0.4019\n",
      "Epoch 125/200\n",
      "2553/2553 [==============================] - 0s 65us/sample - loss: 1.0752 - accuracy: 0.3756 - val_loss: 1.0837 - val_accuracy: 0.4019\n",
      "Epoch 126/200\n",
      "2553/2553 [==============================] - 0s 72us/sample - loss: 1.0731 - accuracy: 0.3882 - val_loss: 1.0822 - val_accuracy: 0.3925\n",
      "Epoch 127/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.0727 - accuracy: 0.3752 - val_loss: 1.0808 - val_accuracy: 0.4019\n",
      "Epoch 128/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0690 - accuracy: 0.3925 - val_loss: 1.0793 - val_accuracy: 0.4019\n",
      "Epoch 129/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0685 - accuracy: 0.3995 - val_loss: 1.0779 - val_accuracy: 0.4019\n",
      "Epoch 130/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0679 - accuracy: 0.3897 - val_loss: 1.0764 - val_accuracy: 0.4019\n",
      "Epoch 131/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0613 - accuracy: 0.4097 - val_loss: 1.0748 - val_accuracy: 0.4112\n",
      "Epoch 132/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0641 - accuracy: 0.4007 - val_loss: 1.0735 - val_accuracy: 0.4112\n",
      "Epoch 133/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0669 - accuracy: 0.3956 - val_loss: 1.0722 - val_accuracy: 0.4112\n",
      "Epoch 134/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0605 - accuracy: 0.4093 - val_loss: 1.0709 - val_accuracy: 0.4019\n",
      "Epoch 135/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0591 - accuracy: 0.4136 - val_loss: 1.0696 - val_accuracy: 0.4112\n",
      "Epoch 136/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0519 - accuracy: 0.4277 - val_loss: 1.0681 - val_accuracy: 0.4206\n",
      "Epoch 137/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0588 - accuracy: 0.4066 - val_loss: 1.0669 - val_accuracy: 0.4206\n",
      "Epoch 138/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.0597 - accuracy: 0.4074 - val_loss: 1.0657 - val_accuracy: 0.4299\n",
      "Epoch 139/200\n",
      "2553/2553 [==============================] - 0s 67us/sample - loss: 1.0560 - accuracy: 0.4078 - val_loss: 1.0645 - val_accuracy: 0.4299\n",
      "Epoch 140/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0516 - accuracy: 0.4215 - val_loss: 1.0632 - val_accuracy: 0.4299\n",
      "Epoch 141/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0550 - accuracy: 0.4085 - val_loss: 1.0620 - val_accuracy: 0.4299\n",
      "Epoch 142/200\n",
      "2553/2553 [==============================] - 0s 67us/sample - loss: 1.0548 - accuracy: 0.4238 - val_loss: 1.0608 - val_accuracy: 0.4393\n",
      "Epoch 143/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0546 - accuracy: 0.4187 - val_loss: 1.0597 - val_accuracy: 0.4299\n",
      "Epoch 144/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0551 - accuracy: 0.4132 - val_loss: 1.0586 - val_accuracy: 0.4299\n",
      "Epoch 145/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.0571 - accuracy: 0.4093 - val_loss: 1.0575 - val_accuracy: 0.4299\n",
      "Epoch 146/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0472 - accuracy: 0.4238 - val_loss: 1.0565 - val_accuracy: 0.4299\n",
      "Epoch 147/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0518 - accuracy: 0.4164 - val_loss: 1.0555 - val_accuracy: 0.4486\n",
      "Epoch 148/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0460 - accuracy: 0.4297 - val_loss: 1.0543 - val_accuracy: 0.4486\n",
      "Epoch 149/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 67us/sample - loss: 1.0498 - accuracy: 0.4097 - val_loss: 1.0534 - val_accuracy: 0.4486\n",
      "Epoch 150/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0504 - accuracy: 0.4195 - val_loss: 1.0525 - val_accuracy: 0.4579\n",
      "Epoch 151/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0408 - accuracy: 0.4262 - val_loss: 1.0514 - val_accuracy: 0.4486\n",
      "Epoch 152/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0479 - accuracy: 0.4168 - val_loss: 1.0504 - val_accuracy: 0.4579\n",
      "Epoch 153/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0484 - accuracy: 0.4191 - val_loss: 1.0496 - val_accuracy: 0.4673\n",
      "Epoch 154/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0434 - accuracy: 0.4269 - val_loss: 1.0486 - val_accuracy: 0.4673\n",
      "Epoch 155/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.0496 - accuracy: 0.4125 - val_loss: 1.0478 - val_accuracy: 0.4673\n",
      "Epoch 156/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.0384 - accuracy: 0.4246 - val_loss: 1.0469 - val_accuracy: 0.4673\n",
      "Epoch 157/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0446 - accuracy: 0.4183 - val_loss: 1.0460 - val_accuracy: 0.4673\n",
      "Epoch 158/200\n",
      "2553/2553 [==============================] - 0s 66us/sample - loss: 1.0424 - accuracy: 0.4191 - val_loss: 1.0452 - val_accuracy: 0.4766\n",
      "Epoch 159/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0464 - accuracy: 0.4195 - val_loss: 1.0446 - val_accuracy: 0.4766\n",
      "Epoch 160/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0447 - accuracy: 0.4262 - val_loss: 1.0439 - val_accuracy: 0.4766\n",
      "Epoch 161/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0393 - accuracy: 0.4324 - val_loss: 1.0431 - val_accuracy: 0.4766\n",
      "Epoch 162/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0375 - accuracy: 0.4269 - val_loss: 1.0423 - val_accuracy: 0.4766\n",
      "Epoch 163/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.0417 - accuracy: 0.4183 - val_loss: 1.0416 - val_accuracy: 0.4766\n",
      "Epoch 164/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0411 - accuracy: 0.4250 - val_loss: 1.0409 - val_accuracy: 0.4766\n",
      "Epoch 165/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0394 - accuracy: 0.4328 - val_loss: 1.0403 - val_accuracy: 0.4673\n",
      "Epoch 166/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0424 - accuracy: 0.4219 - val_loss: 1.0397 - val_accuracy: 0.4673\n",
      "Epoch 167/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0384 - accuracy: 0.4266 - val_loss: 1.0391 - val_accuracy: 0.4673\n",
      "Epoch 168/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.0443 - accuracy: 0.4140 - val_loss: 1.0385 - val_accuracy: 0.4673\n",
      "Epoch 169/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0392 - accuracy: 0.4242 - val_loss: 1.0380 - val_accuracy: 0.4673\n",
      "Epoch 170/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.0444 - accuracy: 0.4113 - val_loss: 1.0375 - val_accuracy: 0.4673\n",
      "Epoch 171/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0435 - accuracy: 0.4273 - val_loss: 1.0369 - val_accuracy: 0.4673\n",
      "Epoch 172/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0387 - accuracy: 0.4258 - val_loss: 1.0364 - val_accuracy: 0.4579\n",
      "Epoch 173/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0384 - accuracy: 0.4246 - val_loss: 1.0358 - val_accuracy: 0.4579\n",
      "Epoch 174/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.0375 - accuracy: 0.4277 - val_loss: 1.0353 - val_accuracy: 0.4673\n",
      "Epoch 175/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0331 - accuracy: 0.4293 - val_loss: 1.0347 - val_accuracy: 0.4673\n",
      "Epoch 176/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.0336 - accuracy: 0.4348 - val_loss: 1.0341 - val_accuracy: 0.4673\n",
      "Epoch 177/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0338 - accuracy: 0.4254 - val_loss: 1.0337 - val_accuracy: 0.4673\n",
      "Epoch 178/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0391 - accuracy: 0.4222 - val_loss: 1.0332 - val_accuracy: 0.4673\n",
      "Epoch 179/200\n",
      "2553/2553 [==============================] - 0s 67us/sample - loss: 1.0458 - accuracy: 0.4211 - val_loss: 1.0329 - val_accuracy: 0.4673\n",
      "Epoch 180/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0302 - accuracy: 0.4313 - val_loss: 1.0323 - val_accuracy: 0.4673\n",
      "Epoch 181/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0390 - accuracy: 0.4348 - val_loss: 1.0319 - val_accuracy: 0.4579\n",
      "Epoch 182/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0392 - accuracy: 0.4273 - val_loss: 1.0315 - val_accuracy: 0.4579\n",
      "Epoch 183/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0356 - accuracy: 0.4340 - val_loss: 1.0310 - val_accuracy: 0.4766\n",
      "Epoch 184/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0377 - accuracy: 0.4340 - val_loss: 1.0308 - val_accuracy: 0.4673\n",
      "Epoch 185/200\n",
      "2553/2553 [==============================] - ETA: 0s - loss: 1.0293 - accuracy: 0.44 - 0s 58us/sample - loss: 1.0334 - accuracy: 0.4375 - val_loss: 1.0304 - val_accuracy: 0.4673\n",
      "Epoch 186/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0352 - accuracy: 0.4360 - val_loss: 1.0300 - val_accuracy: 0.4673\n",
      "Epoch 187/200\n",
      "2553/2553 [==============================] - 0s 70us/sample - loss: 1.0353 - accuracy: 0.4281 - val_loss: 1.0296 - val_accuracy: 0.4673\n",
      "Epoch 188/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0353 - accuracy: 0.4215 - val_loss: 1.0291 - val_accuracy: 0.4673\n",
      "Epoch 189/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0259 - accuracy: 0.4544 - val_loss: 1.0287 - val_accuracy: 0.4673\n",
      "Epoch 190/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0421 - accuracy: 0.4187 - val_loss: 1.0284 - val_accuracy: 0.4673\n",
      "Epoch 191/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0259 - accuracy: 0.4489 - val_loss: 1.0280 - val_accuracy: 0.4673\n",
      "Epoch 192/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0359 - accuracy: 0.4250 - val_loss: 1.0276 - val_accuracy: 0.4673\n",
      "Epoch 193/200\n",
      "2553/2553 [==============================] - 0s 67us/sample - loss: 1.0382 - accuracy: 0.4430 - val_loss: 1.0274 - val_accuracy: 0.4673\n",
      "Epoch 194/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0338 - accuracy: 0.4375 - val_loss: 1.0270 - val_accuracy: 0.4673\n",
      "Epoch 195/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0394 - accuracy: 0.4313 - val_loss: 1.0267 - val_accuracy: 0.4673\n",
      "Epoch 196/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0330 - accuracy: 0.4305 - val_loss: 1.0264 - val_accuracy: 0.4673\n",
      "Epoch 197/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0358 - accuracy: 0.4363 - val_loss: 1.0262 - val_accuracy: 0.4766\n",
      "Epoch 198/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0297 - accuracy: 0.4344 - val_loss: 1.0259 - val_accuracy: 0.4766\n",
      "Epoch 199/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0332 - accuracy: 0.4328 - val_loss: 1.0257 - val_accuracy: 0.4766\n",
      "Epoch 200/200\n",
      "2553/2553 [==============================] - 0s 65us/sample - loss: 1.0289 - accuracy: 0.4426 - val_loss: 1.0253 - val_accuracy: 0.4766\n",
      "0.47663552 {'loss': 1.0288538395821512, 'accuracy': 0.44261652, 'val_loss': 1.02527225908832, 'val_accuracy': 0.47663552}\n",
      "Model: \"model_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_21 (InputLayer)        [(None, 29)]              0         \n",
      "_________________________________________________________________\n",
      "flatten_20 (Flatten)         (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 41)                1230      \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 75)                3150      \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 3)                 228       \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 4,608\n",
      "Trainable params: 4,608\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2553 samples, validate on 107 samples\n",
      "Epoch 1/200\n",
      "2553/2553 [==============================] - 1s 353us/sample - loss: 1.2579 - accuracy: 0.2577 - val_loss: 1.1990 - val_accuracy: 0.2617\n",
      "Epoch 2/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.2321 - accuracy: 0.2711 - val_loss: 1.1940 - val_accuracy: 0.2617\n",
      "Epoch 3/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.2295 - accuracy: 0.2714 - val_loss: 1.1892 - val_accuracy: 0.2617\n",
      "Epoch 4/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.2180 - accuracy: 0.2758 - val_loss: 1.1846 - val_accuracy: 0.2430\n",
      "Epoch 5/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.2198 - accuracy: 0.2754 - val_loss: 1.1800 - val_accuracy: 0.2523\n",
      "Epoch 6/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 1.2128 - accuracy: 0.2758 - val_loss: 1.1754 - val_accuracy: 0.2523\n",
      "Epoch 7/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.2109 - accuracy: 0.2718 - val_loss: 1.1711 - val_accuracy: 0.2523\n",
      "Epoch 8/200\n",
      "2553/2553 [==============================] - 0s 118us/sample - loss: 1.2029 - accuracy: 0.2718 - val_loss: 1.1670 - val_accuracy: 0.2523\n",
      "Epoch 9/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.2034 - accuracy: 0.2660 - val_loss: 1.1628 - val_accuracy: 0.2523\n",
      "Epoch 10/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.1920 - accuracy: 0.2742 - val_loss: 1.1591 - val_accuracy: 0.2523\n",
      "Epoch 11/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.1857 - accuracy: 0.2887 - val_loss: 1.1553 - val_accuracy: 0.2523\n",
      "Epoch 12/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.1758 - accuracy: 0.2789 - val_loss: 1.1522 - val_accuracy: 0.2710\n",
      "Epoch 13/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.1775 - accuracy: 0.2891 - val_loss: 1.1489 - val_accuracy: 0.2710\n",
      "Epoch 14/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.1706 - accuracy: 0.2812 - val_loss: 1.1459 - val_accuracy: 0.2710\n",
      "Epoch 15/200\n",
      "2553/2553 [==============================] - 0s 115us/sample - loss: 1.1678 - accuracy: 0.2777 - val_loss: 1.1429 - val_accuracy: 0.2617\n",
      "Epoch 16/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.1527 - accuracy: 0.2863 - val_loss: 1.1404 - val_accuracy: 0.2617\n",
      "Epoch 17/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.1639 - accuracy: 0.2824 - val_loss: 1.1375 - val_accuracy: 0.2617\n",
      "Epoch 18/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.1547 - accuracy: 0.2785 - val_loss: 1.1350 - val_accuracy: 0.2430\n",
      "Epoch 19/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.1494 - accuracy: 0.2785 - val_loss: 1.1326 - val_accuracy: 0.2430\n",
      "Epoch 20/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.1458 - accuracy: 0.2820 - val_loss: 1.1304 - val_accuracy: 0.2336\n",
      "Epoch 21/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.1486 - accuracy: 0.2738 - val_loss: 1.1281 - val_accuracy: 0.2336\n",
      "Epoch 22/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.1321 - accuracy: 0.2942 - val_loss: 1.1262 - val_accuracy: 0.2336\n",
      "Epoch 23/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.1397 - accuracy: 0.2754 - val_loss: 1.1243 - val_accuracy: 0.2523\n",
      "Epoch 24/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.1349 - accuracy: 0.2848 - val_loss: 1.1226 - val_accuracy: 0.2523\n",
      "Epoch 25/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.1372 - accuracy: 0.2695 - val_loss: 1.1208 - val_accuracy: 0.2523\n",
      "Epoch 26/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.1325 - accuracy: 0.2785 - val_loss: 1.1192 - val_accuracy: 0.2523\n",
      "Epoch 27/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.1332 - accuracy: 0.2703 - val_loss: 1.1178 - val_accuracy: 0.2617\n",
      "Epoch 28/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.1220 - accuracy: 0.2891 - val_loss: 1.1165 - val_accuracy: 0.2523\n",
      "Epoch 29/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.1260 - accuracy: 0.2777 - val_loss: 1.1152 - val_accuracy: 0.2523\n",
      "Epoch 30/200\n",
      "2553/2553 [==============================] - ETA: 0s - loss: 1.1200 - accuracy: 0.29 - 0s 115us/sample - loss: 1.1215 - accuracy: 0.2867 - val_loss: 1.1141 - val_accuracy: 0.2523\n",
      "Epoch 31/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.1209 - accuracy: 0.2812 - val_loss: 1.1130 - val_accuracy: 0.2430\n",
      "Epoch 32/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.1201 - accuracy: 0.2855 - val_loss: 1.1119 - val_accuracy: 0.2430\n",
      "Epoch 33/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.1232 - accuracy: 0.2746 - val_loss: 1.1108 - val_accuracy: 0.2430\n",
      "Epoch 34/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.1168 - accuracy: 0.2879 - val_loss: 1.1098 - val_accuracy: 0.2336\n",
      "Epoch 35/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.1190 - accuracy: 0.2754 - val_loss: 1.1088 - val_accuracy: 0.2243\n",
      "Epoch 36/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.1166 - accuracy: 0.2726 - val_loss: 1.1079 - val_accuracy: 0.2243\n",
      "Epoch 37/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.1177 - accuracy: 0.2738 - val_loss: 1.1070 - val_accuracy: 0.2243\n",
      "Epoch 38/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 1.1166 - accuracy: 0.2793 - val_loss: 1.1062 - val_accuracy: 0.2243\n",
      "Epoch 39/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.1144 - accuracy: 0.2801 - val_loss: 1.1055 - val_accuracy: 0.2150\n",
      "Epoch 40/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.1146 - accuracy: 0.2844 - val_loss: 1.1050 - val_accuracy: 0.2150\n",
      "Epoch 41/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.1138 - accuracy: 0.2808 - val_loss: 1.1045 - val_accuracy: 0.2150\n",
      "Epoch 42/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.1121 - accuracy: 0.2758 - val_loss: 1.1039 - val_accuracy: 0.2150\n",
      "Epoch 43/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.1101 - accuracy: 0.2789 - val_loss: 1.1035 - val_accuracy: 0.2243\n",
      "Epoch 44/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.1106 - accuracy: 0.2808 - val_loss: 1.1031 - val_accuracy: 0.2243\n",
      "Epoch 45/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.1108 - accuracy: 0.2867 - val_loss: 1.1027 - val_accuracy: 0.2243\n",
      "Epoch 46/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.1118 - accuracy: 0.2761 - val_loss: 1.1023 - val_accuracy: 0.2336\n",
      "Epoch 47/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.1088 - accuracy: 0.2836 - val_loss: 1.1020 - val_accuracy: 0.2336\n",
      "Epoch 48/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.1090 - accuracy: 0.2789 - val_loss: 1.1017 - val_accuracy: 0.2430\n",
      "Epoch 49/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.1078 - accuracy: 0.2781 - val_loss: 1.1014 - val_accuracy: 0.2336\n",
      "Epoch 50/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.1102 - accuracy: 0.2750 - val_loss: 1.1012 - val_accuracy: 0.2336\n",
      "Epoch 51/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.1092 - accuracy: 0.2765 - val_loss: 1.1010 - val_accuracy: 0.2336\n",
      "Epoch 52/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.1082 - accuracy: 0.2750 - val_loss: 1.1008 - val_accuracy: 0.2430\n",
      "Epoch 53/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.1060 - accuracy: 0.2824 - val_loss: 1.1007 - val_accuracy: 0.2430\n",
      "Epoch 54/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.1077 - accuracy: 0.2789 - val_loss: 1.1007 - val_accuracy: 0.2430\n",
      "Epoch 55/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.1050 - accuracy: 0.2824 - val_loss: 1.1006 - val_accuracy: 0.2430\n",
      "Epoch 56/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.1066 - accuracy: 0.2785 - val_loss: 1.1005 - val_accuracy: 0.2430\n",
      "Epoch 57/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.1058 - accuracy: 0.2824 - val_loss: 1.1004 - val_accuracy: 0.2430\n",
      "Epoch 58/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.1046 - accuracy: 0.2797 - val_loss: 1.1004 - val_accuracy: 0.2430\n",
      "Epoch 59/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.1066 - accuracy: 0.2761 - val_loss: 1.1003 - val_accuracy: 0.2430\n",
      "Epoch 60/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.1039 - accuracy: 0.2801 - val_loss: 1.1003 - val_accuracy: 0.2430\n",
      "Epoch 61/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.1052 - accuracy: 0.2754 - val_loss: 1.1002 - val_accuracy: 0.2430\n",
      "Epoch 62/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.1040 - accuracy: 0.2797 - val_loss: 1.1002 - val_accuracy: 0.2430\n",
      "Epoch 63/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.1051 - accuracy: 0.2781 - val_loss: 1.1001 - val_accuracy: 0.2430\n",
      "Epoch 64/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.1043 - accuracy: 0.2773 - val_loss: 1.1001 - val_accuracy: 0.2430\n",
      "Epoch 65/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 1.1019 - accuracy: 0.2793 - val_loss: 1.1000 - val_accuracy: 0.2430\n",
      "Epoch 66/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.1039 - accuracy: 0.2754 - val_loss: 1.1000 - val_accuracy: 0.2430\n",
      "Epoch 67/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.1027 - accuracy: 0.2820 - val_loss: 1.0999 - val_accuracy: 0.2430\n",
      "Epoch 68/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.1034 - accuracy: 0.2742 - val_loss: 1.0999 - val_accuracy: 0.2430\n",
      "Epoch 69/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.1031 - accuracy: 0.2816 - val_loss: 1.0998 - val_accuracy: 0.2336\n",
      "Epoch 70/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.1037 - accuracy: 0.2824 - val_loss: 1.0997 - val_accuracy: 0.2336\n",
      "Epoch 71/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.1047 - accuracy: 0.2789 - val_loss: 1.0996 - val_accuracy: 0.2336\n",
      "Epoch 72/200\n",
      "2553/2553 [==============================] - 0s 117us/sample - loss: 1.1024 - accuracy: 0.2797 - val_loss: 1.0996 - val_accuracy: 0.2336\n",
      "Epoch 73/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.1027 - accuracy: 0.2769 - val_loss: 1.0995 - val_accuracy: 0.2336\n",
      "Epoch 74/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.1024 - accuracy: 0.2781 - val_loss: 1.0995 - val_accuracy: 0.2336\n",
      "Epoch 75/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.1023 - accuracy: 0.2836 - val_loss: 1.0994 - val_accuracy: 0.2430\n",
      "Epoch 76/200\n",
      "2553/2553 [==============================] - 0s 115us/sample - loss: 1.1020 - accuracy: 0.2820 - val_loss: 1.0994 - val_accuracy: 0.2430\n",
      "Epoch 77/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.1018 - accuracy: 0.2828 - val_loss: 1.0993 - val_accuracy: 0.2430\n",
      "Epoch 78/200\n",
      "2553/2553 [==============================] - 0s 117us/sample - loss: 1.1028 - accuracy: 0.2785 - val_loss: 1.0993 - val_accuracy: 0.2430\n",
      "Epoch 79/200\n",
      "2553/2553 [==============================] - 0s 158us/sample - loss: 1.1027 - accuracy: 0.2781 - val_loss: 1.0993 - val_accuracy: 0.2430\n",
      "Epoch 80/200\n",
      "2553/2553 [==============================] - 0s 164us/sample - loss: 1.1019 - accuracy: 0.2816 - val_loss: 1.0993 - val_accuracy: 0.2430\n",
      "Epoch 81/200\n",
      "2553/2553 [==============================] - 0s 141us/sample - loss: 1.1003 - accuracy: 0.2863 - val_loss: 1.0992 - val_accuracy: 0.2430\n",
      "Epoch 82/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.1007 - accuracy: 0.2844 - val_loss: 1.0992 - val_accuracy: 0.2430\n",
      "Epoch 83/200\n",
      "2553/2553 [==============================] - 0s 122us/sample - loss: 1.1018 - accuracy: 0.2812 - val_loss: 1.0992 - val_accuracy: 0.2430\n",
      "Epoch 84/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.1018 - accuracy: 0.2781 - val_loss: 1.0992 - val_accuracy: 0.2430\n",
      "Epoch 85/200\n",
      "2553/2553 [==============================] - 0s 115us/sample - loss: 1.1012 - accuracy: 0.2832 - val_loss: 1.0991 - val_accuracy: 0.2430\n",
      "Epoch 86/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.1022 - accuracy: 0.2820 - val_loss: 1.0991 - val_accuracy: 0.2430\n",
      "Epoch 87/200\n",
      "2553/2553 [==============================] - 0s 130us/sample - loss: 1.1020 - accuracy: 0.2773 - val_loss: 1.0991 - val_accuracy: 0.2430\n",
      "Epoch 88/200\n",
      "2553/2553 [==============================] - 0s 122us/sample - loss: 1.1013 - accuracy: 0.2773 - val_loss: 1.0991 - val_accuracy: 0.2430\n",
      "Epoch 89/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.1002 - accuracy: 0.2812 - val_loss: 1.0992 - val_accuracy: 0.2430\n",
      "Epoch 90/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.1011 - accuracy: 0.2832 - val_loss: 1.0991 - val_accuracy: 0.2430\n",
      "Epoch 91/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.1010 - accuracy: 0.2855 - val_loss: 1.0991 - val_accuracy: 0.2430\n",
      "Epoch 92/200\n",
      "2553/2553 [==============================] - 0s 118us/sample - loss: 1.1003 - accuracy: 0.2867 - val_loss: 1.0991 - val_accuracy: 0.2430\n",
      "Epoch 93/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 1.1001 - accuracy: 0.2820 - val_loss: 1.0991 - val_accuracy: 0.2430\n",
      "Epoch 94/200\n",
      "2553/2553 [==============================] - 0s 125us/sample - loss: 1.1003 - accuracy: 0.2805 - val_loss: 1.0991 - val_accuracy: 0.2430\n",
      "Epoch 95/200\n",
      "2553/2553 [==============================] - ETA: 0s - loss: 1.1008 - accuracy: 0.28 - 0s 111us/sample - loss: 1.1009 - accuracy: 0.2828 - val_loss: 1.0991 - val_accuracy: 0.2430\n",
      "Epoch 96/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.1002 - accuracy: 0.2848 - val_loss: 1.0991 - val_accuracy: 0.2430\n",
      "Epoch 97/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.1014 - accuracy: 0.2797 - val_loss: 1.0991 - val_accuracy: 0.2430\n",
      "Epoch 98/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.1007 - accuracy: 0.2828 - val_loss: 1.0991 - val_accuracy: 0.2430\n",
      "Epoch 99/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.1015 - accuracy: 0.2781 - val_loss: 1.0991 - val_accuracy: 0.2430\n",
      "Epoch 100/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0995 - accuracy: 0.2855 - val_loss: 1.0991 - val_accuracy: 0.2430\n",
      "Epoch 101/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.1013 - accuracy: 0.2781 - val_loss: 1.0992 - val_accuracy: 0.2430\n",
      "Epoch 102/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.1003 - accuracy: 0.2797 - val_loss: 1.0992 - val_accuracy: 0.2430\n",
      "Epoch 103/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.1004 - accuracy: 0.2808 - val_loss: 1.0992 - val_accuracy: 0.2430\n",
      "Epoch 104/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.1002 - accuracy: 0.2855 - val_loss: 1.0991 - val_accuracy: 0.2430\n",
      "Epoch 105/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.1002 - accuracy: 0.2836 - val_loss: 1.0992 - val_accuracy: 0.2430\n",
      "Epoch 106/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.1003 - accuracy: 0.2848 - val_loss: 1.0992 - val_accuracy: 0.2336\n",
      "Epoch 107/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.1002 - accuracy: 0.2816 - val_loss: 1.0992 - val_accuracy: 0.2336\n",
      "Epoch 108/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.1004 - accuracy: 0.2820 - val_loss: 1.0991 - val_accuracy: 0.2336\n",
      "Epoch 109/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.1000 - accuracy: 0.2793 - val_loss: 1.0991 - val_accuracy: 0.2336\n",
      "Epoch 110/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.1006 - accuracy: 0.2801 - val_loss: 1.0991 - val_accuracy: 0.2336\n",
      "Epoch 111/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0993 - accuracy: 0.2848 - val_loss: 1.0990 - val_accuracy: 0.2336\n",
      "Epoch 112/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0989 - accuracy: 0.2867 - val_loss: 1.0990 - val_accuracy: 0.2336\n",
      "Epoch 113/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.1006 - accuracy: 0.2808 - val_loss: 1.0990 - val_accuracy: 0.2336\n",
      "Epoch 114/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.1001 - accuracy: 0.2844 - val_loss: 1.0990 - val_accuracy: 0.2336\n",
      "Epoch 115/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.1004 - accuracy: 0.2828 - val_loss: 1.0990 - val_accuracy: 0.2336\n",
      "Epoch 116/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0997 - accuracy: 0.2824 - val_loss: 1.0990 - val_accuracy: 0.2336\n",
      "Epoch 117/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0992 - accuracy: 0.2832 - val_loss: 1.0990 - val_accuracy: 0.2336\n",
      "Epoch 118/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.1009 - accuracy: 0.2801 - val_loss: 1.0990 - val_accuracy: 0.2336\n",
      "Epoch 119/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0990 - accuracy: 0.2836 - val_loss: 1.0990 - val_accuracy: 0.2336\n",
      "Epoch 120/200\n",
      "2553/2553 [==============================] - ETA: 0s - loss: 1.1001 - accuracy: 0.28 - 0s 112us/sample - loss: 1.1001 - accuracy: 0.2832 - val_loss: 1.0989 - val_accuracy: 0.2336\n",
      "Epoch 121/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.1008 - accuracy: 0.2777 - val_loss: 1.0990 - val_accuracy: 0.2336\n",
      "Epoch 122/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0993 - accuracy: 0.2828 - val_loss: 1.0989 - val_accuracy: 0.2336\n",
      "Epoch 123/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0999 - accuracy: 0.2859 - val_loss: 1.0989 - val_accuracy: 0.2336\n",
      "Epoch 124/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.0984 - accuracy: 0.2859 - val_loss: 1.0989 - val_accuracy: 0.2336\n",
      "Epoch 125/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.1006 - accuracy: 0.2859 - val_loss: 1.0989 - val_accuracy: 0.2336\n",
      "Epoch 126/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.1007 - accuracy: 0.2836 - val_loss: 1.0989 - val_accuracy: 0.2336\n",
      "Epoch 127/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0974 - accuracy: 0.2863 - val_loss: 1.0989 - val_accuracy: 0.2336\n",
      "Epoch 128/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0993 - accuracy: 0.2863 - val_loss: 1.0989 - val_accuracy: 0.2336\n",
      "Epoch 129/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0996 - accuracy: 0.2812 - val_loss: 1.0989 - val_accuracy: 0.2336\n",
      "Epoch 130/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0985 - accuracy: 0.2836 - val_loss: 1.0990 - val_accuracy: 0.2336\n",
      "Epoch 131/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.0995 - accuracy: 0.2852 - val_loss: 1.0990 - val_accuracy: 0.2336\n",
      "Epoch 132/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0986 - accuracy: 0.2832 - val_loss: 1.0990 - val_accuracy: 0.2336\n",
      "Epoch 133/200\n",
      "2553/2553 [==============================] - 0s 117us/sample - loss: 1.0988 - accuracy: 0.2840 - val_loss: 1.0990 - val_accuracy: 0.2336\n",
      "Epoch 134/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0979 - accuracy: 0.2852 - val_loss: 1.0990 - val_accuracy: 0.2336\n",
      "Epoch 135/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0989 - accuracy: 0.2859 - val_loss: 1.0990 - val_accuracy: 0.2430\n",
      "Epoch 136/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.0992 - accuracy: 0.2836 - val_loss: 1.0990 - val_accuracy: 0.2430\n",
      "Epoch 137/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0993 - accuracy: 0.2855 - val_loss: 1.0990 - val_accuracy: 0.2430\n",
      "Epoch 138/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0997 - accuracy: 0.2824 - val_loss: 1.0990 - val_accuracy: 0.2430\n",
      "Epoch 139/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0984 - accuracy: 0.2875 - val_loss: 1.0990 - val_accuracy: 0.2430\n",
      "Epoch 140/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0992 - accuracy: 0.2855 - val_loss: 1.0990 - val_accuracy: 0.2430\n",
      "Epoch 141/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0993 - accuracy: 0.2801 - val_loss: 1.0990 - val_accuracy: 0.2430\n",
      "Epoch 142/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0992 - accuracy: 0.2859 - val_loss: 1.0990 - val_accuracy: 0.2430\n",
      "Epoch 143/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0983 - accuracy: 0.2867 - val_loss: 1.0990 - val_accuracy: 0.2523\n",
      "Epoch 144/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0994 - accuracy: 0.2863 - val_loss: 1.0990 - val_accuracy: 0.2523\n",
      "Epoch 145/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.0996 - accuracy: 0.2832 - val_loss: 1.0990 - val_accuracy: 0.2523\n",
      "Epoch 146/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0987 - accuracy: 0.2844 - val_loss: 1.0990 - val_accuracy: 0.2523\n",
      "Epoch 147/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0986 - accuracy: 0.2836 - val_loss: 1.0989 - val_accuracy: 0.2523\n",
      "Epoch 148/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0997 - accuracy: 0.2832 - val_loss: 1.0989 - val_accuracy: 0.2523\n",
      "Epoch 149/200\n",
      "2553/2553 [==============================] - 0s 98us/sample - loss: 1.0980 - accuracy: 0.2863 - val_loss: 1.0989 - val_accuracy: 0.2523\n",
      "Epoch 150/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0991 - accuracy: 0.2840 - val_loss: 1.0989 - val_accuracy: 0.2523\n",
      "Epoch 151/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.1003 - accuracy: 0.2816 - val_loss: 1.0989 - val_accuracy: 0.2523\n",
      "Epoch 152/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0993 - accuracy: 0.2836 - val_loss: 1.0989 - val_accuracy: 0.2523\n",
      "Epoch 153/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0981 - accuracy: 0.2891 - val_loss: 1.0989 - val_accuracy: 0.2617\n",
      "Epoch 154/200\n",
      "2553/2553 [==============================] - 0s 98us/sample - loss: 1.0981 - accuracy: 0.2899 - val_loss: 1.0988 - val_accuracy: 0.2617\n",
      "Epoch 155/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0980 - accuracy: 0.2899 - val_loss: 1.0988 - val_accuracy: 0.2617\n",
      "Epoch 156/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0984 - accuracy: 0.2863 - val_loss: 1.0987 - val_accuracy: 0.2617\n",
      "Epoch 157/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0988 - accuracy: 0.2871 - val_loss: 1.0987 - val_accuracy: 0.2617\n",
      "Epoch 158/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.0975 - accuracy: 0.2914 - val_loss: 1.0987 - val_accuracy: 0.2617\n",
      "Epoch 159/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0978 - accuracy: 0.2852 - val_loss: 1.0986 - val_accuracy: 0.2617\n",
      "Epoch 160/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0988 - accuracy: 0.2840 - val_loss: 1.0986 - val_accuracy: 0.2617\n",
      "Epoch 161/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0979 - accuracy: 0.2879 - val_loss: 1.0986 - val_accuracy: 0.2617\n",
      "Epoch 162/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.0964 - accuracy: 0.2914 - val_loss: 1.0986 - val_accuracy: 0.2617\n",
      "Epoch 163/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0980 - accuracy: 0.2902 - val_loss: 1.0985 - val_accuracy: 0.2617\n",
      "Epoch 164/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0980 - accuracy: 0.2875 - val_loss: 1.0985 - val_accuracy: 0.2617\n",
      "Epoch 165/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0979 - accuracy: 0.2891 - val_loss: 1.0984 - val_accuracy: 0.2617\n",
      "Epoch 166/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.0973 - accuracy: 0.2891 - val_loss: 1.0984 - val_accuracy: 0.2617\n",
      "Epoch 167/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0986 - accuracy: 0.2852 - val_loss: 1.0984 - val_accuracy: 0.2617\n",
      "Epoch 168/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0962 - accuracy: 0.2906 - val_loss: 1.0983 - val_accuracy: 0.2617\n",
      "Epoch 169/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0968 - accuracy: 0.2914 - val_loss: 1.0983 - val_accuracy: 0.2617\n",
      "Epoch 170/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.0970 - accuracy: 0.2910 - val_loss: 1.0983 - val_accuracy: 0.2617\n",
      "Epoch 171/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.0965 - accuracy: 0.2899 - val_loss: 1.0982 - val_accuracy: 0.2617\n",
      "Epoch 172/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0977 - accuracy: 0.2848 - val_loss: 1.0982 - val_accuracy: 0.2617\n",
      "Epoch 173/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0971 - accuracy: 0.2863 - val_loss: 1.0982 - val_accuracy: 0.2617\n",
      "Epoch 174/200\n",
      "2553/2553 [==============================] - 0s 98us/sample - loss: 1.0972 - accuracy: 0.2871 - val_loss: 1.0982 - val_accuracy: 0.2617\n",
      "Epoch 175/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.0979 - accuracy: 0.2863 - val_loss: 1.0982 - val_accuracy: 0.2617\n",
      "Epoch 176/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0986 - accuracy: 0.2879 - val_loss: 1.0982 - val_accuracy: 0.2617\n",
      "Epoch 177/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0968 - accuracy: 0.2934 - val_loss: 1.0981 - val_accuracy: 0.2617\n",
      "Epoch 178/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.1002 - accuracy: 0.2832 - val_loss: 1.0981 - val_accuracy: 0.2617\n",
      "Epoch 179/200\n",
      "2553/2553 [==============================] - 0s 96us/sample - loss: 1.0970 - accuracy: 0.2926 - val_loss: 1.0981 - val_accuracy: 0.2617\n",
      "Epoch 180/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0966 - accuracy: 0.2922 - val_loss: 1.0980 - val_accuracy: 0.2617\n",
      "Epoch 181/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.0973 - accuracy: 0.2867 - val_loss: 1.0980 - val_accuracy: 0.2617\n",
      "Epoch 182/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.0976 - accuracy: 0.2871 - val_loss: 1.0980 - val_accuracy: 0.2617\n",
      "Epoch 183/200\n",
      "2553/2553 [==============================] - 0s 99us/sample - loss: 1.0975 - accuracy: 0.2899 - val_loss: 1.0980 - val_accuracy: 0.2617\n",
      "Epoch 184/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0973 - accuracy: 0.2918 - val_loss: 1.0979 - val_accuracy: 0.2617\n",
      "Epoch 185/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0973 - accuracy: 0.2891 - val_loss: 1.0979 - val_accuracy: 0.2617\n",
      "Epoch 186/200\n",
      "2553/2553 [==============================] - 0s 97us/sample - loss: 1.0972 - accuracy: 0.2910 - val_loss: 1.0979 - val_accuracy: 0.2617\n",
      "Epoch 187/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0973 - accuracy: 0.2953 - val_loss: 1.0979 - val_accuracy: 0.2617\n",
      "Epoch 188/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0978 - accuracy: 0.2871 - val_loss: 1.0978 - val_accuracy: 0.2617\n",
      "Epoch 189/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.0975 - accuracy: 0.2918 - val_loss: 1.0978 - val_accuracy: 0.2710\n",
      "Epoch 190/200\n",
      "2553/2553 [==============================] - 0s 96us/sample - loss: 1.0972 - accuracy: 0.2902 - val_loss: 1.0977 - val_accuracy: 0.2710\n",
      "Epoch 191/200\n",
      "2553/2553 [==============================] - 0s 98us/sample - loss: 1.0980 - accuracy: 0.2895 - val_loss: 1.0977 - val_accuracy: 0.2710\n",
      "Epoch 192/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0965 - accuracy: 0.2906 - val_loss: 1.0977 - val_accuracy: 0.2710\n",
      "Epoch 193/200\n",
      "2553/2553 [==============================] - 0s 99us/sample - loss: 1.0955 - accuracy: 0.2957 - val_loss: 1.0976 - val_accuracy: 0.2710\n",
      "Epoch 194/200\n",
      "2553/2553 [==============================] - 0s 96us/sample - loss: 1.0973 - accuracy: 0.2875 - val_loss: 1.0976 - val_accuracy: 0.2710\n",
      "Epoch 195/200\n",
      "2553/2553 [==============================] - ETA: 0s - loss: 1.0956 - accuracy: 0.29 - 0s 95us/sample - loss: 1.0958 - accuracy: 0.2953 - val_loss: 1.0975 - val_accuracy: 0.2804\n",
      "Epoch 196/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0978 - accuracy: 0.2918 - val_loss: 1.0975 - val_accuracy: 0.2804\n",
      "Epoch 197/200\n",
      "2553/2553 [==============================] - 0s 99us/sample - loss: 1.0964 - accuracy: 0.2902 - val_loss: 1.0974 - val_accuracy: 0.2804\n",
      "Epoch 198/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.0963 - accuracy: 0.2867 - val_loss: 1.0974 - val_accuracy: 0.2804\n",
      "Epoch 199/200\n",
      "2553/2553 [==============================] - 0s 98us/sample - loss: 1.0980 - accuracy: 0.2875 - val_loss: 1.0974 - val_accuracy: 0.2804\n",
      "Epoch 200/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.0943 - accuracy: 0.2965 - val_loss: 1.0973 - val_accuracy: 0.2804\n",
      "0.28037384 {'loss': 1.0942954709844592, 'accuracy': 0.29651392, 'val_loss': 1.0972527443805589, 'val_accuracy': 0.28037384}\n",
      "Model: \"model_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_22 (InputLayer)        [(None, 29)]              0         \n",
      "_________________________________________________________________\n",
      "flatten_21 (Flatten)         (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 41)                1230      \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 75)                3150      \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 3)                 228       \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 4,608\n",
      "Trainable params: 4,608\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2553 samples, validate on 107 samples\n",
      "Epoch 1/200\n",
      "2553/2553 [==============================] - 1s 263us/sample - loss: 1.5536 - accuracy: 0.3220 - val_loss: 1.1976 - val_accuracy: 0.3364\n",
      "Epoch 2/200\n",
      "2553/2553 [==============================] - 0s 51us/sample - loss: 1.5323 - accuracy: 0.3231 - val_loss: 1.1947 - val_accuracy: 0.3364\n",
      "Epoch 3/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.5472 - accuracy: 0.3130 - val_loss: 1.1917 - val_accuracy: 0.3364\n",
      "Epoch 4/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.5317 - accuracy: 0.3130 - val_loss: 1.1885 - val_accuracy: 0.3364\n",
      "Epoch 5/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.5480 - accuracy: 0.3016 - val_loss: 1.1856 - val_accuracy: 0.3364\n",
      "Epoch 6/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.5214 - accuracy: 0.3114 - val_loss: 1.1827 - val_accuracy: 0.3364\n",
      "Epoch 7/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.5328 - accuracy: 0.3055 - val_loss: 1.1797 - val_accuracy: 0.3364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.5434 - accuracy: 0.2949 - val_loss: 1.1771 - val_accuracy: 0.3364\n",
      "Epoch 9/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.5378 - accuracy: 0.3040 - val_loss: 1.1746 - val_accuracy: 0.3364\n",
      "Epoch 10/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.5059 - accuracy: 0.3134 - val_loss: 1.1719 - val_accuracy: 0.3271\n",
      "Epoch 11/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.4928 - accuracy: 0.3184 - val_loss: 1.1694 - val_accuracy: 0.3178\n",
      "Epoch 12/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.4970 - accuracy: 0.3173 - val_loss: 1.1668 - val_accuracy: 0.3178\n",
      "Epoch 13/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.4970 - accuracy: 0.3141 - val_loss: 1.1644 - val_accuracy: 0.3178\n",
      "Epoch 14/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.4807 - accuracy: 0.3102 - val_loss: 1.1620 - val_accuracy: 0.3178\n",
      "Epoch 15/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.4674 - accuracy: 0.3126 - val_loss: 1.1598 - val_accuracy: 0.3084\n",
      "Epoch 16/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.4555 - accuracy: 0.3106 - val_loss: 1.1575 - val_accuracy: 0.3084\n",
      "Epoch 17/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.4749 - accuracy: 0.2993 - val_loss: 1.1553 - val_accuracy: 0.3084\n",
      "Epoch 18/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.4559 - accuracy: 0.3192 - val_loss: 1.1530 - val_accuracy: 0.3084\n",
      "Epoch 19/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.4788 - accuracy: 0.3043 - val_loss: 1.1509 - val_accuracy: 0.3084\n",
      "Epoch 20/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.4290 - accuracy: 0.3275 - val_loss: 1.1486 - val_accuracy: 0.3084\n",
      "Epoch 21/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.4442 - accuracy: 0.3161 - val_loss: 1.1464 - val_accuracy: 0.3084\n",
      "Epoch 22/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.4423 - accuracy: 0.3247 - val_loss: 1.1442 - val_accuracy: 0.3178\n",
      "Epoch 23/200\n",
      "2553/2553 [==============================] - 0s 50us/sample - loss: 1.4048 - accuracy: 0.3247 - val_loss: 1.1423 - val_accuracy: 0.3178\n",
      "Epoch 24/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.4323 - accuracy: 0.3200 - val_loss: 1.1402 - val_accuracy: 0.3178\n",
      "Epoch 25/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.4323 - accuracy: 0.3192 - val_loss: 1.1382 - val_accuracy: 0.3178\n",
      "Epoch 26/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.4419 - accuracy: 0.3157 - val_loss: 1.1361 - val_accuracy: 0.3178\n",
      "Epoch 27/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.4241 - accuracy: 0.3090 - val_loss: 1.1342 - val_accuracy: 0.3178\n",
      "Epoch 28/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.4141 - accuracy: 0.3130 - val_loss: 1.1324 - val_accuracy: 0.3178\n",
      "Epoch 29/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.3931 - accuracy: 0.3247 - val_loss: 1.1305 - val_accuracy: 0.3178\n",
      "Epoch 30/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.4263 - accuracy: 0.3090 - val_loss: 1.1285 - val_accuracy: 0.3271\n",
      "Epoch 31/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.3935 - accuracy: 0.3169 - val_loss: 1.1265 - val_accuracy: 0.3271\n",
      "Epoch 32/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.4163 - accuracy: 0.3228 - val_loss: 1.1247 - val_accuracy: 0.3271\n",
      "Epoch 33/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.4075 - accuracy: 0.3122 - val_loss: 1.1228 - val_accuracy: 0.3271\n",
      "Epoch 34/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.3908 - accuracy: 0.3200 - val_loss: 1.1210 - val_accuracy: 0.3271\n",
      "Epoch 35/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.3736 - accuracy: 0.3392 - val_loss: 1.1193 - val_accuracy: 0.3364\n",
      "Epoch 36/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.4062 - accuracy: 0.3235 - val_loss: 1.1177 - val_accuracy: 0.3364\n",
      "Epoch 37/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.3847 - accuracy: 0.3243 - val_loss: 1.1160 - val_accuracy: 0.3364\n",
      "Epoch 38/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.3761 - accuracy: 0.3216 - val_loss: 1.1142 - val_accuracy: 0.3364\n",
      "Epoch 39/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.3645 - accuracy: 0.3376 - val_loss: 1.1125 - val_accuracy: 0.3364\n",
      "Epoch 40/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.3754 - accuracy: 0.3169 - val_loss: 1.1108 - val_accuracy: 0.3645\n",
      "Epoch 41/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.3566 - accuracy: 0.3169 - val_loss: 1.1092 - val_accuracy: 0.3738\n",
      "Epoch 42/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.3397 - accuracy: 0.3216 - val_loss: 1.1078 - val_accuracy: 0.3738\n",
      "Epoch 43/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.3418 - accuracy: 0.3357 - val_loss: 1.1062 - val_accuracy: 0.3738\n",
      "Epoch 44/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.3259 - accuracy: 0.3243 - val_loss: 1.1047 - val_accuracy: 0.3738\n",
      "Epoch 45/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.3454 - accuracy: 0.3282 - val_loss: 1.1033 - val_accuracy: 0.3738\n",
      "Epoch 46/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.3521 - accuracy: 0.3263 - val_loss: 1.1018 - val_accuracy: 0.3738\n",
      "Epoch 47/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.3331 - accuracy: 0.3278 - val_loss: 1.1004 - val_accuracy: 0.3832\n",
      "Epoch 48/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.3489 - accuracy: 0.3212 - val_loss: 1.0990 - val_accuracy: 0.3832\n",
      "Epoch 49/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.3346 - accuracy: 0.3188 - val_loss: 1.0976 - val_accuracy: 0.3925\n",
      "Epoch 50/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.3424 - accuracy: 0.3388 - val_loss: 1.0960 - val_accuracy: 0.3925\n",
      "Epoch 51/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.3213 - accuracy: 0.3306 - val_loss: 1.0946 - val_accuracy: 0.3925\n",
      "Epoch 52/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.3060 - accuracy: 0.3333 - val_loss: 1.0932 - val_accuracy: 0.3925\n",
      "Epoch 53/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.3156 - accuracy: 0.3408 - val_loss: 1.0919 - val_accuracy: 0.4019\n",
      "Epoch 54/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.3185 - accuracy: 0.3325 - val_loss: 1.0906 - val_accuracy: 0.4206\n",
      "Epoch 55/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.3052 - accuracy: 0.3290 - val_loss: 1.0893 - val_accuracy: 0.4206\n",
      "Epoch 56/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.3094 - accuracy: 0.3318 - val_loss: 1.0877 - val_accuracy: 0.4206\n",
      "Epoch 57/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.3049 - accuracy: 0.3239 - val_loss: 1.0863 - val_accuracy: 0.4206\n",
      "Epoch 58/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.3051 - accuracy: 0.3329 - val_loss: 1.0850 - val_accuracy: 0.4299\n",
      "Epoch 59/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.3069 - accuracy: 0.3255 - val_loss: 1.0836 - val_accuracy: 0.4299\n",
      "Epoch 60/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.2837 - accuracy: 0.3470 - val_loss: 1.0823 - val_accuracy: 0.4299\n",
      "Epoch 61/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.2994 - accuracy: 0.3306 - val_loss: 1.0810 - val_accuracy: 0.4299\n",
      "Epoch 62/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.2775 - accuracy: 0.3443 - val_loss: 1.0796 - val_accuracy: 0.4393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.2962 - accuracy: 0.3325 - val_loss: 1.0783 - val_accuracy: 0.4393\n",
      "Epoch 64/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.2888 - accuracy: 0.3376 - val_loss: 1.0769 - val_accuracy: 0.4486\n",
      "Epoch 65/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.2817 - accuracy: 0.3318 - val_loss: 1.0756 - val_accuracy: 0.4486\n",
      "Epoch 66/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.2759 - accuracy: 0.3325 - val_loss: 1.0743 - val_accuracy: 0.4393\n",
      "Epoch 67/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.2747 - accuracy: 0.3439 - val_loss: 1.0730 - val_accuracy: 0.4486\n",
      "Epoch 68/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.2727 - accuracy: 0.3537 - val_loss: 1.0716 - val_accuracy: 0.4579\n",
      "Epoch 69/200\n",
      "2553/2553 [==============================] - 0s 51us/sample - loss: 1.2668 - accuracy: 0.3408 - val_loss: 1.0704 - val_accuracy: 0.4579\n",
      "Epoch 70/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.2643 - accuracy: 0.3361 - val_loss: 1.0692 - val_accuracy: 0.4579\n",
      "Epoch 71/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.2562 - accuracy: 0.3470 - val_loss: 1.0679 - val_accuracy: 0.4579\n",
      "Epoch 72/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.2577 - accuracy: 0.3361 - val_loss: 1.0668 - val_accuracy: 0.4579\n",
      "Epoch 73/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.2520 - accuracy: 0.3376 - val_loss: 1.0655 - val_accuracy: 0.4579\n",
      "Epoch 74/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.2622 - accuracy: 0.3384 - val_loss: 1.0644 - val_accuracy: 0.4486\n",
      "Epoch 75/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.2420 - accuracy: 0.3549 - val_loss: 1.0632 - val_accuracy: 0.4486\n",
      "Epoch 76/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.2655 - accuracy: 0.3353 - val_loss: 1.0621 - val_accuracy: 0.4486\n",
      "Epoch 77/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.2446 - accuracy: 0.3314 - val_loss: 1.0610 - val_accuracy: 0.4486\n",
      "Epoch 78/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.2490 - accuracy: 0.3228 - val_loss: 1.0600 - val_accuracy: 0.4486\n",
      "Epoch 79/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.2353 - accuracy: 0.3482 - val_loss: 1.0589 - val_accuracy: 0.4486\n",
      "Epoch 80/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.2299 - accuracy: 0.3580 - val_loss: 1.0579 - val_accuracy: 0.4486\n",
      "Epoch 81/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.2234 - accuracy: 0.3474 - val_loss: 1.0569 - val_accuracy: 0.4393\n",
      "Epoch 82/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.2321 - accuracy: 0.3467 - val_loss: 1.0559 - val_accuracy: 0.4393\n",
      "Epoch 83/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.2226 - accuracy: 0.3549 - val_loss: 1.0549 - val_accuracy: 0.4393\n",
      "Epoch 84/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.2400 - accuracy: 0.3420 - val_loss: 1.0538 - val_accuracy: 0.4393\n",
      "Epoch 85/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.2204 - accuracy: 0.3498 - val_loss: 1.0529 - val_accuracy: 0.4393\n",
      "Epoch 86/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.2036 - accuracy: 0.3561 - val_loss: 1.0520 - val_accuracy: 0.4486\n",
      "Epoch 87/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.2315 - accuracy: 0.3510 - val_loss: 1.0511 - val_accuracy: 0.4486\n",
      "Epoch 88/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.2155 - accuracy: 0.3478 - val_loss: 1.0502 - val_accuracy: 0.4393\n",
      "Epoch 89/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.2182 - accuracy: 0.3349 - val_loss: 1.0494 - val_accuracy: 0.4393\n",
      "Epoch 90/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.2049 - accuracy: 0.3564 - val_loss: 1.0484 - val_accuracy: 0.4486\n",
      "Epoch 91/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.2169 - accuracy: 0.3561 - val_loss: 1.0475 - val_accuracy: 0.4486\n",
      "Epoch 92/200\n",
      "2553/2553 [==============================] - 0s 50us/sample - loss: 1.2109 - accuracy: 0.3541 - val_loss: 1.0467 - val_accuracy: 0.4486\n",
      "Epoch 93/200\n",
      "2553/2553 [==============================] - 0s 51us/sample - loss: 1.2100 - accuracy: 0.3529 - val_loss: 1.0458 - val_accuracy: 0.4393\n",
      "Epoch 94/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.2005 - accuracy: 0.3541 - val_loss: 1.0450 - val_accuracy: 0.4393\n",
      "Epoch 95/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.2014 - accuracy: 0.3470 - val_loss: 1.0443 - val_accuracy: 0.4393\n",
      "Epoch 96/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1812 - accuracy: 0.3584 - val_loss: 1.0436 - val_accuracy: 0.4299\n",
      "Epoch 97/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.2097 - accuracy: 0.3470 - val_loss: 1.0428 - val_accuracy: 0.4393\n",
      "Epoch 98/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1964 - accuracy: 0.3525 - val_loss: 1.0421 - val_accuracy: 0.4393\n",
      "Epoch 99/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.1988 - accuracy: 0.3564 - val_loss: 1.0413 - val_accuracy: 0.4486\n",
      "Epoch 100/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.2010 - accuracy: 0.3517 - val_loss: 1.0406 - val_accuracy: 0.4486\n",
      "Epoch 101/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1900 - accuracy: 0.3537 - val_loss: 1.0398 - val_accuracy: 0.4486\n",
      "Epoch 102/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1930 - accuracy: 0.3510 - val_loss: 1.0391 - val_accuracy: 0.4486\n",
      "Epoch 103/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1834 - accuracy: 0.3502 - val_loss: 1.0384 - val_accuracy: 0.4486\n",
      "Epoch 104/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1873 - accuracy: 0.3561 - val_loss: 1.0376 - val_accuracy: 0.4486\n",
      "Epoch 105/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1851 - accuracy: 0.3611 - val_loss: 1.0371 - val_accuracy: 0.4579\n",
      "Epoch 106/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.1731 - accuracy: 0.3608 - val_loss: 1.0366 - val_accuracy: 0.4579\n",
      "Epoch 107/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.1951 - accuracy: 0.3545 - val_loss: 1.0360 - val_accuracy: 0.4579\n",
      "Epoch 108/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1628 - accuracy: 0.3670 - val_loss: 1.0354 - val_accuracy: 0.4579\n",
      "Epoch 109/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1725 - accuracy: 0.3568 - val_loss: 1.0348 - val_accuracy: 0.4486\n",
      "Epoch 110/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1904 - accuracy: 0.3447 - val_loss: 1.0344 - val_accuracy: 0.4486\n",
      "Epoch 111/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1814 - accuracy: 0.3412 - val_loss: 1.0340 - val_accuracy: 0.4486\n",
      "Epoch 112/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1651 - accuracy: 0.3576 - val_loss: 1.0335 - val_accuracy: 0.4486\n",
      "Epoch 113/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1700 - accuracy: 0.3572 - val_loss: 1.0329 - val_accuracy: 0.4486\n",
      "Epoch 114/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.1715 - accuracy: 0.3510 - val_loss: 1.0324 - val_accuracy: 0.4486\n",
      "Epoch 115/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1671 - accuracy: 0.3576 - val_loss: 1.0319 - val_accuracy: 0.4486\n",
      "Epoch 116/200\n",
      "2553/2553 [==============================] - 0s 51us/sample - loss: 1.1589 - accuracy: 0.3678 - val_loss: 1.0313 - val_accuracy: 0.4486\n",
      "Epoch 117/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.1568 - accuracy: 0.3745 - val_loss: 1.0308 - val_accuracy: 0.4486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1743 - accuracy: 0.3470 - val_loss: 1.0304 - val_accuracy: 0.4486\n",
      "Epoch 119/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1655 - accuracy: 0.3658 - val_loss: 1.0299 - val_accuracy: 0.4486\n",
      "Epoch 120/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1643 - accuracy: 0.3580 - val_loss: 1.0295 - val_accuracy: 0.4486\n",
      "Epoch 121/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.1560 - accuracy: 0.3611 - val_loss: 1.0291 - val_accuracy: 0.4579\n",
      "Epoch 122/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1566 - accuracy: 0.3666 - val_loss: 1.0286 - val_accuracy: 0.4579\n",
      "Epoch 123/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.1502 - accuracy: 0.3745 - val_loss: 1.0282 - val_accuracy: 0.4579\n",
      "Epoch 124/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.1497 - accuracy: 0.3655 - val_loss: 1.0279 - val_accuracy: 0.4579\n",
      "Epoch 125/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.1510 - accuracy: 0.3674 - val_loss: 1.0276 - val_accuracy: 0.4579\n",
      "Epoch 126/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1521 - accuracy: 0.3721 - val_loss: 1.0273 - val_accuracy: 0.4579\n",
      "Epoch 127/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1296 - accuracy: 0.3662 - val_loss: 1.0269 - val_accuracy: 0.4579\n",
      "Epoch 128/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1479 - accuracy: 0.3525 - val_loss: 1.0266 - val_accuracy: 0.4579\n",
      "Epoch 129/200\n",
      "2553/2553 [==============================] - 0s 51us/sample - loss: 1.1503 - accuracy: 0.3568 - val_loss: 1.0262 - val_accuracy: 0.4579\n",
      "Epoch 130/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1517 - accuracy: 0.3545 - val_loss: 1.0259 - val_accuracy: 0.4579\n",
      "Epoch 131/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.1504 - accuracy: 0.3572 - val_loss: 1.0257 - val_accuracy: 0.4579\n",
      "Epoch 132/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1464 - accuracy: 0.3557 - val_loss: 1.0253 - val_accuracy: 0.4579\n",
      "Epoch 133/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1407 - accuracy: 0.3470 - val_loss: 1.0250 - val_accuracy: 0.4579\n",
      "Epoch 134/200\n",
      "2553/2553 [==============================] - 0s 51us/sample - loss: 1.1452 - accuracy: 0.3611 - val_loss: 1.0249 - val_accuracy: 0.4579\n",
      "Epoch 135/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.1357 - accuracy: 0.3792 - val_loss: 1.0246 - val_accuracy: 0.4673\n",
      "Epoch 136/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.1458 - accuracy: 0.3553 - val_loss: 1.0243 - val_accuracy: 0.4673\n",
      "Epoch 137/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1524 - accuracy: 0.3611 - val_loss: 1.0241 - val_accuracy: 0.4673\n",
      "Epoch 138/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1363 - accuracy: 0.3709 - val_loss: 1.0239 - val_accuracy: 0.4579\n",
      "Epoch 139/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1432 - accuracy: 0.3572 - val_loss: 1.0237 - val_accuracy: 0.4579\n",
      "Epoch 140/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.1149 - accuracy: 0.3776 - val_loss: 1.0234 - val_accuracy: 0.4579\n",
      "Epoch 141/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1317 - accuracy: 0.3647 - val_loss: 1.0233 - val_accuracy: 0.4486\n",
      "Epoch 142/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.1304 - accuracy: 0.3639 - val_loss: 1.0231 - val_accuracy: 0.4486\n",
      "Epoch 143/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1368 - accuracy: 0.3517 - val_loss: 1.0229 - val_accuracy: 0.4579\n",
      "Epoch 144/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1332 - accuracy: 0.3631 - val_loss: 1.0226 - val_accuracy: 0.4579\n",
      "Epoch 145/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1281 - accuracy: 0.3725 - val_loss: 1.0223 - val_accuracy: 0.4579\n",
      "Epoch 146/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1274 - accuracy: 0.3662 - val_loss: 1.0221 - val_accuracy: 0.4579\n",
      "Epoch 147/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.1246 - accuracy: 0.3627 - val_loss: 1.0219 - val_accuracy: 0.4673\n",
      "Epoch 148/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1246 - accuracy: 0.3658 - val_loss: 1.0217 - val_accuracy: 0.4673\n",
      "Epoch 149/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1256 - accuracy: 0.3600 - val_loss: 1.0214 - val_accuracy: 0.4673\n",
      "Epoch 150/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.1267 - accuracy: 0.3635 - val_loss: 1.0211 - val_accuracy: 0.4766\n",
      "Epoch 151/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.1018 - accuracy: 0.3811 - val_loss: 1.0207 - val_accuracy: 0.4766\n",
      "Epoch 152/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1176 - accuracy: 0.3658 - val_loss: 1.0205 - val_accuracy: 0.4766\n",
      "Epoch 153/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1310 - accuracy: 0.3658 - val_loss: 1.0204 - val_accuracy: 0.4766\n",
      "Epoch 154/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.1216 - accuracy: 0.3658 - val_loss: 1.0202 - val_accuracy: 0.4766\n",
      "Epoch 155/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1201 - accuracy: 0.3819 - val_loss: 1.0199 - val_accuracy: 0.4766\n",
      "Epoch 156/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1157 - accuracy: 0.3788 - val_loss: 1.0196 - val_accuracy: 0.4953\n",
      "Epoch 157/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.1146 - accuracy: 0.3725 - val_loss: 1.0194 - val_accuracy: 0.4953\n",
      "Epoch 158/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1108 - accuracy: 0.3764 - val_loss: 1.0192 - val_accuracy: 0.4953\n",
      "Epoch 159/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1128 - accuracy: 0.3662 - val_loss: 1.0190 - val_accuracy: 0.4953\n",
      "Epoch 160/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1115 - accuracy: 0.3674 - val_loss: 1.0188 - val_accuracy: 0.4953\n",
      "Epoch 161/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1094 - accuracy: 0.3576 - val_loss: 1.0187 - val_accuracy: 0.4953\n",
      "Epoch 162/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.1095 - accuracy: 0.3839 - val_loss: 1.0185 - val_accuracy: 0.4953\n",
      "Epoch 163/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1158 - accuracy: 0.3678 - val_loss: 1.0184 - val_accuracy: 0.4953\n",
      "Epoch 164/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.1109 - accuracy: 0.3713 - val_loss: 1.0183 - val_accuracy: 0.4953\n",
      "Epoch 165/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1052 - accuracy: 0.3780 - val_loss: 1.0181 - val_accuracy: 0.4953\n",
      "Epoch 166/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.1133 - accuracy: 0.3635 - val_loss: 1.0179 - val_accuracy: 0.4953\n",
      "Epoch 167/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1102 - accuracy: 0.3615 - val_loss: 1.0178 - val_accuracy: 0.4953\n",
      "Epoch 168/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1152 - accuracy: 0.3662 - val_loss: 1.0176 - val_accuracy: 0.5047\n",
      "Epoch 169/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0974 - accuracy: 0.3733 - val_loss: 1.0175 - val_accuracy: 0.5047\n",
      "Epoch 170/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.1078 - accuracy: 0.3713 - val_loss: 1.0173 - val_accuracy: 0.5047\n",
      "Epoch 171/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.1048 - accuracy: 0.3784 - val_loss: 1.0172 - val_accuracy: 0.5047\n",
      "Epoch 172/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0954 - accuracy: 0.3756 - val_loss: 1.0170 - val_accuracy: 0.5047\n",
      "Epoch 173/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.0904 - accuracy: 0.3854 - val_loss: 1.0168 - val_accuracy: 0.5047\n",
      "Epoch 174/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0948 - accuracy: 0.3792 - val_loss: 1.0166 - val_accuracy: 0.5047\n",
      "Epoch 175/200\n",
      "2553/2553 [==============================] - 0s 65us/sample - loss: 1.0990 - accuracy: 0.3788 - val_loss: 1.0164 - val_accuracy: 0.5047\n",
      "Epoch 176/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0855 - accuracy: 0.3827 - val_loss: 1.0162 - val_accuracy: 0.5047\n",
      "Epoch 177/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.1054 - accuracy: 0.3631 - val_loss: 1.0162 - val_accuracy: 0.5047\n",
      "Epoch 178/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1022 - accuracy: 0.3760 - val_loss: 1.0161 - val_accuracy: 0.5047\n",
      "Epoch 179/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0949 - accuracy: 0.3909 - val_loss: 1.0160 - val_accuracy: 0.5047\n",
      "Epoch 180/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.0979 - accuracy: 0.3803 - val_loss: 1.0159 - val_accuracy: 0.5047\n",
      "Epoch 181/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0988 - accuracy: 0.3827 - val_loss: 1.0158 - val_accuracy: 0.5140\n",
      "Epoch 182/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0870 - accuracy: 0.3854 - val_loss: 1.0156 - val_accuracy: 0.5140\n",
      "Epoch 183/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.0953 - accuracy: 0.3709 - val_loss: 1.0154 - val_accuracy: 0.5140\n",
      "Epoch 184/200\n",
      "2553/2553 [==============================] - 0s 81us/sample - loss: 1.0892 - accuracy: 0.3862 - val_loss: 1.0152 - val_accuracy: 0.5140\n",
      "Epoch 185/200\n",
      "2553/2553 [==============================] - 0s 82us/sample - loss: 1.0835 - accuracy: 0.3737 - val_loss: 1.0150 - val_accuracy: 0.5140\n",
      "Epoch 186/200\n",
      "2553/2553 [==============================] - 0s 84us/sample - loss: 1.0891 - accuracy: 0.3737 - val_loss: 1.0148 - val_accuracy: 0.5140\n",
      "Epoch 187/200\n",
      "2553/2553 [==============================] - 0s 81us/sample - loss: 1.0926 - accuracy: 0.3764 - val_loss: 1.0147 - val_accuracy: 0.5140\n",
      "Epoch 188/200\n",
      "2553/2553 [==============================] - 0s 83us/sample - loss: 1.0886 - accuracy: 0.3831 - val_loss: 1.0146 - val_accuracy: 0.5140\n",
      "Epoch 189/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0946 - accuracy: 0.3803 - val_loss: 1.0145 - val_accuracy: 0.5140\n",
      "Epoch 190/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0851 - accuracy: 0.3858 - val_loss: 1.0145 - val_accuracy: 0.5234\n",
      "Epoch 191/200\n",
      "2553/2553 [==============================] - 0s 66us/sample - loss: 1.0895 - accuracy: 0.3764 - val_loss: 1.0144 - val_accuracy: 0.5234\n",
      "Epoch 192/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.0851 - accuracy: 0.3807 - val_loss: 1.0142 - val_accuracy: 0.5234\n",
      "Epoch 193/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0923 - accuracy: 0.3799 - val_loss: 1.0141 - val_accuracy: 0.5234\n",
      "Epoch 194/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0875 - accuracy: 0.3733 - val_loss: 1.0139 - val_accuracy: 0.5327\n",
      "Epoch 195/200\n",
      "2553/2553 [==============================] - 0s 51us/sample - loss: 1.0945 - accuracy: 0.3772 - val_loss: 1.0139 - val_accuracy: 0.5327\n",
      "Epoch 196/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0894 - accuracy: 0.3831 - val_loss: 1.0138 - val_accuracy: 0.5421\n",
      "Epoch 197/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0829 - accuracy: 0.3890 - val_loss: 1.0136 - val_accuracy: 0.5421\n",
      "Epoch 198/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0709 - accuracy: 0.4050 - val_loss: 1.0134 - val_accuracy: 0.5421\n",
      "Epoch 199/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0825 - accuracy: 0.3843 - val_loss: 1.0133 - val_accuracy: 0.5514\n",
      "Epoch 200/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0900 - accuracy: 0.3666 - val_loss: 1.0132 - val_accuracy: 0.5514\n",
      "0.55140185 {'loss': 1.0900274840607813, 'accuracy': 0.36662748, 'val_loss': 1.0131895987786979, 'val_accuracy': 0.55140185}\n",
      "Model: \"model_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_23 (InputLayer)        [(None, 29)]              0         \n",
      "_________________________________________________________________\n",
      "flatten_22 (Flatten)         (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_82 (Dense)             (None, 41)                1230      \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 75)                3150      \n",
      "_________________________________________________________________\n",
      "dense_84 (Dense)             (None, 3)                 228       \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 4,608\n",
      "Trainable params: 4,608\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2553 samples, validate on 107 samples\n",
      "Epoch 1/200\n",
      "2553/2553 [==============================] - 1s 394us/sample - loss: 1.4150 - accuracy: 0.2852 - val_loss: 1.2060 - val_accuracy: 0.3364\n",
      "Epoch 2/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.4140 - accuracy: 0.2902 - val_loss: 1.2018 - val_accuracy: 0.3364\n",
      "Epoch 3/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.4011 - accuracy: 0.2996 - val_loss: 1.1980 - val_accuracy: 0.3364\n",
      "Epoch 4/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.4031 - accuracy: 0.2824 - val_loss: 1.1940 - val_accuracy: 0.3364\n",
      "Epoch 5/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.3712 - accuracy: 0.2910 - val_loss: 1.1903 - val_accuracy: 0.3364\n",
      "Epoch 6/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.3639 - accuracy: 0.2934 - val_loss: 1.1868 - val_accuracy: 0.3364\n",
      "Epoch 7/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.3633 - accuracy: 0.2946 - val_loss: 1.1834 - val_accuracy: 0.3364\n",
      "Epoch 8/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.3468 - accuracy: 0.2946 - val_loss: 1.1800 - val_accuracy: 0.3364\n",
      "Epoch 9/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.3482 - accuracy: 0.2961 - val_loss: 1.1766 - val_accuracy: 0.3364\n",
      "Epoch 10/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.3366 - accuracy: 0.2981 - val_loss: 1.1731 - val_accuracy: 0.3364\n",
      "Epoch 11/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.3409 - accuracy: 0.2761 - val_loss: 1.1699 - val_accuracy: 0.3364\n",
      "Epoch 12/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.3199 - accuracy: 0.2973 - val_loss: 1.1667 - val_accuracy: 0.3364\n",
      "Epoch 13/200\n",
      "2553/2553 [==============================] - 0s 99us/sample - loss: 1.3360 - accuracy: 0.2914 - val_loss: 1.1635 - val_accuracy: 0.3458\n",
      "Epoch 14/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.3023 - accuracy: 0.2985 - val_loss: 1.1606 - val_accuracy: 0.3551\n",
      "Epoch 15/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.2998 - accuracy: 0.2989 - val_loss: 1.1578 - val_accuracy: 0.3458\n",
      "Epoch 16/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.2959 - accuracy: 0.3020 - val_loss: 1.1548 - val_accuracy: 0.3458\n",
      "Epoch 17/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.2527 - accuracy: 0.3067 - val_loss: 1.1523 - val_accuracy: 0.3364\n",
      "Epoch 18/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.2668 - accuracy: 0.3075 - val_loss: 1.1495 - val_accuracy: 0.3458\n",
      "Epoch 19/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.2911 - accuracy: 0.2910 - val_loss: 1.1469 - val_accuracy: 0.3458\n",
      "Epoch 20/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.2737 - accuracy: 0.3032 - val_loss: 1.1441 - val_accuracy: 0.3364\n",
      "Epoch 21/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.2742 - accuracy: 0.2922 - val_loss: 1.1417 - val_accuracy: 0.3458\n",
      "Epoch 22/200\n",
      "2553/2553 [==============================] - 0s 98us/sample - loss: 1.2448 - accuracy: 0.3028 - val_loss: 1.1392 - val_accuracy: 0.3458\n",
      "Epoch 23/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.2292 - accuracy: 0.2930 - val_loss: 1.1371 - val_accuracy: 0.3458\n",
      "Epoch 24/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.2346 - accuracy: 0.3055 - val_loss: 1.1351 - val_accuracy: 0.3458\n",
      "Epoch 25/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.2524 - accuracy: 0.2910 - val_loss: 1.1326 - val_accuracy: 0.3364\n",
      "Epoch 26/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.2302 - accuracy: 0.3043 - val_loss: 1.1302 - val_accuracy: 0.3271\n",
      "Epoch 27/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.2320 - accuracy: 0.3059 - val_loss: 1.1282 - val_accuracy: 0.3178\n",
      "Epoch 28/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.2177 - accuracy: 0.3055 - val_loss: 1.1263 - val_accuracy: 0.3084\n",
      "Epoch 29/200\n",
      "2553/2553 [==============================] - 0s 99us/sample - loss: 1.1974 - accuracy: 0.3122 - val_loss: 1.1244 - val_accuracy: 0.3178\n",
      "Epoch 30/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.2144 - accuracy: 0.3040 - val_loss: 1.1224 - val_accuracy: 0.3178\n",
      "Epoch 31/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.1902 - accuracy: 0.3153 - val_loss: 1.1207 - val_accuracy: 0.3178\n",
      "Epoch 32/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.2047 - accuracy: 0.3043 - val_loss: 1.1188 - val_accuracy: 0.3178\n",
      "Epoch 33/200\n",
      "2553/2553 [==============================] - 0s 98us/sample - loss: 1.1668 - accuracy: 0.3267 - val_loss: 1.1170 - val_accuracy: 0.3178\n",
      "Epoch 34/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.1875 - accuracy: 0.3079 - val_loss: 1.1152 - val_accuracy: 0.3271\n",
      "Epoch 35/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.1918 - accuracy: 0.3028 - val_loss: 1.1136 - val_accuracy: 0.3271\n",
      "Epoch 36/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.1934 - accuracy: 0.3063 - val_loss: 1.1122 - val_accuracy: 0.3271\n",
      "Epoch 37/200\n",
      "2553/2553 [==============================] - 0s 95us/sample - loss: 1.1712 - accuracy: 0.3032 - val_loss: 1.1107 - val_accuracy: 0.3364\n",
      "Epoch 38/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.1609 - accuracy: 0.3184 - val_loss: 1.1094 - val_accuracy: 0.3364\n",
      "Epoch 39/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.1728 - accuracy: 0.3149 - val_loss: 1.1079 - val_accuracy: 0.3271\n",
      "Epoch 40/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.1695 - accuracy: 0.3024 - val_loss: 1.1066 - val_accuracy: 0.3364\n",
      "Epoch 41/200\n",
      "2553/2553 [==============================] - 0s 99us/sample - loss: 1.1629 - accuracy: 0.3208 - val_loss: 1.1052 - val_accuracy: 0.3271\n",
      "Epoch 42/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.1603 - accuracy: 0.3102 - val_loss: 1.1042 - val_accuracy: 0.3271\n",
      "Epoch 43/200\n",
      "2553/2553 [==============================] - 0s 99us/sample - loss: 1.1540 - accuracy: 0.3122 - val_loss: 1.1028 - val_accuracy: 0.3271\n",
      "Epoch 44/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.1404 - accuracy: 0.3275 - val_loss: 1.1014 - val_accuracy: 0.3271\n",
      "Epoch 45/200\n",
      "2553/2553 [==============================] - 0s 96us/sample - loss: 1.1378 - accuracy: 0.3271 - val_loss: 1.1001 - val_accuracy: 0.3271\n",
      "Epoch 46/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.1541 - accuracy: 0.3106 - val_loss: 1.0989 - val_accuracy: 0.3271\n",
      "Epoch 47/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.1436 - accuracy: 0.3149 - val_loss: 1.0978 - val_accuracy: 0.3271\n",
      "Epoch 48/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.1544 - accuracy: 0.2957 - val_loss: 1.0965 - val_accuracy: 0.3271\n",
      "Epoch 49/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.1451 - accuracy: 0.3181 - val_loss: 1.0955 - val_accuracy: 0.3271\n",
      "Epoch 50/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.1348 - accuracy: 0.3271 - val_loss: 1.0945 - val_accuracy: 0.3178\n",
      "Epoch 51/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.1413 - accuracy: 0.3137 - val_loss: 1.0936 - val_accuracy: 0.3271\n",
      "Epoch 52/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.1377 - accuracy: 0.3137 - val_loss: 1.0927 - val_accuracy: 0.3364\n",
      "Epoch 53/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.1313 - accuracy: 0.3220 - val_loss: 1.0919 - val_accuracy: 0.3364\n",
      "Epoch 54/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.1264 - accuracy: 0.3184 - val_loss: 1.0911 - val_accuracy: 0.3364\n",
      "Epoch 55/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.1430 - accuracy: 0.3075 - val_loss: 1.0905 - val_accuracy: 0.3364\n",
      "Epoch 56/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.1319 - accuracy: 0.3184 - val_loss: 1.0897 - val_accuracy: 0.3364\n",
      "Epoch 57/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.1240 - accuracy: 0.3208 - val_loss: 1.0892 - val_accuracy: 0.3271\n",
      "Epoch 58/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.1290 - accuracy: 0.3087 - val_loss: 1.0885 - val_accuracy: 0.3271\n",
      "Epoch 59/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.1356 - accuracy: 0.3063 - val_loss: 1.0878 - val_accuracy: 0.3271\n",
      "Epoch 60/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.1205 - accuracy: 0.3204 - val_loss: 1.0870 - val_accuracy: 0.3364\n",
      "Epoch 61/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.1273 - accuracy: 0.3114 - val_loss: 1.0864 - val_accuracy: 0.3364\n",
      "Epoch 62/200\n",
      "2553/2553 [==============================] - 0s 99us/sample - loss: 1.1215 - accuracy: 0.3224 - val_loss: 1.0856 - val_accuracy: 0.3364\n",
      "Epoch 63/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.1140 - accuracy: 0.3278 - val_loss: 1.0849 - val_accuracy: 0.3364\n",
      "Epoch 64/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.1147 - accuracy: 0.3114 - val_loss: 1.0842 - val_accuracy: 0.3458\n",
      "Epoch 65/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.1063 - accuracy: 0.3231 - val_loss: 1.0836 - val_accuracy: 0.3458\n",
      "Epoch 66/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.1170 - accuracy: 0.3184 - val_loss: 1.0831 - val_accuracy: 0.3458\n",
      "Epoch 67/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.1185 - accuracy: 0.3118 - val_loss: 1.0826 - val_accuracy: 0.3458\n",
      "Epoch 68/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.1148 - accuracy: 0.3043 - val_loss: 1.0822 - val_accuracy: 0.3458\n",
      "Epoch 69/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.1022 - accuracy: 0.3286 - val_loss: 1.0818 - val_accuracy: 0.3551\n",
      "Epoch 70/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.1093 - accuracy: 0.3259 - val_loss: 1.0813 - val_accuracy: 0.3551\n",
      "Epoch 71/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.1238 - accuracy: 0.3036 - val_loss: 1.0809 - val_accuracy: 0.3551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.1174 - accuracy: 0.3141 - val_loss: 1.0807 - val_accuracy: 0.3645\n",
      "Epoch 73/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.1125 - accuracy: 0.3161 - val_loss: 1.0806 - val_accuracy: 0.3645\n",
      "Epoch 74/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.1168 - accuracy: 0.3118 - val_loss: 1.0806 - val_accuracy: 0.3738\n",
      "Epoch 75/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.1013 - accuracy: 0.3177 - val_loss: 1.0801 - val_accuracy: 0.3738\n",
      "Epoch 76/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0983 - accuracy: 0.3306 - val_loss: 1.0796 - val_accuracy: 0.3738\n",
      "Epoch 77/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.1085 - accuracy: 0.3208 - val_loss: 1.0794 - val_accuracy: 0.3738\n",
      "Epoch 78/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0999 - accuracy: 0.3294 - val_loss: 1.0791 - val_accuracy: 0.3738\n",
      "Epoch 79/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.1019 - accuracy: 0.3208 - val_loss: 1.0787 - val_accuracy: 0.3645\n",
      "Epoch 80/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.0966 - accuracy: 0.3322 - val_loss: 1.0781 - val_accuracy: 0.3645\n",
      "Epoch 81/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0978 - accuracy: 0.3290 - val_loss: 1.0776 - val_accuracy: 0.3645\n",
      "Epoch 82/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.1066 - accuracy: 0.3231 - val_loss: 1.0774 - val_accuracy: 0.3645\n",
      "Epoch 83/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.0943 - accuracy: 0.3239 - val_loss: 1.0769 - val_accuracy: 0.3738\n",
      "Epoch 84/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.1032 - accuracy: 0.3239 - val_loss: 1.0769 - val_accuracy: 0.3738\n",
      "Epoch 85/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.1050 - accuracy: 0.3145 - val_loss: 1.0767 - val_accuracy: 0.3645\n",
      "Epoch 86/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0923 - accuracy: 0.3255 - val_loss: 1.0764 - val_accuracy: 0.3738\n",
      "Epoch 87/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0958 - accuracy: 0.3263 - val_loss: 1.0761 - val_accuracy: 0.3832\n",
      "Epoch 88/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0963 - accuracy: 0.3278 - val_loss: 1.0757 - val_accuracy: 0.3832\n",
      "Epoch 89/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0960 - accuracy: 0.3239 - val_loss: 1.0754 - val_accuracy: 0.3832\n",
      "Epoch 90/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0890 - accuracy: 0.3314 - val_loss: 1.0751 - val_accuracy: 0.3832\n",
      "Epoch 91/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.1016 - accuracy: 0.3184 - val_loss: 1.0751 - val_accuracy: 0.3925\n",
      "Epoch 92/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.0931 - accuracy: 0.3263 - val_loss: 1.0749 - val_accuracy: 0.3925\n",
      "Epoch 93/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.1014 - accuracy: 0.3263 - val_loss: 1.0748 - val_accuracy: 0.3925\n",
      "Epoch 94/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.1042 - accuracy: 0.3228 - val_loss: 1.0748 - val_accuracy: 0.3832\n",
      "Epoch 95/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.0952 - accuracy: 0.3231 - val_loss: 1.0747 - val_accuracy: 0.3832\n",
      "Epoch 96/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.0885 - accuracy: 0.3302 - val_loss: 1.0743 - val_accuracy: 0.3832\n",
      "Epoch 97/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.0996 - accuracy: 0.3196 - val_loss: 1.0742 - val_accuracy: 0.3645\n",
      "Epoch 98/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.1024 - accuracy: 0.3067 - val_loss: 1.0742 - val_accuracy: 0.3645\n",
      "Epoch 99/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0959 - accuracy: 0.3255 - val_loss: 1.0741 - val_accuracy: 0.3738\n",
      "Epoch 100/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0943 - accuracy: 0.3243 - val_loss: 1.0741 - val_accuracy: 0.3738\n",
      "Epoch 101/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.0928 - accuracy: 0.3259 - val_loss: 1.0740 - val_accuracy: 0.3738\n",
      "Epoch 102/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.0966 - accuracy: 0.3243 - val_loss: 1.0737 - val_accuracy: 0.3738\n",
      "Epoch 103/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0861 - accuracy: 0.3337 - val_loss: 1.0734 - val_accuracy: 0.3738\n",
      "Epoch 104/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0985 - accuracy: 0.3188 - val_loss: 1.0731 - val_accuracy: 0.3738\n",
      "Epoch 105/200\n",
      "2553/2553 [==============================] - 0s 98us/sample - loss: 1.0948 - accuracy: 0.3220 - val_loss: 1.0733 - val_accuracy: 0.3738\n",
      "Epoch 106/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.0860 - accuracy: 0.3157 - val_loss: 1.0730 - val_accuracy: 0.3738\n",
      "Epoch 107/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0945 - accuracy: 0.3216 - val_loss: 1.0730 - val_accuracy: 0.3738\n",
      "Epoch 108/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0943 - accuracy: 0.3145 - val_loss: 1.0731 - val_accuracy: 0.3738\n",
      "Epoch 109/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0941 - accuracy: 0.3157 - val_loss: 1.0729 - val_accuracy: 0.3738\n",
      "Epoch 110/200\n",
      "2553/2553 [==============================] - 0s 99us/sample - loss: 1.0899 - accuracy: 0.3294 - val_loss: 1.0726 - val_accuracy: 0.3738\n",
      "Epoch 111/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0880 - accuracy: 0.3251 - val_loss: 1.0724 - val_accuracy: 0.3738\n",
      "Epoch 112/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0877 - accuracy: 0.3224 - val_loss: 1.0723 - val_accuracy: 0.3738\n",
      "Epoch 113/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0924 - accuracy: 0.3243 - val_loss: 1.0722 - val_accuracy: 0.3738\n",
      "Epoch 114/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0895 - accuracy: 0.3259 - val_loss: 1.0720 - val_accuracy: 0.3738\n",
      "Epoch 115/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.0956 - accuracy: 0.3216 - val_loss: 1.0722 - val_accuracy: 0.3832\n",
      "Epoch 116/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.0934 - accuracy: 0.3247 - val_loss: 1.0722 - val_accuracy: 0.3832\n",
      "Epoch 117/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.0910 - accuracy: 0.3208 - val_loss: 1.0721 - val_accuracy: 0.3832\n",
      "Epoch 118/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0862 - accuracy: 0.3130 - val_loss: 1.0720 - val_accuracy: 0.3832\n",
      "Epoch 119/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0903 - accuracy: 0.3161 - val_loss: 1.0720 - val_accuracy: 0.3832\n",
      "Epoch 120/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0870 - accuracy: 0.3251 - val_loss: 1.0717 - val_accuracy: 0.3832\n",
      "Epoch 121/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.0884 - accuracy: 0.3271 - val_loss: 1.0715 - val_accuracy: 0.3832\n",
      "Epoch 122/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0865 - accuracy: 0.3298 - val_loss: 1.0713 - val_accuracy: 0.3832\n",
      "Epoch 123/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0857 - accuracy: 0.3294 - val_loss: 1.0710 - val_accuracy: 0.3832\n",
      "Epoch 124/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0814 - accuracy: 0.3294 - val_loss: 1.0706 - val_accuracy: 0.3832\n",
      "Epoch 125/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.0853 - accuracy: 0.3322 - val_loss: 1.0702 - val_accuracy: 0.3925\n",
      "Epoch 126/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0870 - accuracy: 0.3302 - val_loss: 1.0700 - val_accuracy: 0.3925\n",
      "Epoch 127/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0837 - accuracy: 0.3184 - val_loss: 1.0698 - val_accuracy: 0.3925\n",
      "Epoch 128/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0929 - accuracy: 0.3286 - val_loss: 1.0698 - val_accuracy: 0.3925\n",
      "Epoch 129/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.0910 - accuracy: 0.3259 - val_loss: 1.0699 - val_accuracy: 0.3925\n",
      "Epoch 130/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0849 - accuracy: 0.3278 - val_loss: 1.0695 - val_accuracy: 0.3925\n",
      "Epoch 131/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0823 - accuracy: 0.3357 - val_loss: 1.0694 - val_accuracy: 0.3925\n",
      "Epoch 132/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0978 - accuracy: 0.3165 - val_loss: 1.0697 - val_accuracy: 0.3925\n",
      "Epoch 133/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0856 - accuracy: 0.3322 - val_loss: 1.0696 - val_accuracy: 0.3925\n",
      "Epoch 134/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.0873 - accuracy: 0.3228 - val_loss: 1.0695 - val_accuracy: 0.3925\n",
      "Epoch 135/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.0825 - accuracy: 0.3310 - val_loss: 1.0693 - val_accuracy: 0.3925\n",
      "Epoch 136/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0877 - accuracy: 0.3192 - val_loss: 1.0694 - val_accuracy: 0.3832\n",
      "Epoch 137/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0836 - accuracy: 0.3251 - val_loss: 1.0694 - val_accuracy: 0.3832\n",
      "Epoch 138/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0860 - accuracy: 0.3278 - val_loss: 1.0694 - val_accuracy: 0.3832\n",
      "Epoch 139/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 1.0721 - accuracy: 0.3408 - val_loss: 1.0689 - val_accuracy: 0.3832\n",
      "Epoch 140/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.0835 - accuracy: 0.3239 - val_loss: 1.0688 - val_accuracy: 0.3832\n",
      "Epoch 141/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0919 - accuracy: 0.3204 - val_loss: 1.0690 - val_accuracy: 0.3832\n",
      "Epoch 142/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0895 - accuracy: 0.3255 - val_loss: 1.0689 - val_accuracy: 0.3832\n",
      "Epoch 143/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0916 - accuracy: 0.3224 - val_loss: 1.0690 - val_accuracy: 0.3832\n",
      "Epoch 144/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0832 - accuracy: 0.3212 - val_loss: 1.0689 - val_accuracy: 0.3832\n",
      "Epoch 145/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.0865 - accuracy: 0.3267 - val_loss: 1.0689 - val_accuracy: 0.4019\n",
      "Epoch 146/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0817 - accuracy: 0.3302 - val_loss: 1.0688 - val_accuracy: 0.4019\n",
      "Epoch 147/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.0807 - accuracy: 0.3306 - val_loss: 1.0684 - val_accuracy: 0.4112\n",
      "Epoch 148/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.0836 - accuracy: 0.3259 - val_loss: 1.0683 - val_accuracy: 0.4112\n",
      "Epoch 149/200\n",
      "2553/2553 [==============================] - 0s 99us/sample - loss: 1.0865 - accuracy: 0.3247 - val_loss: 1.0681 - val_accuracy: 0.4112\n",
      "Epoch 150/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0855 - accuracy: 0.3290 - val_loss: 1.0680 - val_accuracy: 0.4112\n",
      "Epoch 151/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0841 - accuracy: 0.3337 - val_loss: 1.0678 - val_accuracy: 0.4112\n",
      "Epoch 152/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0790 - accuracy: 0.3341 - val_loss: 1.0675 - val_accuracy: 0.4206\n",
      "Epoch 153/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.0849 - accuracy: 0.3365 - val_loss: 1.0674 - val_accuracy: 0.4206\n",
      "Epoch 154/200\n",
      "2553/2553 [==============================] - 0s 119us/sample - loss: 1.0757 - accuracy: 0.3380 - val_loss: 1.0673 - val_accuracy: 0.4206\n",
      "Epoch 155/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0830 - accuracy: 0.3333 - val_loss: 1.0673 - val_accuracy: 0.4206\n",
      "Epoch 156/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0836 - accuracy: 0.3239 - val_loss: 1.0672 - val_accuracy: 0.4206\n",
      "Epoch 157/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0824 - accuracy: 0.3333 - val_loss: 1.0669 - val_accuracy: 0.4206\n",
      "Epoch 158/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.0873 - accuracy: 0.3329 - val_loss: 1.0669 - val_accuracy: 0.4206\n",
      "Epoch 159/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0825 - accuracy: 0.3333 - val_loss: 1.0667 - val_accuracy: 0.4299\n",
      "Epoch 160/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0777 - accuracy: 0.3357 - val_loss: 1.0665 - val_accuracy: 0.4299\n",
      "Epoch 161/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0847 - accuracy: 0.3294 - val_loss: 1.0665 - val_accuracy: 0.4299\n",
      "Epoch 162/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0896 - accuracy: 0.3235 - val_loss: 1.0665 - val_accuracy: 0.4299\n",
      "Epoch 163/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0830 - accuracy: 0.3318 - val_loss: 1.0664 - val_accuracy: 0.4299\n",
      "Epoch 164/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.0819 - accuracy: 0.3357 - val_loss: 1.0663 - val_accuracy: 0.4393\n",
      "Epoch 165/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.0815 - accuracy: 0.3329 - val_loss: 1.0659 - val_accuracy: 0.4393\n",
      "Epoch 166/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.0731 - accuracy: 0.3408 - val_loss: 1.0655 - val_accuracy: 0.4393\n",
      "Epoch 167/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.0788 - accuracy: 0.3369 - val_loss: 1.0650 - val_accuracy: 0.4393\n",
      "Epoch 168/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0800 - accuracy: 0.3310 - val_loss: 1.0649 - val_accuracy: 0.4393\n",
      "Epoch 169/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0800 - accuracy: 0.3384 - val_loss: 1.0647 - val_accuracy: 0.4393\n",
      "Epoch 170/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.0822 - accuracy: 0.3392 - val_loss: 1.0645 - val_accuracy: 0.4393\n",
      "Epoch 171/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0913 - accuracy: 0.3302 - val_loss: 1.0645 - val_accuracy: 0.4393\n",
      "Epoch 172/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.0840 - accuracy: 0.3247 - val_loss: 1.0646 - val_accuracy: 0.4393\n",
      "Epoch 173/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.0754 - accuracy: 0.3337 - val_loss: 1.0644 - val_accuracy: 0.4393\n",
      "Epoch 174/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0918 - accuracy: 0.3188 - val_loss: 1.0647 - val_accuracy: 0.4393\n",
      "Epoch 175/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0873 - accuracy: 0.3306 - val_loss: 1.0649 - val_accuracy: 0.4393\n",
      "Epoch 176/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0725 - accuracy: 0.3345 - val_loss: 1.0646 - val_accuracy: 0.4393\n",
      "Epoch 177/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.0760 - accuracy: 0.3373 - val_loss: 1.0646 - val_accuracy: 0.4393\n",
      "Epoch 178/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0795 - accuracy: 0.3310 - val_loss: 1.0644 - val_accuracy: 0.4393\n",
      "Epoch 179/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0791 - accuracy: 0.3380 - val_loss: 1.0641 - val_accuracy: 0.4393\n",
      "Epoch 180/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0791 - accuracy: 0.3369 - val_loss: 1.0639 - val_accuracy: 0.4393\n",
      "Epoch 181/200\n",
      "2553/2553 [==============================] - 0s 99us/sample - loss: 1.0651 - accuracy: 0.3514 - val_loss: 1.0631 - val_accuracy: 0.4393\n",
      "Epoch 182/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0874 - accuracy: 0.3259 - val_loss: 1.0632 - val_accuracy: 0.4393\n",
      "Epoch 183/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0889 - accuracy: 0.3243 - val_loss: 1.0634 - val_accuracy: 0.4393\n",
      "Epoch 184/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0807 - accuracy: 0.3369 - val_loss: 1.0633 - val_accuracy: 0.4393\n",
      "Epoch 185/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.0818 - accuracy: 0.3427 - val_loss: 1.0632 - val_accuracy: 0.4393\n",
      "Epoch 186/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0770 - accuracy: 0.3400 - val_loss: 1.0630 - val_accuracy: 0.4393\n",
      "Epoch 187/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0808 - accuracy: 0.3314 - val_loss: 1.0628 - val_accuracy: 0.4393\n",
      "Epoch 188/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0786 - accuracy: 0.3408 - val_loss: 1.0628 - val_accuracy: 0.4393\n",
      "Epoch 189/200\n",
      "2553/2553 [==============================] - 0s 98us/sample - loss: 1.0822 - accuracy: 0.3298 - val_loss: 1.0630 - val_accuracy: 0.4393\n",
      "Epoch 190/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.0781 - accuracy: 0.3396 - val_loss: 1.0627 - val_accuracy: 0.4393\n",
      "Epoch 191/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0791 - accuracy: 0.3420 - val_loss: 1.0626 - val_accuracy: 0.4393\n",
      "Epoch 192/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0803 - accuracy: 0.3384 - val_loss: 1.0622 - val_accuracy: 0.4486\n",
      "Epoch 193/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0792 - accuracy: 0.3353 - val_loss: 1.0620 - val_accuracy: 0.4486\n",
      "Epoch 194/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.0828 - accuracy: 0.3408 - val_loss: 1.0619 - val_accuracy: 0.4486\n",
      "Epoch 195/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0722 - accuracy: 0.3408 - val_loss: 1.0616 - val_accuracy: 0.4486\n",
      "Epoch 196/200\n",
      "2553/2553 [==============================] - 0s 99us/sample - loss: 1.0809 - accuracy: 0.3400 - val_loss: 1.0616 - val_accuracy: 0.4486\n",
      "Epoch 197/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0760 - accuracy: 0.3482 - val_loss: 1.0615 - val_accuracy: 0.4486\n",
      "Epoch 198/200\n",
      "2553/2553 [==============================] - 0s 98us/sample - loss: 1.0784 - accuracy: 0.3388 - val_loss: 1.0616 - val_accuracy: 0.4486\n",
      "Epoch 199/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0848 - accuracy: 0.3412 - val_loss: 1.0618 - val_accuracy: 0.4486\n",
      "Epoch 200/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0834 - accuracy: 0.3333 - val_loss: 1.0620 - val_accuracy: 0.4486\n",
      "0.44859812 {'loss': 1.0833716933231377, 'accuracy': 0.33333334, 'val_loss': 1.061974850770469, 'val_accuracy': 0.44859812}\n",
      "Model: \"model_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_24 (InputLayer)        [(None, 29)]              0         \n",
      "_________________________________________________________________\n",
      "flatten_23 (Flatten)         (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_85 (Dense)             (None, 41)                1230      \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 75)                3150      \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 3)                 228       \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 4,608\n",
      "Trainable params: 4,608\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2553 samples, validate on 107 samples\n",
      "Epoch 1/200\n",
      "2553/2553 [==============================] - 1s 260us/sample - loss: 1.5575 - accuracy: 0.3423 - val_loss: 1.0660 - val_accuracy: 0.4766\n",
      "Epoch 2/200\n",
      "2553/2553 [==============================] - 0s 51us/sample - loss: 1.5683 - accuracy: 0.3325 - val_loss: 1.0645 - val_accuracy: 0.4766\n",
      "Epoch 3/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.5641 - accuracy: 0.3294 - val_loss: 1.0631 - val_accuracy: 0.4860\n",
      "Epoch 4/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.5565 - accuracy: 0.3392 - val_loss: 1.0615 - val_accuracy: 0.4766\n",
      "Epoch 5/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.5396 - accuracy: 0.3278 - val_loss: 1.0601 - val_accuracy: 0.4766\n",
      "Epoch 6/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.5394 - accuracy: 0.3302 - val_loss: 1.0586 - val_accuracy: 0.4766\n",
      "Epoch 7/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.5582 - accuracy: 0.3259 - val_loss: 1.0572 - val_accuracy: 0.4766\n",
      "Epoch 8/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.5063 - accuracy: 0.3396 - val_loss: 1.0561 - val_accuracy: 0.4766\n",
      "Epoch 9/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.5104 - accuracy: 0.3494 - val_loss: 1.0549 - val_accuracy: 0.4766\n",
      "Epoch 10/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.4977 - accuracy: 0.3463 - val_loss: 1.0537 - val_accuracy: 0.4766\n",
      "Epoch 11/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.4908 - accuracy: 0.3443 - val_loss: 1.0526 - val_accuracy: 0.4766\n",
      "Epoch 12/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.5386 - accuracy: 0.3278 - val_loss: 1.0514 - val_accuracy: 0.4766\n",
      "Epoch 13/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.5144 - accuracy: 0.3247 - val_loss: 1.0502 - val_accuracy: 0.4766\n",
      "Epoch 14/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.4842 - accuracy: 0.3400 - val_loss: 1.0490 - val_accuracy: 0.4766\n",
      "Epoch 15/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.5043 - accuracy: 0.3361 - val_loss: 1.0479 - val_accuracy: 0.4766\n",
      "Epoch 16/200\n",
      "2553/2553 [==============================] - 0s 69us/sample - loss: 1.4704 - accuracy: 0.3412 - val_loss: 1.0467 - val_accuracy: 0.4766\n",
      "Epoch 17/200\n",
      "2553/2553 [==============================] - 0s 82us/sample - loss: 1.4756 - accuracy: 0.3255 - val_loss: 1.0458 - val_accuracy: 0.4766\n",
      "Epoch 18/200\n",
      "2553/2553 [==============================] - 0s 79us/sample - loss: 1.4186 - accuracy: 0.3451 - val_loss: 1.0447 - val_accuracy: 0.4766\n",
      "Epoch 19/200\n",
      "2553/2553 [==============================] - 0s 79us/sample - loss: 1.4307 - accuracy: 0.3392 - val_loss: 1.0438 - val_accuracy: 0.4766\n",
      "Epoch 20/200\n",
      "2553/2553 [==============================] - 0s 89us/sample - loss: 1.4021 - accuracy: 0.3439 - val_loss: 1.0428 - val_accuracy: 0.4766\n",
      "Epoch 21/200\n",
      "2553/2553 [==============================] - 0s 73us/sample - loss: 1.4446 - accuracy: 0.3369 - val_loss: 1.0419 - val_accuracy: 0.4673\n",
      "Epoch 22/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.4559 - accuracy: 0.3376 - val_loss: 1.0409 - val_accuracy: 0.4673\n",
      "Epoch 23/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.4322 - accuracy: 0.3322 - val_loss: 1.0400 - val_accuracy: 0.4673\n",
      "Epoch 24/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.4412 - accuracy: 0.3275 - val_loss: 1.0391 - val_accuracy: 0.4673\n",
      "Epoch 25/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.4613 - accuracy: 0.3231 - val_loss: 1.0382 - val_accuracy: 0.4673\n",
      "Epoch 26/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.4255 - accuracy: 0.3384 - val_loss: 1.0374 - val_accuracy: 0.4673\n",
      "Epoch 27/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.4560 - accuracy: 0.3188 - val_loss: 1.0367 - val_accuracy: 0.4673\n",
      "Epoch 28/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.4204 - accuracy: 0.3353 - val_loss: 1.0360 - val_accuracy: 0.4673\n",
      "Epoch 29/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.4416 - accuracy: 0.3357 - val_loss: 1.0354 - val_accuracy: 0.4766\n",
      "Epoch 30/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.4133 - accuracy: 0.3282 - val_loss: 1.0348 - val_accuracy: 0.4766\n",
      "Epoch 31/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.4161 - accuracy: 0.3282 - val_loss: 1.0342 - val_accuracy: 0.4766\n",
      "Epoch 32/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.3845 - accuracy: 0.3333 - val_loss: 1.0338 - val_accuracy: 0.4766\n",
      "Epoch 33/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.3858 - accuracy: 0.3388 - val_loss: 1.0331 - val_accuracy: 0.4766\n",
      "Epoch 34/200\n",
      "2553/2553 [==============================] - 0s 65us/sample - loss: 1.3928 - accuracy: 0.3196 - val_loss: 1.0327 - val_accuracy: 0.4766\n",
      "Epoch 35/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.3892 - accuracy: 0.3235 - val_loss: 1.0322 - val_accuracy: 0.4673\n",
      "Epoch 36/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.3925 - accuracy: 0.3267 - val_loss: 1.0317 - val_accuracy: 0.4673\n",
      "Epoch 37/200\n",
      "2553/2553 [==============================] - 0s 72us/sample - loss: 1.3529 - accuracy: 0.3392 - val_loss: 1.0312 - val_accuracy: 0.4673\n",
      "Epoch 38/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.3865 - accuracy: 0.3325 - val_loss: 1.0306 - val_accuracy: 0.4766\n",
      "Epoch 39/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.3568 - accuracy: 0.3318 - val_loss: 1.0302 - val_accuracy: 0.4673\n",
      "Epoch 40/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.3816 - accuracy: 0.3306 - val_loss: 1.0297 - val_accuracy: 0.4673\n",
      "Epoch 41/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.3494 - accuracy: 0.3306 - val_loss: 1.0292 - val_accuracy: 0.4766\n",
      "Epoch 42/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.3443 - accuracy: 0.3345 - val_loss: 1.0288 - val_accuracy: 0.4766\n",
      "Epoch 43/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.3758 - accuracy: 0.3098 - val_loss: 1.0284 - val_accuracy: 0.4766\n",
      "Epoch 44/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.3365 - accuracy: 0.3310 - val_loss: 1.0281 - val_accuracy: 0.4766\n",
      "Epoch 45/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.3194 - accuracy: 0.3423 - val_loss: 1.0277 - val_accuracy: 0.4766\n",
      "Epoch 46/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.3114 - accuracy: 0.3533 - val_loss: 1.0272 - val_accuracy: 0.4766\n",
      "Epoch 47/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.3624 - accuracy: 0.3216 - val_loss: 1.0270 - val_accuracy: 0.4579\n",
      "Epoch 48/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.3110 - accuracy: 0.3314 - val_loss: 1.0266 - val_accuracy: 0.4579\n",
      "Epoch 49/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.3190 - accuracy: 0.3337 - val_loss: 1.0263 - val_accuracy: 0.4579\n",
      "Epoch 50/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.3150 - accuracy: 0.3231 - val_loss: 1.0262 - val_accuracy: 0.4579\n",
      "Epoch 51/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.3065 - accuracy: 0.3333 - val_loss: 1.0259 - val_accuracy: 0.4673\n",
      "Epoch 52/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.3018 - accuracy: 0.3349 - val_loss: 1.0258 - val_accuracy: 0.4673\n",
      "Epoch 53/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.3023 - accuracy: 0.3208 - val_loss: 1.0256 - val_accuracy: 0.4673\n",
      "Epoch 54/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.2776 - accuracy: 0.3310 - val_loss: 1.0256 - val_accuracy: 0.4673\n",
      "Epoch 55/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.2939 - accuracy: 0.3349 - val_loss: 1.0254 - val_accuracy: 0.4673\n",
      "Epoch 56/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.2788 - accuracy: 0.3380 - val_loss: 1.0254 - val_accuracy: 0.4673\n",
      "Epoch 57/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.2683 - accuracy: 0.3333 - val_loss: 1.0254 - val_accuracy: 0.4673\n",
      "Epoch 58/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.3026 - accuracy: 0.3173 - val_loss: 1.0253 - val_accuracy: 0.4673\n",
      "Epoch 59/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.2685 - accuracy: 0.3510 - val_loss: 1.0251 - val_accuracy: 0.4673\n",
      "Epoch 60/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.2633 - accuracy: 0.3357 - val_loss: 1.0250 - val_accuracy: 0.4673\n",
      "Epoch 61/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.2770 - accuracy: 0.3361 - val_loss: 1.0251 - val_accuracy: 0.4673\n",
      "Epoch 62/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.2689 - accuracy: 0.3376 - val_loss: 1.0251 - val_accuracy: 0.4766\n",
      "Epoch 63/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.2831 - accuracy: 0.3282 - val_loss: 1.0252 - val_accuracy: 0.4673\n",
      "Epoch 64/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.2573 - accuracy: 0.3416 - val_loss: 1.0251 - val_accuracy: 0.4766\n",
      "Epoch 65/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.2594 - accuracy: 0.3369 - val_loss: 1.0251 - val_accuracy: 0.4766\n",
      "Epoch 66/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.2548 - accuracy: 0.3216 - val_loss: 1.0252 - val_accuracy: 0.4766\n",
      "Epoch 67/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.2548 - accuracy: 0.3369 - val_loss: 1.0254 - val_accuracy: 0.4766\n",
      "Epoch 68/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.2289 - accuracy: 0.3427 - val_loss: 1.0253 - val_accuracy: 0.4673\n",
      "Epoch 69/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.2357 - accuracy: 0.3259 - val_loss: 1.0253 - val_accuracy: 0.4673\n",
      "Epoch 70/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.2000 - accuracy: 0.3517 - val_loss: 1.0252 - val_accuracy: 0.4766\n",
      "Epoch 71/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.2339 - accuracy: 0.3427 - val_loss: 1.0252 - val_accuracy: 0.4766\n",
      "Epoch 72/200\n",
      "2553/2553 [==============================] - 0s 51us/sample - loss: 1.2326 - accuracy: 0.3361 - val_loss: 1.0252 - val_accuracy: 0.4860\n",
      "Epoch 73/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.2576 - accuracy: 0.3181 - val_loss: 1.0254 - val_accuracy: 0.4953\n",
      "Epoch 74/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.2304 - accuracy: 0.3282 - val_loss: 1.0254 - val_accuracy: 0.4953\n",
      "Epoch 75/200\n",
      "2553/2553 [==============================] - 0s 51us/sample - loss: 1.2079 - accuracy: 0.3459 - val_loss: 1.0255 - val_accuracy: 0.4953\n",
      "Epoch 76/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.2176 - accuracy: 0.3494 - val_loss: 1.0254 - val_accuracy: 0.5047\n",
      "Epoch 77/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.2031 - accuracy: 0.3357 - val_loss: 1.0253 - val_accuracy: 0.5047\n",
      "Epoch 78/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.2306 - accuracy: 0.3255 - val_loss: 1.0254 - val_accuracy: 0.5047\n",
      "Epoch 79/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.2216 - accuracy: 0.3329 - val_loss: 1.0254 - val_accuracy: 0.5047\n",
      "Epoch 80/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 51us/sample - loss: 1.2060 - accuracy: 0.3376 - val_loss: 1.0255 - val_accuracy: 0.5047\n",
      "Epoch 81/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.2120 - accuracy: 0.3298 - val_loss: 1.0256 - val_accuracy: 0.5047\n",
      "Epoch 82/200\n",
      "2553/2553 [==============================] - 0s 50us/sample - loss: 1.2019 - accuracy: 0.3376 - val_loss: 1.0256 - val_accuracy: 0.5047\n",
      "Epoch 83/200\n",
      "2553/2553 [==============================] - 0s 51us/sample - loss: 1.2073 - accuracy: 0.3369 - val_loss: 1.0258 - val_accuracy: 0.5047\n",
      "Epoch 84/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.2153 - accuracy: 0.3294 - val_loss: 1.0259 - val_accuracy: 0.4953\n",
      "Epoch 85/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1926 - accuracy: 0.3435 - val_loss: 1.0260 - val_accuracy: 0.4860\n",
      "Epoch 86/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1721 - accuracy: 0.3435 - val_loss: 1.0261 - val_accuracy: 0.4860\n",
      "Epoch 87/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.1972 - accuracy: 0.3373 - val_loss: 1.0263 - val_accuracy: 0.4860\n",
      "Epoch 88/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.1843 - accuracy: 0.3373 - val_loss: 1.0264 - val_accuracy: 0.4860\n",
      "Epoch 89/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1856 - accuracy: 0.3404 - val_loss: 1.0265 - val_accuracy: 0.4953\n",
      "Epoch 90/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1955 - accuracy: 0.3263 - val_loss: 1.0267 - val_accuracy: 0.4860\n",
      "Epoch 91/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1892 - accuracy: 0.3443 - val_loss: 1.0271 - val_accuracy: 0.4860\n",
      "Epoch 92/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1805 - accuracy: 0.3400 - val_loss: 1.0274 - val_accuracy: 0.4860\n",
      "Epoch 93/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.1724 - accuracy: 0.3463 - val_loss: 1.0273 - val_accuracy: 0.4860\n",
      "Epoch 94/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1825 - accuracy: 0.3325 - val_loss: 1.0276 - val_accuracy: 0.4766\n",
      "Epoch 95/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1864 - accuracy: 0.3208 - val_loss: 1.0280 - val_accuracy: 0.4766\n",
      "Epoch 96/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.1675 - accuracy: 0.3361 - val_loss: 1.0282 - val_accuracy: 0.4766\n",
      "Epoch 97/200\n",
      "2553/2553 [==============================] - 0s 51us/sample - loss: 1.1694 - accuracy: 0.3349 - val_loss: 1.0286 - val_accuracy: 0.4766\n",
      "Epoch 98/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1793 - accuracy: 0.3408 - val_loss: 1.0291 - val_accuracy: 0.4860\n",
      "Epoch 99/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1707 - accuracy: 0.3275 - val_loss: 1.0292 - val_accuracy: 0.4860\n",
      "Epoch 100/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.1794 - accuracy: 0.3412 - val_loss: 1.0294 - val_accuracy: 0.4860\n",
      "Epoch 101/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1716 - accuracy: 0.3282 - val_loss: 1.0296 - val_accuracy: 0.4860\n",
      "Epoch 102/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1485 - accuracy: 0.3427 - val_loss: 1.0297 - val_accuracy: 0.4860\n",
      "Epoch 103/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1583 - accuracy: 0.3412 - val_loss: 1.0299 - val_accuracy: 0.4860\n",
      "Epoch 104/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1716 - accuracy: 0.3275 - val_loss: 1.0300 - val_accuracy: 0.4860\n",
      "Epoch 105/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1594 - accuracy: 0.3451 - val_loss: 1.0301 - val_accuracy: 0.4860\n",
      "Epoch 106/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.1475 - accuracy: 0.3470 - val_loss: 1.0301 - val_accuracy: 0.4860\n",
      "Epoch 107/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.1517 - accuracy: 0.3396 - val_loss: 1.0300 - val_accuracy: 0.4860\n",
      "Epoch 108/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.1463 - accuracy: 0.3325 - val_loss: 1.0302 - val_accuracy: 0.4860\n",
      "Epoch 109/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1560 - accuracy: 0.3470 - val_loss: 1.0301 - val_accuracy: 0.4860\n",
      "Epoch 110/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1424 - accuracy: 0.3439 - val_loss: 1.0302 - val_accuracy: 0.4860\n",
      "Epoch 111/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.1557 - accuracy: 0.3278 - val_loss: 1.0303 - val_accuracy: 0.4860\n",
      "Epoch 112/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1261 - accuracy: 0.3541 - val_loss: 1.0303 - val_accuracy: 0.4860\n",
      "Epoch 113/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1531 - accuracy: 0.3400 - val_loss: 1.0305 - val_accuracy: 0.4860\n",
      "Epoch 114/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1557 - accuracy: 0.3290 - val_loss: 1.0305 - val_accuracy: 0.4766\n",
      "Epoch 115/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1620 - accuracy: 0.3278 - val_loss: 1.0306 - val_accuracy: 0.4860\n",
      "Epoch 116/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1470 - accuracy: 0.3318 - val_loss: 1.0307 - val_accuracy: 0.4860\n",
      "Epoch 117/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1387 - accuracy: 0.3474 - val_loss: 1.0307 - val_accuracy: 0.4860\n",
      "Epoch 118/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.1474 - accuracy: 0.3259 - val_loss: 1.0309 - val_accuracy: 0.4860\n",
      "Epoch 119/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1557 - accuracy: 0.3357 - val_loss: 1.0310 - val_accuracy: 0.4860\n",
      "Epoch 120/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.1431 - accuracy: 0.3396 - val_loss: 1.0309 - val_accuracy: 0.4860\n",
      "Epoch 121/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1419 - accuracy: 0.3404 - val_loss: 1.0310 - val_accuracy: 0.4860\n",
      "Epoch 122/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1316 - accuracy: 0.3322 - val_loss: 1.0311 - val_accuracy: 0.4860\n",
      "Epoch 123/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1341 - accuracy: 0.3396 - val_loss: 1.0310 - val_accuracy: 0.4860\n",
      "Epoch 124/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.1115 - accuracy: 0.3572 - val_loss: 1.0310 - val_accuracy: 0.4860\n",
      "Epoch 125/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.1294 - accuracy: 0.3345 - val_loss: 1.0310 - val_accuracy: 0.4860\n",
      "Epoch 126/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1247 - accuracy: 0.3404 - val_loss: 1.0309 - val_accuracy: 0.4860\n",
      "Epoch 127/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.1317 - accuracy: 0.3302 - val_loss: 1.0308 - val_accuracy: 0.4860\n",
      "Epoch 128/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1310 - accuracy: 0.3435 - val_loss: 1.0309 - val_accuracy: 0.4860\n",
      "Epoch 129/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1351 - accuracy: 0.3310 - val_loss: 1.0308 - val_accuracy: 0.4860\n",
      "Epoch 130/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1257 - accuracy: 0.3474 - val_loss: 1.0308 - val_accuracy: 0.4860\n",
      "Epoch 131/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.1230 - accuracy: 0.3439 - val_loss: 1.0308 - val_accuracy: 0.4860\n",
      "Epoch 132/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1417 - accuracy: 0.3251 - val_loss: 1.0310 - val_accuracy: 0.4860\n",
      "Epoch 133/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.1344 - accuracy: 0.3239 - val_loss: 1.0310 - val_accuracy: 0.4860\n",
      "Epoch 134/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.1149 - accuracy: 0.3420 - val_loss: 1.0310 - val_accuracy: 0.4766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1260 - accuracy: 0.3435 - val_loss: 1.0311 - val_accuracy: 0.4766\n",
      "Epoch 136/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1399 - accuracy: 0.3255 - val_loss: 1.0312 - val_accuracy: 0.4766\n",
      "Epoch 137/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1200 - accuracy: 0.3373 - val_loss: 1.0312 - val_accuracy: 0.4766\n",
      "Epoch 138/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.1162 - accuracy: 0.3557 - val_loss: 1.0310 - val_accuracy: 0.4766\n",
      "Epoch 139/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1246 - accuracy: 0.3271 - val_loss: 1.0310 - val_accuracy: 0.4766\n",
      "Epoch 140/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1300 - accuracy: 0.3408 - val_loss: 1.0309 - val_accuracy: 0.4766\n",
      "Epoch 141/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1249 - accuracy: 0.3455 - val_loss: 1.0309 - val_accuracy: 0.4766\n",
      "Epoch 142/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.1039 - accuracy: 0.3568 - val_loss: 1.0309 - val_accuracy: 0.4766\n",
      "Epoch 143/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.1184 - accuracy: 0.3463 - val_loss: 1.0310 - val_accuracy: 0.4766\n",
      "Epoch 144/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1023 - accuracy: 0.3623 - val_loss: 1.0309 - val_accuracy: 0.4766\n",
      "Epoch 145/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1191 - accuracy: 0.3369 - val_loss: 1.0310 - val_accuracy: 0.4766\n",
      "Epoch 146/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1213 - accuracy: 0.3329 - val_loss: 1.0309 - val_accuracy: 0.4673\n",
      "Epoch 147/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1059 - accuracy: 0.3431 - val_loss: 1.0310 - val_accuracy: 0.4673\n",
      "Epoch 148/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.1278 - accuracy: 0.3286 - val_loss: 1.0312 - val_accuracy: 0.4673\n",
      "Epoch 149/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1106 - accuracy: 0.3533 - val_loss: 1.0313 - val_accuracy: 0.4673\n",
      "Epoch 150/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1223 - accuracy: 0.3380 - val_loss: 1.0314 - val_accuracy: 0.4673\n",
      "Epoch 151/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1214 - accuracy: 0.3349 - val_loss: 1.0316 - val_accuracy: 0.4673\n",
      "Epoch 152/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1162 - accuracy: 0.3420 - val_loss: 1.0316 - val_accuracy: 0.4673\n",
      "Epoch 153/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.1084 - accuracy: 0.3408 - val_loss: 1.0316 - val_accuracy: 0.4673\n",
      "Epoch 154/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1157 - accuracy: 0.3361 - val_loss: 1.0316 - val_accuracy: 0.4673\n",
      "Epoch 155/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.1100 - accuracy: 0.3345 - val_loss: 1.0319 - val_accuracy: 0.4673\n",
      "Epoch 156/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1080 - accuracy: 0.3345 - val_loss: 1.0320 - val_accuracy: 0.4673\n",
      "Epoch 157/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0976 - accuracy: 0.3463 - val_loss: 1.0319 - val_accuracy: 0.4673\n",
      "Epoch 158/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1069 - accuracy: 0.3490 - val_loss: 1.0320 - val_accuracy: 0.4579\n",
      "Epoch 159/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1076 - accuracy: 0.3447 - val_loss: 1.0320 - val_accuracy: 0.4579\n",
      "Epoch 160/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.1072 - accuracy: 0.3490 - val_loss: 1.0319 - val_accuracy: 0.4579\n",
      "Epoch 161/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.1113 - accuracy: 0.3329 - val_loss: 1.0320 - val_accuracy: 0.4579\n",
      "Epoch 162/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.1145 - accuracy: 0.3443 - val_loss: 1.0320 - val_accuracy: 0.4579\n",
      "Epoch 163/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1079 - accuracy: 0.3376 - val_loss: 1.0321 - val_accuracy: 0.4579\n",
      "Epoch 164/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1169 - accuracy: 0.3463 - val_loss: 1.0322 - val_accuracy: 0.4579\n",
      "Epoch 165/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1124 - accuracy: 0.3412 - val_loss: 1.0322 - val_accuracy: 0.4579\n",
      "Epoch 166/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1217 - accuracy: 0.3325 - val_loss: 1.0322 - val_accuracy: 0.4579\n",
      "Epoch 167/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1090 - accuracy: 0.3337 - val_loss: 1.0323 - val_accuracy: 0.4579\n",
      "Epoch 168/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.1058 - accuracy: 0.3490 - val_loss: 1.0322 - val_accuracy: 0.4579\n",
      "Epoch 169/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1000 - accuracy: 0.3545 - val_loss: 1.0322 - val_accuracy: 0.4579\n",
      "Epoch 170/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1129 - accuracy: 0.3467 - val_loss: 1.0324 - val_accuracy: 0.4579\n",
      "Epoch 171/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.1032 - accuracy: 0.3416 - val_loss: 1.0325 - val_accuracy: 0.4579\n",
      "Epoch 172/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1116 - accuracy: 0.3337 - val_loss: 1.0326 - val_accuracy: 0.4579\n",
      "Epoch 173/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.0961 - accuracy: 0.3396 - val_loss: 1.0325 - val_accuracy: 0.4579\n",
      "Epoch 174/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.1043 - accuracy: 0.3427 - val_loss: 1.0325 - val_accuracy: 0.4579\n",
      "Epoch 175/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1134 - accuracy: 0.3388 - val_loss: 1.0326 - val_accuracy: 0.4579\n",
      "Epoch 176/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.0983 - accuracy: 0.3423 - val_loss: 1.0323 - val_accuracy: 0.4579\n",
      "Epoch 177/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0943 - accuracy: 0.3373 - val_loss: 1.0321 - val_accuracy: 0.4579\n",
      "Epoch 178/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1010 - accuracy: 0.3490 - val_loss: 1.0321 - val_accuracy: 0.4579\n",
      "Epoch 179/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0937 - accuracy: 0.3463 - val_loss: 1.0320 - val_accuracy: 0.4579\n",
      "Epoch 180/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0887 - accuracy: 0.3486 - val_loss: 1.0320 - val_accuracy: 0.4579\n",
      "Epoch 181/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0987 - accuracy: 0.3439 - val_loss: 1.0320 - val_accuracy: 0.4486\n",
      "Epoch 182/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1086 - accuracy: 0.3451 - val_loss: 1.0320 - val_accuracy: 0.4486\n",
      "Epoch 183/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.1048 - accuracy: 0.3373 - val_loss: 1.0320 - val_accuracy: 0.4486\n",
      "Epoch 184/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0984 - accuracy: 0.3474 - val_loss: 1.0319 - val_accuracy: 0.4486\n",
      "Epoch 185/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.1055 - accuracy: 0.3380 - val_loss: 1.0319 - val_accuracy: 0.4393\n",
      "Epoch 186/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1048 - accuracy: 0.3345 - val_loss: 1.0320 - val_accuracy: 0.4393\n",
      "Epoch 187/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1042 - accuracy: 0.3384 - val_loss: 1.0319 - val_accuracy: 0.4393\n",
      "Epoch 188/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1105 - accuracy: 0.3447 - val_loss: 1.0320 - val_accuracy: 0.4393\n",
      "Epoch 189/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.0908 - accuracy: 0.3463 - val_loss: 1.0320 - val_accuracy: 0.4486\n",
      "Epoch 190/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.1054 - accuracy: 0.3431 - val_loss: 1.0321 - val_accuracy: 0.4486\n",
      "Epoch 191/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.0943 - accuracy: 0.3580 - val_loss: 1.0321 - val_accuracy: 0.4486\n",
      "Epoch 192/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0834 - accuracy: 0.3545 - val_loss: 1.0320 - val_accuracy: 0.4486\n",
      "Epoch 193/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0834 - accuracy: 0.3568 - val_loss: 1.0319 - val_accuracy: 0.4486\n",
      "Epoch 194/200\n",
      "2553/2553 [==============================] - 0s 51us/sample - loss: 1.0955 - accuracy: 0.3510 - val_loss: 1.0319 - val_accuracy: 0.4486\n",
      "Epoch 195/200\n",
      "2553/2553 [==============================] - 0s 51us/sample - loss: 1.1020 - accuracy: 0.3404 - val_loss: 1.0319 - val_accuracy: 0.4579\n",
      "Epoch 196/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.0926 - accuracy: 0.3400 - val_loss: 1.0319 - val_accuracy: 0.4579\n",
      "Epoch 197/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0944 - accuracy: 0.3392 - val_loss: 1.0319 - val_accuracy: 0.4579\n",
      "Epoch 198/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0833 - accuracy: 0.3564 - val_loss: 1.0320 - val_accuracy: 0.4579\n",
      "Epoch 199/200\n",
      "2553/2553 [==============================] - 0s 50us/sample - loss: 1.1081 - accuracy: 0.3231 - val_loss: 1.0321 - val_accuracy: 0.4579\n",
      "Epoch 200/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0887 - accuracy: 0.3474 - val_loss: 1.0322 - val_accuracy: 0.4579\n",
      "0.45794392 {'loss': 1.08865240327153, 'accuracy': 0.3474344, 'val_loss': 1.032223802860652, 'val_accuracy': 0.45794392}\n",
      "Model: \"model_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_25 (InputLayer)        [(None, 29)]              0         \n",
      "_________________________________________________________________\n",
      "flatten_24 (Flatten)         (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_88 (Dense)             (None, 41)                1230      \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 10)                420       \n",
      "_________________________________________________________________\n",
      "dense_90 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_91 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 3)                 33        \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 1,903\n",
      "Trainable params: 1,903\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2553 samples, validate on 107 samples\n",
      "Epoch 1/200\n",
      "2553/2553 [==============================] - 1s 331us/sample - loss: 1.4352 - accuracy: 0.2327 - val_loss: 1.3946 - val_accuracy: 0.2523\n",
      "Epoch 2/200\n",
      "2553/2553 [==============================] - 0s 94us/sample - loss: 1.4299 - accuracy: 0.2327 - val_loss: 1.3895 - val_accuracy: 0.2523\n",
      "Epoch 3/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.4247 - accuracy: 0.2327 - val_loss: 1.3844 - val_accuracy: 0.2523\n",
      "Epoch 4/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.4196 - accuracy: 0.2327 - val_loss: 1.3795 - val_accuracy: 0.2523\n",
      "Epoch 5/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.4145 - accuracy: 0.2327 - val_loss: 1.3746 - val_accuracy: 0.2523\n",
      "Epoch 6/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.4096 - accuracy: 0.2327 - val_loss: 1.3699 - val_accuracy: 0.2523\n",
      "Epoch 7/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.4048 - accuracy: 0.2327 - val_loss: 1.3652 - val_accuracy: 0.2523\n",
      "Epoch 8/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.4000 - accuracy: 0.2327 - val_loss: 1.3606 - val_accuracy: 0.2523\n",
      "Epoch 9/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.3953 - accuracy: 0.2327 - val_loss: 1.3560 - val_accuracy: 0.2523\n",
      "Epoch 10/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.3906 - accuracy: 0.2327 - val_loss: 1.3516 - val_accuracy: 0.2523\n",
      "Epoch 11/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.3860 - accuracy: 0.2327 - val_loss: 1.3472 - val_accuracy: 0.2523\n",
      "Epoch 12/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.3815 - accuracy: 0.2327 - val_loss: 1.3428 - val_accuracy: 0.2523\n",
      "Epoch 13/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.3770 - accuracy: 0.2327 - val_loss: 1.3385 - val_accuracy: 0.2523\n",
      "Epoch 14/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.3726 - accuracy: 0.2327 - val_loss: 1.3343 - val_accuracy: 0.2523\n",
      "Epoch 15/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.3682 - accuracy: 0.2327 - val_loss: 1.3302 - val_accuracy: 0.2523\n",
      "Epoch 16/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.3639 - accuracy: 0.2327 - val_loss: 1.3261 - val_accuracy: 0.2523\n",
      "Epoch 17/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.3597 - accuracy: 0.2327 - val_loss: 1.3221 - val_accuracy: 0.2523\n",
      "Epoch 18/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.3555 - accuracy: 0.2331 - val_loss: 1.3181 - val_accuracy: 0.2523\n",
      "Epoch 19/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.3514 - accuracy: 0.2331 - val_loss: 1.3141 - val_accuracy: 0.2523\n",
      "Epoch 20/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.3473 - accuracy: 0.2331 - val_loss: 1.3102 - val_accuracy: 0.2523\n",
      "Epoch 21/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.3433 - accuracy: 0.2331 - val_loss: 1.3063 - val_accuracy: 0.2523\n",
      "Epoch 22/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.3393 - accuracy: 0.2331 - val_loss: 1.3025 - val_accuracy: 0.2523\n",
      "Epoch 23/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.3354 - accuracy: 0.2331 - val_loss: 1.2988 - val_accuracy: 0.2523\n",
      "Epoch 24/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.3315 - accuracy: 0.2331 - val_loss: 1.2952 - val_accuracy: 0.2523\n",
      "Epoch 25/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.3277 - accuracy: 0.2331 - val_loss: 1.2917 - val_accuracy: 0.2523\n",
      "Epoch 26/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.3240 - accuracy: 0.2331 - val_loss: 1.2883 - val_accuracy: 0.2523\n",
      "Epoch 27/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.3203 - accuracy: 0.2331 - val_loss: 1.2850 - val_accuracy: 0.2523\n",
      "Epoch 28/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.3167 - accuracy: 0.2331 - val_loss: 1.2816 - val_accuracy: 0.2523\n",
      "Epoch 29/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.3131 - accuracy: 0.2338 - val_loss: 1.2782 - val_accuracy: 0.2523\n",
      "Epoch 30/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.3095 - accuracy: 0.2338 - val_loss: 1.2748 - val_accuracy: 0.2523\n",
      "Epoch 31/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.3060 - accuracy: 0.2338 - val_loss: 1.2713 - val_accuracy: 0.2523\n",
      "Epoch 32/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.3025 - accuracy: 0.2338 - val_loss: 1.2679 - val_accuracy: 0.2523\n",
      "Epoch 33/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.2989 - accuracy: 0.2338 - val_loss: 1.2645 - val_accuracy: 0.2523\n",
      "Epoch 34/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.2955 - accuracy: 0.2342 - val_loss: 1.2611 - val_accuracy: 0.2523\n",
      "Epoch 35/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.2921 - accuracy: 0.2342 - val_loss: 1.2577 - val_accuracy: 0.2523\n",
      "Epoch 36/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.2888 - accuracy: 0.2342 - val_loss: 1.2543 - val_accuracy: 0.2523\n",
      "Epoch 37/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.2855 - accuracy: 0.2342 - val_loss: 1.2510 - val_accuracy: 0.2523\n",
      "Epoch 38/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.2822 - accuracy: 0.2342 - val_loss: 1.2477 - val_accuracy: 0.2523\n",
      "Epoch 39/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.2790 - accuracy: 0.2342 - val_loss: 1.2444 - val_accuracy: 0.2523\n",
      "Epoch 40/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.2758 - accuracy: 0.2342 - val_loss: 1.2412 - val_accuracy: 0.2523\n",
      "Epoch 41/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.2727 - accuracy: 0.2346 - val_loss: 1.2380 - val_accuracy: 0.2523\n",
      "Epoch 42/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.2696 - accuracy: 0.2346 - val_loss: 1.2348 - val_accuracy: 0.2523\n",
      "Epoch 43/200\n",
      "2553/2553 [==============================] - 0s 122us/sample - loss: 1.2665 - accuracy: 0.2350 - val_loss: 1.2317 - val_accuracy: 0.2523\n",
      "Epoch 44/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.2635 - accuracy: 0.2346 - val_loss: 1.2287 - val_accuracy: 0.2523\n",
      "Epoch 45/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.2605 - accuracy: 0.2350 - val_loss: 1.2257 - val_accuracy: 0.2523\n",
      "Epoch 46/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.2575 - accuracy: 0.2358 - val_loss: 1.2227 - val_accuracy: 0.2523\n",
      "Epoch 47/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.2546 - accuracy: 0.2366 - val_loss: 1.2198 - val_accuracy: 0.2523\n",
      "Epoch 48/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.2517 - accuracy: 0.2366 - val_loss: 1.2169 - val_accuracy: 0.2617\n",
      "Epoch 49/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.2488 - accuracy: 0.2366 - val_loss: 1.2141 - val_accuracy: 0.2617\n",
      "Epoch 50/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.2459 - accuracy: 0.2358 - val_loss: 1.2113 - val_accuracy: 0.2617\n",
      "Epoch 51/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.2431 - accuracy: 0.2362 - val_loss: 1.2086 - val_accuracy: 0.2617\n",
      "Epoch 52/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.2402 - accuracy: 0.2370 - val_loss: 1.2059 - val_accuracy: 0.2617\n",
      "Epoch 53/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.2374 - accuracy: 0.2382 - val_loss: 1.2032 - val_accuracy: 0.2617\n",
      "Epoch 54/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.2346 - accuracy: 0.2389 - val_loss: 1.2004 - val_accuracy: 0.2617\n",
      "Epoch 55/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.2317 - accuracy: 0.2397 - val_loss: 1.1976 - val_accuracy: 0.2617\n",
      "Epoch 56/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.2289 - accuracy: 0.2389 - val_loss: 1.1948 - val_accuracy: 0.2710\n",
      "Epoch 57/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.2261 - accuracy: 0.2405 - val_loss: 1.1921 - val_accuracy: 0.2804\n",
      "Epoch 58/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.2233 - accuracy: 0.2421 - val_loss: 1.1894 - val_accuracy: 0.2710\n",
      "Epoch 59/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.2205 - accuracy: 0.2425 - val_loss: 1.1868 - val_accuracy: 0.2710\n",
      "Epoch 60/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.2178 - accuracy: 0.2421 - val_loss: 1.1843 - val_accuracy: 0.2710\n",
      "Epoch 61/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.2150 - accuracy: 0.2440 - val_loss: 1.1818 - val_accuracy: 0.2617\n",
      "Epoch 62/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.2123 - accuracy: 0.2464 - val_loss: 1.1794 - val_accuracy: 0.2804\n",
      "Epoch 63/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.2096 - accuracy: 0.2483 - val_loss: 1.1769 - val_accuracy: 0.2804\n",
      "Epoch 64/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.2070 - accuracy: 0.2499 - val_loss: 1.1746 - val_accuracy: 0.2897\n",
      "Epoch 65/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.2043 - accuracy: 0.2511 - val_loss: 1.1723 - val_accuracy: 0.2897\n",
      "Epoch 66/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.2017 - accuracy: 0.2523 - val_loss: 1.1699 - val_accuracy: 0.2897\n",
      "Epoch 67/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.1991 - accuracy: 0.2546 - val_loss: 1.1677 - val_accuracy: 0.2991\n",
      "Epoch 68/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.1966 - accuracy: 0.2562 - val_loss: 1.1654 - val_accuracy: 0.3084\n",
      "Epoch 69/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.1940 - accuracy: 0.2577 - val_loss: 1.1631 - val_accuracy: 0.3084\n",
      "Epoch 70/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.1916 - accuracy: 0.2577 - val_loss: 1.1609 - val_accuracy: 0.3084\n",
      "Epoch 71/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.1891 - accuracy: 0.2609 - val_loss: 1.1587 - val_accuracy: 0.3271\n",
      "Epoch 72/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.1866 - accuracy: 0.2640 - val_loss: 1.1566 - val_accuracy: 0.3271\n",
      "Epoch 73/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.1842 - accuracy: 0.2660 - val_loss: 1.1545 - val_accuracy: 0.3178\n",
      "Epoch 74/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.1818 - accuracy: 0.2675 - val_loss: 1.1525 - val_accuracy: 0.3178\n",
      "Epoch 75/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.1794 - accuracy: 0.2687 - val_loss: 1.1504 - val_accuracy: 0.3271\n",
      "Epoch 76/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.1770 - accuracy: 0.2703 - val_loss: 1.1483 - val_accuracy: 0.3271\n",
      "Epoch 77/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.1747 - accuracy: 0.2714 - val_loss: 1.1463 - val_accuracy: 0.3271\n",
      "Epoch 78/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.1724 - accuracy: 0.2726 - val_loss: 1.1442 - val_accuracy: 0.3364\n",
      "Epoch 79/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.1701 - accuracy: 0.2738 - val_loss: 1.1422 - val_accuracy: 0.3364\n",
      "Epoch 80/200\n",
      "2553/2553 [==============================] - 0s 99us/sample - loss: 1.1679 - accuracy: 0.2761 - val_loss: 1.1403 - val_accuracy: 0.3364\n",
      "Epoch 81/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.1656 - accuracy: 0.2777 - val_loss: 1.1384 - val_accuracy: 0.3364\n",
      "Epoch 82/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.1634 - accuracy: 0.2797 - val_loss: 1.1364 - val_accuracy: 0.3458\n",
      "Epoch 83/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.1612 - accuracy: 0.2836 - val_loss: 1.1345 - val_accuracy: 0.3551\n",
      "Epoch 84/200\n",
      "2553/2553 [==============================] - 0s 99us/sample - loss: 1.1591 - accuracy: 0.2859 - val_loss: 1.1326 - val_accuracy: 0.3645\n",
      "Epoch 85/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.1570 - accuracy: 0.2879 - val_loss: 1.1308 - val_accuracy: 0.3645\n",
      "Epoch 86/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.1549 - accuracy: 0.2891 - val_loss: 1.1290 - val_accuracy: 0.3645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.1528 - accuracy: 0.2926 - val_loss: 1.1272 - val_accuracy: 0.3738\n",
      "Epoch 88/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.1508 - accuracy: 0.2981 - val_loss: 1.1255 - val_accuracy: 0.3645\n",
      "Epoch 89/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.1488 - accuracy: 0.3047 - val_loss: 1.1238 - val_accuracy: 0.3738\n",
      "Epoch 90/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.1469 - accuracy: 0.3106 - val_loss: 1.1222 - val_accuracy: 0.3832\n",
      "Epoch 91/200\n",
      "2553/2553 [==============================] - 0s 99us/sample - loss: 1.1449 - accuracy: 0.3157 - val_loss: 1.1206 - val_accuracy: 0.3925\n",
      "Epoch 92/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.1430 - accuracy: 0.3208 - val_loss: 1.1190 - val_accuracy: 0.3925\n",
      "Epoch 93/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.1411 - accuracy: 0.3255 - val_loss: 1.1174 - val_accuracy: 0.3925\n",
      "Epoch 94/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.1392 - accuracy: 0.3259 - val_loss: 1.1159 - val_accuracy: 0.4019\n",
      "Epoch 95/200\n",
      "2553/2553 [==============================] - 0s 98us/sample - loss: 1.1373 - accuracy: 0.3302 - val_loss: 1.1144 - val_accuracy: 0.4019\n",
      "Epoch 96/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.1355 - accuracy: 0.3322 - val_loss: 1.1129 - val_accuracy: 0.4019\n",
      "Epoch 97/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.1337 - accuracy: 0.3373 - val_loss: 1.1114 - val_accuracy: 0.3925\n",
      "Epoch 98/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.1319 - accuracy: 0.3408 - val_loss: 1.1100 - val_accuracy: 0.3925\n",
      "Epoch 99/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.1302 - accuracy: 0.3451 - val_loss: 1.1086 - val_accuracy: 0.4019\n",
      "Epoch 100/200\n",
      "2553/2553 [==============================] - 0s 99us/sample - loss: 1.1284 - accuracy: 0.3455 - val_loss: 1.1073 - val_accuracy: 0.4019\n",
      "Epoch 101/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.1267 - accuracy: 0.3498 - val_loss: 1.1059 - val_accuracy: 0.4112\n",
      "Epoch 102/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.1250 - accuracy: 0.3561 - val_loss: 1.1046 - val_accuracy: 0.4112\n",
      "Epoch 103/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.1233 - accuracy: 0.3608 - val_loss: 1.1033 - val_accuracy: 0.4019\n",
      "Epoch 104/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.1216 - accuracy: 0.3662 - val_loss: 1.1020 - val_accuracy: 0.4112\n",
      "Epoch 105/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.1200 - accuracy: 0.3694 - val_loss: 1.1008 - val_accuracy: 0.4112\n",
      "Epoch 106/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.1183 - accuracy: 0.3717 - val_loss: 1.0995 - val_accuracy: 0.4206\n",
      "Epoch 107/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.1167 - accuracy: 0.3741 - val_loss: 1.0982 - val_accuracy: 0.4206\n",
      "Epoch 108/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.1151 - accuracy: 0.3788 - val_loss: 1.0970 - val_accuracy: 0.4206\n",
      "Epoch 109/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.1135 - accuracy: 0.3819 - val_loss: 1.0958 - val_accuracy: 0.4206\n",
      "Epoch 110/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.1119 - accuracy: 0.3827 - val_loss: 1.0945 - val_accuracy: 0.4206\n",
      "Epoch 111/200\n",
      "2553/2553 [==============================] - 0s 99us/sample - loss: 1.1104 - accuracy: 0.3866 - val_loss: 1.0934 - val_accuracy: 0.4206\n",
      "Epoch 112/200\n",
      "2553/2553 [==============================] - 0s 98us/sample - loss: 1.1089 - accuracy: 0.3913 - val_loss: 1.0922 - val_accuracy: 0.4299\n",
      "Epoch 113/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.1073 - accuracy: 0.3952 - val_loss: 1.0910 - val_accuracy: 0.4206\n",
      "Epoch 114/200\n",
      "2553/2553 [==============================] - 0s 88us/sample - loss: 1.1058 - accuracy: 0.3984 - val_loss: 1.0899 - val_accuracy: 0.4299\n",
      "Epoch 115/200\n",
      "2553/2553 [==============================] - 0s 87us/sample - loss: 1.1044 - accuracy: 0.4015 - val_loss: 1.0887 - val_accuracy: 0.4299\n",
      "Epoch 116/200\n",
      "2553/2553 [==============================] - 0s 99us/sample - loss: 1.1029 - accuracy: 0.4054 - val_loss: 1.0876 - val_accuracy: 0.4112\n",
      "Epoch 117/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.1015 - accuracy: 0.4062 - val_loss: 1.0865 - val_accuracy: 0.4112\n",
      "Epoch 118/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.1001 - accuracy: 0.4089 - val_loss: 1.0854 - val_accuracy: 0.4112\n",
      "Epoch 119/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.0987 - accuracy: 0.4113 - val_loss: 1.0843 - val_accuracy: 0.4112\n",
      "Epoch 120/200\n",
      "2553/2553 [==============================] - 0s 99us/sample - loss: 1.0974 - accuracy: 0.4140 - val_loss: 1.0832 - val_accuracy: 0.4112\n",
      "Epoch 121/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0960 - accuracy: 0.4132 - val_loss: 1.0822 - val_accuracy: 0.4206\n",
      "Epoch 122/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.0947 - accuracy: 0.4136 - val_loss: 1.0812 - val_accuracy: 0.4206\n",
      "Epoch 123/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 1.0934 - accuracy: 0.4172 - val_loss: 1.0802 - val_accuracy: 0.4299\n",
      "Epoch 124/200\n",
      "2553/2553 [==============================] - 0s 160us/sample - loss: 1.0922 - accuracy: 0.4199 - val_loss: 1.0792 - val_accuracy: 0.4299\n",
      "Epoch 125/200\n",
      "2553/2553 [==============================] - 0s 166us/sample - loss: 1.0909 - accuracy: 0.4211 - val_loss: 1.0783 - val_accuracy: 0.4393\n",
      "Epoch 126/200\n",
      "2553/2553 [==============================] - 0s 138us/sample - loss: 1.0897 - accuracy: 0.4211 - val_loss: 1.0773 - val_accuracy: 0.4393\n",
      "Epoch 127/200\n",
      "2553/2553 [==============================] - 0s 120us/sample - loss: 1.0884 - accuracy: 0.4222 - val_loss: 1.0764 - val_accuracy: 0.4393\n",
      "Epoch 128/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.0872 - accuracy: 0.4258 - val_loss: 1.0755 - val_accuracy: 0.4393\n",
      "Epoch 129/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0860 - accuracy: 0.4285 - val_loss: 1.0745 - val_accuracy: 0.4393\n",
      "Epoch 130/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.0848 - accuracy: 0.4293 - val_loss: 1.0736 - val_accuracy: 0.4579\n",
      "Epoch 131/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0836 - accuracy: 0.4320 - val_loss: 1.0728 - val_accuracy: 0.4579\n",
      "Epoch 132/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.0824 - accuracy: 0.4320 - val_loss: 1.0719 - val_accuracy: 0.4579\n",
      "Epoch 133/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0813 - accuracy: 0.4344 - val_loss: 1.0710 - val_accuracy: 0.4579\n",
      "Epoch 134/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0801 - accuracy: 0.4344 - val_loss: 1.0701 - val_accuracy: 0.4579\n",
      "Epoch 135/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 1.0789 - accuracy: 0.4344 - val_loss: 1.0692 - val_accuracy: 0.4766\n",
      "Epoch 136/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0778 - accuracy: 0.4363 - val_loss: 1.0683 - val_accuracy: 0.4766\n",
      "Epoch 137/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.0767 - accuracy: 0.4375 - val_loss: 1.0675 - val_accuracy: 0.4766\n",
      "Epoch 138/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.0756 - accuracy: 0.4391 - val_loss: 1.0666 - val_accuracy: 0.4766\n",
      "Epoch 139/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.0744 - accuracy: 0.4403 - val_loss: 1.0658 - val_accuracy: 0.4766\n",
      "Epoch 140/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.0734 - accuracy: 0.4422 - val_loss: 1.0650 - val_accuracy: 0.4766\n",
      "Epoch 141/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.0723 - accuracy: 0.4430 - val_loss: 1.0641 - val_accuracy: 0.4766\n",
      "Epoch 142/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.0712 - accuracy: 0.4446 - val_loss: 1.0633 - val_accuracy: 0.4766\n",
      "Epoch 143/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.0702 - accuracy: 0.4458 - val_loss: 1.0625 - val_accuracy: 0.4766\n",
      "Epoch 144/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.0691 - accuracy: 0.4458 - val_loss: 1.0618 - val_accuracy: 0.4766\n",
      "Epoch 145/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0681 - accuracy: 0.4465 - val_loss: 1.0610 - val_accuracy: 0.4766\n",
      "Epoch 146/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.0670 - accuracy: 0.4469 - val_loss: 1.0601 - val_accuracy: 0.4766\n",
      "Epoch 147/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0660 - accuracy: 0.4485 - val_loss: 1.0593 - val_accuracy: 0.4766\n",
      "Epoch 148/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.0650 - accuracy: 0.4497 - val_loss: 1.0585 - val_accuracy: 0.4766\n",
      "Epoch 149/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.0640 - accuracy: 0.4497 - val_loss: 1.0576 - val_accuracy: 0.4766\n",
      "Epoch 150/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.0630 - accuracy: 0.4493 - val_loss: 1.0568 - val_accuracy: 0.4766\n",
      "Epoch 151/200\n",
      "2553/2553 [==============================] - 0s 117us/sample - loss: 1.0620 - accuracy: 0.4524 - val_loss: 1.0560 - val_accuracy: 0.4766\n",
      "Epoch 152/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0611 - accuracy: 0.4544 - val_loss: 1.0552 - val_accuracy: 0.4766\n",
      "Epoch 153/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.0601 - accuracy: 0.4555 - val_loss: 1.0544 - val_accuracy: 0.4673\n",
      "Epoch 154/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0591 - accuracy: 0.4555 - val_loss: 1.0536 - val_accuracy: 0.4673\n",
      "Epoch 155/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.0581 - accuracy: 0.4559 - val_loss: 1.0528 - val_accuracy: 0.4673\n",
      "Epoch 156/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0571 - accuracy: 0.4548 - val_loss: 1.0520 - val_accuracy: 0.4673\n",
      "Epoch 157/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0562 - accuracy: 0.4548 - val_loss: 1.0513 - val_accuracy: 0.4766\n",
      "Epoch 158/200\n",
      "2553/2553 [==============================] - 0s 141us/sample - loss: 1.0552 - accuracy: 0.4559 - val_loss: 1.0505 - val_accuracy: 0.4766\n",
      "Epoch 159/200\n",
      "2553/2553 [==============================] - 0s 125us/sample - loss: 1.0543 - accuracy: 0.4571 - val_loss: 1.0497 - val_accuracy: 0.4766\n",
      "Epoch 160/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.0534 - accuracy: 0.4591 - val_loss: 1.0490 - val_accuracy: 0.4766\n",
      "Epoch 161/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.0525 - accuracy: 0.4606 - val_loss: 1.0482 - val_accuracy: 0.4766\n",
      "Epoch 162/200\n",
      "2553/2553 [==============================] - 0s 126us/sample - loss: 1.0516 - accuracy: 0.4626 - val_loss: 1.0475 - val_accuracy: 0.4766\n",
      "Epoch 163/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0508 - accuracy: 0.4622 - val_loss: 1.0468 - val_accuracy: 0.4766\n",
      "Epoch 164/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0499 - accuracy: 0.4642 - val_loss: 1.0461 - val_accuracy: 0.4860\n",
      "Epoch 165/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.0491 - accuracy: 0.4638 - val_loss: 1.0454 - val_accuracy: 0.4860\n",
      "Epoch 166/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.0483 - accuracy: 0.4642 - val_loss: 1.0448 - val_accuracy: 0.4766\n",
      "Epoch 167/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0475 - accuracy: 0.4646 - val_loss: 1.0441 - val_accuracy: 0.4766\n",
      "Epoch 168/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.0467 - accuracy: 0.4653 - val_loss: 1.0434 - val_accuracy: 0.4766\n",
      "Epoch 169/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0459 - accuracy: 0.4657 - val_loss: 1.0427 - val_accuracy: 0.4766\n",
      "Epoch 170/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0451 - accuracy: 0.4653 - val_loss: 1.0421 - val_accuracy: 0.4860\n",
      "Epoch 171/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0443 - accuracy: 0.4661 - val_loss: 1.0414 - val_accuracy: 0.4953\n",
      "Epoch 172/200\n",
      "2553/2553 [==============================] - 0s 115us/sample - loss: 1.0435 - accuracy: 0.4657 - val_loss: 1.0408 - val_accuracy: 0.4953\n",
      "Epoch 173/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0428 - accuracy: 0.4653 - val_loss: 1.0402 - val_accuracy: 0.4953\n",
      "Epoch 174/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0420 - accuracy: 0.4657 - val_loss: 1.0396 - val_accuracy: 0.4953\n",
      "Epoch 175/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0413 - accuracy: 0.4677 - val_loss: 1.0390 - val_accuracy: 0.4953\n",
      "Epoch 176/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0406 - accuracy: 0.4693 - val_loss: 1.0384 - val_accuracy: 0.4953\n",
      "Epoch 177/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.0399 - accuracy: 0.4700 - val_loss: 1.0378 - val_accuracy: 0.4953\n",
      "Epoch 178/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0392 - accuracy: 0.4708 - val_loss: 1.0372 - val_accuracy: 0.4953\n",
      "Epoch 179/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0385 - accuracy: 0.4704 - val_loss: 1.0367 - val_accuracy: 0.4860\n",
      "Epoch 180/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.0379 - accuracy: 0.4704 - val_loss: 1.0361 - val_accuracy: 0.4860\n",
      "Epoch 181/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.0372 - accuracy: 0.4720 - val_loss: 1.0356 - val_accuracy: 0.4860\n",
      "Epoch 182/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0366 - accuracy: 0.4704 - val_loss: 1.0351 - val_accuracy: 0.4860\n",
      "Epoch 183/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0359 - accuracy: 0.4700 - val_loss: 1.0346 - val_accuracy: 0.4860\n",
      "Epoch 184/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.0353 - accuracy: 0.4720 - val_loss: 1.0341 - val_accuracy: 0.4953\n",
      "Epoch 185/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0347 - accuracy: 0.4728 - val_loss: 1.0336 - val_accuracy: 0.4953\n",
      "Epoch 186/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0341 - accuracy: 0.4755 - val_loss: 1.0332 - val_accuracy: 0.4860\n",
      "Epoch 187/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0335 - accuracy: 0.4755 - val_loss: 1.0327 - val_accuracy: 0.4860\n",
      "Epoch 188/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0329 - accuracy: 0.4743 - val_loss: 1.0323 - val_accuracy: 0.4860\n",
      "Epoch 189/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0324 - accuracy: 0.4755 - val_loss: 1.0319 - val_accuracy: 0.4860\n",
      "Epoch 190/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0318 - accuracy: 0.4747 - val_loss: 1.0314 - val_accuracy: 0.4860\n",
      "Epoch 191/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0313 - accuracy: 0.4747 - val_loss: 1.0310 - val_accuracy: 0.4860\n",
      "Epoch 192/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0307 - accuracy: 0.4759 - val_loss: 1.0306 - val_accuracy: 0.4766\n",
      "Epoch 193/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.0302 - accuracy: 0.4767 - val_loss: 1.0302 - val_accuracy: 0.4766\n",
      "Epoch 194/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0297 - accuracy: 0.4767 - val_loss: 1.0297 - val_accuracy: 0.4766\n",
      "Epoch 195/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0292 - accuracy: 0.4767 - val_loss: 1.0293 - val_accuracy: 0.4766\n",
      "Epoch 196/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0287 - accuracy: 0.4771 - val_loss: 1.0289 - val_accuracy: 0.4766\n",
      "Epoch 197/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0282 - accuracy: 0.4779 - val_loss: 1.0285 - val_accuracy: 0.4673\n",
      "Epoch 198/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.0277 - accuracy: 0.4767 - val_loss: 1.0281 - val_accuracy: 0.4673\n",
      "Epoch 199/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.0272 - accuracy: 0.4759 - val_loss: 1.0277 - val_accuracy: 0.4673\n",
      "Epoch 200/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.0267 - accuracy: 0.4771 - val_loss: 1.0273 - val_accuracy: 0.4766\n",
      "0.47663552 {'loss': 1.0267085565616698, 'accuracy': 0.47708577, 'val_loss': 1.0272782082869627, 'val_accuracy': 0.47663552}\n",
      "Model: \"model_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_26 (InputLayer)        [(None, 29)]              0         \n",
      "_________________________________________________________________\n",
      "flatten_25 (Flatten)         (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 41)                1230      \n",
      "_________________________________________________________________\n",
      "dense_94 (Dense)             (None, 10)                420       \n",
      "_________________________________________________________________\n",
      "dense_95 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_96 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_97 (Dense)             (None, 3)                 33        \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 1,903\n",
      "Trainable params: 1,903\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2553 samples, validate on 107 samples\n",
      "Epoch 1/200\n",
      "2553/2553 [==============================] - 1s 299us/sample - loss: 1.1107 - accuracy: 0.2812 - val_loss: 1.1105 - val_accuracy: 0.2710\n",
      "Epoch 2/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.1106 - accuracy: 0.2805 - val_loss: 1.1104 - val_accuracy: 0.2710\n",
      "Epoch 3/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.1105 - accuracy: 0.2801 - val_loss: 1.1102 - val_accuracy: 0.2710\n",
      "Epoch 4/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.1104 - accuracy: 0.2801 - val_loss: 1.1101 - val_accuracy: 0.2710\n",
      "Epoch 5/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1102 - accuracy: 0.2801 - val_loss: 1.1099 - val_accuracy: 0.2710\n",
      "Epoch 6/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1101 - accuracy: 0.2797 - val_loss: 1.1098 - val_accuracy: 0.2710\n",
      "Epoch 7/200\n",
      "2553/2553 [==============================] - 0s 71us/sample - loss: 1.1100 - accuracy: 0.2793 - val_loss: 1.1097 - val_accuracy: 0.2710\n",
      "Epoch 8/200\n",
      "2553/2553 [==============================] - 0s 66us/sample - loss: 1.1099 - accuracy: 0.2797 - val_loss: 1.1096 - val_accuracy: 0.2710\n",
      "Epoch 9/200\n",
      "2553/2553 [==============================] - 0s 76us/sample - loss: 1.1098 - accuracy: 0.2789 - val_loss: 1.1094 - val_accuracy: 0.2710\n",
      "Epoch 10/200\n",
      "2553/2553 [==============================] - 0s 70us/sample - loss: 1.1097 - accuracy: 0.2785 - val_loss: 1.1093 - val_accuracy: 0.2710\n",
      "Epoch 11/200\n",
      "2553/2553 [==============================] - 0s 70us/sample - loss: 1.1096 - accuracy: 0.2781 - val_loss: 1.1092 - val_accuracy: 0.2710\n",
      "Epoch 12/200\n",
      "2553/2553 [==============================] - 0s 69us/sample - loss: 1.1095 - accuracy: 0.2781 - val_loss: 1.1091 - val_accuracy: 0.2710\n",
      "Epoch 13/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1094 - accuracy: 0.2777 - val_loss: 1.1090 - val_accuracy: 0.2710\n",
      "Epoch 14/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1093 - accuracy: 0.2777 - val_loss: 1.1088 - val_accuracy: 0.2710\n",
      "Epoch 15/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1092 - accuracy: 0.2781 - val_loss: 1.1087 - val_accuracy: 0.2710\n",
      "Epoch 16/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1091 - accuracy: 0.2785 - val_loss: 1.1086 - val_accuracy: 0.2710\n",
      "Epoch 17/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1090 - accuracy: 0.2789 - val_loss: 1.1085 - val_accuracy: 0.2710\n",
      "Epoch 18/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1089 - accuracy: 0.2785 - val_loss: 1.1084 - val_accuracy: 0.2710\n",
      "Epoch 19/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1088 - accuracy: 0.2785 - val_loss: 1.1083 - val_accuracy: 0.2710\n",
      "Epoch 20/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1087 - accuracy: 0.2785 - val_loss: 1.1082 - val_accuracy: 0.2710\n",
      "Epoch 21/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1086 - accuracy: 0.2777 - val_loss: 1.1081 - val_accuracy: 0.2710\n",
      "Epoch 22/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1085 - accuracy: 0.2777 - val_loss: 1.1080 - val_accuracy: 0.2804\n",
      "Epoch 23/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.1084 - accuracy: 0.2777 - val_loss: 1.1079 - val_accuracy: 0.2710\n",
      "Epoch 24/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1083 - accuracy: 0.2777 - val_loss: 1.1078 - val_accuracy: 0.2804\n",
      "Epoch 25/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1082 - accuracy: 0.2785 - val_loss: 1.1077 - val_accuracy: 0.2804\n",
      "Epoch 26/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1081 - accuracy: 0.2785 - val_loss: 1.1076 - val_accuracy: 0.2804\n",
      "Epoch 27/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1081 - accuracy: 0.2773 - val_loss: 1.1075 - val_accuracy: 0.2804\n",
      "Epoch 28/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1080 - accuracy: 0.2769 - val_loss: 1.1074 - val_accuracy: 0.2804\n",
      "Epoch 29/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1079 - accuracy: 0.2765 - val_loss: 1.1073 - val_accuracy: 0.2804\n",
      "Epoch 30/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.1078 - accuracy: 0.2769 - val_loss: 1.1072 - val_accuracy: 0.2804\n",
      "Epoch 31/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1077 - accuracy: 0.2765 - val_loss: 1.1071 - val_accuracy: 0.2804\n",
      "Epoch 32/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1076 - accuracy: 0.2761 - val_loss: 1.1070 - val_accuracy: 0.2804\n",
      "Epoch 33/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1075 - accuracy: 0.2761 - val_loss: 1.1069 - val_accuracy: 0.2804\n",
      "Epoch 34/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1074 - accuracy: 0.2761 - val_loss: 1.1068 - val_accuracy: 0.2804\n",
      "Epoch 35/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1073 - accuracy: 0.2761 - val_loss: 1.1067 - val_accuracy: 0.2804\n",
      "Epoch 36/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1072 - accuracy: 0.2761 - val_loss: 1.1066 - val_accuracy: 0.2804\n",
      "Epoch 37/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.1071 - accuracy: 0.2758 - val_loss: 1.1065 - val_accuracy: 0.2804\n",
      "Epoch 38/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.1071 - accuracy: 0.2761 - val_loss: 1.1064 - val_accuracy: 0.2804\n",
      "Epoch 39/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1070 - accuracy: 0.2765 - val_loss: 1.1063 - val_accuracy: 0.2804\n",
      "Epoch 40/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1069 - accuracy: 0.2769 - val_loss: 1.1063 - val_accuracy: 0.2804\n",
      "Epoch 41/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1068 - accuracy: 0.2773 - val_loss: 1.1062 - val_accuracy: 0.2804\n",
      "Epoch 42/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.1067 - accuracy: 0.2773 - val_loss: 1.1061 - val_accuracy: 0.2804\n",
      "Epoch 43/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.1066 - accuracy: 0.2781 - val_loss: 1.1060 - val_accuracy: 0.2804\n",
      "Epoch 44/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1065 - accuracy: 0.2777 - val_loss: 1.1059 - val_accuracy: 0.2804\n",
      "Epoch 45/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.1064 - accuracy: 0.2777 - val_loss: 1.1058 - val_accuracy: 0.2804\n",
      "Epoch 46/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1064 - accuracy: 0.2781 - val_loss: 1.1057 - val_accuracy: 0.2804\n",
      "Epoch 47/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1063 - accuracy: 0.2781 - val_loss: 1.1057 - val_accuracy: 0.2804\n",
      "Epoch 48/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1062 - accuracy: 0.2781 - val_loss: 1.1056 - val_accuracy: 0.2804\n",
      "Epoch 49/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1061 - accuracy: 0.2785 - val_loss: 1.1055 - val_accuracy: 0.2804\n",
      "Epoch 50/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1060 - accuracy: 0.2785 - val_loss: 1.1054 - val_accuracy: 0.2804\n",
      "Epoch 51/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.1060 - accuracy: 0.2789 - val_loss: 1.1053 - val_accuracy: 0.2804\n",
      "Epoch 52/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.1059 - accuracy: 0.2789 - val_loss: 1.1053 - val_accuracy: 0.2804\n",
      "Epoch 53/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1058 - accuracy: 0.2793 - val_loss: 1.1052 - val_accuracy: 0.2804\n",
      "Epoch 54/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.1057 - accuracy: 0.2789 - val_loss: 1.1051 - val_accuracy: 0.2804\n",
      "Epoch 55/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1056 - accuracy: 0.2797 - val_loss: 1.1050 - val_accuracy: 0.2804\n",
      "Epoch 56/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1056 - accuracy: 0.2797 - val_loss: 1.1050 - val_accuracy: 0.2804\n",
      "Epoch 57/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1055 - accuracy: 0.2793 - val_loss: 1.1049 - val_accuracy: 0.2804\n",
      "Epoch 58/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.1054 - accuracy: 0.2801 - val_loss: 1.1048 - val_accuracy: 0.2804\n",
      "Epoch 59/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1053 - accuracy: 0.2793 - val_loss: 1.1047 - val_accuracy: 0.2804\n",
      "Epoch 60/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.1053 - accuracy: 0.2793 - val_loss: 1.1047 - val_accuracy: 0.2804\n",
      "Epoch 61/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.1052 - accuracy: 0.2793 - val_loss: 1.1046 - val_accuracy: 0.2804\n",
      "Epoch 62/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1051 - accuracy: 0.2801 - val_loss: 1.1045 - val_accuracy: 0.2804\n",
      "Epoch 63/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1051 - accuracy: 0.2801 - val_loss: 1.1045 - val_accuracy: 0.2804\n",
      "Epoch 64/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1050 - accuracy: 0.2808 - val_loss: 1.1044 - val_accuracy: 0.2804\n",
      "Epoch 65/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.1049 - accuracy: 0.2808 - val_loss: 1.1043 - val_accuracy: 0.2804\n",
      "Epoch 66/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.1049 - accuracy: 0.2808 - val_loss: 1.1043 - val_accuracy: 0.2804\n",
      "Epoch 67/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.1048 - accuracy: 0.2812 - val_loss: 1.1042 - val_accuracy: 0.2804\n",
      "Epoch 68/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.1048 - accuracy: 0.2808 - val_loss: 1.1042 - val_accuracy: 0.2804\n",
      "Epoch 69/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1047 - accuracy: 0.2812 - val_loss: 1.1041 - val_accuracy: 0.2804\n",
      "Epoch 70/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1046 - accuracy: 0.2816 - val_loss: 1.1041 - val_accuracy: 0.2804\n",
      "Epoch 71/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.1046 - accuracy: 0.2812 - val_loss: 1.1040 - val_accuracy: 0.2804\n",
      "Epoch 72/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.1045 - accuracy: 0.2801 - val_loss: 1.1039 - val_accuracy: 0.2804\n",
      "Epoch 73/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1044 - accuracy: 0.2797 - val_loss: 1.1039 - val_accuracy: 0.2804\n",
      "Epoch 74/200\n",
      "2553/2553 [==============================] - 0s 71us/sample - loss: 1.1044 - accuracy: 0.2801 - val_loss: 1.1038 - val_accuracy: 0.2804\n",
      "Epoch 75/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1043 - accuracy: 0.2797 - val_loss: 1.1038 - val_accuracy: 0.2804\n",
      "Epoch 76/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.1043 - accuracy: 0.2797 - val_loss: 1.1037 - val_accuracy: 0.2804\n",
      "Epoch 77/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1042 - accuracy: 0.2805 - val_loss: 1.1037 - val_accuracy: 0.2804\n",
      "Epoch 78/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1041 - accuracy: 0.2801 - val_loss: 1.1037 - val_accuracy: 0.2804\n",
      "Epoch 79/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.1041 - accuracy: 0.2805 - val_loss: 1.1036 - val_accuracy: 0.2804\n",
      "Epoch 80/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1040 - accuracy: 0.2808 - val_loss: 1.1036 - val_accuracy: 0.2804\n",
      "Epoch 81/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.1039 - accuracy: 0.2812 - val_loss: 1.1035 - val_accuracy: 0.2804\n",
      "Epoch 82/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1039 - accuracy: 0.2812 - val_loss: 1.1035 - val_accuracy: 0.2804\n",
      "Epoch 83/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1038 - accuracy: 0.2820 - val_loss: 1.1035 - val_accuracy: 0.2804\n",
      "Epoch 84/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1038 - accuracy: 0.2820 - val_loss: 1.1034 - val_accuracy: 0.2804\n",
      "Epoch 85/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1037 - accuracy: 0.2820 - val_loss: 1.1034 - val_accuracy: 0.2804\n",
      "Epoch 86/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.1036 - accuracy: 0.2820 - val_loss: 1.1033 - val_accuracy: 0.2804\n",
      "Epoch 87/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1036 - accuracy: 0.2820 - val_loss: 1.1033 - val_accuracy: 0.2804\n",
      "Epoch 88/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.1035 - accuracy: 0.2824 - val_loss: 1.1033 - val_accuracy: 0.2804\n",
      "Epoch 89/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1035 - accuracy: 0.2832 - val_loss: 1.1033 - val_accuracy: 0.2804\n",
      "Epoch 90/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1034 - accuracy: 0.2828 - val_loss: 1.1032 - val_accuracy: 0.2804\n",
      "Epoch 91/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1034 - accuracy: 0.2828 - val_loss: 1.1032 - val_accuracy: 0.2804\n",
      "Epoch 92/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1033 - accuracy: 0.2832 - val_loss: 1.1032 - val_accuracy: 0.2804\n",
      "Epoch 93/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1033 - accuracy: 0.2832 - val_loss: 1.1031 - val_accuracy: 0.2804\n",
      "Epoch 94/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.1032 - accuracy: 0.2832 - val_loss: 1.1031 - val_accuracy: 0.2804\n",
      "Epoch 95/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.1032 - accuracy: 0.2832 - val_loss: 1.1031 - val_accuracy: 0.2804\n",
      "Epoch 96/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1031 - accuracy: 0.2840 - val_loss: 1.1030 - val_accuracy: 0.2804\n",
      "Epoch 97/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1031 - accuracy: 0.2840 - val_loss: 1.1030 - val_accuracy: 0.2804\n",
      "Epoch 98/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.1030 - accuracy: 0.2844 - val_loss: 1.1030 - val_accuracy: 0.2804\n",
      "Epoch 99/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1030 - accuracy: 0.2840 - val_loss: 1.1030 - val_accuracy: 0.2804\n",
      "Epoch 100/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1029 - accuracy: 0.2844 - val_loss: 1.1029 - val_accuracy: 0.2804\n",
      "Epoch 101/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.1029 - accuracy: 0.2840 - val_loss: 1.1029 - val_accuracy: 0.2804\n",
      "Epoch 102/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1028 - accuracy: 0.2840 - val_loss: 1.1029 - val_accuracy: 0.2804\n",
      "Epoch 103/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.1028 - accuracy: 0.2840 - val_loss: 1.1028 - val_accuracy: 0.2804\n",
      "Epoch 104/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1027 - accuracy: 0.2840 - val_loss: 1.1028 - val_accuracy: 0.2804\n",
      "Epoch 105/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1027 - accuracy: 0.2844 - val_loss: 1.1028 - val_accuracy: 0.2804\n",
      "Epoch 106/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1026 - accuracy: 0.2844 - val_loss: 1.1027 - val_accuracy: 0.2804\n",
      "Epoch 107/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1026 - accuracy: 0.2844 - val_loss: 1.1027 - val_accuracy: 0.2804\n",
      "Epoch 108/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.1025 - accuracy: 0.2844 - val_loss: 1.1027 - val_accuracy: 0.2804\n",
      "Epoch 109/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.1025 - accuracy: 0.2844 - val_loss: 1.1026 - val_accuracy: 0.2710\n",
      "Epoch 110/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.1025 - accuracy: 0.2848 - val_loss: 1.1026 - val_accuracy: 0.2710\n",
      "Epoch 111/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.1024 - accuracy: 0.2852 - val_loss: 1.1026 - val_accuracy: 0.2617\n",
      "Epoch 112/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1024 - accuracy: 0.2848 - val_loss: 1.1025 - val_accuracy: 0.2617\n",
      "Epoch 113/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1023 - accuracy: 0.2848 - val_loss: 1.1025 - val_accuracy: 0.2617\n",
      "Epoch 114/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1023 - accuracy: 0.2848 - val_loss: 1.1025 - val_accuracy: 0.2617\n",
      "Epoch 115/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1022 - accuracy: 0.2855 - val_loss: 1.1024 - val_accuracy: 0.2617\n",
      "Epoch 116/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1022 - accuracy: 0.2859 - val_loss: 1.1024 - val_accuracy: 0.2617\n",
      "Epoch 117/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.1022 - accuracy: 0.2859 - val_loss: 1.1024 - val_accuracy: 0.2617\n",
      "Epoch 118/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1021 - accuracy: 0.2852 - val_loss: 1.1024 - val_accuracy: 0.2617\n",
      "Epoch 119/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1021 - accuracy: 0.2852 - val_loss: 1.1023 - val_accuracy: 0.2617\n",
      "Epoch 120/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.1020 - accuracy: 0.2852 - val_loss: 1.1023 - val_accuracy: 0.2617\n",
      "Epoch 121/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1020 - accuracy: 0.2848 - val_loss: 1.1023 - val_accuracy: 0.2617\n",
      "Epoch 122/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1020 - accuracy: 0.2844 - val_loss: 1.1022 - val_accuracy: 0.2617\n",
      "Epoch 123/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1019 - accuracy: 0.2848 - val_loss: 1.1022 - val_accuracy: 0.2617\n",
      "Epoch 124/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.1019 - accuracy: 0.2852 - val_loss: 1.1022 - val_accuracy: 0.2617\n",
      "Epoch 125/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.1018 - accuracy: 0.2848 - val_loss: 1.1022 - val_accuracy: 0.2617\n",
      "Epoch 126/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1018 - accuracy: 0.2844 - val_loss: 1.1021 - val_accuracy: 0.2617\n",
      "Epoch 127/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1018 - accuracy: 0.2852 - val_loss: 1.1021 - val_accuracy: 0.2617\n",
      "Epoch 128/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1017 - accuracy: 0.2852 - val_loss: 1.1021 - val_accuracy: 0.2617\n",
      "Epoch 129/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1017 - accuracy: 0.2859 - val_loss: 1.1020 - val_accuracy: 0.2617\n",
      "Epoch 130/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1017 - accuracy: 0.2863 - val_loss: 1.1020 - val_accuracy: 0.2617\n",
      "Epoch 131/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1017 - accuracy: 0.2863 - val_loss: 1.1020 - val_accuracy: 0.2617\n",
      "Epoch 132/200\n",
      "2553/2553 [==============================] - 0s 65us/sample - loss: 1.1016 - accuracy: 0.2863 - val_loss: 1.1020 - val_accuracy: 0.2617\n",
      "Epoch 133/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.1016 - accuracy: 0.2863 - val_loss: 1.1019 - val_accuracy: 0.2617\n",
      "Epoch 134/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1016 - accuracy: 0.2863 - val_loss: 1.1019 - val_accuracy: 0.2617\n",
      "Epoch 135/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1015 - accuracy: 0.2863 - val_loss: 1.1019 - val_accuracy: 0.2617\n",
      "Epoch 136/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1015 - accuracy: 0.2871 - val_loss: 1.1019 - val_accuracy: 0.2617\n",
      "Epoch 137/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.1015 - accuracy: 0.2867 - val_loss: 1.1018 - val_accuracy: 0.2617\n",
      "Epoch 138/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1014 - accuracy: 0.2863 - val_loss: 1.1018 - val_accuracy: 0.2617\n",
      "Epoch 139/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.1014 - accuracy: 0.2863 - val_loss: 1.1018 - val_accuracy: 0.2617\n",
      "Epoch 140/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1014 - accuracy: 0.2863 - val_loss: 1.1017 - val_accuracy: 0.2617\n",
      "Epoch 141/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1014 - accuracy: 0.2863 - val_loss: 1.1017 - val_accuracy: 0.2617\n",
      "Epoch 142/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1013 - accuracy: 0.2863 - val_loss: 1.1017 - val_accuracy: 0.2617\n",
      "Epoch 143/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1013 - accuracy: 0.2855 - val_loss: 1.1017 - val_accuracy: 0.2617\n",
      "Epoch 144/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1013 - accuracy: 0.2859 - val_loss: 1.1016 - val_accuracy: 0.2617\n",
      "Epoch 145/200\n",
      "2553/2553 [==============================] - 0s 65us/sample - loss: 1.1013 - accuracy: 0.2859 - val_loss: 1.1016 - val_accuracy: 0.2617\n",
      "Epoch 146/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1012 - accuracy: 0.2871 - val_loss: 1.1016 - val_accuracy: 0.2617\n",
      "Epoch 147/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.1012 - accuracy: 0.2875 - val_loss: 1.1016 - val_accuracy: 0.2617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 148/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1012 - accuracy: 0.2879 - val_loss: 1.1016 - val_accuracy: 0.2617\n",
      "Epoch 149/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.1011 - accuracy: 0.2863 - val_loss: 1.1015 - val_accuracy: 0.2617\n",
      "Epoch 150/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.1011 - accuracy: 0.2867 - val_loss: 1.1015 - val_accuracy: 0.2617\n",
      "Epoch 151/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.1011 - accuracy: 0.2871 - val_loss: 1.1015 - val_accuracy: 0.2617\n",
      "Epoch 152/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.1011 - accuracy: 0.2875 - val_loss: 1.1015 - val_accuracy: 0.2617\n",
      "Epoch 153/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1010 - accuracy: 0.2875 - val_loss: 1.1014 - val_accuracy: 0.2617\n",
      "Epoch 154/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1010 - accuracy: 0.2875 - val_loss: 1.1014 - val_accuracy: 0.2617\n",
      "Epoch 155/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1010 - accuracy: 0.2875 - val_loss: 1.1014 - val_accuracy: 0.2617\n",
      "Epoch 156/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1010 - accuracy: 0.2879 - val_loss: 1.1014 - val_accuracy: 0.2617\n",
      "Epoch 157/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1009 - accuracy: 0.2875 - val_loss: 1.1013 - val_accuracy: 0.2617\n",
      "Epoch 158/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1009 - accuracy: 0.2875 - val_loss: 1.1013 - val_accuracy: 0.2523\n",
      "Epoch 159/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1009 - accuracy: 0.2875 - val_loss: 1.1013 - val_accuracy: 0.2523\n",
      "Epoch 160/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.1009 - accuracy: 0.2875 - val_loss: 1.1013 - val_accuracy: 0.2523\n",
      "Epoch 161/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1009 - accuracy: 0.2879 - val_loss: 1.1012 - val_accuracy: 0.2523\n",
      "Epoch 162/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.1008 - accuracy: 0.2875 - val_loss: 1.1012 - val_accuracy: 0.2430\n",
      "Epoch 163/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1008 - accuracy: 0.2879 - val_loss: 1.1012 - val_accuracy: 0.2430\n",
      "Epoch 164/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1008 - accuracy: 0.2879 - val_loss: 1.1012 - val_accuracy: 0.2430\n",
      "Epoch 165/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1008 - accuracy: 0.2883 - val_loss: 1.1012 - val_accuracy: 0.2430\n",
      "Epoch 166/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1007 - accuracy: 0.2887 - val_loss: 1.1011 - val_accuracy: 0.2430\n",
      "Epoch 167/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.1007 - accuracy: 0.2891 - val_loss: 1.1011 - val_accuracy: 0.2430\n",
      "Epoch 168/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1007 - accuracy: 0.2895 - val_loss: 1.1011 - val_accuracy: 0.2430\n",
      "Epoch 169/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1007 - accuracy: 0.2899 - val_loss: 1.1011 - val_accuracy: 0.2430\n",
      "Epoch 170/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1007 - accuracy: 0.2895 - val_loss: 1.1011 - val_accuracy: 0.2430\n",
      "Epoch 171/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1006 - accuracy: 0.2895 - val_loss: 1.1010 - val_accuracy: 0.2430\n",
      "Epoch 172/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1006 - accuracy: 0.2891 - val_loss: 1.1010 - val_accuracy: 0.2430\n",
      "Epoch 173/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1006 - accuracy: 0.2891 - val_loss: 1.1010 - val_accuracy: 0.2430\n",
      "Epoch 174/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1006 - accuracy: 0.2895 - val_loss: 1.1010 - val_accuracy: 0.2430\n",
      "Epoch 175/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.1006 - accuracy: 0.2895 - val_loss: 1.1010 - val_accuracy: 0.2430\n",
      "Epoch 176/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1006 - accuracy: 0.2895 - val_loss: 1.1009 - val_accuracy: 0.2430\n",
      "Epoch 177/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.1005 - accuracy: 0.2895 - val_loss: 1.1009 - val_accuracy: 0.2430\n",
      "Epoch 178/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1005 - accuracy: 0.2895 - val_loss: 1.1009 - val_accuracy: 0.2430\n",
      "Epoch 179/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.1005 - accuracy: 0.2891 - val_loss: 1.1009 - val_accuracy: 0.2430\n",
      "Epoch 180/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1005 - accuracy: 0.2887 - val_loss: 1.1009 - val_accuracy: 0.2430\n",
      "Epoch 181/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1005 - accuracy: 0.2875 - val_loss: 1.1008 - val_accuracy: 0.2430\n",
      "Epoch 182/200\n",
      "2553/2553 [==============================] - 0s 70us/sample - loss: 1.1005 - accuracy: 0.2875 - val_loss: 1.1008 - val_accuracy: 0.2430\n",
      "Epoch 183/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.1004 - accuracy: 0.2871 - val_loss: 1.1008 - val_accuracy: 0.2430\n",
      "Epoch 184/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1004 - accuracy: 0.2871 - val_loss: 1.1008 - val_accuracy: 0.2430\n",
      "Epoch 185/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1004 - accuracy: 0.2871 - val_loss: 1.1007 - val_accuracy: 0.2430\n",
      "Epoch 186/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1004 - accuracy: 0.2879 - val_loss: 1.1007 - val_accuracy: 0.2430\n",
      "Epoch 187/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1004 - accuracy: 0.2887 - val_loss: 1.1007 - val_accuracy: 0.2430\n",
      "Epoch 188/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1003 - accuracy: 0.2887 - val_loss: 1.1007 - val_accuracy: 0.2430\n",
      "Epoch 189/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.1003 - accuracy: 0.2887 - val_loss: 1.1007 - val_accuracy: 0.2430\n",
      "Epoch 190/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1003 - accuracy: 0.2887 - val_loss: 1.1007 - val_accuracy: 0.2430\n",
      "Epoch 191/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1003 - accuracy: 0.2887 - val_loss: 1.1006 - val_accuracy: 0.2430\n",
      "Epoch 192/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.1003 - accuracy: 0.2891 - val_loss: 1.1006 - val_accuracy: 0.2430\n",
      "Epoch 193/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.1003 - accuracy: 0.2895 - val_loss: 1.1006 - val_accuracy: 0.2430\n",
      "Epoch 194/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1003 - accuracy: 0.2899 - val_loss: 1.1006 - val_accuracy: 0.2430\n",
      "Epoch 195/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1002 - accuracy: 0.2899 - val_loss: 1.1006 - val_accuracy: 0.2430\n",
      "Epoch 196/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.1002 - accuracy: 0.2895 - val_loss: 1.1006 - val_accuracy: 0.2430\n",
      "Epoch 197/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.1002 - accuracy: 0.2891 - val_loss: 1.1006 - val_accuracy: 0.2430\n",
      "Epoch 198/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1002 - accuracy: 0.2895 - val_loss: 1.1005 - val_accuracy: 0.2430\n",
      "Epoch 199/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.1002 - accuracy: 0.2899 - val_loss: 1.1005 - val_accuracy: 0.2430\n",
      "Epoch 200/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1002 - accuracy: 0.2895 - val_loss: 1.1005 - val_accuracy: 0.2430\n",
      "0.24299066 {'loss': 1.1001636932935615, 'accuracy': 0.28946337, 'val_loss': 1.1005203946728572, 'val_accuracy': 0.24299066}\n",
      "Model: \"model_26\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_27 (InputLayer)        [(None, 29)]              0         \n",
      "_________________________________________________________________\n",
      "flatten_26 (Flatten)         (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_98 (Dense)             (None, 41)                1230      \n",
      "_________________________________________________________________\n",
      "dense_99 (Dense)             (None, 10)                420       \n",
      "_________________________________________________________________\n",
      "dense_100 (Dense)            (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_101 (Dense)            (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_102 (Dense)            (None, 3)                 33        \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 1,903\n",
      "Trainable params: 1,903\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2553 samples, validate on 107 samples\n",
      "Epoch 1/200\n",
      "2553/2553 [==============================] - 1s 350us/sample - loss: 1.2163 - accuracy: 0.2902 - val_loss: 1.2040 - val_accuracy: 0.2336\n",
      "Epoch 2/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.2179 - accuracy: 0.2883 - val_loss: 1.2017 - val_accuracy: 0.2336\n",
      "Epoch 3/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.2120 - accuracy: 0.2867 - val_loss: 1.1995 - val_accuracy: 0.2336\n",
      "Epoch 4/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.2102 - accuracy: 0.2918 - val_loss: 1.1973 - val_accuracy: 0.2336\n",
      "Epoch 5/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.2055 - accuracy: 0.2961 - val_loss: 1.1952 - val_accuracy: 0.2336\n",
      "Epoch 6/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.2117 - accuracy: 0.2934 - val_loss: 1.1931 - val_accuracy: 0.2336\n",
      "Epoch 7/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.2046 - accuracy: 0.2942 - val_loss: 1.1910 - val_accuracy: 0.2336\n",
      "Epoch 8/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.2044 - accuracy: 0.2973 - val_loss: 1.1889 - val_accuracy: 0.2336\n",
      "Epoch 9/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.2043 - accuracy: 0.2961 - val_loss: 1.1869 - val_accuracy: 0.2336\n",
      "Epoch 10/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.1938 - accuracy: 0.2969 - val_loss: 1.1849 - val_accuracy: 0.2336\n",
      "Epoch 11/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.1923 - accuracy: 0.2914 - val_loss: 1.1830 - val_accuracy: 0.2336\n",
      "Epoch 12/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.1990 - accuracy: 0.2930 - val_loss: 1.1809 - val_accuracy: 0.2336\n",
      "Epoch 13/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.1926 - accuracy: 0.2953 - val_loss: 1.1789 - val_accuracy: 0.2336\n",
      "Epoch 14/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.1888 - accuracy: 0.2969 - val_loss: 1.1769 - val_accuracy: 0.2336\n",
      "Epoch 15/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.1880 - accuracy: 0.2891 - val_loss: 1.1751 - val_accuracy: 0.2336\n",
      "Epoch 16/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.1855 - accuracy: 0.2949 - val_loss: 1.1733 - val_accuracy: 0.2336\n",
      "Epoch 17/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.1892 - accuracy: 0.2938 - val_loss: 1.1714 - val_accuracy: 0.2336\n",
      "Epoch 18/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.1753 - accuracy: 0.2914 - val_loss: 1.1697 - val_accuracy: 0.2336\n",
      "Epoch 19/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.1751 - accuracy: 0.2949 - val_loss: 1.1679 - val_accuracy: 0.2336\n",
      "Epoch 20/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.1803 - accuracy: 0.2930 - val_loss: 1.1661 - val_accuracy: 0.2336\n",
      "Epoch 21/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.1723 - accuracy: 0.2969 - val_loss: 1.1645 - val_accuracy: 0.2336\n",
      "Epoch 22/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.1665 - accuracy: 0.3004 - val_loss: 1.1629 - val_accuracy: 0.2336\n",
      "Epoch 23/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.1683 - accuracy: 0.2957 - val_loss: 1.1612 - val_accuracy: 0.2336\n",
      "Epoch 24/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.1692 - accuracy: 0.3000 - val_loss: 1.1595 - val_accuracy: 0.2336\n",
      "Epoch 25/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.1751 - accuracy: 0.3024 - val_loss: 1.1578 - val_accuracy: 0.2336\n",
      "Epoch 26/200\n",
      "2553/2553 [==============================] - 0s 120us/sample - loss: 1.1639 - accuracy: 0.3020 - val_loss: 1.1561 - val_accuracy: 0.2336\n",
      "Epoch 27/200\n",
      "2553/2553 [==============================] - 0s 159us/sample - loss: 1.1616 - accuracy: 0.2977 - val_loss: 1.1545 - val_accuracy: 0.2336\n",
      "Epoch 28/200\n",
      "2553/2553 [==============================] - 0s 159us/sample - loss: 1.1616 - accuracy: 0.3063 - val_loss: 1.1529 - val_accuracy: 0.2430\n",
      "Epoch 29/200\n",
      "2553/2553 [==============================] - 0s 146us/sample - loss: 1.1690 - accuracy: 0.2957 - val_loss: 1.1514 - val_accuracy: 0.2430\n",
      "Epoch 30/200\n",
      "2553/2553 [==============================] - 0s 118us/sample - loss: 1.1562 - accuracy: 0.3024 - val_loss: 1.1500 - val_accuracy: 0.2430\n",
      "Epoch 31/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.1612 - accuracy: 0.2996 - val_loss: 1.1485 - val_accuracy: 0.2523\n",
      "Epoch 32/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.1574 - accuracy: 0.2938 - val_loss: 1.1470 - val_accuracy: 0.2523\n",
      "Epoch 33/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 1.1588 - accuracy: 0.3028 - val_loss: 1.1456 - val_accuracy: 0.2523\n",
      "Epoch 34/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.1547 - accuracy: 0.3036 - val_loss: 1.1442 - val_accuracy: 0.2523\n",
      "Epoch 35/200\n",
      "2553/2553 [==============================] - 0s 125us/sample - loss: 1.1528 - accuracy: 0.3016 - val_loss: 1.1429 - val_accuracy: 0.2523\n",
      "Epoch 36/200\n",
      "2553/2553 [==============================] - 0s 121us/sample - loss: 1.1521 - accuracy: 0.3020 - val_loss: 1.1415 - val_accuracy: 0.2523\n",
      "Epoch 37/200\n",
      "2553/2553 [==============================] - 0s 118us/sample - loss: 1.1433 - accuracy: 0.3008 - val_loss: 1.1403 - val_accuracy: 0.2523\n",
      "Epoch 38/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.1402 - accuracy: 0.3047 - val_loss: 1.1391 - val_accuracy: 0.2617\n",
      "Epoch 39/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.1419 - accuracy: 0.3047 - val_loss: 1.1378 - val_accuracy: 0.2617\n",
      "Epoch 40/200\n",
      "2553/2553 [==============================] - 0s 115us/sample - loss: 1.1499 - accuracy: 0.2977 - val_loss: 1.1366 - val_accuracy: 0.2617\n",
      "Epoch 41/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 1.1451 - accuracy: 0.3043 - val_loss: 1.1353 - val_accuracy: 0.2617\n",
      "Epoch 42/200\n",
      "2553/2553 [==============================] - 0s 120us/sample - loss: 1.1428 - accuracy: 0.3028 - val_loss: 1.1341 - val_accuracy: 0.2617\n",
      "Epoch 43/200\n",
      "2553/2553 [==============================] - 0s 122us/sample - loss: 1.1421 - accuracy: 0.3094 - val_loss: 1.1330 - val_accuracy: 0.2617\n",
      "Epoch 44/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.1386 - accuracy: 0.3071 - val_loss: 1.1319 - val_accuracy: 0.2617\n",
      "Epoch 45/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.1353 - accuracy: 0.3040 - val_loss: 1.1308 - val_accuracy: 0.2804\n",
      "Epoch 46/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.1392 - accuracy: 0.3098 - val_loss: 1.1297 - val_accuracy: 0.2804\n",
      "Epoch 47/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.1299 - accuracy: 0.3083 - val_loss: 1.1287 - val_accuracy: 0.2804\n",
      "Epoch 48/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.1385 - accuracy: 0.3040 - val_loss: 1.1275 - val_accuracy: 0.2804\n",
      "Epoch 49/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.1359 - accuracy: 0.3059 - val_loss: 1.1265 - val_accuracy: 0.2804\n",
      "Epoch 50/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.1270 - accuracy: 0.3063 - val_loss: 1.1255 - val_accuracy: 0.2804\n",
      "Epoch 51/200\n",
      "2553/2553 [==============================] - 0s 118us/sample - loss: 1.1308 - accuracy: 0.3071 - val_loss: 1.1246 - val_accuracy: 0.2804\n",
      "Epoch 52/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.1273 - accuracy: 0.3102 - val_loss: 1.1236 - val_accuracy: 0.2804\n",
      "Epoch 53/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.1255 - accuracy: 0.3192 - val_loss: 1.1227 - val_accuracy: 0.2804\n",
      "Epoch 54/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.1244 - accuracy: 0.3118 - val_loss: 1.1217 - val_accuracy: 0.2804\n",
      "Epoch 55/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.1291 - accuracy: 0.3141 - val_loss: 1.1208 - val_accuracy: 0.2804\n",
      "Epoch 56/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.1207 - accuracy: 0.3188 - val_loss: 1.1199 - val_accuracy: 0.2897\n",
      "Epoch 57/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.1241 - accuracy: 0.3165 - val_loss: 1.1190 - val_accuracy: 0.2991\n",
      "Epoch 58/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.1260 - accuracy: 0.3157 - val_loss: 1.1181 - val_accuracy: 0.3084\n",
      "Epoch 59/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.1193 - accuracy: 0.3173 - val_loss: 1.1172 - val_accuracy: 0.3084\n",
      "Epoch 60/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.1185 - accuracy: 0.3188 - val_loss: 1.1164 - val_accuracy: 0.3084\n",
      "Epoch 61/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.1215 - accuracy: 0.3188 - val_loss: 1.1156 - val_accuracy: 0.3178\n",
      "Epoch 62/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.1227 - accuracy: 0.3157 - val_loss: 1.1149 - val_accuracy: 0.3178\n",
      "Epoch 63/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.1167 - accuracy: 0.3145 - val_loss: 1.1142 - val_accuracy: 0.3178\n",
      "Epoch 64/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.1189 - accuracy: 0.3165 - val_loss: 1.1135 - val_accuracy: 0.3178\n",
      "Epoch 65/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.1186 - accuracy: 0.3177 - val_loss: 1.1129 - val_accuracy: 0.3178\n",
      "Epoch 66/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.1178 - accuracy: 0.3184 - val_loss: 1.1122 - val_accuracy: 0.3271\n",
      "Epoch 67/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.1116 - accuracy: 0.3255 - val_loss: 1.1116 - val_accuracy: 0.3364\n",
      "Epoch 68/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.1120 - accuracy: 0.3184 - val_loss: 1.1109 - val_accuracy: 0.3364\n",
      "Epoch 69/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.1100 - accuracy: 0.3314 - val_loss: 1.1102 - val_accuracy: 0.3364\n",
      "Epoch 70/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.1112 - accuracy: 0.3294 - val_loss: 1.1096 - val_accuracy: 0.3364\n",
      "Epoch 71/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.1080 - accuracy: 0.3365 - val_loss: 1.1089 - val_accuracy: 0.3364\n",
      "Epoch 72/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.1136 - accuracy: 0.3239 - val_loss: 1.1082 - val_accuracy: 0.3551\n",
      "Epoch 73/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.1070 - accuracy: 0.3290 - val_loss: 1.1076 - val_accuracy: 0.3551\n",
      "Epoch 74/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.1087 - accuracy: 0.3298 - val_loss: 1.1069 - val_accuracy: 0.3551\n",
      "Epoch 75/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.1052 - accuracy: 0.3306 - val_loss: 1.1063 - val_accuracy: 0.3645\n",
      "Epoch 76/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.1041 - accuracy: 0.3357 - val_loss: 1.1058 - val_accuracy: 0.3645\n",
      "Epoch 77/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.1004 - accuracy: 0.3314 - val_loss: 1.1052 - val_accuracy: 0.3645\n",
      "Epoch 78/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.1027 - accuracy: 0.3361 - val_loss: 1.1046 - val_accuracy: 0.3645\n",
      "Epoch 79/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.1051 - accuracy: 0.3400 - val_loss: 1.1040 - val_accuracy: 0.3645\n",
      "Epoch 80/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.1056 - accuracy: 0.3337 - val_loss: 1.1034 - val_accuracy: 0.3645\n",
      "Epoch 81/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.1014 - accuracy: 0.3325 - val_loss: 1.1029 - val_accuracy: 0.3645\n",
      "Epoch 82/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.1014 - accuracy: 0.3388 - val_loss: 1.1024 - val_accuracy: 0.3645\n",
      "Epoch 83/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.0965 - accuracy: 0.3373 - val_loss: 1.1019 - val_accuracy: 0.3738\n",
      "Epoch 84/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.1005 - accuracy: 0.3392 - val_loss: 1.1014 - val_accuracy: 0.3738\n",
      "Epoch 85/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0980 - accuracy: 0.3463 - val_loss: 1.1009 - val_accuracy: 0.3738\n",
      "Epoch 86/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0993 - accuracy: 0.3486 - val_loss: 1.1004 - val_accuracy: 0.3738\n",
      "Epoch 87/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0948 - accuracy: 0.3459 - val_loss: 1.1000 - val_accuracy: 0.3738\n",
      "Epoch 88/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0941 - accuracy: 0.3514 - val_loss: 1.0995 - val_accuracy: 0.3738\n",
      "Epoch 89/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0997 - accuracy: 0.3447 - val_loss: 1.0991 - val_accuracy: 0.3645\n",
      "Epoch 90/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.1013 - accuracy: 0.3404 - val_loss: 1.0986 - val_accuracy: 0.3645\n",
      "Epoch 91/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0974 - accuracy: 0.3455 - val_loss: 1.0982 - val_accuracy: 0.3645\n",
      "Epoch 92/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 1.0960 - accuracy: 0.3478 - val_loss: 1.0978 - val_accuracy: 0.3738\n",
      "Epoch 93/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0956 - accuracy: 0.3584 - val_loss: 1.0974 - val_accuracy: 0.3738\n",
      "Epoch 94/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.0946 - accuracy: 0.3600 - val_loss: 1.0970 - val_accuracy: 0.3738\n",
      "Epoch 95/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0960 - accuracy: 0.3576 - val_loss: 1.0966 - val_accuracy: 0.3832\n",
      "Epoch 96/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0910 - accuracy: 0.3580 - val_loss: 1.0962 - val_accuracy: 0.3832\n",
      "Epoch 97/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.0936 - accuracy: 0.3572 - val_loss: 1.0959 - val_accuracy: 0.3645\n",
      "Epoch 98/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0894 - accuracy: 0.3619 - val_loss: 1.0955 - val_accuracy: 0.3645\n",
      "Epoch 99/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.0876 - accuracy: 0.3564 - val_loss: 1.0951 - val_accuracy: 0.3645\n",
      "Epoch 100/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.0912 - accuracy: 0.3596 - val_loss: 1.0948 - val_accuracy: 0.3832\n",
      "Epoch 101/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.0897 - accuracy: 0.3627 - val_loss: 1.0945 - val_accuracy: 0.3832\n",
      "Epoch 102/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0924 - accuracy: 0.3756 - val_loss: 1.0941 - val_accuracy: 0.3832\n",
      "Epoch 103/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0866 - accuracy: 0.3666 - val_loss: 1.0938 - val_accuracy: 0.3832\n",
      "Epoch 104/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0904 - accuracy: 0.3643 - val_loss: 1.0935 - val_accuracy: 0.3832\n",
      "Epoch 105/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.0848 - accuracy: 0.3752 - val_loss: 1.0931 - val_accuracy: 0.3925\n",
      "Epoch 106/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0900 - accuracy: 0.3694 - val_loss: 1.0928 - val_accuracy: 0.3925\n",
      "Epoch 107/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.0824 - accuracy: 0.3823 - val_loss: 1.0925 - val_accuracy: 0.3925\n",
      "Epoch 108/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0889 - accuracy: 0.3690 - val_loss: 1.0922 - val_accuracy: 0.4019\n",
      "Epoch 109/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.0895 - accuracy: 0.3721 - val_loss: 1.0919 - val_accuracy: 0.4206\n",
      "Epoch 110/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0880 - accuracy: 0.3682 - val_loss: 1.0915 - val_accuracy: 0.4206\n",
      "Epoch 111/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0864 - accuracy: 0.3776 - val_loss: 1.0912 - val_accuracy: 0.4206\n",
      "Epoch 112/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0872 - accuracy: 0.3725 - val_loss: 1.0908 - val_accuracy: 0.4112\n",
      "Epoch 113/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.0813 - accuracy: 0.3843 - val_loss: 1.0904 - val_accuracy: 0.4112\n",
      "Epoch 114/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0881 - accuracy: 0.3768 - val_loss: 1.0901 - val_accuracy: 0.4112\n",
      "Epoch 115/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.0861 - accuracy: 0.3796 - val_loss: 1.0897 - val_accuracy: 0.4206\n",
      "Epoch 116/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0883 - accuracy: 0.3913 - val_loss: 1.0893 - val_accuracy: 0.4112\n",
      "Epoch 117/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0840 - accuracy: 0.3780 - val_loss: 1.0890 - val_accuracy: 0.4112\n",
      "Epoch 118/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0848 - accuracy: 0.3796 - val_loss: 1.0886 - val_accuracy: 0.4112\n",
      "Epoch 119/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0864 - accuracy: 0.3940 - val_loss: 1.0883 - val_accuracy: 0.4112\n",
      "Epoch 120/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0839 - accuracy: 0.3831 - val_loss: 1.0880 - val_accuracy: 0.4112\n",
      "Epoch 121/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0852 - accuracy: 0.3749 - val_loss: 1.0877 - val_accuracy: 0.4112\n",
      "Epoch 122/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0818 - accuracy: 0.3937 - val_loss: 1.0873 - val_accuracy: 0.4019\n",
      "Epoch 123/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.0832 - accuracy: 0.3788 - val_loss: 1.0870 - val_accuracy: 0.4112\n",
      "Epoch 124/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.0836 - accuracy: 0.3913 - val_loss: 1.0867 - val_accuracy: 0.4112\n",
      "Epoch 125/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0842 - accuracy: 0.3862 - val_loss: 1.0864 - val_accuracy: 0.4112\n",
      "Epoch 126/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0814 - accuracy: 0.3925 - val_loss: 1.0860 - val_accuracy: 0.4112\n",
      "Epoch 127/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.0767 - accuracy: 0.3964 - val_loss: 1.0857 - val_accuracy: 0.4112\n",
      "Epoch 128/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0824 - accuracy: 0.3886 - val_loss: 1.0854 - val_accuracy: 0.4112\n",
      "Epoch 129/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0815 - accuracy: 0.4011 - val_loss: 1.0851 - val_accuracy: 0.4112\n",
      "Epoch 130/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.0816 - accuracy: 0.4015 - val_loss: 1.0847 - val_accuracy: 0.4112\n",
      "Epoch 131/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0797 - accuracy: 0.4034 - val_loss: 1.0844 - val_accuracy: 0.4112\n",
      "Epoch 132/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.0792 - accuracy: 0.3980 - val_loss: 1.0841 - val_accuracy: 0.4112\n",
      "Epoch 133/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0816 - accuracy: 0.3897 - val_loss: 1.0838 - val_accuracy: 0.4112\n",
      "Epoch 134/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0784 - accuracy: 0.4034 - val_loss: 1.0834 - val_accuracy: 0.4112\n",
      "Epoch 135/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.0807 - accuracy: 0.4042 - val_loss: 1.0831 - val_accuracy: 0.4112\n",
      "Epoch 136/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0794 - accuracy: 0.4070 - val_loss: 1.0828 - val_accuracy: 0.4112\n",
      "Epoch 137/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0764 - accuracy: 0.4085 - val_loss: 1.0825 - val_accuracy: 0.4112\n",
      "Epoch 138/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0809 - accuracy: 0.3980 - val_loss: 1.0822 - val_accuracy: 0.4112\n",
      "Epoch 139/200\n",
      "2553/2553 [==============================] - 0s 99us/sample - loss: 1.0761 - accuracy: 0.4132 - val_loss: 1.0819 - val_accuracy: 0.4112\n",
      "Epoch 140/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0761 - accuracy: 0.4089 - val_loss: 1.0816 - val_accuracy: 0.4112\n",
      "Epoch 141/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0761 - accuracy: 0.4089 - val_loss: 1.0813 - val_accuracy: 0.4112\n",
      "Epoch 142/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.0777 - accuracy: 0.4023 - val_loss: 1.0810 - val_accuracy: 0.4112\n",
      "Epoch 143/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.0758 - accuracy: 0.4058 - val_loss: 1.0807 - val_accuracy: 0.4112\n",
      "Epoch 144/200\n",
      "2553/2553 [==============================] - 0s 120us/sample - loss: 1.0748 - accuracy: 0.4050 - val_loss: 1.0804 - val_accuracy: 0.4112\n",
      "Epoch 145/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0706 - accuracy: 0.4156 - val_loss: 1.0801 - val_accuracy: 0.4112\n",
      "Epoch 146/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0736 - accuracy: 0.4109 - val_loss: 1.0798 - val_accuracy: 0.4112\n",
      "Epoch 147/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0723 - accuracy: 0.4160 - val_loss: 1.0795 - val_accuracy: 0.4112\n",
      "Epoch 148/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0762 - accuracy: 0.4074 - val_loss: 1.0792 - val_accuracy: 0.4112\n",
      "Epoch 149/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0723 - accuracy: 0.4191 - val_loss: 1.0790 - val_accuracy: 0.4112\n",
      "Epoch 150/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0747 - accuracy: 0.4187 - val_loss: 1.0787 - val_accuracy: 0.4019\n",
      "Epoch 151/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0725 - accuracy: 0.4054 - val_loss: 1.0784 - val_accuracy: 0.4019\n",
      "Epoch 152/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.0732 - accuracy: 0.4152 - val_loss: 1.0782 - val_accuracy: 0.4019\n",
      "Epoch 153/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.0712 - accuracy: 0.4179 - val_loss: 1.0779 - val_accuracy: 0.4019\n",
      "Epoch 154/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0734 - accuracy: 0.4152 - val_loss: 1.0777 - val_accuracy: 0.4019\n",
      "Epoch 155/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.0734 - accuracy: 0.4109 - val_loss: 1.0775 - val_accuracy: 0.4019\n",
      "Epoch 156/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 1.0735 - accuracy: 0.4117 - val_loss: 1.0772 - val_accuracy: 0.4019\n",
      "Epoch 157/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0701 - accuracy: 0.4093 - val_loss: 1.0770 - val_accuracy: 0.4112\n",
      "Epoch 158/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0717 - accuracy: 0.4191 - val_loss: 1.0767 - val_accuracy: 0.4206\n",
      "Epoch 159/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.0694 - accuracy: 0.4152 - val_loss: 1.0765 - val_accuracy: 0.4206\n",
      "Epoch 160/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.0695 - accuracy: 0.4125 - val_loss: 1.0762 - val_accuracy: 0.4206\n",
      "Epoch 161/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.0719 - accuracy: 0.4121 - val_loss: 1.0760 - val_accuracy: 0.4112\n",
      "Epoch 162/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0700 - accuracy: 0.4113 - val_loss: 1.0757 - val_accuracy: 0.4112\n",
      "Epoch 163/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 119us/sample - loss: 1.0674 - accuracy: 0.4215 - val_loss: 1.0755 - val_accuracy: 0.4112\n",
      "Epoch 164/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0689 - accuracy: 0.4246 - val_loss: 1.0752 - val_accuracy: 0.4112\n",
      "Epoch 165/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0714 - accuracy: 0.4215 - val_loss: 1.0750 - val_accuracy: 0.4112\n",
      "Epoch 166/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0671 - accuracy: 0.4242 - val_loss: 1.0747 - val_accuracy: 0.4112\n",
      "Epoch 167/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.0669 - accuracy: 0.4211 - val_loss: 1.0744 - val_accuracy: 0.4112\n",
      "Epoch 168/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.0669 - accuracy: 0.4074 - val_loss: 1.0742 - val_accuracy: 0.4112\n",
      "Epoch 169/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0685 - accuracy: 0.4128 - val_loss: 1.0740 - val_accuracy: 0.4112\n",
      "Epoch 170/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.0655 - accuracy: 0.4203 - val_loss: 1.0737 - val_accuracy: 0.4112\n",
      "Epoch 171/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.0714 - accuracy: 0.4199 - val_loss: 1.0735 - val_accuracy: 0.4112\n",
      "Epoch 172/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0691 - accuracy: 0.4070 - val_loss: 1.0733 - val_accuracy: 0.4112\n",
      "Epoch 173/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0646 - accuracy: 0.4360 - val_loss: 1.0730 - val_accuracy: 0.4112\n",
      "Epoch 174/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0735 - accuracy: 0.4183 - val_loss: 1.0728 - val_accuracy: 0.4112\n",
      "Epoch 175/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0665 - accuracy: 0.4148 - val_loss: 1.0726 - val_accuracy: 0.4112\n",
      "Epoch 176/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.0710 - accuracy: 0.4187 - val_loss: 1.0723 - val_accuracy: 0.4112\n",
      "Epoch 177/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.0692 - accuracy: 0.4215 - val_loss: 1.0721 - val_accuracy: 0.4112\n",
      "Epoch 178/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0648 - accuracy: 0.4297 - val_loss: 1.0718 - val_accuracy: 0.4112\n",
      "Epoch 179/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0656 - accuracy: 0.4172 - val_loss: 1.0716 - val_accuracy: 0.4112\n",
      "Epoch 180/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.0640 - accuracy: 0.4254 - val_loss: 1.0713 - val_accuracy: 0.4112\n",
      "Epoch 181/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0658 - accuracy: 0.4230 - val_loss: 1.0711 - val_accuracy: 0.4112\n",
      "Epoch 182/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0676 - accuracy: 0.4109 - val_loss: 1.0708 - val_accuracy: 0.4112\n",
      "Epoch 183/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0687 - accuracy: 0.4164 - val_loss: 1.0706 - val_accuracy: 0.4112\n",
      "Epoch 184/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0608 - accuracy: 0.4309 - val_loss: 1.0703 - val_accuracy: 0.4206\n",
      "Epoch 185/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0663 - accuracy: 0.4132 - val_loss: 1.0700 - val_accuracy: 0.4206\n",
      "Epoch 186/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.0634 - accuracy: 0.4266 - val_loss: 1.0698 - val_accuracy: 0.4206\n",
      "Epoch 187/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0665 - accuracy: 0.4062 - val_loss: 1.0695 - val_accuracy: 0.4206\n",
      "Epoch 188/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0669 - accuracy: 0.4132 - val_loss: 1.0693 - val_accuracy: 0.4206\n",
      "Epoch 189/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.0664 - accuracy: 0.4262 - val_loss: 1.0690 - val_accuracy: 0.4206\n",
      "Epoch 190/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0668 - accuracy: 0.4066 - val_loss: 1.0688 - val_accuracy: 0.4206\n",
      "Epoch 191/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.0662 - accuracy: 0.4183 - val_loss: 1.0685 - val_accuracy: 0.4206\n",
      "Epoch 192/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0627 - accuracy: 0.4246 - val_loss: 1.0683 - val_accuracy: 0.4206\n",
      "Epoch 193/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.0575 - accuracy: 0.4293 - val_loss: 1.0680 - val_accuracy: 0.4206\n",
      "Epoch 194/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.0614 - accuracy: 0.4183 - val_loss: 1.0677 - val_accuracy: 0.4206\n",
      "Epoch 195/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0650 - accuracy: 0.4148 - val_loss: 1.0675 - val_accuracy: 0.4206\n",
      "Epoch 196/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0595 - accuracy: 0.4320 - val_loss: 1.0672 - val_accuracy: 0.4206\n",
      "Epoch 197/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0625 - accuracy: 0.4246 - val_loss: 1.0670 - val_accuracy: 0.4206\n",
      "Epoch 198/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0641 - accuracy: 0.4215 - val_loss: 1.0667 - val_accuracy: 0.4206\n",
      "Epoch 199/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.0612 - accuracy: 0.4172 - val_loss: 1.0665 - val_accuracy: 0.4206\n",
      "Epoch 200/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.0604 - accuracy: 0.4320 - val_loss: 1.0663 - val_accuracy: 0.4206\n",
      "0.42056075 {'loss': 1.0604428276098619, 'accuracy': 0.43204075, 'val_loss': 1.066251500744686, 'val_accuracy': 0.42056075}\n",
      "Model: \"model_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_28 (InputLayer)        [(None, 29)]              0         \n",
      "_________________________________________________________________\n",
      "flatten_27 (Flatten)         (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_103 (Dense)            (None, 41)                1230      \n",
      "_________________________________________________________________\n",
      "dense_104 (Dense)            (None, 10)                420       \n",
      "_________________________________________________________________\n",
      "dense_105 (Dense)            (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_106 (Dense)            (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_107 (Dense)            (None, 3)                 33        \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 1,903\n",
      "Trainable params: 1,903\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2553 samples, validate on 107 samples\n",
      "Epoch 1/200\n",
      "2553/2553 [==============================] - 1s 300us/sample - loss: 1.1331 - accuracy: 0.2695 - val_loss: 1.1215 - val_accuracy: 0.2430\n",
      "Epoch 2/200\n",
      "2553/2553 [==============================] - 0s 50us/sample - loss: 1.1236 - accuracy: 0.2902 - val_loss: 1.1214 - val_accuracy: 0.2430\n",
      "Epoch 3/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.1383 - accuracy: 0.2667 - val_loss: 1.1213 - val_accuracy: 0.2430\n",
      "Epoch 4/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1350 - accuracy: 0.2812 - val_loss: 1.1211 - val_accuracy: 0.2430\n",
      "Epoch 5/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.1365 - accuracy: 0.2726 - val_loss: 1.1210 - val_accuracy: 0.2430\n",
      "Epoch 6/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1353 - accuracy: 0.2750 - val_loss: 1.1208 - val_accuracy: 0.2430\n",
      "Epoch 7/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.1339 - accuracy: 0.2679 - val_loss: 1.1207 - val_accuracy: 0.2430\n",
      "Epoch 8/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1295 - accuracy: 0.2758 - val_loss: 1.1206 - val_accuracy: 0.2430\n",
      "Epoch 9/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1319 - accuracy: 0.2801 - val_loss: 1.1204 - val_accuracy: 0.2430\n",
      "Epoch 10/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1285 - accuracy: 0.2828 - val_loss: 1.1203 - val_accuracy: 0.2430\n",
      "Epoch 11/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1344 - accuracy: 0.2730 - val_loss: 1.1201 - val_accuracy: 0.2430\n",
      "Epoch 12/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.1276 - accuracy: 0.2750 - val_loss: 1.1200 - val_accuracy: 0.2430\n",
      "Epoch 13/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.1254 - accuracy: 0.2863 - val_loss: 1.1198 - val_accuracy: 0.2430\n",
      "Epoch 14/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1303 - accuracy: 0.2808 - val_loss: 1.1197 - val_accuracy: 0.2430\n",
      "Epoch 15/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1286 - accuracy: 0.2769 - val_loss: 1.1196 - val_accuracy: 0.2430\n",
      "Epoch 16/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1333 - accuracy: 0.2746 - val_loss: 1.1194 - val_accuracy: 0.2430\n",
      "Epoch 17/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1300 - accuracy: 0.2667 - val_loss: 1.1193 - val_accuracy: 0.2430\n",
      "Epoch 18/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.1318 - accuracy: 0.2722 - val_loss: 1.1191 - val_accuracy: 0.2430\n",
      "Epoch 19/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1277 - accuracy: 0.2808 - val_loss: 1.1190 - val_accuracy: 0.2430\n",
      "Epoch 20/200\n",
      "2553/2553 [==============================] - ETA: 0s - loss: 1.1315 - accuracy: 0.27 - 0s 59us/sample - loss: 1.1330 - accuracy: 0.2707 - val_loss: 1.1189 - val_accuracy: 0.2430\n",
      "Epoch 21/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1287 - accuracy: 0.2758 - val_loss: 1.1187 - val_accuracy: 0.2430\n",
      "Epoch 22/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.1302 - accuracy: 0.2726 - val_loss: 1.1186 - val_accuracy: 0.2430\n",
      "Epoch 23/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1267 - accuracy: 0.2812 - val_loss: 1.1185 - val_accuracy: 0.2430\n",
      "Epoch 24/200\n",
      "2553/2553 [==============================] - ETA: 0s - loss: 1.1280 - accuracy: 0.27 - 0s 54us/sample - loss: 1.1254 - accuracy: 0.2808 - val_loss: 1.1184 - val_accuracy: 0.2430\n",
      "Epoch 25/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.1303 - accuracy: 0.2671 - val_loss: 1.1182 - val_accuracy: 0.2430\n",
      "Epoch 26/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1268 - accuracy: 0.2742 - val_loss: 1.1181 - val_accuracy: 0.2430\n",
      "Epoch 27/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.1261 - accuracy: 0.2781 - val_loss: 1.1180 - val_accuracy: 0.2430\n",
      "Epoch 28/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1273 - accuracy: 0.2789 - val_loss: 1.1179 - val_accuracy: 0.2430\n",
      "Epoch 29/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1270 - accuracy: 0.2714 - val_loss: 1.1177 - val_accuracy: 0.2430\n",
      "Epoch 30/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1265 - accuracy: 0.2785 - val_loss: 1.1176 - val_accuracy: 0.2430\n",
      "Epoch 31/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1281 - accuracy: 0.2754 - val_loss: 1.1174 - val_accuracy: 0.2430\n",
      "Epoch 32/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1280 - accuracy: 0.2742 - val_loss: 1.1173 - val_accuracy: 0.2430\n",
      "Epoch 33/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1201 - accuracy: 0.2801 - val_loss: 1.1172 - val_accuracy: 0.2430\n",
      "Epoch 34/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1255 - accuracy: 0.2793 - val_loss: 1.1170 - val_accuracy: 0.2430\n",
      "Epoch 35/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.1237 - accuracy: 0.2761 - val_loss: 1.1169 - val_accuracy: 0.2430\n",
      "Epoch 36/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1214 - accuracy: 0.2922 - val_loss: 1.1168 - val_accuracy: 0.2430\n",
      "Epoch 37/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1232 - accuracy: 0.2773 - val_loss: 1.1166 - val_accuracy: 0.2430\n",
      "Epoch 38/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.1215 - accuracy: 0.2812 - val_loss: 1.1165 - val_accuracy: 0.2430\n",
      "Epoch 39/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.1270 - accuracy: 0.2777 - val_loss: 1.1164 - val_accuracy: 0.2430\n",
      "Epoch 40/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.1258 - accuracy: 0.2761 - val_loss: 1.1162 - val_accuracy: 0.2430\n",
      "Epoch 41/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.1273 - accuracy: 0.2648 - val_loss: 1.1161 - val_accuracy: 0.2430\n",
      "Epoch 42/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1237 - accuracy: 0.2781 - val_loss: 1.1160 - val_accuracy: 0.2430\n",
      "Epoch 43/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1253 - accuracy: 0.2711 - val_loss: 1.1158 - val_accuracy: 0.2430\n",
      "Epoch 44/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.1268 - accuracy: 0.2679 - val_loss: 1.1157 - val_accuracy: 0.2430\n",
      "Epoch 45/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1286 - accuracy: 0.2644 - val_loss: 1.1156 - val_accuracy: 0.2430\n",
      "Epoch 46/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1214 - accuracy: 0.2699 - val_loss: 1.1155 - val_accuracy: 0.2430\n",
      "Epoch 47/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1239 - accuracy: 0.2695 - val_loss: 1.1154 - val_accuracy: 0.2430\n",
      "Epoch 48/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1206 - accuracy: 0.2816 - val_loss: 1.1153 - val_accuracy: 0.2430\n",
      "Epoch 49/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.1161 - accuracy: 0.2820 - val_loss: 1.1151 - val_accuracy: 0.2430\n",
      "Epoch 50/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.1202 - accuracy: 0.2797 - val_loss: 1.1150 - val_accuracy: 0.2430\n",
      "Epoch 51/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1279 - accuracy: 0.2683 - val_loss: 1.1149 - val_accuracy: 0.2430\n",
      "Epoch 52/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1231 - accuracy: 0.2785 - val_loss: 1.1148 - val_accuracy: 0.2430\n",
      "Epoch 53/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1207 - accuracy: 0.2820 - val_loss: 1.1147 - val_accuracy: 0.2430\n",
      "Epoch 54/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1206 - accuracy: 0.2801 - val_loss: 1.1145 - val_accuracy: 0.2430\n",
      "Epoch 55/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.1214 - accuracy: 0.2781 - val_loss: 1.1144 - val_accuracy: 0.2430\n",
      "Epoch 56/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.1176 - accuracy: 0.2765 - val_loss: 1.1143 - val_accuracy: 0.2430\n",
      "Epoch 57/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.1175 - accuracy: 0.2801 - val_loss: 1.1142 - val_accuracy: 0.2430\n",
      "Epoch 58/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.1191 - accuracy: 0.2781 - val_loss: 1.1141 - val_accuracy: 0.2430\n",
      "Epoch 59/200\n",
      "2553/2553 [==============================] - 0s 51us/sample - loss: 1.1193 - accuracy: 0.2742 - val_loss: 1.1140 - val_accuracy: 0.2430\n",
      "Epoch 60/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.1214 - accuracy: 0.2848 - val_loss: 1.1139 - val_accuracy: 0.2430\n",
      "Epoch 61/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1197 - accuracy: 0.2828 - val_loss: 1.1137 - val_accuracy: 0.2430\n",
      "Epoch 62/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1173 - accuracy: 0.2777 - val_loss: 1.1136 - val_accuracy: 0.2430\n",
      "Epoch 63/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1220 - accuracy: 0.2648 - val_loss: 1.1135 - val_accuracy: 0.2430\n",
      "Epoch 64/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1199 - accuracy: 0.2781 - val_loss: 1.1134 - val_accuracy: 0.2430\n",
      "Epoch 65/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.1247 - accuracy: 0.2695 - val_loss: 1.1133 - val_accuracy: 0.2430\n",
      "Epoch 66/200\n",
      "2553/2553 [==============================] - 0s 50us/sample - loss: 1.1183 - accuracy: 0.2769 - val_loss: 1.1132 - val_accuracy: 0.2430\n",
      "Epoch 67/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1165 - accuracy: 0.2879 - val_loss: 1.1131 - val_accuracy: 0.2430\n",
      "Epoch 68/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1161 - accuracy: 0.2855 - val_loss: 1.1129 - val_accuracy: 0.2430\n",
      "Epoch 69/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1138 - accuracy: 0.2887 - val_loss: 1.1128 - val_accuracy: 0.2430\n",
      "Epoch 70/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1138 - accuracy: 0.2922 - val_loss: 1.1127 - val_accuracy: 0.2430\n",
      "Epoch 71/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1157 - accuracy: 0.2816 - val_loss: 1.1126 - val_accuracy: 0.2430\n",
      "Epoch 72/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.1186 - accuracy: 0.2793 - val_loss: 1.1125 - val_accuracy: 0.2430\n",
      "Epoch 73/200\n",
      "2553/2553 [==============================] - 0s 65us/sample - loss: 1.1204 - accuracy: 0.2746 - val_loss: 1.1124 - val_accuracy: 0.2430\n",
      "Epoch 74/200\n",
      "2553/2553 [==============================] - 0s 76us/sample - loss: 1.1175 - accuracy: 0.2808 - val_loss: 1.1122 - val_accuracy: 0.2430\n",
      "Epoch 75/200\n",
      "2553/2553 [==============================] - 0s 86us/sample - loss: 1.1183 - accuracy: 0.2808 - val_loss: 1.1121 - val_accuracy: 0.2430\n",
      "Epoch 76/200\n",
      "2553/2553 [==============================] - 0s 85us/sample - loss: 1.1159 - accuracy: 0.2820 - val_loss: 1.1120 - val_accuracy: 0.2430\n",
      "Epoch 77/200\n",
      "2553/2553 [==============================] - 0s 86us/sample - loss: 1.1161 - accuracy: 0.2832 - val_loss: 1.1119 - val_accuracy: 0.2430\n",
      "Epoch 78/200\n",
      "2553/2553 [==============================] - 0s 77us/sample - loss: 1.1167 - accuracy: 0.2832 - val_loss: 1.1118 - val_accuracy: 0.2430\n",
      "Epoch 79/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1192 - accuracy: 0.2734 - val_loss: 1.1117 - val_accuracy: 0.2430\n",
      "Epoch 80/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1120 - accuracy: 0.2852 - val_loss: 1.1116 - val_accuracy: 0.2430\n",
      "Epoch 81/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.1175 - accuracy: 0.2761 - val_loss: 1.1114 - val_accuracy: 0.2336\n",
      "Epoch 82/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.1170 - accuracy: 0.2801 - val_loss: 1.1113 - val_accuracy: 0.2336\n",
      "Epoch 83/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1176 - accuracy: 0.2769 - val_loss: 1.1112 - val_accuracy: 0.2336\n",
      "Epoch 84/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1119 - accuracy: 0.2910 - val_loss: 1.1111 - val_accuracy: 0.2336\n",
      "Epoch 85/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1157 - accuracy: 0.2718 - val_loss: 1.1110 - val_accuracy: 0.2336\n",
      "Epoch 86/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.1166 - accuracy: 0.2758 - val_loss: 1.1109 - val_accuracy: 0.2336\n",
      "Epoch 87/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1172 - accuracy: 0.2797 - val_loss: 1.1107 - val_accuracy: 0.2336\n",
      "Epoch 88/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.1150 - accuracy: 0.2805 - val_loss: 1.1106 - val_accuracy: 0.2336\n",
      "Epoch 89/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1162 - accuracy: 0.2824 - val_loss: 1.1105 - val_accuracy: 0.2336\n",
      "Epoch 90/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.1121 - accuracy: 0.2844 - val_loss: 1.1104 - val_accuracy: 0.2336\n",
      "Epoch 91/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.1155 - accuracy: 0.2812 - val_loss: 1.1103 - val_accuracy: 0.2336\n",
      "Epoch 92/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.1163 - accuracy: 0.2808 - val_loss: 1.1102 - val_accuracy: 0.2336\n",
      "Epoch 93/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.1152 - accuracy: 0.2769 - val_loss: 1.1101 - val_accuracy: 0.2336\n",
      "Epoch 94/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1157 - accuracy: 0.2722 - val_loss: 1.1100 - val_accuracy: 0.2336\n",
      "Epoch 95/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1172 - accuracy: 0.2785 - val_loss: 1.1098 - val_accuracy: 0.2336\n",
      "Epoch 96/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.1176 - accuracy: 0.2734 - val_loss: 1.1097 - val_accuracy: 0.2336\n",
      "Epoch 97/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1156 - accuracy: 0.2797 - val_loss: 1.1096 - val_accuracy: 0.2243\n",
      "Epoch 98/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1148 - accuracy: 0.2734 - val_loss: 1.1095 - val_accuracy: 0.2243\n",
      "Epoch 99/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1102 - accuracy: 0.2820 - val_loss: 1.1094 - val_accuracy: 0.2243\n",
      "Epoch 100/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1143 - accuracy: 0.2785 - val_loss: 1.1093 - val_accuracy: 0.2243\n",
      "Epoch 101/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1117 - accuracy: 0.2777 - val_loss: 1.1092 - val_accuracy: 0.2243\n",
      "Epoch 102/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1124 - accuracy: 0.2746 - val_loss: 1.1091 - val_accuracy: 0.2243\n",
      "Epoch 103/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1122 - accuracy: 0.2863 - val_loss: 1.1090 - val_accuracy: 0.2243\n",
      "Epoch 104/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1147 - accuracy: 0.2726 - val_loss: 1.1089 - val_accuracy: 0.2243\n",
      "Epoch 105/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.1151 - accuracy: 0.2750 - val_loss: 1.1088 - val_accuracy: 0.2243\n",
      "Epoch 106/200\n",
      "2553/2553 [==============================] - 0s 51us/sample - loss: 1.1130 - accuracy: 0.2781 - val_loss: 1.1087 - val_accuracy: 0.2243\n",
      "Epoch 107/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.1149 - accuracy: 0.2781 - val_loss: 1.1086 - val_accuracy: 0.2243\n",
      "Epoch 108/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1086 - accuracy: 0.2891 - val_loss: 1.1085 - val_accuracy: 0.2243\n",
      "Epoch 109/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.1161 - accuracy: 0.2687 - val_loss: 1.1084 - val_accuracy: 0.2243\n",
      "Epoch 110/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1150 - accuracy: 0.2738 - val_loss: 1.1083 - val_accuracy: 0.2243\n",
      "Epoch 111/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.1156 - accuracy: 0.2785 - val_loss: 1.1082 - val_accuracy: 0.2243\n",
      "Epoch 112/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1115 - accuracy: 0.2769 - val_loss: 1.1081 - val_accuracy: 0.2243\n",
      "Epoch 113/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1111 - accuracy: 0.2859 - val_loss: 1.1080 - val_accuracy: 0.2243\n",
      "Epoch 114/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1095 - accuracy: 0.2840 - val_loss: 1.1079 - val_accuracy: 0.2243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1127 - accuracy: 0.2758 - val_loss: 1.1078 - val_accuracy: 0.2243\n",
      "Epoch 116/200\n",
      "2553/2553 [==============================] - 0s 51us/sample - loss: 1.1113 - accuracy: 0.2746 - val_loss: 1.1077 - val_accuracy: 0.2243\n",
      "Epoch 117/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.1153 - accuracy: 0.2777 - val_loss: 1.1076 - val_accuracy: 0.2243\n",
      "Epoch 118/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.1073 - accuracy: 0.2895 - val_loss: 1.1075 - val_accuracy: 0.2243\n",
      "Epoch 119/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.1068 - accuracy: 0.2883 - val_loss: 1.1074 - val_accuracy: 0.2243\n",
      "Epoch 120/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1109 - accuracy: 0.2777 - val_loss: 1.1073 - val_accuracy: 0.2243\n",
      "Epoch 121/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1116 - accuracy: 0.2789 - val_loss: 1.1072 - val_accuracy: 0.2243\n",
      "Epoch 122/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1084 - accuracy: 0.2867 - val_loss: 1.1072 - val_accuracy: 0.2243\n",
      "Epoch 123/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1110 - accuracy: 0.2707 - val_loss: 1.1071 - val_accuracy: 0.2243\n",
      "Epoch 124/200\n",
      "2553/2553 [==============================] - 0s 50us/sample - loss: 1.1102 - accuracy: 0.2828 - val_loss: 1.1070 - val_accuracy: 0.2243\n",
      "Epoch 125/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.1094 - accuracy: 0.2777 - val_loss: 1.1069 - val_accuracy: 0.2243\n",
      "Epoch 126/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1079 - accuracy: 0.2863 - val_loss: 1.1068 - val_accuracy: 0.2243\n",
      "Epoch 127/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.1096 - accuracy: 0.2801 - val_loss: 1.1067 - val_accuracy: 0.2243\n",
      "Epoch 128/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1097 - accuracy: 0.2891 - val_loss: 1.1066 - val_accuracy: 0.2243\n",
      "Epoch 129/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1062 - accuracy: 0.2793 - val_loss: 1.1065 - val_accuracy: 0.2243\n",
      "Epoch 130/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1099 - accuracy: 0.2812 - val_loss: 1.1064 - val_accuracy: 0.2243\n",
      "Epoch 131/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1085 - accuracy: 0.2750 - val_loss: 1.1063 - val_accuracy: 0.2243\n",
      "Epoch 132/200\n",
      "2553/2553 [==============================] - 0s 50us/sample - loss: 1.1064 - accuracy: 0.2859 - val_loss: 1.1062 - val_accuracy: 0.2243\n",
      "Epoch 133/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1111 - accuracy: 0.2785 - val_loss: 1.1062 - val_accuracy: 0.2243\n",
      "Epoch 134/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1104 - accuracy: 0.2769 - val_loss: 1.1061 - val_accuracy: 0.2243\n",
      "Epoch 135/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1061 - accuracy: 0.2746 - val_loss: 1.1060 - val_accuracy: 0.2243\n",
      "Epoch 136/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1084 - accuracy: 0.2761 - val_loss: 1.1059 - val_accuracy: 0.2243\n",
      "Epoch 137/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1119 - accuracy: 0.2773 - val_loss: 1.1058 - val_accuracy: 0.2336\n",
      "Epoch 138/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1107 - accuracy: 0.2687 - val_loss: 1.1057 - val_accuracy: 0.2336\n",
      "Epoch 139/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.1082 - accuracy: 0.2820 - val_loss: 1.1056 - val_accuracy: 0.2336\n",
      "Epoch 140/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1096 - accuracy: 0.2769 - val_loss: 1.1055 - val_accuracy: 0.2336\n",
      "Epoch 141/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.1079 - accuracy: 0.2765 - val_loss: 1.1054 - val_accuracy: 0.2336\n",
      "Epoch 142/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.1080 - accuracy: 0.2761 - val_loss: 1.1053 - val_accuracy: 0.2336\n",
      "Epoch 143/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1056 - accuracy: 0.2824 - val_loss: 1.1052 - val_accuracy: 0.2336\n",
      "Epoch 144/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.1084 - accuracy: 0.2785 - val_loss: 1.1051 - val_accuracy: 0.2336\n",
      "Epoch 145/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1131 - accuracy: 0.2714 - val_loss: 1.1050 - val_accuracy: 0.2336\n",
      "Epoch 146/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1058 - accuracy: 0.2824 - val_loss: 1.1049 - val_accuracy: 0.2336\n",
      "Epoch 147/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1062 - accuracy: 0.2797 - val_loss: 1.1048 - val_accuracy: 0.2336\n",
      "Epoch 148/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1105 - accuracy: 0.2722 - val_loss: 1.1047 - val_accuracy: 0.2336\n",
      "Epoch 149/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1073 - accuracy: 0.2761 - val_loss: 1.1046 - val_accuracy: 0.2336\n",
      "Epoch 150/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1092 - accuracy: 0.2785 - val_loss: 1.1046 - val_accuracy: 0.2336\n",
      "Epoch 151/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.1073 - accuracy: 0.2824 - val_loss: 1.1045 - val_accuracy: 0.2336\n",
      "Epoch 152/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1150 - accuracy: 0.2730 - val_loss: 1.1044 - val_accuracy: 0.2336\n",
      "Epoch 153/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1032 - accuracy: 0.2867 - val_loss: 1.1043 - val_accuracy: 0.2336\n",
      "Epoch 154/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.1084 - accuracy: 0.2844 - val_loss: 1.1042 - val_accuracy: 0.2336\n",
      "Epoch 155/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1074 - accuracy: 0.2812 - val_loss: 1.1041 - val_accuracy: 0.2336\n",
      "Epoch 156/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1059 - accuracy: 0.2816 - val_loss: 1.1040 - val_accuracy: 0.2336\n",
      "Epoch 157/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1043 - accuracy: 0.2808 - val_loss: 1.1039 - val_accuracy: 0.2336\n",
      "Epoch 158/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1098 - accuracy: 0.2816 - val_loss: 1.1038 - val_accuracy: 0.2336\n",
      "Epoch 159/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1058 - accuracy: 0.2879 - val_loss: 1.1037 - val_accuracy: 0.2336\n",
      "Epoch 160/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1073 - accuracy: 0.2714 - val_loss: 1.1036 - val_accuracy: 0.2336\n",
      "Epoch 161/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1090 - accuracy: 0.2765 - val_loss: 1.1035 - val_accuracy: 0.2336\n",
      "Epoch 162/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.1078 - accuracy: 0.2754 - val_loss: 1.1035 - val_accuracy: 0.2336\n",
      "Epoch 163/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1099 - accuracy: 0.2738 - val_loss: 1.1034 - val_accuracy: 0.2336\n",
      "Epoch 164/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.1054 - accuracy: 0.2761 - val_loss: 1.1033 - val_accuracy: 0.2336\n",
      "Epoch 165/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1086 - accuracy: 0.2812 - val_loss: 1.1032 - val_accuracy: 0.2336\n",
      "Epoch 166/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.1029 - accuracy: 0.2906 - val_loss: 1.1031 - val_accuracy: 0.2336\n",
      "Epoch 167/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1033 - accuracy: 0.2859 - val_loss: 1.1030 - val_accuracy: 0.2336\n",
      "Epoch 168/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1055 - accuracy: 0.2808 - val_loss: 1.1029 - val_accuracy: 0.2336\n",
      "Epoch 169/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1064 - accuracy: 0.2781 - val_loss: 1.1028 - val_accuracy: 0.2336\n",
      "Epoch 170/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.1053 - accuracy: 0.2801 - val_loss: 1.1027 - val_accuracy: 0.2336\n",
      "Epoch 171/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1033 - accuracy: 0.2793 - val_loss: 1.1027 - val_accuracy: 0.2336\n",
      "Epoch 172/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1052 - accuracy: 0.2797 - val_loss: 1.1026 - val_accuracy: 0.2336\n",
      "Epoch 173/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.1067 - accuracy: 0.2789 - val_loss: 1.1025 - val_accuracy: 0.2336\n",
      "Epoch 174/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1046 - accuracy: 0.2773 - val_loss: 1.1024 - val_accuracy: 0.2336\n",
      "Epoch 175/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1074 - accuracy: 0.2750 - val_loss: 1.1023 - val_accuracy: 0.2430\n",
      "Epoch 176/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1083 - accuracy: 0.2781 - val_loss: 1.1022 - val_accuracy: 0.2430\n",
      "Epoch 177/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1008 - accuracy: 0.2875 - val_loss: 1.1022 - val_accuracy: 0.2430\n",
      "Epoch 178/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1021 - accuracy: 0.2863 - val_loss: 1.1021 - val_accuracy: 0.2430\n",
      "Epoch 179/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.1036 - accuracy: 0.2867 - val_loss: 1.1020 - val_accuracy: 0.2523\n",
      "Epoch 180/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1043 - accuracy: 0.2871 - val_loss: 1.1019 - val_accuracy: 0.2523\n",
      "Epoch 181/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1061 - accuracy: 0.2848 - val_loss: 1.1018 - val_accuracy: 0.2523\n",
      "Epoch 182/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1028 - accuracy: 0.2895 - val_loss: 1.1017 - val_accuracy: 0.2523\n",
      "Epoch 183/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.1055 - accuracy: 0.2781 - val_loss: 1.1016 - val_accuracy: 0.2523\n",
      "Epoch 184/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1038 - accuracy: 0.2824 - val_loss: 1.1016 - val_accuracy: 0.2617\n",
      "Epoch 185/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.1059 - accuracy: 0.2797 - val_loss: 1.1015 - val_accuracy: 0.2617\n",
      "Epoch 186/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1034 - accuracy: 0.2852 - val_loss: 1.1014 - val_accuracy: 0.2617\n",
      "Epoch 187/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1044 - accuracy: 0.2828 - val_loss: 1.1013 - val_accuracy: 0.2617\n",
      "Epoch 188/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.1034 - accuracy: 0.2926 - val_loss: 1.1012 - val_accuracy: 0.2617\n",
      "Epoch 189/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.1033 - accuracy: 0.2899 - val_loss: 1.1012 - val_accuracy: 0.2617\n",
      "Epoch 190/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1063 - accuracy: 0.2891 - val_loss: 1.1011 - val_accuracy: 0.2710\n",
      "Epoch 191/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1051 - accuracy: 0.2805 - val_loss: 1.1010 - val_accuracy: 0.2710\n",
      "Epoch 192/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1021 - accuracy: 0.2852 - val_loss: 1.1009 - val_accuracy: 0.2710\n",
      "Epoch 193/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1030 - accuracy: 0.2855 - val_loss: 1.1008 - val_accuracy: 0.2710\n",
      "Epoch 194/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1016 - accuracy: 0.2879 - val_loss: 1.1007 - val_accuracy: 0.2710\n",
      "Epoch 195/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1042 - accuracy: 0.2758 - val_loss: 1.1006 - val_accuracy: 0.2710\n",
      "Epoch 196/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.1011 - accuracy: 0.2828 - val_loss: 1.1005 - val_accuracy: 0.2710\n",
      "Epoch 197/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1021 - accuracy: 0.2867 - val_loss: 1.1005 - val_accuracy: 0.2617\n",
      "Epoch 198/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1053 - accuracy: 0.2832 - val_loss: 1.1004 - val_accuracy: 0.2617\n",
      "Epoch 199/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.1020 - accuracy: 0.2879 - val_loss: 1.1003 - val_accuracy: 0.2617\n",
      "Epoch 200/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.1017 - accuracy: 0.2848 - val_loss: 1.1002 - val_accuracy: 0.2617\n",
      "0.26168224 {'loss': 1.1017296015399136, 'accuracy': 0.28476304, 'val_loss': 1.100229632074588, 'val_accuracy': 0.26168224}\n",
      "Model: \"model_28\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_29 (InputLayer)        [(None, 29)]              0         \n",
      "_________________________________________________________________\n",
      "flatten_28 (Flatten)         (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_108 (Dense)            (None, 41)                1230      \n",
      "_________________________________________________________________\n",
      "dense_109 (Dense)            (None, 10)                420       \n",
      "_________________________________________________________________\n",
      "dense_110 (Dense)            (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_111 (Dense)            (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_112 (Dense)            (None, 3)                 33        \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 1,903\n",
      "Trainable params: 1,903\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2553 samples, validate on 107 samples\n",
      "Epoch 1/200\n",
      "2553/2553 [==============================] - 1s 337us/sample - loss: 1.2106 - accuracy: 0.2797 - val_loss: 1.1898 - val_accuracy: 0.2243\n",
      "Epoch 2/200\n",
      "2553/2553 [==============================] - 0s 95us/sample - loss: 1.2011 - accuracy: 0.2797 - val_loss: 1.1876 - val_accuracy: 0.2243\n",
      "Epoch 3/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.1877 - accuracy: 0.2797 - val_loss: 1.1856 - val_accuracy: 0.2243\n",
      "Epoch 4/200\n",
      "2553/2553 [==============================] - 0s 99us/sample - loss: 1.1990 - accuracy: 0.2797 - val_loss: 1.1834 - val_accuracy: 0.2243\n",
      "Epoch 5/200\n",
      "2553/2553 [==============================] - 0s 96us/sample - loss: 1.1976 - accuracy: 0.2797 - val_loss: 1.1812 - val_accuracy: 0.2243\n",
      "Epoch 6/200\n",
      "2553/2553 [==============================] - 0s 96us/sample - loss: 1.1982 - accuracy: 0.2797 - val_loss: 1.1789 - val_accuracy: 0.2243\n",
      "Epoch 7/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.1900 - accuracy: 0.2797 - val_loss: 1.1768 - val_accuracy: 0.2243\n",
      "Epoch 8/200\n",
      "2553/2553 [==============================] - 0s 96us/sample - loss: 1.1896 - accuracy: 0.2797 - val_loss: 1.1747 - val_accuracy: 0.2243\n",
      "Epoch 9/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.1826 - accuracy: 0.2797 - val_loss: 1.1727 - val_accuracy: 0.2243\n",
      "Epoch 10/200\n",
      "2553/2553 [==============================] - 0s 96us/sample - loss: 1.1845 - accuracy: 0.2797 - val_loss: 1.1707 - val_accuracy: 0.2243\n",
      "Epoch 11/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.1836 - accuracy: 0.2797 - val_loss: 1.1688 - val_accuracy: 0.2243\n",
      "Epoch 12/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 95us/sample - loss: 1.1733 - accuracy: 0.2797 - val_loss: 1.1669 - val_accuracy: 0.2243\n",
      "Epoch 13/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.1715 - accuracy: 0.2797 - val_loss: 1.1650 - val_accuracy: 0.2243\n",
      "Epoch 14/200\n",
      "2553/2553 [==============================] - 0s 97us/sample - loss: 1.1732 - accuracy: 0.2797 - val_loss: 1.1631 - val_accuracy: 0.2243\n",
      "Epoch 15/200\n",
      "2553/2553 [==============================] - 0s 98us/sample - loss: 1.1711 - accuracy: 0.2797 - val_loss: 1.1613 - val_accuracy: 0.2243\n",
      "Epoch 16/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.1711 - accuracy: 0.2797 - val_loss: 1.1594 - val_accuracy: 0.2243\n",
      "Epoch 17/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.1685 - accuracy: 0.2797 - val_loss: 1.1576 - val_accuracy: 0.2243\n",
      "Epoch 18/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.1585 - accuracy: 0.2797 - val_loss: 1.1560 - val_accuracy: 0.2243\n",
      "Epoch 19/200\n",
      "2553/2553 [==============================] - 0s 99us/sample - loss: 1.1621 - accuracy: 0.2797 - val_loss: 1.1544 - val_accuracy: 0.2243\n",
      "Epoch 20/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.1595 - accuracy: 0.2797 - val_loss: 1.1528 - val_accuracy: 0.2243\n",
      "Epoch 21/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.1643 - accuracy: 0.2797 - val_loss: 1.1511 - val_accuracy: 0.2243\n",
      "Epoch 22/200\n",
      "2553/2553 [==============================] - 0s 95us/sample - loss: 1.1535 - accuracy: 0.2797 - val_loss: 1.1496 - val_accuracy: 0.2243\n",
      "Epoch 23/200\n",
      "2553/2553 [==============================] - 0s 99us/sample - loss: 1.1535 - accuracy: 0.2797 - val_loss: 1.1480 - val_accuracy: 0.2243\n",
      "Epoch 24/200\n",
      "2553/2553 [==============================] - 0s 98us/sample - loss: 1.1486 - accuracy: 0.2797 - val_loss: 1.1465 - val_accuracy: 0.2243\n",
      "Epoch 25/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.1444 - accuracy: 0.2797 - val_loss: 1.1452 - val_accuracy: 0.2243\n",
      "Epoch 26/200\n",
      "2553/2553 [==============================] - 0s 96us/sample - loss: 1.1431 - accuracy: 0.2797 - val_loss: 1.1438 - val_accuracy: 0.2243\n",
      "Epoch 27/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.1482 - accuracy: 0.2797 - val_loss: 1.1422 - val_accuracy: 0.2243\n",
      "Epoch 28/200\n",
      "2553/2553 [==============================] - 0s 99us/sample - loss: 1.1444 - accuracy: 0.2797 - val_loss: 1.1407 - val_accuracy: 0.2243\n",
      "Epoch 29/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.1393 - accuracy: 0.2797 - val_loss: 1.1394 - val_accuracy: 0.2243\n",
      "Epoch 30/200\n",
      "2553/2553 [==============================] - 0s 97us/sample - loss: 1.1378 - accuracy: 0.2797 - val_loss: 1.1381 - val_accuracy: 0.2243\n",
      "Epoch 31/200\n",
      "2553/2553 [==============================] - 0s 99us/sample - loss: 1.1381 - accuracy: 0.2797 - val_loss: 1.1368 - val_accuracy: 0.2243\n",
      "Epoch 32/200\n",
      "2553/2553 [==============================] - 0s 99us/sample - loss: 1.1372 - accuracy: 0.2797 - val_loss: 1.1355 - val_accuracy: 0.2243\n",
      "Epoch 33/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.1352 - accuracy: 0.2797 - val_loss: 1.1343 - val_accuracy: 0.2243\n",
      "Epoch 34/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.1320 - accuracy: 0.2797 - val_loss: 1.1332 - val_accuracy: 0.2243\n",
      "Epoch 35/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.1329 - accuracy: 0.2797 - val_loss: 1.1319 - val_accuracy: 0.2243\n",
      "Epoch 36/200\n",
      "2553/2553 [==============================] - 0s 99us/sample - loss: 1.1314 - accuracy: 0.2797 - val_loss: 1.1308 - val_accuracy: 0.2243\n",
      "Epoch 37/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.1245 - accuracy: 0.2797 - val_loss: 1.1297 - val_accuracy: 0.2243\n",
      "Epoch 38/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.1273 - accuracy: 0.2797 - val_loss: 1.1287 - val_accuracy: 0.2243\n",
      "Epoch 39/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.1236 - accuracy: 0.2797 - val_loss: 1.1278 - val_accuracy: 0.2243\n",
      "Epoch 40/200\n",
      "2553/2553 [==============================] - 0s 98us/sample - loss: 1.1206 - accuracy: 0.2797 - val_loss: 1.1268 - val_accuracy: 0.2243\n",
      "Epoch 41/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.1200 - accuracy: 0.2797 - val_loss: 1.1259 - val_accuracy: 0.2243\n",
      "Epoch 42/200\n",
      "2553/2553 [==============================] - 0s 99us/sample - loss: 1.1229 - accuracy: 0.2797 - val_loss: 1.1249 - val_accuracy: 0.2243\n",
      "Epoch 43/200\n",
      "2553/2553 [==============================] - 0s 98us/sample - loss: 1.1255 - accuracy: 0.2797 - val_loss: 1.1238 - val_accuracy: 0.2243\n",
      "Epoch 44/200\n",
      "2553/2553 [==============================] - 0s 97us/sample - loss: 1.1218 - accuracy: 0.2797 - val_loss: 1.1228 - val_accuracy: 0.2243\n",
      "Epoch 45/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.1271 - accuracy: 0.2797 - val_loss: 1.1218 - val_accuracy: 0.2243\n",
      "Epoch 46/200\n",
      "2553/2553 [==============================] - 0s 97us/sample - loss: 1.1180 - accuracy: 0.2797 - val_loss: 1.1209 - val_accuracy: 0.2243\n",
      "Epoch 47/200\n",
      "2553/2553 [==============================] - 0s 98us/sample - loss: 1.1209 - accuracy: 0.2797 - val_loss: 1.1200 - val_accuracy: 0.2243\n",
      "Epoch 48/200\n",
      "2553/2553 [==============================] - 0s 94us/sample - loss: 1.1152 - accuracy: 0.2797 - val_loss: 1.1193 - val_accuracy: 0.2243\n",
      "Epoch 49/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.1153 - accuracy: 0.2797 - val_loss: 1.1185 - val_accuracy: 0.2243\n",
      "Epoch 50/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.1132 - accuracy: 0.2797 - val_loss: 1.1177 - val_accuracy: 0.2243\n",
      "Epoch 51/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.1133 - accuracy: 0.2797 - val_loss: 1.1170 - val_accuracy: 0.2243\n",
      "Epoch 52/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.1142 - accuracy: 0.2797 - val_loss: 1.1162 - val_accuracy: 0.2243\n",
      "Epoch 53/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.1144 - accuracy: 0.2797 - val_loss: 1.1155 - val_accuracy: 0.2243\n",
      "Epoch 54/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.1120 - accuracy: 0.2797 - val_loss: 1.1149 - val_accuracy: 0.2243\n",
      "Epoch 55/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.1103 - accuracy: 0.2797 - val_loss: 1.1143 - val_accuracy: 0.2243\n",
      "Epoch 56/200\n",
      "2553/2553 [==============================] - 0s 99us/sample - loss: 1.1101 - accuracy: 0.2797 - val_loss: 1.1137 - val_accuracy: 0.2243\n",
      "Epoch 57/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.1099 - accuracy: 0.2797 - val_loss: 1.1131 - val_accuracy: 0.2243\n",
      "Epoch 58/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.1102 - accuracy: 0.2797 - val_loss: 1.1125 - val_accuracy: 0.2243\n",
      "Epoch 59/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.1080 - accuracy: 0.2797 - val_loss: 1.1119 - val_accuracy: 0.2243\n",
      "Epoch 60/200\n",
      "2553/2553 [==============================] - 0s 98us/sample - loss: 1.1077 - accuracy: 0.2797 - val_loss: 1.1114 - val_accuracy: 0.2243\n",
      "Epoch 61/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.1056 - accuracy: 0.2797 - val_loss: 1.1109 - val_accuracy: 0.2243\n",
      "Epoch 62/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.1080 - accuracy: 0.2797 - val_loss: 1.1104 - val_accuracy: 0.2243\n",
      "Epoch 63/200\n",
      "2553/2553 [==============================] - 0s 97us/sample - loss: 1.1051 - accuracy: 0.2797 - val_loss: 1.1099 - val_accuracy: 0.2243\n",
      "Epoch 64/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.1058 - accuracy: 0.2797 - val_loss: 1.1095 - val_accuracy: 0.2243\n",
      "Epoch 65/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.1032 - accuracy: 0.2797 - val_loss: 1.1091 - val_accuracy: 0.2243\n",
      "Epoch 66/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.1038 - accuracy: 0.2797 - val_loss: 1.1087 - val_accuracy: 0.2243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.1032 - accuracy: 0.2797 - val_loss: 1.1083 - val_accuracy: 0.2243\n",
      "Epoch 68/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.1034 - accuracy: 0.2797 - val_loss: 1.1079 - val_accuracy: 0.2243\n",
      "Epoch 69/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.1043 - accuracy: 0.2797 - val_loss: 1.1076 - val_accuracy: 0.2243\n",
      "Epoch 70/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.1046 - accuracy: 0.2797 - val_loss: 1.1072 - val_accuracy: 0.2243\n",
      "Epoch 71/200\n",
      "2553/2553 [==============================] - 0s 99us/sample - loss: 1.1040 - accuracy: 0.2797 - val_loss: 1.1069 - val_accuracy: 0.2243\n",
      "Epoch 72/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.1039 - accuracy: 0.2797 - val_loss: 1.1066 - val_accuracy: 0.2243\n",
      "Epoch 73/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.1019 - accuracy: 0.2797 - val_loss: 1.1064 - val_accuracy: 0.2243\n",
      "Epoch 74/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.1023 - accuracy: 0.2797 - val_loss: 1.1061 - val_accuracy: 0.2243\n",
      "Epoch 75/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.1002 - accuracy: 0.2797 - val_loss: 1.1059 - val_accuracy: 0.2243\n",
      "Epoch 76/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0997 - accuracy: 0.2797 - val_loss: 1.1056 - val_accuracy: 0.2243\n",
      "Epoch 77/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.0989 - accuracy: 0.2797 - val_loss: 1.1054 - val_accuracy: 0.2243\n",
      "Epoch 78/200\n",
      "2553/2553 [==============================] - 0s 98us/sample - loss: 1.1004 - accuracy: 0.2797 - val_loss: 1.1052 - val_accuracy: 0.2243\n",
      "Epoch 79/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.1001 - accuracy: 0.2797 - val_loss: 1.1050 - val_accuracy: 0.2243\n",
      "Epoch 80/200\n",
      "2553/2553 [==============================] - 0s 99us/sample - loss: 1.0999 - accuracy: 0.2797 - val_loss: 1.1048 - val_accuracy: 0.2243\n",
      "Epoch 81/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0996 - accuracy: 0.2797 - val_loss: 1.1046 - val_accuracy: 0.2243\n",
      "Epoch 82/200\n",
      "2553/2553 [==============================] - 0s 97us/sample - loss: 1.0980 - accuracy: 0.2797 - val_loss: 1.1043 - val_accuracy: 0.2243\n",
      "Epoch 83/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0997 - accuracy: 0.2797 - val_loss: 1.1041 - val_accuracy: 0.2243\n",
      "Epoch 84/200\n",
      "2553/2553 [==============================] - 0s 96us/sample - loss: 1.0992 - accuracy: 0.2797 - val_loss: 1.1038 - val_accuracy: 0.2243\n",
      "Epoch 85/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.0973 - accuracy: 0.2797 - val_loss: 1.1036 - val_accuracy: 0.2243\n",
      "Epoch 86/200\n",
      "2553/2553 [==============================] - 0s 99us/sample - loss: 1.0987 - accuracy: 0.2797 - val_loss: 1.1034 - val_accuracy: 0.2243\n",
      "Epoch 87/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0982 - accuracy: 0.2797 - val_loss: 1.1031 - val_accuracy: 0.2243\n",
      "Epoch 88/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.0990 - accuracy: 0.2797 - val_loss: 1.1029 - val_accuracy: 0.2243\n",
      "Epoch 89/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.0970 - accuracy: 0.2797 - val_loss: 1.1027 - val_accuracy: 0.2243\n",
      "Epoch 90/200\n",
      "2553/2553 [==============================] - 0s 97us/sample - loss: 1.0980 - accuracy: 0.2797 - val_loss: 1.1025 - val_accuracy: 0.2243\n",
      "Epoch 91/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0991 - accuracy: 0.2797 - val_loss: 1.1023 - val_accuracy: 0.2243\n",
      "Epoch 92/200\n",
      "2553/2553 [==============================] - 0s 97us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.1021 - val_accuracy: 0.2243\n",
      "Epoch 93/200\n",
      "2553/2553 [==============================] - 0s 99us/sample - loss: 1.0972 - accuracy: 0.2797 - val_loss: 1.1019 - val_accuracy: 0.2243\n",
      "Epoch 94/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0959 - accuracy: 0.2797 - val_loss: 1.1017 - val_accuracy: 0.2243\n",
      "Epoch 95/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0973 - accuracy: 0.2797 - val_loss: 1.1016 - val_accuracy: 0.2243\n",
      "Epoch 96/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.0996 - accuracy: 0.2797 - val_loss: 1.1014 - val_accuracy: 0.2243\n",
      "Epoch 97/200\n",
      "2553/2553 [==============================] - 0s 99us/sample - loss: 1.0966 - accuracy: 0.2797 - val_loss: 1.1012 - val_accuracy: 0.2243\n",
      "Epoch 98/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.0976 - accuracy: 0.2797 - val_loss: 1.1011 - val_accuracy: 0.2243\n",
      "Epoch 99/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.0969 - accuracy: 0.2797 - val_loss: 1.1009 - val_accuracy: 0.2243\n",
      "Epoch 100/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.0970 - accuracy: 0.2797 - val_loss: 1.1008 - val_accuracy: 0.2243\n",
      "Epoch 101/200\n",
      "2553/2553 [==============================] - 0s 97us/sample - loss: 1.0963 - accuracy: 0.2797 - val_loss: 1.1007 - val_accuracy: 0.2243\n",
      "Epoch 102/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0967 - accuracy: 0.2797 - val_loss: 1.1006 - val_accuracy: 0.2243\n",
      "Epoch 103/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0968 - accuracy: 0.2797 - val_loss: 1.1005 - val_accuracy: 0.2243\n",
      "Epoch 104/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0965 - accuracy: 0.2797 - val_loss: 1.1004 - val_accuracy: 0.2243\n",
      "Epoch 105/200\n",
      "2553/2553 [==============================] - 0s 98us/sample - loss: 1.0965 - accuracy: 0.2797 - val_loss: 1.1003 - val_accuracy: 0.2243\n",
      "Epoch 106/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.0969 - accuracy: 0.2797 - val_loss: 1.1002 - val_accuracy: 0.2243\n",
      "Epoch 107/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0965 - accuracy: 0.2797 - val_loss: 1.1001 - val_accuracy: 0.2243\n",
      "Epoch 108/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.0956 - accuracy: 0.2797 - val_loss: 1.1001 - val_accuracy: 0.2243\n",
      "Epoch 109/200\n",
      "2553/2553 [==============================] - 0s 98us/sample - loss: 1.0953 - accuracy: 0.2797 - val_loss: 1.1000 - val_accuracy: 0.2243\n",
      "Epoch 110/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0963 - accuracy: 0.2797 - val_loss: 1.0999 - val_accuracy: 0.2243\n",
      "Epoch 111/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0950 - accuracy: 0.2797 - val_loss: 1.0999 - val_accuracy: 0.2243\n",
      "Epoch 112/200\n",
      "2553/2553 [==============================] - 0s 99us/sample - loss: 1.0970 - accuracy: 0.2797 - val_loss: 1.0999 - val_accuracy: 0.2243\n",
      "Epoch 113/200\n",
      "2553/2553 [==============================] - 0s 96us/sample - loss: 1.0959 - accuracy: 0.2797 - val_loss: 1.0998 - val_accuracy: 0.2243\n",
      "Epoch 114/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0943 - accuracy: 0.2797 - val_loss: 1.0998 - val_accuracy: 0.2243\n",
      "Epoch 115/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.0982 - accuracy: 0.2797 - val_loss: 1.0997 - val_accuracy: 0.2243\n",
      "Epoch 116/200\n",
      "2553/2553 [==============================] - 0s 98us/sample - loss: 1.0954 - accuracy: 0.2797 - val_loss: 1.0997 - val_accuracy: 0.2243\n",
      "Epoch 117/200\n",
      "2553/2553 [==============================] - 0s 98us/sample - loss: 1.0975 - accuracy: 0.2797 - val_loss: 1.0997 - val_accuracy: 0.2243\n",
      "Epoch 118/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0961 - accuracy: 0.2797 - val_loss: 1.0996 - val_accuracy: 0.2243\n",
      "Epoch 119/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0971 - accuracy: 0.2797 - val_loss: 1.0996 - val_accuracy: 0.2243\n",
      "Epoch 120/200\n",
      "2553/2553 [==============================] - 0s 97us/sample - loss: 1.0956 - accuracy: 0.2797 - val_loss: 1.0996 - val_accuracy: 0.2243\n",
      "Epoch 121/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 97us/sample - loss: 1.0954 - accuracy: 0.2797 - val_loss: 1.0996 - val_accuracy: 0.2243\n",
      "Epoch 122/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0977 - accuracy: 0.2797 - val_loss: 1.0996 - val_accuracy: 0.2243\n",
      "Epoch 123/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0961 - accuracy: 0.2797 - val_loss: 1.0996 - val_accuracy: 0.2243\n",
      "Epoch 124/200\n",
      "2553/2553 [==============================] - ETA: 0s - loss: 1.0957 - accuracy: 0.27 - 0s 98us/sample - loss: 1.0957 - accuracy: 0.2797 - val_loss: 1.0996 - val_accuracy: 0.2243\n",
      "Epoch 125/200\n",
      "2553/2553 [==============================] - 0s 96us/sample - loss: 1.0969 - accuracy: 0.2797 - val_loss: 1.0995 - val_accuracy: 0.2243\n",
      "Epoch 126/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0969 - accuracy: 0.2797 - val_loss: 1.0995 - val_accuracy: 0.2243\n",
      "Epoch 127/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0960 - accuracy: 0.2797 - val_loss: 1.0995 - val_accuracy: 0.2243\n",
      "Epoch 128/200\n",
      "2553/2553 [==============================] - 0s 98us/sample - loss: 1.0965 - accuracy: 0.2797 - val_loss: 1.0995 - val_accuracy: 0.2243\n",
      "Epoch 129/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.0951 - accuracy: 0.2797 - val_loss: 1.0995 - val_accuracy: 0.2243\n",
      "Epoch 130/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0950 - accuracy: 0.2797 - val_loss: 1.0995 - val_accuracy: 0.2243\n",
      "Epoch 131/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.0951 - accuracy: 0.2797 - val_loss: 1.0995 - val_accuracy: 0.2243\n",
      "Epoch 132/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0968 - accuracy: 0.2797 - val_loss: 1.0995 - val_accuracy: 0.2243\n",
      "Epoch 133/200\n",
      "2553/2553 [==============================] - 0s 98us/sample - loss: 1.0954 - accuracy: 0.2797 - val_loss: 1.0995 - val_accuracy: 0.2243\n",
      "Epoch 134/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.0949 - accuracy: 0.2797 - val_loss: 1.0995 - val_accuracy: 0.2243\n",
      "Epoch 135/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0946 - accuracy: 0.2797 - val_loss: 1.0995 - val_accuracy: 0.2243\n",
      "Epoch 136/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.0952 - accuracy: 0.2797 - val_loss: 1.0995 - val_accuracy: 0.2243\n",
      "Epoch 137/200\n",
      "2553/2553 [==============================] - 0s 98us/sample - loss: 1.0963 - accuracy: 0.2797 - val_loss: 1.0995 - val_accuracy: 0.2243\n",
      "Epoch 138/200\n",
      "2553/2553 [==============================] - 0s 98us/sample - loss: 1.0946 - accuracy: 0.2797 - val_loss: 1.0995 - val_accuracy: 0.2243\n",
      "Epoch 139/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0971 - accuracy: 0.2797 - val_loss: 1.0995 - val_accuracy: 0.2243\n",
      "Epoch 140/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.0949 - accuracy: 0.2797 - val_loss: 1.0995 - val_accuracy: 0.2243\n",
      "Epoch 141/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.0964 - accuracy: 0.2797 - val_loss: 1.0995 - val_accuracy: 0.2243\n",
      "Epoch 142/200\n",
      "2553/2553 [==============================] - 0s 97us/sample - loss: 1.0936 - accuracy: 0.2797 - val_loss: 1.0995 - val_accuracy: 0.2243\n",
      "Epoch 143/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0962 - accuracy: 0.2797 - val_loss: 1.0995 - val_accuracy: 0.2243\n",
      "Epoch 144/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.0955 - accuracy: 0.2797 - val_loss: 1.0995 - val_accuracy: 0.2243\n",
      "Epoch 145/200\n",
      "2553/2553 [==============================] - 0s 99us/sample - loss: 1.0957 - accuracy: 0.2797 - val_loss: 1.0995 - val_accuracy: 0.2243\n",
      "Epoch 146/200\n",
      "2553/2553 [==============================] - 0s 99us/sample - loss: 1.0949 - accuracy: 0.2797 - val_loss: 1.0995 - val_accuracy: 0.2243\n",
      "Epoch 147/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0950 - accuracy: 0.2797 - val_loss: 1.0995 - val_accuracy: 0.2243\n",
      "Epoch 148/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.0954 - accuracy: 0.2797 - val_loss: 1.0995 - val_accuracy: 0.2243\n",
      "Epoch 149/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.0969 - accuracy: 0.2797 - val_loss: 1.0995 - val_accuracy: 0.2243\n",
      "Epoch 150/200\n",
      "2553/2553 [==============================] - 0s 96us/sample - loss: 1.0955 - accuracy: 0.2797 - val_loss: 1.0995 - val_accuracy: 0.2243\n",
      "Epoch 151/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0950 - accuracy: 0.2797 - val_loss: 1.0995 - val_accuracy: 0.2243\n",
      "Epoch 152/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.0956 - accuracy: 0.2797 - val_loss: 1.0995 - val_accuracy: 0.2243\n",
      "Epoch 153/200\n",
      "2553/2553 [==============================] - 0s 98us/sample - loss: 1.0964 - accuracy: 0.2797 - val_loss: 1.0995 - val_accuracy: 0.2243\n",
      "Epoch 154/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0941 - accuracy: 0.2797 - val_loss: 1.0995 - val_accuracy: 0.2243\n",
      "Epoch 155/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.0945 - accuracy: 0.2797 - val_loss: 1.0995 - val_accuracy: 0.2243\n",
      "Epoch 156/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0959 - accuracy: 0.2797 - val_loss: 1.0995 - val_accuracy: 0.2243\n",
      "Epoch 157/200\n",
      "2553/2553 [==============================] - 0s 98us/sample - loss: 1.0971 - accuracy: 0.2797 - val_loss: 1.0994 - val_accuracy: 0.2243\n",
      "Epoch 158/200\n",
      "2553/2553 [==============================] - 0s 99us/sample - loss: 1.0957 - accuracy: 0.2797 - val_loss: 1.0994 - val_accuracy: 0.2243\n",
      "Epoch 159/200\n",
      "2553/2553 [==============================] - 0s 121us/sample - loss: 1.0958 - accuracy: 0.2797 - val_loss: 1.0994 - val_accuracy: 0.2243\n",
      "Epoch 160/200\n",
      "2553/2553 [==============================] - 0s 147us/sample - loss: 1.0945 - accuracy: 0.2797 - val_loss: 1.0994 - val_accuracy: 0.2243\n",
      "Epoch 161/200\n",
      "2553/2553 [==============================] - 0s 155us/sample - loss: 1.0961 - accuracy: 0.2797 - val_loss: 1.0994 - val_accuracy: 0.2243\n",
      "Epoch 162/200\n",
      "2553/2553 [==============================] - 0s 145us/sample - loss: 1.0942 - accuracy: 0.2797 - val_loss: 1.0994 - val_accuracy: 0.2243\n",
      "Epoch 163/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0974 - accuracy: 0.2797 - val_loss: 1.0994 - val_accuracy: 0.2243\n",
      "Epoch 164/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0966 - accuracy: 0.2797 - val_loss: 1.0994 - val_accuracy: 0.2243\n",
      "Epoch 165/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.0963 - accuracy: 0.2797 - val_loss: 1.0994 - val_accuracy: 0.2243\n",
      "Epoch 166/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0962 - accuracy: 0.2797 - val_loss: 1.0994 - val_accuracy: 0.2243\n",
      "Epoch 167/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0961 - accuracy: 0.2797 - val_loss: 1.0994 - val_accuracy: 0.2243\n",
      "Epoch 168/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 1.0977 - accuracy: 0.2797 - val_loss: 1.0994 - val_accuracy: 0.2243\n",
      "Epoch 169/200\n",
      "2553/2553 [==============================] - 0s 96us/sample - loss: 1.0964 - accuracy: 0.2797 - val_loss: 1.0994 - val_accuracy: 0.2243\n",
      "Epoch 170/200\n",
      "2553/2553 [==============================] - 0s 120us/sample - loss: 1.0963 - accuracy: 0.2797 - val_loss: 1.0994 - val_accuracy: 0.2243\n",
      "Epoch 171/200\n",
      "2553/2553 [==============================] - 0s 119us/sample - loss: 1.0956 - accuracy: 0.2797 - val_loss: 1.0994 - val_accuracy: 0.2243\n",
      "Epoch 172/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0955 - accuracy: 0.2797 - val_loss: 1.0993 - val_accuracy: 0.2243\n",
      "Epoch 173/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0953 - accuracy: 0.2797 - val_loss: 1.0994 - val_accuracy: 0.2243\n",
      "Epoch 174/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0950 - accuracy: 0.2797 - val_loss: 1.0994 - val_accuracy: 0.2243\n",
      "Epoch 175/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.0946 - accuracy: 0.2797 - val_loss: 1.0993 - val_accuracy: 0.2243\n",
      "Epoch 176/200\n",
      "2553/2553 [==============================] - 0s 98us/sample - loss: 1.0965 - accuracy: 0.2797 - val_loss: 1.0993 - val_accuracy: 0.2243\n",
      "Epoch 177/200\n",
      "2553/2553 [==============================] - 0s 114us/sample - loss: 1.0959 - accuracy: 0.2797 - val_loss: 1.0993 - val_accuracy: 0.2243\n",
      "Epoch 178/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0961 - accuracy: 0.2797 - val_loss: 1.0993 - val_accuracy: 0.2243\n",
      "Epoch 179/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0949 - accuracy: 0.2797 - val_loss: 1.0993 - val_accuracy: 0.2243\n",
      "Epoch 180/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.0947 - accuracy: 0.2797 - val_loss: 1.0993 - val_accuracy: 0.2243\n",
      "Epoch 181/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0951 - accuracy: 0.2797 - val_loss: 1.0993 - val_accuracy: 0.2243\n",
      "Epoch 182/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.0967 - accuracy: 0.2797 - val_loss: 1.0993 - val_accuracy: 0.2243\n",
      "Epoch 183/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.0948 - accuracy: 0.2797 - val_loss: 1.0993 - val_accuracy: 0.2243\n",
      "Epoch 184/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.0948 - accuracy: 0.2797 - val_loss: 1.0993 - val_accuracy: 0.2243\n",
      "Epoch 185/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0935 - accuracy: 0.2797 - val_loss: 1.0993 - val_accuracy: 0.2243\n",
      "Epoch 186/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0962 - accuracy: 0.2797 - val_loss: 1.0993 - val_accuracy: 0.2243\n",
      "Epoch 187/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.0948 - accuracy: 0.2797 - val_loss: 1.0993 - val_accuracy: 0.2243\n",
      "Epoch 188/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0954 - accuracy: 0.2797 - val_loss: 1.0993 - val_accuracy: 0.2243\n",
      "Epoch 189/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.0936 - accuracy: 0.2797 - val_loss: 1.0993 - val_accuracy: 0.2243\n",
      "Epoch 190/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.0958 - accuracy: 0.2797 - val_loss: 1.0993 - val_accuracy: 0.2243\n",
      "Epoch 191/200\n",
      "2553/2553 [==============================] - 0s 99us/sample - loss: 1.0943 - accuracy: 0.2797 - val_loss: 1.0993 - val_accuracy: 0.2243\n",
      "Epoch 192/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0953 - accuracy: 0.2797 - val_loss: 1.0993 - val_accuracy: 0.2243\n",
      "Epoch 193/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0972 - accuracy: 0.2797 - val_loss: 1.0993 - val_accuracy: 0.2243\n",
      "Epoch 194/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0969 - accuracy: 0.2797 - val_loss: 1.0993 - val_accuracy: 0.2243\n",
      "Epoch 195/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0957 - accuracy: 0.2797 - val_loss: 1.0993 - val_accuracy: 0.2243\n",
      "Epoch 196/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0954 - accuracy: 0.2797 - val_loss: 1.0993 - val_accuracy: 0.2243\n",
      "Epoch 197/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.0942 - accuracy: 0.2797 - val_loss: 1.0993 - val_accuracy: 0.2243\n",
      "Epoch 198/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0945 - accuracy: 0.2797 - val_loss: 1.0993 - val_accuracy: 0.2243\n",
      "Epoch 199/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.0931 - accuracy: 0.2797 - val_loss: 1.0993 - val_accuracy: 0.2243\n",
      "Epoch 200/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.0960 - accuracy: 0.2797 - val_loss: 1.0992 - val_accuracy: 0.2243\n",
      "0.22429906 {'loss': 1.0959917826602097, 'accuracy': 0.27967098, 'val_loss': 1.0992463559747856, 'val_accuracy': 0.22429906}\n",
      "Model: \"model_29\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_30 (InputLayer)        [(None, 29)]              0         \n",
      "_________________________________________________________________\n",
      "flatten_29 (Flatten)         (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_113 (Dense)            (None, 41)                1230      \n",
      "_________________________________________________________________\n",
      "dense_114 (Dense)            (None, 10)                420       \n",
      "_________________________________________________________________\n",
      "dense_115 (Dense)            (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_116 (Dense)            (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_117 (Dense)            (None, 3)                 33        \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 1,903\n",
      "Trainable params: 1,903\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2553 samples, validate on 107 samples\n",
      "Epoch 1/200\n",
      "2553/2553 [==============================] - 1s 285us/sample - loss: 1.1616 - accuracy: 0.3008 - val_loss: 1.1476 - val_accuracy: 0.2617\n",
      "Epoch 2/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.1765 - accuracy: 0.3165 - val_loss: 1.1470 - val_accuracy: 0.2710\n",
      "Epoch 3/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.1755 - accuracy: 0.3024 - val_loss: 1.1465 - val_accuracy: 0.2710\n",
      "Epoch 4/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.1632 - accuracy: 0.3126 - val_loss: 1.1460 - val_accuracy: 0.2710\n",
      "Epoch 5/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1557 - accuracy: 0.3169 - val_loss: 1.1455 - val_accuracy: 0.2710\n",
      "Epoch 6/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.1760 - accuracy: 0.3047 - val_loss: 1.1450 - val_accuracy: 0.2710\n",
      "Epoch 7/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.1546 - accuracy: 0.3157 - val_loss: 1.1445 - val_accuracy: 0.2710\n",
      "Epoch 8/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1665 - accuracy: 0.3106 - val_loss: 1.1440 - val_accuracy: 0.2710\n",
      "Epoch 9/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.1671 - accuracy: 0.3024 - val_loss: 1.1435 - val_accuracy: 0.2710\n",
      "Epoch 10/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.1587 - accuracy: 0.3169 - val_loss: 1.1430 - val_accuracy: 0.2710\n",
      "Epoch 11/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1647 - accuracy: 0.3157 - val_loss: 1.1426 - val_accuracy: 0.2710\n",
      "Epoch 12/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1486 - accuracy: 0.3184 - val_loss: 1.1422 - val_accuracy: 0.2710\n",
      "Epoch 13/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1538 - accuracy: 0.3134 - val_loss: 1.1418 - val_accuracy: 0.2804\n",
      "Epoch 14/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1634 - accuracy: 0.3098 - val_loss: 1.1413 - val_accuracy: 0.2804\n",
      "Epoch 15/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1610 - accuracy: 0.3137 - val_loss: 1.1409 - val_accuracy: 0.2804\n",
      "Epoch 16/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1521 - accuracy: 0.3220 - val_loss: 1.1405 - val_accuracy: 0.2804\n",
      "Epoch 17/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1545 - accuracy: 0.3157 - val_loss: 1.1400 - val_accuracy: 0.2804\n",
      "Epoch 18/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1490 - accuracy: 0.3157 - val_loss: 1.1396 - val_accuracy: 0.2804\n",
      "Epoch 19/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1542 - accuracy: 0.3259 - val_loss: 1.1392 - val_accuracy: 0.2804\n",
      "Epoch 20/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.1561 - accuracy: 0.3169 - val_loss: 1.1388 - val_accuracy: 0.2804\n",
      "Epoch 21/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1521 - accuracy: 0.3149 - val_loss: 1.1384 - val_accuracy: 0.2804\n",
      "Epoch 22/200\n",
      "2553/2553 [==============================] - 0s 51us/sample - loss: 1.1577 - accuracy: 0.3079 - val_loss: 1.1379 - val_accuracy: 0.2804\n",
      "Epoch 23/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1606 - accuracy: 0.3188 - val_loss: 1.1375 - val_accuracy: 0.2804\n",
      "Epoch 24/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1571 - accuracy: 0.3141 - val_loss: 1.1371 - val_accuracy: 0.2804\n",
      "Epoch 25/200\n",
      "2553/2553 [==============================] - 0s 51us/sample - loss: 1.1469 - accuracy: 0.3306 - val_loss: 1.1367 - val_accuracy: 0.2804\n",
      "Epoch 26/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.1564 - accuracy: 0.3130 - val_loss: 1.1364 - val_accuracy: 0.2804\n",
      "Epoch 27/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1507 - accuracy: 0.3231 - val_loss: 1.1360 - val_accuracy: 0.2804\n",
      "Epoch 28/200\n",
      "2553/2553 [==============================] - 0s 51us/sample - loss: 1.1530 - accuracy: 0.3161 - val_loss: 1.1356 - val_accuracy: 0.2804\n",
      "Epoch 29/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.1491 - accuracy: 0.3243 - val_loss: 1.1352 - val_accuracy: 0.2897\n",
      "Epoch 30/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.1493 - accuracy: 0.3063 - val_loss: 1.1348 - val_accuracy: 0.2897\n",
      "Epoch 31/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1498 - accuracy: 0.3173 - val_loss: 1.1345 - val_accuracy: 0.2897\n",
      "Epoch 32/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.1488 - accuracy: 0.3216 - val_loss: 1.1341 - val_accuracy: 0.2897\n",
      "Epoch 33/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1465 - accuracy: 0.3216 - val_loss: 1.1337 - val_accuracy: 0.2897\n",
      "Epoch 34/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.1431 - accuracy: 0.3181 - val_loss: 1.1333 - val_accuracy: 0.2897\n",
      "Epoch 35/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1552 - accuracy: 0.3122 - val_loss: 1.1329 - val_accuracy: 0.2897\n",
      "Epoch 36/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1385 - accuracy: 0.3098 - val_loss: 1.1326 - val_accuracy: 0.2897\n",
      "Epoch 37/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1505 - accuracy: 0.3137 - val_loss: 1.1322 - val_accuracy: 0.2897\n",
      "Epoch 38/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1432 - accuracy: 0.3278 - val_loss: 1.1319 - val_accuracy: 0.2897\n",
      "Epoch 39/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1466 - accuracy: 0.3157 - val_loss: 1.1315 - val_accuracy: 0.2897\n",
      "Epoch 40/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1486 - accuracy: 0.3134 - val_loss: 1.1311 - val_accuracy: 0.2991\n",
      "Epoch 41/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1477 - accuracy: 0.3278 - val_loss: 1.1307 - val_accuracy: 0.2991\n",
      "Epoch 42/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1434 - accuracy: 0.3294 - val_loss: 1.1304 - val_accuracy: 0.2991\n",
      "Epoch 43/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.1454 - accuracy: 0.3094 - val_loss: 1.1300 - val_accuracy: 0.2991\n",
      "Epoch 44/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1481 - accuracy: 0.3212 - val_loss: 1.1296 - val_accuracy: 0.2991\n",
      "Epoch 45/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.1356 - accuracy: 0.3251 - val_loss: 1.1293 - val_accuracy: 0.3084\n",
      "Epoch 46/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1403 - accuracy: 0.3251 - val_loss: 1.1289 - val_accuracy: 0.3084\n",
      "Epoch 47/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1507 - accuracy: 0.3134 - val_loss: 1.1285 - val_accuracy: 0.3084\n",
      "Epoch 48/200\n",
      "2553/2553 [==============================] - 0s 51us/sample - loss: 1.1417 - accuracy: 0.3212 - val_loss: 1.1281 - val_accuracy: 0.3084\n",
      "Epoch 49/200\n",
      "2553/2553 [==============================] - 0s 50us/sample - loss: 1.1454 - accuracy: 0.3259 - val_loss: 1.1278 - val_accuracy: 0.3084\n",
      "Epoch 50/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1437 - accuracy: 0.3157 - val_loss: 1.1274 - val_accuracy: 0.3084\n",
      "Epoch 51/200\n",
      "2553/2553 [==============================] - 0s 50us/sample - loss: 1.1469 - accuracy: 0.3130 - val_loss: 1.1271 - val_accuracy: 0.3084\n",
      "Epoch 52/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1481 - accuracy: 0.3306 - val_loss: 1.1267 - val_accuracy: 0.3084\n",
      "Epoch 53/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.1467 - accuracy: 0.3220 - val_loss: 1.1263 - val_accuracy: 0.3084\n",
      "Epoch 54/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1340 - accuracy: 0.3275 - val_loss: 1.1260 - val_accuracy: 0.3084\n",
      "Epoch 55/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1290 - accuracy: 0.3188 - val_loss: 1.1256 - val_accuracy: 0.3084\n",
      "Epoch 56/200\n",
      "2553/2553 [==============================] - 0s 51us/sample - loss: 1.1447 - accuracy: 0.3306 - val_loss: 1.1252 - val_accuracy: 0.3084\n",
      "Epoch 57/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1316 - accuracy: 0.3251 - val_loss: 1.1249 - val_accuracy: 0.3084\n",
      "Epoch 58/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1434 - accuracy: 0.3282 - val_loss: 1.1245 - val_accuracy: 0.3084\n",
      "Epoch 59/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1401 - accuracy: 0.3181 - val_loss: 1.1242 - val_accuracy: 0.3084\n",
      "Epoch 60/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1421 - accuracy: 0.3137 - val_loss: 1.1238 - val_accuracy: 0.3084\n",
      "Epoch 61/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1383 - accuracy: 0.3247 - val_loss: 1.1235 - val_accuracy: 0.3084\n",
      "Epoch 62/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1261 - accuracy: 0.3220 - val_loss: 1.1231 - val_accuracy: 0.3084\n",
      "Epoch 63/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.1396 - accuracy: 0.3196 - val_loss: 1.1228 - val_accuracy: 0.3084\n",
      "Epoch 64/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.1403 - accuracy: 0.3169 - val_loss: 1.1225 - val_accuracy: 0.3084\n",
      "Epoch 65/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1302 - accuracy: 0.3255 - val_loss: 1.1222 - val_accuracy: 0.3084\n",
      "Epoch 66/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.1393 - accuracy: 0.3318 - val_loss: 1.1218 - val_accuracy: 0.3084\n",
      "Epoch 67/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.1396 - accuracy: 0.3134 - val_loss: 1.1215 - val_accuracy: 0.3084\n",
      "Epoch 68/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1337 - accuracy: 0.3337 - val_loss: 1.1212 - val_accuracy: 0.3084\n",
      "Epoch 69/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1342 - accuracy: 0.3216 - val_loss: 1.1209 - val_accuracy: 0.3084\n",
      "Epoch 70/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1296 - accuracy: 0.3278 - val_loss: 1.1206 - val_accuracy: 0.3084\n",
      "Epoch 71/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1361 - accuracy: 0.3329 - val_loss: 1.1202 - val_accuracy: 0.3084\n",
      "Epoch 72/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1272 - accuracy: 0.3216 - val_loss: 1.1199 - val_accuracy: 0.3084\n",
      "Epoch 73/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.1295 - accuracy: 0.3318 - val_loss: 1.1196 - val_accuracy: 0.3084\n",
      "Epoch 74/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1341 - accuracy: 0.3243 - val_loss: 1.1193 - val_accuracy: 0.3084\n",
      "Epoch 75/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1346 - accuracy: 0.3239 - val_loss: 1.1190 - val_accuracy: 0.3178\n",
      "Epoch 76/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.1255 - accuracy: 0.3329 - val_loss: 1.1187 - val_accuracy: 0.3178\n",
      "Epoch 77/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1329 - accuracy: 0.3278 - val_loss: 1.1184 - val_accuracy: 0.3178\n",
      "Epoch 78/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1260 - accuracy: 0.3290 - val_loss: 1.1181 - val_accuracy: 0.3178\n",
      "Epoch 79/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1189 - accuracy: 0.3267 - val_loss: 1.1178 - val_accuracy: 0.3178\n",
      "Epoch 80/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.1296 - accuracy: 0.3231 - val_loss: 1.1175 - val_accuracy: 0.3178\n",
      "Epoch 81/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1308 - accuracy: 0.3255 - val_loss: 1.1171 - val_accuracy: 0.3178\n",
      "Epoch 82/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.1261 - accuracy: 0.3427 - val_loss: 1.1168 - val_accuracy: 0.3178\n",
      "Epoch 83/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.1285 - accuracy: 0.3322 - val_loss: 1.1165 - val_accuracy: 0.3178\n",
      "Epoch 84/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1223 - accuracy: 0.3325 - val_loss: 1.1162 - val_accuracy: 0.3178\n",
      "Epoch 85/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1283 - accuracy: 0.3275 - val_loss: 1.1159 - val_accuracy: 0.3178\n",
      "Epoch 86/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1216 - accuracy: 0.3349 - val_loss: 1.1156 - val_accuracy: 0.3178\n",
      "Epoch 87/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.1269 - accuracy: 0.3384 - val_loss: 1.1153 - val_accuracy: 0.3178\n",
      "Epoch 88/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.1255 - accuracy: 0.3310 - val_loss: 1.1150 - val_accuracy: 0.3178\n",
      "Epoch 89/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.1307 - accuracy: 0.3263 - val_loss: 1.1147 - val_accuracy: 0.3178\n",
      "Epoch 90/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.1231 - accuracy: 0.3298 - val_loss: 1.1144 - val_accuracy: 0.3178\n",
      "Epoch 91/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1262 - accuracy: 0.3286 - val_loss: 1.1141 - val_accuracy: 0.3178\n",
      "Epoch 92/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1206 - accuracy: 0.3337 - val_loss: 1.1138 - val_accuracy: 0.3178\n",
      "Epoch 93/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1239 - accuracy: 0.3345 - val_loss: 1.1135 - val_accuracy: 0.3178\n",
      "Epoch 94/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1200 - accuracy: 0.3286 - val_loss: 1.1132 - val_accuracy: 0.3178\n",
      "Epoch 95/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1232 - accuracy: 0.3271 - val_loss: 1.1129 - val_accuracy: 0.3178\n",
      "Epoch 96/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.1270 - accuracy: 0.3286 - val_loss: 1.1126 - val_accuracy: 0.3178\n",
      "Epoch 97/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.1173 - accuracy: 0.3376 - val_loss: 1.1123 - val_accuracy: 0.3178\n",
      "Epoch 98/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1190 - accuracy: 0.3337 - val_loss: 1.1120 - val_accuracy: 0.3178\n",
      "Epoch 99/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1229 - accuracy: 0.3251 - val_loss: 1.1117 - val_accuracy: 0.3178\n",
      "Epoch 100/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1264 - accuracy: 0.3341 - val_loss: 1.1114 - val_accuracy: 0.3178\n",
      "Epoch 101/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.1193 - accuracy: 0.3306 - val_loss: 1.1111 - val_accuracy: 0.3178\n",
      "Epoch 102/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.1185 - accuracy: 0.3361 - val_loss: 1.1108 - val_accuracy: 0.3178\n",
      "Epoch 103/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1218 - accuracy: 0.3231 - val_loss: 1.1105 - val_accuracy: 0.3178\n",
      "Epoch 104/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.1208 - accuracy: 0.3325 - val_loss: 1.1102 - val_accuracy: 0.3178\n",
      "Epoch 105/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1198 - accuracy: 0.3263 - val_loss: 1.1099 - val_accuracy: 0.3178\n",
      "Epoch 106/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1233 - accuracy: 0.3353 - val_loss: 1.1096 - val_accuracy: 0.3178\n",
      "Epoch 107/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1180 - accuracy: 0.3325 - val_loss: 1.1093 - val_accuracy: 0.3178\n",
      "Epoch 108/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1162 - accuracy: 0.3286 - val_loss: 1.1091 - val_accuracy: 0.3178\n",
      "Epoch 109/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1176 - accuracy: 0.3275 - val_loss: 1.1088 - val_accuracy: 0.3178\n",
      "Epoch 110/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1244 - accuracy: 0.3243 - val_loss: 1.1085 - val_accuracy: 0.3178\n",
      "Epoch 111/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.1226 - accuracy: 0.3251 - val_loss: 1.1082 - val_accuracy: 0.3178\n",
      "Epoch 112/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1201 - accuracy: 0.3212 - val_loss: 1.1079 - val_accuracy: 0.3178\n",
      "Epoch 113/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1224 - accuracy: 0.3251 - val_loss: 1.1076 - val_accuracy: 0.3084\n",
      "Epoch 114/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1178 - accuracy: 0.3369 - val_loss: 1.1073 - val_accuracy: 0.3084\n",
      "Epoch 115/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1166 - accuracy: 0.3314 - val_loss: 1.1071 - val_accuracy: 0.3084\n",
      "Epoch 116/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1144 - accuracy: 0.3349 - val_loss: 1.1068 - val_accuracy: 0.3084\n",
      "Epoch 117/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1221 - accuracy: 0.3228 - val_loss: 1.1065 - val_accuracy: 0.3084\n",
      "Epoch 118/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.1108 - accuracy: 0.3420 - val_loss: 1.1062 - val_accuracy: 0.3084\n",
      "Epoch 119/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1118 - accuracy: 0.3361 - val_loss: 1.1060 - val_accuracy: 0.3084\n",
      "Epoch 120/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1125 - accuracy: 0.3302 - val_loss: 1.1057 - val_accuracy: 0.3084\n",
      "Epoch 121/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1175 - accuracy: 0.3298 - val_loss: 1.1055 - val_accuracy: 0.3084\n",
      "Epoch 122/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1195 - accuracy: 0.3239 - val_loss: 1.1052 - val_accuracy: 0.3084\n",
      "Epoch 123/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1086 - accuracy: 0.3376 - val_loss: 1.1049 - val_accuracy: 0.3178\n",
      "Epoch 124/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.1172 - accuracy: 0.3412 - val_loss: 1.1046 - val_accuracy: 0.3178\n",
      "Epoch 125/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.1101 - accuracy: 0.3365 - val_loss: 1.1044 - val_accuracy: 0.3178\n",
      "Epoch 126/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.1108 - accuracy: 0.3376 - val_loss: 1.1041 - val_accuracy: 0.3178\n",
      "Epoch 127/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1174 - accuracy: 0.3380 - val_loss: 1.1038 - val_accuracy: 0.3178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 128/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1201 - accuracy: 0.3286 - val_loss: 1.1036 - val_accuracy: 0.3271\n",
      "Epoch 129/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1154 - accuracy: 0.3349 - val_loss: 1.1033 - val_accuracy: 0.3271\n",
      "Epoch 130/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1062 - accuracy: 0.3373 - val_loss: 1.1031 - val_accuracy: 0.3271\n",
      "Epoch 131/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.1122 - accuracy: 0.3337 - val_loss: 1.1028 - val_accuracy: 0.3271\n",
      "Epoch 132/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1102 - accuracy: 0.3349 - val_loss: 1.1026 - val_accuracy: 0.3271\n",
      "Epoch 133/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.1070 - accuracy: 0.3380 - val_loss: 1.1023 - val_accuracy: 0.3271\n",
      "Epoch 134/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1109 - accuracy: 0.3408 - val_loss: 1.1021 - val_accuracy: 0.3271\n",
      "Epoch 135/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1123 - accuracy: 0.3369 - val_loss: 1.1018 - val_accuracy: 0.3271\n",
      "Epoch 136/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1044 - accuracy: 0.3341 - val_loss: 1.1016 - val_accuracy: 0.3271\n",
      "Epoch 137/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1127 - accuracy: 0.3384 - val_loss: 1.1013 - val_accuracy: 0.3271\n",
      "Epoch 138/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.1104 - accuracy: 0.3357 - val_loss: 1.1011 - val_accuracy: 0.3271\n",
      "Epoch 139/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1139 - accuracy: 0.3337 - val_loss: 1.1008 - val_accuracy: 0.3271\n",
      "Epoch 140/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.1109 - accuracy: 0.3361 - val_loss: 1.1005 - val_accuracy: 0.3271\n",
      "Epoch 141/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1092 - accuracy: 0.3396 - val_loss: 1.1003 - val_accuracy: 0.3271\n",
      "Epoch 142/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1118 - accuracy: 0.3380 - val_loss: 1.1000 - val_accuracy: 0.3364\n",
      "Epoch 143/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1094 - accuracy: 0.3239 - val_loss: 1.0998 - val_accuracy: 0.3364\n",
      "Epoch 144/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1024 - accuracy: 0.3498 - val_loss: 1.0996 - val_accuracy: 0.3364\n",
      "Epoch 145/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.1105 - accuracy: 0.3357 - val_loss: 1.0993 - val_accuracy: 0.3364\n",
      "Epoch 146/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1073 - accuracy: 0.3490 - val_loss: 1.0991 - val_accuracy: 0.3364\n",
      "Epoch 147/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.1131 - accuracy: 0.3267 - val_loss: 1.0988 - val_accuracy: 0.3458\n",
      "Epoch 148/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1091 - accuracy: 0.3373 - val_loss: 1.0986 - val_accuracy: 0.3458\n",
      "Epoch 149/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1045 - accuracy: 0.3400 - val_loss: 1.0984 - val_accuracy: 0.3458\n",
      "Epoch 150/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1052 - accuracy: 0.3412 - val_loss: 1.0981 - val_accuracy: 0.3458\n",
      "Epoch 151/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.1096 - accuracy: 0.3341 - val_loss: 1.0979 - val_accuracy: 0.3458\n",
      "Epoch 152/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.1049 - accuracy: 0.3482 - val_loss: 1.0977 - val_accuracy: 0.3458\n",
      "Epoch 153/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1018 - accuracy: 0.3439 - val_loss: 1.0975 - val_accuracy: 0.3458\n",
      "Epoch 154/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1019 - accuracy: 0.3412 - val_loss: 1.0972 - val_accuracy: 0.3458\n",
      "Epoch 155/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.1084 - accuracy: 0.3337 - val_loss: 1.0970 - val_accuracy: 0.3458\n",
      "Epoch 156/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1046 - accuracy: 0.3455 - val_loss: 1.0968 - val_accuracy: 0.3458\n",
      "Epoch 157/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1018 - accuracy: 0.3306 - val_loss: 1.0966 - val_accuracy: 0.3458\n",
      "Epoch 158/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1076 - accuracy: 0.3416 - val_loss: 1.0963 - val_accuracy: 0.3458\n",
      "Epoch 159/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1089 - accuracy: 0.3286 - val_loss: 1.0961 - val_accuracy: 0.3458\n",
      "Epoch 160/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.1091 - accuracy: 0.3329 - val_loss: 1.0959 - val_accuracy: 0.3458\n",
      "Epoch 161/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.1064 - accuracy: 0.3388 - val_loss: 1.0957 - val_accuracy: 0.3458\n",
      "Epoch 162/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.1083 - accuracy: 0.3392 - val_loss: 1.0955 - val_accuracy: 0.3458\n",
      "Epoch 163/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1077 - accuracy: 0.3298 - val_loss: 1.0953 - val_accuracy: 0.3458\n",
      "Epoch 164/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.1091 - accuracy: 0.3420 - val_loss: 1.0951 - val_accuracy: 0.3458\n",
      "Epoch 165/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.1028 - accuracy: 0.3349 - val_loss: 1.0948 - val_accuracy: 0.3458\n",
      "Epoch 166/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1002 - accuracy: 0.3478 - val_loss: 1.0946 - val_accuracy: 0.3458\n",
      "Epoch 167/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0975 - accuracy: 0.3463 - val_loss: 1.0944 - val_accuracy: 0.3551\n",
      "Epoch 168/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0935 - accuracy: 0.3561 - val_loss: 1.0942 - val_accuracy: 0.3551\n",
      "Epoch 169/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1059 - accuracy: 0.3349 - val_loss: 1.0940 - val_accuracy: 0.3551\n",
      "Epoch 170/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1028 - accuracy: 0.3392 - val_loss: 1.0938 - val_accuracy: 0.3551\n",
      "Epoch 171/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.1032 - accuracy: 0.3412 - val_loss: 1.0936 - val_accuracy: 0.3551\n",
      "Epoch 172/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1023 - accuracy: 0.3494 - val_loss: 1.0934 - val_accuracy: 0.3551\n",
      "Epoch 173/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0984 - accuracy: 0.3369 - val_loss: 1.0932 - val_accuracy: 0.3551\n",
      "Epoch 174/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.1079 - accuracy: 0.3345 - val_loss: 1.0930 - val_accuracy: 0.3551\n",
      "Epoch 175/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0988 - accuracy: 0.3404 - val_loss: 1.0928 - val_accuracy: 0.3551\n",
      "Epoch 176/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0988 - accuracy: 0.3490 - val_loss: 1.0926 - val_accuracy: 0.3551\n",
      "Epoch 177/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1015 - accuracy: 0.3357 - val_loss: 1.0924 - val_accuracy: 0.3645\n",
      "Epoch 178/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1041 - accuracy: 0.3369 - val_loss: 1.0922 - val_accuracy: 0.3738\n",
      "Epoch 179/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0968 - accuracy: 0.3506 - val_loss: 1.0920 - val_accuracy: 0.3738\n",
      "Epoch 180/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0940 - accuracy: 0.3490 - val_loss: 1.0918 - val_accuracy: 0.3738\n",
      "Epoch 181/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.1077 - accuracy: 0.3357 - val_loss: 1.0916 - val_accuracy: 0.3738\n",
      "Epoch 182/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.1047 - accuracy: 0.3392 - val_loss: 1.0914 - val_accuracy: 0.3738\n",
      "Epoch 183/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0929 - accuracy: 0.3474 - val_loss: 1.0912 - val_accuracy: 0.3738\n",
      "Epoch 184/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.1030 - accuracy: 0.3517 - val_loss: 1.0910 - val_accuracy: 0.3738\n",
      "Epoch 185/200\n",
      "2553/2553 [==============================] - 0s 66us/sample - loss: 1.0994 - accuracy: 0.3514 - val_loss: 1.0908 - val_accuracy: 0.3738\n",
      "Epoch 186/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0938 - accuracy: 0.3388 - val_loss: 1.0906 - val_accuracy: 0.3738\n",
      "Epoch 187/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0940 - accuracy: 0.3451 - val_loss: 1.0904 - val_accuracy: 0.3738\n",
      "Epoch 188/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0995 - accuracy: 0.3435 - val_loss: 1.0902 - val_accuracy: 0.3738\n",
      "Epoch 189/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.0965 - accuracy: 0.3478 - val_loss: 1.0900 - val_accuracy: 0.3738\n",
      "Epoch 190/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.0918 - accuracy: 0.3580 - val_loss: 1.0898 - val_accuracy: 0.3738\n",
      "Epoch 191/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0918 - accuracy: 0.3490 - val_loss: 1.0896 - val_accuracy: 0.3738\n",
      "Epoch 192/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0894 - accuracy: 0.3361 - val_loss: 1.0894 - val_accuracy: 0.3738\n",
      "Epoch 193/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.0983 - accuracy: 0.3365 - val_loss: 1.0892 - val_accuracy: 0.3738\n",
      "Epoch 194/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.1010 - accuracy: 0.3306 - val_loss: 1.0890 - val_accuracy: 0.3738\n",
      "Epoch 195/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.0998 - accuracy: 0.3494 - val_loss: 1.0888 - val_accuracy: 0.3645\n",
      "Epoch 196/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.1031 - accuracy: 0.3361 - val_loss: 1.0886 - val_accuracy: 0.3645\n",
      "Epoch 197/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0996 - accuracy: 0.3404 - val_loss: 1.0884 - val_accuracy: 0.3645\n",
      "Epoch 198/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0956 - accuracy: 0.3455 - val_loss: 1.0882 - val_accuracy: 0.3645\n",
      "Epoch 199/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0919 - accuracy: 0.3549 - val_loss: 1.0880 - val_accuracy: 0.3738\n",
      "Epoch 200/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0925 - accuracy: 0.3517 - val_loss: 1.0878 - val_accuracy: 0.3832\n",
      "0.38317758 {'loss': 1.09254855484856, 'accuracy': 0.35174304, 'val_loss': 1.0877821701709356, 'val_accuracy': 0.38317758}\n",
      "Model: \"model_30\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_31 (InputLayer)        [(None, 29)]              0         \n",
      "_________________________________________________________________\n",
      "flatten_30 (Flatten)         (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_118 (Dense)            (None, 41)                1230      \n",
      "_________________________________________________________________\n",
      "dense_119 (Dense)            (None, 10)                420       \n",
      "_________________________________________________________________\n",
      "dense_120 (Dense)            (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_121 (Dense)            (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_122 (Dense)            (None, 3)                 33        \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 1,903\n",
      "Trainable params: 1,903\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2553 samples, validate on 107 samples\n",
      "Epoch 1/200\n",
      "2553/2553 [==============================] - 1s 427us/sample - loss: 1.7794 - accuracy: 0.2581 - val_loss: 1.4267 - val_accuracy: 0.2617\n",
      "Epoch 2/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.7676 - accuracy: 0.2781 - val_loss: 1.4205 - val_accuracy: 0.2617\n",
      "Epoch 3/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.7497 - accuracy: 0.2581 - val_loss: 1.4147 - val_accuracy: 0.2617\n",
      "Epoch 4/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.7754 - accuracy: 0.2601 - val_loss: 1.4087 - val_accuracy: 0.2617\n",
      "Epoch 5/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.7081 - accuracy: 0.2609 - val_loss: 1.4031 - val_accuracy: 0.2617\n",
      "Epoch 6/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.7231 - accuracy: 0.2679 - val_loss: 1.3973 - val_accuracy: 0.2617\n",
      "Epoch 7/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.7487 - accuracy: 0.2687 - val_loss: 1.3915 - val_accuracy: 0.2617\n",
      "Epoch 8/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.7232 - accuracy: 0.2628 - val_loss: 1.3861 - val_accuracy: 0.2617\n",
      "Epoch 9/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.6933 - accuracy: 0.2613 - val_loss: 1.3807 - val_accuracy: 0.2617\n",
      "Epoch 10/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.6362 - accuracy: 0.2714 - val_loss: 1.3758 - val_accuracy: 0.2617\n",
      "Epoch 11/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.7213 - accuracy: 0.2499 - val_loss: 1.3704 - val_accuracy: 0.2617\n",
      "Epoch 12/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.6132 - accuracy: 0.2660 - val_loss: 1.3658 - val_accuracy: 0.2617\n",
      "Epoch 13/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.6355 - accuracy: 0.2730 - val_loss: 1.3609 - val_accuracy: 0.2617\n",
      "Epoch 14/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.6624 - accuracy: 0.2695 - val_loss: 1.3560 - val_accuracy: 0.2617\n",
      "Epoch 15/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.6683 - accuracy: 0.2687 - val_loss: 1.3508 - val_accuracy: 0.2617\n",
      "Epoch 16/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.6315 - accuracy: 0.2644 - val_loss: 1.3463 - val_accuracy: 0.2617\n",
      "Epoch 17/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.6606 - accuracy: 0.2636 - val_loss: 1.3414 - val_accuracy: 0.2617\n",
      "Epoch 18/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.6148 - accuracy: 0.2585 - val_loss: 1.3370 - val_accuracy: 0.2617\n",
      "Epoch 19/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.5847 - accuracy: 0.2824 - val_loss: 1.3327 - val_accuracy: 0.2617\n",
      "Epoch 20/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.6340 - accuracy: 0.2546 - val_loss: 1.3284 - val_accuracy: 0.2617\n",
      "Epoch 21/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.6007 - accuracy: 0.2644 - val_loss: 1.3242 - val_accuracy: 0.2617\n",
      "Epoch 22/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.5875 - accuracy: 0.2671 - val_loss: 1.3201 - val_accuracy: 0.2617\n",
      "Epoch 23/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.5784 - accuracy: 0.2675 - val_loss: 1.3162 - val_accuracy: 0.2617\n",
      "Epoch 24/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.5765 - accuracy: 0.2703 - val_loss: 1.3123 - val_accuracy: 0.2617\n",
      "Epoch 25/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.5281 - accuracy: 0.2695 - val_loss: 1.3087 - val_accuracy: 0.2617\n",
      "Epoch 26/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.5903 - accuracy: 0.2722 - val_loss: 1.3045 - val_accuracy: 0.2617\n",
      "Epoch 27/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.5299 - accuracy: 0.2675 - val_loss: 1.3010 - val_accuracy: 0.2617\n",
      "Epoch 28/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.5637 - accuracy: 0.2601 - val_loss: 1.2973 - val_accuracy: 0.2617\n",
      "Epoch 29/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.5815 - accuracy: 0.2636 - val_loss: 1.2936 - val_accuracy: 0.2617\n",
      "Epoch 30/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.5318 - accuracy: 0.2628 - val_loss: 1.2903 - val_accuracy: 0.2617\n",
      "Epoch 31/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.5407 - accuracy: 0.2667 - val_loss: 1.2870 - val_accuracy: 0.2617\n",
      "Epoch 32/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.4989 - accuracy: 0.2664 - val_loss: 1.2838 - val_accuracy: 0.2617\n",
      "Epoch 33/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.5337 - accuracy: 0.2538 - val_loss: 1.2805 - val_accuracy: 0.2617\n",
      "Epoch 34/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.5361 - accuracy: 0.2593 - val_loss: 1.2771 - val_accuracy: 0.2617\n",
      "Epoch 35/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.5067 - accuracy: 0.2648 - val_loss: 1.2742 - val_accuracy: 0.2617\n",
      "Epoch 36/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.4491 - accuracy: 0.2691 - val_loss: 1.2715 - val_accuracy: 0.2617\n",
      "Epoch 37/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.4658 - accuracy: 0.2714 - val_loss: 1.2687 - val_accuracy: 0.2617\n",
      "Epoch 38/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.4514 - accuracy: 0.2773 - val_loss: 1.2660 - val_accuracy: 0.2617\n",
      "Epoch 39/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.4814 - accuracy: 0.2562 - val_loss: 1.2630 - val_accuracy: 0.2617\n",
      "Epoch 40/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.4589 - accuracy: 0.2734 - val_loss: 1.2603 - val_accuracy: 0.2617\n",
      "Epoch 41/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.4379 - accuracy: 0.2664 - val_loss: 1.2577 - val_accuracy: 0.2617\n",
      "Epoch 42/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.4440 - accuracy: 0.2683 - val_loss: 1.2551 - val_accuracy: 0.2617\n",
      "Epoch 43/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.4392 - accuracy: 0.2679 - val_loss: 1.2523 - val_accuracy: 0.2617\n",
      "Epoch 44/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.4184 - accuracy: 0.2714 - val_loss: 1.2498 - val_accuracy: 0.2617\n",
      "Epoch 45/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.3943 - accuracy: 0.2675 - val_loss: 1.2476 - val_accuracy: 0.2617\n",
      "Epoch 46/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.4201 - accuracy: 0.2605 - val_loss: 1.2452 - val_accuracy: 0.2617\n",
      "Epoch 47/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.3876 - accuracy: 0.2648 - val_loss: 1.2430 - val_accuracy: 0.2617\n",
      "Epoch 48/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.4126 - accuracy: 0.2742 - val_loss: 1.2406 - val_accuracy: 0.2617\n",
      "Epoch 49/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.4406 - accuracy: 0.2601 - val_loss: 1.2381 - val_accuracy: 0.2617\n",
      "Epoch 50/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.4200 - accuracy: 0.2699 - val_loss: 1.2358 - val_accuracy: 0.2617\n",
      "Epoch 51/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.3816 - accuracy: 0.2695 - val_loss: 1.2337 - val_accuracy: 0.2617\n",
      "Epoch 52/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.3930 - accuracy: 0.2620 - val_loss: 1.2316 - val_accuracy: 0.2617\n",
      "Epoch 53/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.3782 - accuracy: 0.2679 - val_loss: 1.2296 - val_accuracy: 0.2617\n",
      "Epoch 54/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.3763 - accuracy: 0.2679 - val_loss: 1.2276 - val_accuracy: 0.2617\n",
      "Epoch 55/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.3875 - accuracy: 0.2550 - val_loss: 1.2257 - val_accuracy: 0.2617\n",
      "Epoch 56/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.3566 - accuracy: 0.2773 - val_loss: 1.2239 - val_accuracy: 0.2617\n",
      "Epoch 57/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.3724 - accuracy: 0.2577 - val_loss: 1.2221 - val_accuracy: 0.2617\n",
      "Epoch 58/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.3691 - accuracy: 0.2605 - val_loss: 1.2203 - val_accuracy: 0.2617\n",
      "Epoch 59/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.3679 - accuracy: 0.2632 - val_loss: 1.2185 - val_accuracy: 0.2617\n",
      "Epoch 60/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.3679 - accuracy: 0.2589 - val_loss: 1.2167 - val_accuracy: 0.2617\n",
      "Epoch 61/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.3656 - accuracy: 0.2620 - val_loss: 1.2150 - val_accuracy: 0.2617\n",
      "Epoch 62/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.3311 - accuracy: 0.2632 - val_loss: 1.2134 - val_accuracy: 0.2523\n",
      "Epoch 63/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.3412 - accuracy: 0.2703 - val_loss: 1.2117 - val_accuracy: 0.2523\n",
      "Epoch 64/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.3133 - accuracy: 0.2899 - val_loss: 1.2101 - val_accuracy: 0.2523\n",
      "Epoch 65/200\n",
      "2553/2553 [==============================] - 0s 121us/sample - loss: 1.3293 - accuracy: 0.2593 - val_loss: 1.2086 - val_accuracy: 0.2523\n",
      "Epoch 66/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.3447 - accuracy: 0.2577 - val_loss: 1.2070 - val_accuracy: 0.2523\n",
      "Epoch 67/200\n",
      "2553/2553 [==============================] - 0s 118us/sample - loss: 1.3243 - accuracy: 0.2620 - val_loss: 1.2054 - val_accuracy: 0.2523\n",
      "Epoch 68/200\n",
      "2553/2553 [==============================] - 0s 149us/sample - loss: 1.3414 - accuracy: 0.2718 - val_loss: 1.2037 - val_accuracy: 0.2523\n",
      "Epoch 69/200\n",
      "2553/2553 [==============================] - 0s 170us/sample - loss: 1.3062 - accuracy: 0.2664 - val_loss: 1.2022 - val_accuracy: 0.2523\n",
      "Epoch 70/200\n",
      "2553/2553 [==============================] - 0s 137us/sample - loss: 1.3144 - accuracy: 0.2620 - val_loss: 1.2007 - val_accuracy: 0.2523\n",
      "Epoch 71/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.2957 - accuracy: 0.2652 - val_loss: 1.1993 - val_accuracy: 0.2523\n",
      "Epoch 72/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.2947 - accuracy: 0.2773 - val_loss: 1.1979 - val_accuracy: 0.2523\n",
      "Epoch 73/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.2981 - accuracy: 0.2617 - val_loss: 1.1963 - val_accuracy: 0.2430\n",
      "Epoch 74/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.2907 - accuracy: 0.2699 - val_loss: 1.1949 - val_accuracy: 0.2430\n",
      "Epoch 75/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.2977 - accuracy: 0.2675 - val_loss: 1.1935 - val_accuracy: 0.2430\n",
      "Epoch 76/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.3041 - accuracy: 0.2542 - val_loss: 1.1921 - val_accuracy: 0.2336\n",
      "Epoch 77/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.2909 - accuracy: 0.2754 - val_loss: 1.1907 - val_accuracy: 0.2336\n",
      "Epoch 78/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.2929 - accuracy: 0.2687 - val_loss: 1.1894 - val_accuracy: 0.2336\n",
      "Epoch 79/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.2830 - accuracy: 0.2667 - val_loss: 1.1882 - val_accuracy: 0.2336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/200\n",
      "2553/2553 [==============================] - 0s 116us/sample - loss: 1.2879 - accuracy: 0.2526 - val_loss: 1.1870 - val_accuracy: 0.2336\n",
      "Epoch 81/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.2777 - accuracy: 0.2566 - val_loss: 1.1859 - val_accuracy: 0.2336\n",
      "Epoch 82/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.2820 - accuracy: 0.2683 - val_loss: 1.1846 - val_accuracy: 0.2336\n",
      "Epoch 83/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.2877 - accuracy: 0.2644 - val_loss: 1.1834 - val_accuracy: 0.2336\n",
      "Epoch 84/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.2612 - accuracy: 0.2644 - val_loss: 1.1823 - val_accuracy: 0.2336\n",
      "Epoch 85/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.2856 - accuracy: 0.2652 - val_loss: 1.1812 - val_accuracy: 0.2336\n",
      "Epoch 86/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.2580 - accuracy: 0.2671 - val_loss: 1.1801 - val_accuracy: 0.2336\n",
      "Epoch 87/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.2688 - accuracy: 0.2675 - val_loss: 1.1790 - val_accuracy: 0.2336\n",
      "Epoch 88/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.2556 - accuracy: 0.2656 - val_loss: 1.1780 - val_accuracy: 0.2336\n",
      "Epoch 89/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.2369 - accuracy: 0.2777 - val_loss: 1.1771 - val_accuracy: 0.2336\n",
      "Epoch 90/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.2479 - accuracy: 0.2730 - val_loss: 1.1761 - val_accuracy: 0.2336\n",
      "Epoch 91/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.2700 - accuracy: 0.2620 - val_loss: 1.1751 - val_accuracy: 0.2336\n",
      "Epoch 92/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.2386 - accuracy: 0.2664 - val_loss: 1.1741 - val_accuracy: 0.2336\n",
      "Epoch 93/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.2398 - accuracy: 0.2664 - val_loss: 1.1732 - val_accuracy: 0.2336\n",
      "Epoch 94/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.2430 - accuracy: 0.2636 - val_loss: 1.1722 - val_accuracy: 0.2336\n",
      "Epoch 95/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.2462 - accuracy: 0.2683 - val_loss: 1.1713 - val_accuracy: 0.2336\n",
      "Epoch 96/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.2339 - accuracy: 0.2664 - val_loss: 1.1704 - val_accuracy: 0.2336\n",
      "Epoch 97/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.2424 - accuracy: 0.2609 - val_loss: 1.1695 - val_accuracy: 0.2336\n",
      "Epoch 98/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.2255 - accuracy: 0.2703 - val_loss: 1.1686 - val_accuracy: 0.2336\n",
      "Epoch 99/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.2377 - accuracy: 0.2613 - val_loss: 1.1676 - val_accuracy: 0.2243\n",
      "Epoch 100/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.2356 - accuracy: 0.2773 - val_loss: 1.1668 - val_accuracy: 0.2243\n",
      "Epoch 101/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.2297 - accuracy: 0.2711 - val_loss: 1.1659 - val_accuracy: 0.2243\n",
      "Epoch 102/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.2407 - accuracy: 0.2617 - val_loss: 1.1651 - val_accuracy: 0.2243\n",
      "Epoch 103/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.2236 - accuracy: 0.2675 - val_loss: 1.1643 - val_accuracy: 0.2243\n",
      "Epoch 104/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.2229 - accuracy: 0.2648 - val_loss: 1.1635 - val_accuracy: 0.2243\n",
      "Epoch 105/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.2215 - accuracy: 0.2573 - val_loss: 1.1627 - val_accuracy: 0.2243\n",
      "Epoch 106/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.2211 - accuracy: 0.2675 - val_loss: 1.1620 - val_accuracy: 0.2243\n",
      "Epoch 107/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.2360 - accuracy: 0.2620 - val_loss: 1.1612 - val_accuracy: 0.2243\n",
      "Epoch 108/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.2303 - accuracy: 0.2687 - val_loss: 1.1605 - val_accuracy: 0.2243\n",
      "Epoch 109/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.2186 - accuracy: 0.2660 - val_loss: 1.1598 - val_accuracy: 0.2243\n",
      "Epoch 110/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.2142 - accuracy: 0.2679 - val_loss: 1.1591 - val_accuracy: 0.2243\n",
      "Epoch 111/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.2231 - accuracy: 0.2577 - val_loss: 1.1583 - val_accuracy: 0.2243\n",
      "Epoch 112/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.2043 - accuracy: 0.2675 - val_loss: 1.1576 - val_accuracy: 0.2243\n",
      "Epoch 113/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.2221 - accuracy: 0.2597 - val_loss: 1.1569 - val_accuracy: 0.2243\n",
      "Epoch 114/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.2026 - accuracy: 0.2687 - val_loss: 1.1563 - val_accuracy: 0.2243\n",
      "Epoch 115/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.1967 - accuracy: 0.2730 - val_loss: 1.1558 - val_accuracy: 0.2150\n",
      "Epoch 116/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.2100 - accuracy: 0.2609 - val_loss: 1.1552 - val_accuracy: 0.2150\n",
      "Epoch 117/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.1971 - accuracy: 0.2738 - val_loss: 1.1547 - val_accuracy: 0.2150\n",
      "Epoch 118/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.1971 - accuracy: 0.2675 - val_loss: 1.1542 - val_accuracy: 0.2150\n",
      "Epoch 119/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.2060 - accuracy: 0.2789 - val_loss: 1.1536 - val_accuracy: 0.2150\n",
      "Epoch 120/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.2027 - accuracy: 0.2730 - val_loss: 1.1531 - val_accuracy: 0.2243\n",
      "Epoch 121/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.1943 - accuracy: 0.2683 - val_loss: 1.1525 - val_accuracy: 0.2243\n",
      "Epoch 122/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.1942 - accuracy: 0.2660 - val_loss: 1.1520 - val_accuracy: 0.2243\n",
      "Epoch 123/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.1911 - accuracy: 0.2742 - val_loss: 1.1515 - val_accuracy: 0.2243\n",
      "Epoch 124/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.1955 - accuracy: 0.2640 - val_loss: 1.1510 - val_accuracy: 0.2243\n",
      "Epoch 125/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.1853 - accuracy: 0.2754 - val_loss: 1.1505 - val_accuracy: 0.2243\n",
      "Epoch 126/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.1872 - accuracy: 0.2758 - val_loss: 1.1501 - val_accuracy: 0.2243\n",
      "Epoch 127/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.1839 - accuracy: 0.2769 - val_loss: 1.1496 - val_accuracy: 0.2243\n",
      "Epoch 128/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.1931 - accuracy: 0.2656 - val_loss: 1.1492 - val_accuracy: 0.2243\n",
      "Epoch 129/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.1778 - accuracy: 0.2781 - val_loss: 1.1488 - val_accuracy: 0.2243\n",
      "Epoch 130/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.1939 - accuracy: 0.2609 - val_loss: 1.1483 - val_accuracy: 0.2243\n",
      "Epoch 131/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.1879 - accuracy: 0.2640 - val_loss: 1.1479 - val_accuracy: 0.2243\n",
      "Epoch 132/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.1849 - accuracy: 0.2687 - val_loss: 1.1475 - val_accuracy: 0.2243\n",
      "Epoch 133/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.1745 - accuracy: 0.2793 - val_loss: 1.1471 - val_accuracy: 0.2243\n",
      "Epoch 134/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.1787 - accuracy: 0.2667 - val_loss: 1.1467 - val_accuracy: 0.2243\n",
      "Epoch 135/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.1756 - accuracy: 0.2675 - val_loss: 1.1463 - val_accuracy: 0.2243\n",
      "Epoch 136/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.1805 - accuracy: 0.2671 - val_loss: 1.1460 - val_accuracy: 0.2243\n",
      "Epoch 137/200\n",
      "2553/2553 [==============================] - 0s 100us/sample - loss: 1.1728 - accuracy: 0.2750 - val_loss: 1.1456 - val_accuracy: 0.2243\n",
      "Epoch 138/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.1849 - accuracy: 0.2671 - val_loss: 1.1452 - val_accuracy: 0.2243\n",
      "Epoch 139/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.1757 - accuracy: 0.2581 - val_loss: 1.1449 - val_accuracy: 0.2243\n",
      "Epoch 140/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.1768 - accuracy: 0.2636 - val_loss: 1.1445 - val_accuracy: 0.2243\n",
      "Epoch 141/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.1713 - accuracy: 0.2640 - val_loss: 1.1442 - val_accuracy: 0.2243\n",
      "Epoch 142/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.1716 - accuracy: 0.2714 - val_loss: 1.1439 - val_accuracy: 0.2336\n",
      "Epoch 143/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.1744 - accuracy: 0.2726 - val_loss: 1.1436 - val_accuracy: 0.2336\n",
      "Epoch 144/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.1743 - accuracy: 0.2726 - val_loss: 1.1433 - val_accuracy: 0.2336\n",
      "Epoch 145/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.1647 - accuracy: 0.2593 - val_loss: 1.1430 - val_accuracy: 0.2336\n",
      "Epoch 146/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.1717 - accuracy: 0.2617 - val_loss: 1.1427 - val_accuracy: 0.2336\n",
      "Epoch 147/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.1694 - accuracy: 0.2664 - val_loss: 1.1424 - val_accuracy: 0.2336\n",
      "Epoch 148/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.1694 - accuracy: 0.2699 - val_loss: 1.1422 - val_accuracy: 0.2336\n",
      "Epoch 149/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.1702 - accuracy: 0.2675 - val_loss: 1.1419 - val_accuracy: 0.2336\n",
      "Epoch 150/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.1583 - accuracy: 0.2816 - val_loss: 1.1416 - val_accuracy: 0.2336\n",
      "Epoch 151/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.1651 - accuracy: 0.2730 - val_loss: 1.1413 - val_accuracy: 0.2336\n",
      "Epoch 152/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.1715 - accuracy: 0.2617 - val_loss: 1.1410 - val_accuracy: 0.2336\n",
      "Epoch 153/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.1633 - accuracy: 0.2730 - val_loss: 1.1407 - val_accuracy: 0.2336\n",
      "Epoch 154/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.1646 - accuracy: 0.2703 - val_loss: 1.1404 - val_accuracy: 0.2336\n",
      "Epoch 155/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.1710 - accuracy: 0.2656 - val_loss: 1.1401 - val_accuracy: 0.2430\n",
      "Epoch 156/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.1586 - accuracy: 0.2785 - val_loss: 1.1398 - val_accuracy: 0.2430\n",
      "Epoch 157/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.1643 - accuracy: 0.2570 - val_loss: 1.1396 - val_accuracy: 0.2430\n",
      "Epoch 158/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.1546 - accuracy: 0.2667 - val_loss: 1.1393 - val_accuracy: 0.2430\n",
      "Epoch 159/200\n",
      "2553/2553 [==============================] - 0s 115us/sample - loss: 1.1617 - accuracy: 0.2636 - val_loss: 1.1390 - val_accuracy: 0.2430\n",
      "Epoch 160/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.1631 - accuracy: 0.2660 - val_loss: 1.1387 - val_accuracy: 0.2430\n",
      "Epoch 161/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.1526 - accuracy: 0.2808 - val_loss: 1.1385 - val_accuracy: 0.2430\n",
      "Epoch 162/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.1657 - accuracy: 0.2620 - val_loss: 1.1382 - val_accuracy: 0.2430\n",
      "Epoch 163/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.1538 - accuracy: 0.2738 - val_loss: 1.1379 - val_accuracy: 0.2430\n",
      "Epoch 164/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.1526 - accuracy: 0.2777 - val_loss: 1.1376 - val_accuracy: 0.2430\n",
      "Epoch 165/200\n",
      "2553/2553 [==============================] - 0s 101us/sample - loss: 1.1519 - accuracy: 0.2781 - val_loss: 1.1373 - val_accuracy: 0.2430\n",
      "Epoch 166/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.1565 - accuracy: 0.2777 - val_loss: 1.1370 - val_accuracy: 0.2430\n",
      "Epoch 167/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.1574 - accuracy: 0.2699 - val_loss: 1.1367 - val_accuracy: 0.2430\n",
      "Epoch 168/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.1621 - accuracy: 0.2624 - val_loss: 1.1364 - val_accuracy: 0.2430\n",
      "Epoch 169/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.1609 - accuracy: 0.2695 - val_loss: 1.1361 - val_accuracy: 0.2430\n",
      "Epoch 170/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.1613 - accuracy: 0.2812 - val_loss: 1.1358 - val_accuracy: 0.2430\n",
      "Epoch 171/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.1569 - accuracy: 0.2695 - val_loss: 1.1355 - val_accuracy: 0.2430\n",
      "Epoch 172/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.1546 - accuracy: 0.2675 - val_loss: 1.1353 - val_accuracy: 0.2617\n",
      "Epoch 173/200\n",
      "2553/2553 [==============================] - 0s 96us/sample - loss: 1.1546 - accuracy: 0.2679 - val_loss: 1.1350 - val_accuracy: 0.2617\n",
      "Epoch 174/200\n",
      "2553/2553 [==============================] - 0s 122us/sample - loss: 1.1492 - accuracy: 0.2777 - val_loss: 1.1348 - val_accuracy: 0.2523\n",
      "Epoch 175/200\n",
      "2553/2553 [==============================] - 0s 108us/sample - loss: 1.1481 - accuracy: 0.2750 - val_loss: 1.1346 - val_accuracy: 0.2523\n",
      "Epoch 176/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.1527 - accuracy: 0.2628 - val_loss: 1.1343 - val_accuracy: 0.2523\n",
      "Epoch 177/200\n",
      "2553/2553 [==============================] - 0s 102us/sample - loss: 1.1517 - accuracy: 0.2640 - val_loss: 1.1341 - val_accuracy: 0.2523\n",
      "Epoch 178/200\n",
      "2553/2553 [==============================] - 0s 110us/sample - loss: 1.1503 - accuracy: 0.2805 - val_loss: 1.1338 - val_accuracy: 0.2430\n",
      "Epoch 179/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.1538 - accuracy: 0.2613 - val_loss: 1.1335 - val_accuracy: 0.2430\n",
      "Epoch 180/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.1474 - accuracy: 0.2761 - val_loss: 1.1333 - val_accuracy: 0.2430\n",
      "Epoch 181/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.1456 - accuracy: 0.2624 - val_loss: 1.1330 - val_accuracy: 0.2430\n",
      "Epoch 182/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.1467 - accuracy: 0.2628 - val_loss: 1.1328 - val_accuracy: 0.2430\n",
      "Epoch 183/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.1494 - accuracy: 0.2714 - val_loss: 1.1325 - val_accuracy: 0.2430\n",
      "Epoch 184/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.1485 - accuracy: 0.2613 - val_loss: 1.1323 - val_accuracy: 0.2430\n",
      "Epoch 185/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.1426 - accuracy: 0.2675 - val_loss: 1.1320 - val_accuracy: 0.2430\n",
      "Epoch 186/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.1460 - accuracy: 0.2714 - val_loss: 1.1318 - val_accuracy: 0.2430\n",
      "Epoch 187/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.1413 - accuracy: 0.2765 - val_loss: 1.1316 - val_accuracy: 0.2430\n",
      "Epoch 188/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.1475 - accuracy: 0.2703 - val_loss: 1.1313 - val_accuracy: 0.2430\n",
      "Epoch 189/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.1478 - accuracy: 0.2620 - val_loss: 1.1311 - val_accuracy: 0.2430\n",
      "Epoch 190/200\n",
      "2553/2553 [==============================] - 0s 107us/sample - loss: 1.1435 - accuracy: 0.2793 - val_loss: 1.1308 - val_accuracy: 0.2430\n",
      "Epoch 191/200\n",
      "2553/2553 [==============================] - 0s 106us/sample - loss: 1.1415 - accuracy: 0.2761 - val_loss: 1.1306 - val_accuracy: 0.2430\n",
      "Epoch 192/200\n",
      "2553/2553 [==============================] - 0s 103us/sample - loss: 1.1423 - accuracy: 0.2683 - val_loss: 1.1304 - val_accuracy: 0.2430\n",
      "Epoch 193/200\n",
      "2553/2553 [==============================] - 0s 105us/sample - loss: 1.1377 - accuracy: 0.2769 - val_loss: 1.1302 - val_accuracy: 0.2430\n",
      "Epoch 194/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.1420 - accuracy: 0.2675 - val_loss: 1.1299 - val_accuracy: 0.2430\n",
      "Epoch 195/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.1374 - accuracy: 0.2691 - val_loss: 1.1297 - val_accuracy: 0.2430\n",
      "Epoch 196/200\n",
      "2553/2553 [==============================] - 0s 104us/sample - loss: 1.1467 - accuracy: 0.2632 - val_loss: 1.1295 - val_accuracy: 0.2430\n",
      "Epoch 197/200\n",
      "2553/2553 [==============================] - 0s 113us/sample - loss: 1.1408 - accuracy: 0.2711 - val_loss: 1.1293 - val_accuracy: 0.2430\n",
      "Epoch 198/200\n",
      "2553/2553 [==============================] - 0s 112us/sample - loss: 1.1347 - accuracy: 0.2777 - val_loss: 1.1290 - val_accuracy: 0.2430\n",
      "Epoch 199/200\n",
      "2553/2553 [==============================] - 0s 111us/sample - loss: 1.1436 - accuracy: 0.2597 - val_loss: 1.1288 - val_accuracy: 0.2430\n",
      "Epoch 200/200\n",
      "2553/2553 [==============================] - 0s 109us/sample - loss: 1.1404 - accuracy: 0.2656 - val_loss: 1.1287 - val_accuracy: 0.2430\n",
      "0.24299066 {'loss': 1.1403840674730175, 'accuracy': 0.26556993, 'val_loss': 1.128655074912811, 'val_accuracy': 0.24299066}\n",
      "Model: \"model_31\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_32 (InputLayer)        [(None, 29)]              0         \n",
      "_________________________________________________________________\n",
      "flatten_31 (Flatten)         (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_123 (Dense)            (None, 41)                1230      \n",
      "_________________________________________________________________\n",
      "dense_124 (Dense)            (None, 10)                420       \n",
      "_________________________________________________________________\n",
      "dense_125 (Dense)            (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_126 (Dense)            (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_127 (Dense)            (None, 3)                 33        \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 1,903\n",
      "Trainable params: 1,903\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2553 samples, validate on 107 samples\n",
      "Epoch 1/200\n",
      "2553/2553 [==============================] - 1s 302us/sample - loss: 1.0986 - accuracy: 0.2793 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 2/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0986 - accuracy: 0.2801 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 3/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0986 - accuracy: 0.2793 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 4/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 5/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 6/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 7/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 8/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0986 - accuracy: 0.2793 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 9/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0986 - accuracy: 0.2801 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 10/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 11/200\n",
      "2553/2553 [==============================] - 0s 69us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 12/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0986 - accuracy: 0.2793 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 13/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 14/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0986 - accuracy: 0.2801 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 15/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 16/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 17/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0986 - accuracy: 0.2801 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 18/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0986 - accuracy: 0.2801 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 19/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 20/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 21/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 22/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 23/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 24/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0986 - accuracy: 0.2801 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 25/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 26/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0986 - accuracy: 0.2801 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 27/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 28/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 29/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0986 - accuracy: 0.2801 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 30/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0986 - accuracy: 0.2793 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 31/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 32/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0986 - accuracy: 0.2793 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 33/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0986 - accuracy: 0.2801 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 34/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0986 - accuracy: 0.2801 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 35/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0986 - accuracy: 0.2801 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 36/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0986 - accuracy: 0.2793 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 37/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 38/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 39/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0986 - accuracy: 0.2801 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 40/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 41/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0986 - accuracy: 0.2801 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 42/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 43/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 44/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 45/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 46/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0986 - accuracy: 0.2793 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 47/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0986 - accuracy: 0.2793 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 48/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 49/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 50/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 51/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 52/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0986 - accuracy: 0.2801 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 53/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 54/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 55/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0986 - accuracy: 0.2793 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 56/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0986 - accuracy: 0.2801 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 57/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 58/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 59/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 60/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0986 - accuracy: 0.2793 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 61/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 62/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 63/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0986 - accuracy: 0.2793 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 64/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0986 - accuracy: 0.2801 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 65/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 66/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0986 - accuracy: 0.2801 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 67/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 68/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 69/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 70/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 71/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 72/200\n",
      "2553/2553 [==============================] - ETA: 0s - loss: 1.0986 - accuracy: 0.27 - 0s 56us/sample - loss: 1.0986 - accuracy: 0.2793 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 73/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 74/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.0986 - accuracy: 0.2801 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 75/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0986 - accuracy: 0.2793 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 76/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 77/200\n",
      "2553/2553 [==============================] - 0s 64us/sample - loss: 1.0986 - accuracy: 0.2801 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 78/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 79/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 80/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0986 - accuracy: 0.2793 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 81/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0986 - accuracy: 0.2801 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 82/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0986 - accuracy: 0.2801 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 83/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 84/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 85/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0986 - accuracy: 0.2801 - val_loss: 1.0986 - val_accuracy: 0.2243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 87/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 88/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.0986 - accuracy: 0.2801 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 89/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 90/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 91/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 92/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0986 - accuracy: 0.2801 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 93/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0986 - accuracy: 0.2793 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 94/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 95/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 96/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0986 - accuracy: 0.2793 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 97/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 98/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0986 - accuracy: 0.2793 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 99/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 100/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 101/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 102/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 103/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0986 - accuracy: 0.2801 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 104/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0986 - accuracy: 0.2801 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 105/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0986 - accuracy: 0.2793 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 106/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0986 - accuracy: 0.2801 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 107/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0986 - accuracy: 0.2801 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 108/200\n",
      "2553/2553 [==============================] - 0s 62us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 109/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0986 - accuracy: 0.2801 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 110/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 111/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 112/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0986 - accuracy: 0.2801 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 113/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 114/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 115/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0986 - accuracy: 0.2801 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 116/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 117/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 118/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 119/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 120/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0986 - accuracy: 0.2801 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 121/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 122/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.0986 - accuracy: 0.2801 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 123/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 124/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 125/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0986 - accuracy: 0.2801 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 126/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 127/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 128/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0986 - accuracy: 0.2793 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 129/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0986 - accuracy: 0.2793 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 130/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 131/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 132/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0986 - accuracy: 0.2793 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 133/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0986 - accuracy: 0.2793 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 134/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0986 - accuracy: 0.2793 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 135/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0986 - accuracy: 0.2801 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 136/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0986 - accuracy: 0.2793 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 137/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 138/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0986 - accuracy: 0.2793 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 139/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 140/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 141/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 142/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 143/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 144/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0986 - accuracy: 0.2801 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 145/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 146/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 147/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0986 - accuracy: 0.2793 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 148/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 149/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 150/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 151/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 152/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0985 - accuracy: 0.2801 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 153/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0985 - accuracy: 0.2801 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 154/200\n",
      "2553/2553 [==============================] - 0s 50us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 155/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0985 - accuracy: 0.2801 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 156/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 157/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 158/200\n",
      "2553/2553 [==============================] - 0s 68us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 159/200\n",
      "2553/2553 [==============================] - 0s 86us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 160/200\n",
      "2553/2553 [==============================] - 0s 89us/sample - loss: 1.0986 - accuracy: 0.2793 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 161/200\n",
      "2553/2553 [==============================] - 0s 84us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 162/200\n",
      "2553/2553 [==============================] - 0s 84us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 163/200\n",
      "2553/2553 [==============================] - 0s 81us/sample - loss: 1.0985 - accuracy: 0.2801 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 164/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0985 - accuracy: 0.2801 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 165/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 166/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 167/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 168/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 169/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 170/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 171/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 172/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0985 - accuracy: 0.2801 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 173/200\n",
      "2553/2553 [==============================] - 0s 56us/sample - loss: 1.0986 - accuracy: 0.2793 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 174/200\n",
      "2553/2553 [==============================] - 0s 65us/sample - loss: 1.0985 - accuracy: 0.2801 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 175/200\n",
      "2553/2553 [==============================] - 0s 58us/sample - loss: 1.0986 - accuracy: 0.2793 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 176/200\n",
      "2553/2553 [==============================] - 0s 60us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 177/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 178/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.0985 - accuracy: 0.2801 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 179/200\n",
      "2553/2553 [==============================] - 0s 68us/sample - loss: 1.0986 - accuracy: 0.2793 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 180/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0986 - accuracy: 0.2793 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 181/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 182/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 183/200\n",
      "2553/2553 [==============================] - 0s 55us/sample - loss: 1.0986 - accuracy: 0.2793 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 184/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.0985 - accuracy: 0.2801 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 185/200\n",
      "2553/2553 [==============================] - 0s 63us/sample - loss: 1.0986 - accuracy: 0.2793 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 186/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0986 - accuracy: 0.2793 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 187/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 188/200\n",
      "2553/2553 [==============================] - 0s 53us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 189/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 190/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 191/200\n",
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0985 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 192/200\n",
      "2553/2553 [==============================] - 0s 61us/sample - loss: 1.0986 - accuracy: 0.2793 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 193/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 194/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0986 - accuracy: 0.2793 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 195/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2553 [==============================] - 0s 54us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 196/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 197/200\n",
      "2553/2553 [==============================] - 0s 52us/sample - loss: 1.0985 - accuracy: 0.2801 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 198/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0986 - accuracy: 0.2793 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 199/200\n",
      "2553/2553 [==============================] - 0s 59us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "Epoch 200/200\n",
      "2553/2553 [==============================] - 0s 57us/sample - loss: 1.0986 - accuracy: 0.2797 - val_loss: 1.0986 - val_accuracy: 0.2243\n",
      "0.22429906 {'loss': 1.0986123085021973, 'accuracy': 0.27967098, 'val_loss': 1.0986123085021973, 'val_accuracy': 0.22429906}\n"
     ]
    }
   ],
   "source": [
    "#hyperparam tuning\n",
    "#learning_rate\n",
    "# learning_rates = [1e-5,1e-6,1e-7]\n",
    "learning_rates = [1e-5,1e-6]\n",
    "#hidden_layers\n",
    "# hidden_layers = [[41,75],[41,10],[41,10,10,10]]\n",
    "hidden_layers = [[41,75,3],[41,10,10,10,3]]\n",
    "#dropout\n",
    "dropouts = [0,.3,.5,.7]\n",
    "# dropouts = [.3,.5]\n",
    "#batch_size\n",
    "# batch_sizes = [8,16,32,64]\n",
    "batch_sizes = [16,32]\n",
    "#result\n",
    "result = {}\n",
    "best_history = None\n",
    "best_val_accuracy = 0\n",
    "best_model = None\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for hl in hidden_layers:\n",
    "        hl_str = '-'.join(map(str, hl))+'-3'\n",
    "        for dp in dropouts:\n",
    "            for bs in batch_sizes:\n",
    "                history, model = fit_model(lr, hl, dp, bs)\n",
    "                tmp = {}\n",
    "                tmp['loss'] = history.history['loss'][-1]\n",
    "                tmp['accuracy'] = history.history['accuracy'][-1]\n",
    "                tmp['val_loss'] = history.history['val_loss'][-1]\n",
    "                tmp['val_accuracy'] = history.history['val_accuracy'][-1]\n",
    "    #             print(history)\n",
    "                result[(lr,hl_str,dp, bs)] = tmp\n",
    "                print(tmp['val_accuracy'], tmp)\n",
    "                if tmp['val_accuracy'] > best_val_accuracy:\n",
    "                    best_val_accuracy = tmp['val_accuracy']\n",
    "                    best_history = history\n",
    "                    best_model = model\n",
    "                \n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2020-06-15_21-32-07_hyper_param_result.npy'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "timestamp = datetime.now()\n",
    "timestamp = timestamp.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "timestamp + '_hyper_param_result.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(1e-05, '41-75-3-3', 0, 16): {'loss': 0.9352710839117269,\n",
       "  'accuracy': 0.5597336,\n",
       "  'val_loss': 0.925082886887488,\n",
       "  'val_accuracy': 0.5607477},\n",
       " (1e-05, '41-75-3-3', 0, 32): {'loss': 0.9712734546000192,\n",
       "  'accuracy': 0.53349,\n",
       "  'val_loss': 0.9545081820443412,\n",
       "  'val_accuracy': 0.55140185},\n",
       " (1e-05, '41-75-3-3', 0.3, 16): {'loss': 1.0837724909238893,\n",
       "  'accuracy': 0.28437132,\n",
       "  'val_loss': 1.090225048154314,\n",
       "  'val_accuracy': 0.25233644},\n",
       " (1e-05, '41-75-3-3', 0.3, 32): {'loss': 1.0835074190060578,\n",
       "  'accuracy': 0.28045437,\n",
       "  'val_loss': 1.087467913315675,\n",
       "  'val_accuracy': 0.22429906},\n",
       " (1e-05, '41-75-3-3', 0.5, 16): {'loss': 1.031739786961851,\n",
       "  'accuracy': 0.4061888,\n",
       "  'val_loss': 0.9787415722820246,\n",
       "  'val_accuracy': 0.53271025},\n",
       " (1e-05, '41-75-3-3', 0.5, 32): {'loss': 1.0221766046202048,\n",
       "  'accuracy': 0.40423033,\n",
       "  'val_loss': 0.988469571710747,\n",
       "  'val_accuracy': 0.5140187},\n",
       " (1e-05, '41-75-3-3', 0.7, 16): {'loss': 1.056134997210781,\n",
       "  'accuracy': 0.3564434,\n",
       "  'val_loss': 1.0321482910174076,\n",
       "  'val_accuracy': 0.44859812},\n",
       " (1e-05, '41-75-3-3', 0.7, 32): {'loss': 1.0657294067363388,\n",
       "  'accuracy': 0.34351742,\n",
       "  'val_loss': 1.044191596664001,\n",
       "  'val_accuracy': 0.43925235},\n",
       " (1e-05, '41-10-10-10-3-3', 0, 16): {'loss': 0.9659754360044325,\n",
       "  'accuracy': 0.5327066,\n",
       "  'val_loss': 0.9732264341595017,\n",
       "  'val_accuracy': 0.5140187},\n",
       " (1e-05, '41-10-10-10-3-3', 0, 32): {'loss': 0.9598539168583473,\n",
       "  'accuracy': 0.5432824,\n",
       "  'val_loss': 0.9623381812995839,\n",
       "  'val_accuracy': 0.53271025},\n",
       " (1e-05, '41-10-10-10-3-3', 0.3, 16): {'loss': 1.009417046251084,\n",
       "  'accuracy': 0.46886018,\n",
       "  'val_loss': 0.9780730649689647,\n",
       "  'val_accuracy': 0.5420561},\n",
       " (1e-05, '41-10-10-10-3-3', 0.3, 32): {'loss': 1.0180113154021704,\n",
       "  'accuracy': 0.45240894,\n",
       "  'val_loss': 0.9962128267109951,\n",
       "  'val_accuracy': 0.55140185},\n",
       " (1e-05, '41-10-10-10-3-3', 0.5, 16): {'loss': 1.0347311054310797,\n",
       "  'accuracy': 0.40383863,\n",
       "  'val_loss': 0.9946716951432629,\n",
       "  'val_accuracy': 0.5046729},\n",
       " (1e-05, '41-10-10-10-3-3', 0.5, 32): {'loss': 1.0959690783101346,\n",
       "  'accuracy': 0.30043086,\n",
       "  'val_loss': 1.0930207132179046,\n",
       "  'val_accuracy': 0.3364486},\n",
       " (1e-05, '41-10-10-10-3-3', 0.7, 16): {'loss': 1.0555994956109556,\n",
       "  'accuracy': 0.3638856,\n",
       "  'val_loss': 1.0387764032756057,\n",
       "  'val_accuracy': 0.49532712},\n",
       " (1e-05, '41-10-10-10-3-3', 0.7, 32): {'loss': 1.0600600109537395,\n",
       "  'accuracy': 0.36114374,\n",
       "  'val_loss': 1.033629916538702,\n",
       "  'val_accuracy': 0.53271025},\n",
       " (1e-06, '41-75-3-3', 0, 16): {'loss': 0.9830159241435017,\n",
       "  'accuracy': 0.51821387,\n",
       "  'val_loss': 1.000368595123291,\n",
       "  'val_accuracy': 0.5046729},\n",
       " (1e-06, '41-75-3-3', 0, 32): {'loss': 0.994055931679277,\n",
       "  'accuracy': 0.5135135,\n",
       "  'val_loss': 0.9985859082123943,\n",
       "  'val_accuracy': 0.48598132},\n",
       " (1e-06, '41-75-3-3', 0.3, 16): {'loss': 1.0100229045619136,\n",
       "  'accuracy': 0.4457501,\n",
       "  'val_loss': 0.9908906811865691,\n",
       "  'val_accuracy': 0.45794392},\n",
       " (1e-06, '41-75-3-3', 0.3, 32): {'loss': 1.0288538395821512,\n",
       "  'accuracy': 0.44261652,\n",
       "  'val_loss': 1.02527225908832,\n",
       "  'val_accuracy': 0.47663552},\n",
       " (1e-06, '41-75-3-3', 0.5, 16): {'loss': 1.0942954709844592,\n",
       "  'accuracy': 0.29651392,\n",
       "  'val_loss': 1.0972527443805589,\n",
       "  'val_accuracy': 0.28037384},\n",
       " (1e-06, '41-75-3-3', 0.5, 32): {'loss': 1.0900274840607813,\n",
       "  'accuracy': 0.36662748,\n",
       "  'val_loss': 1.0131895987786979,\n",
       "  'val_accuracy': 0.55140185},\n",
       " (1e-06, '41-75-3-3', 0.7, 16): {'loss': 1.0833716933231377,\n",
       "  'accuracy': 0.33333334,\n",
       "  'val_loss': 1.061974850770469,\n",
       "  'val_accuracy': 0.44859812},\n",
       " (1e-06, '41-75-3-3', 0.7, 32): {'loss': 1.08865240327153,\n",
       "  'accuracy': 0.3474344,\n",
       "  'val_loss': 1.032223802860652,\n",
       "  'val_accuracy': 0.45794392},\n",
       " (1e-06, '41-10-10-10-3-3', 0, 16): {'loss': 1.0267085565616698,\n",
       "  'accuracy': 0.47708577,\n",
       "  'val_loss': 1.0272782082869627,\n",
       "  'val_accuracy': 0.47663552},\n",
       " (1e-06, '41-10-10-10-3-3', 0, 32): {'loss': 1.1001636932935615,\n",
       "  'accuracy': 0.28946337,\n",
       "  'val_loss': 1.1005203946728572,\n",
       "  'val_accuracy': 0.24299066},\n",
       " (1e-06, '41-10-10-10-3-3', 0.3, 16): {'loss': 1.0604428276098619,\n",
       "  'accuracy': 0.43204075,\n",
       "  'val_loss': 1.066251500744686,\n",
       "  'val_accuracy': 0.42056075},\n",
       " (1e-06, '41-10-10-10-3-3', 0.3, 32): {'loss': 1.1017296015399136,\n",
       "  'accuracy': 0.28476304,\n",
       "  'val_loss': 1.100229632074588,\n",
       "  'val_accuracy': 0.26168224},\n",
       " (1e-06, '41-10-10-10-3-3', 0.5, 16): {'loss': 1.0959917826602097,\n",
       "  'accuracy': 0.27967098,\n",
       "  'val_loss': 1.0992463559747856,\n",
       "  'val_accuracy': 0.22429906},\n",
       " (1e-06, '41-10-10-10-3-3', 0.5, 32): {'loss': 1.09254855484856,\n",
       "  'accuracy': 0.35174304,\n",
       "  'val_loss': 1.0877821701709356,\n",
       "  'val_accuracy': 0.38317758},\n",
       " (1e-06, '41-10-10-10-3-3', 0.7, 16): {'loss': 1.1403840674730175,\n",
       "  'accuracy': 0.26556993,\n",
       "  'val_loss': 1.128655074912811,\n",
       "  'val_accuracy': 0.24299066},\n",
       " (1e-06, '41-10-10-10-3-3', 0.7, 32): {'loss': 1.0986123085021973,\n",
       "  'accuracy': 0.27967098,\n",
       "  'val_loss': 1.0986123085021973,\n",
       "  'val_accuracy': 0.22429906}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.save(timestamp + '_hyper_param_result_laliga.npy', result) \n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = best_model\n",
    "history = best_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='validation')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.plot(history.history['acc'], label='train')\n",
    "# plt.plot(history.history['val_acc'], label='validation')\n",
    "plt.plot(history.history['accuracy'], label='train')\n",
    "plt.plot(history.history['val_accuracy'], label='validation')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.5157894736842106\n"
     ]
    }
   ],
   "source": [
    "test_predictions = np.argmax(model.predict(X_test), axis=1)\n",
    "accuracy = (test_predictions == y_test.values).sum() / y_test.values.shape[0]\n",
    "print(\"Test set accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y train\n",
      "Unique train labels: [0 1 2]\n",
      "Away win count: 738\n",
      "Draw count: 621\n",
      "Away win count: 1301\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(\"Y train\")\n",
    "print(\"Unique train labels:\", np.unique(y_train.values))\n",
    "print(\"Away win count:\", (y_train==0).sum())\n",
    "print(\"Draw count:\", (y_train==1).sum())\n",
    "print(\"Away win count:\", (y_train==2).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Prediction\n",
      "Unique train labels: [0 1 2]\n",
      "Away win count: 738\n",
      "Draw count: 621\n",
      "Home win count: 1301\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Prediction\")\n",
    "train_predictions = np.argmax(model.predict(X_train), axis=1)\n",
    "print(\"Unique train labels:\", np.unique(train_predictions))\n",
    "print(\"Away win count:\", (y_train==0).sum())\n",
    "print(\"Draw count:\", (y_train==1).sum())\n",
    "print(\"Home win count:\", (y_train==2).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred home</th>\n",
       "      <th>pred draw</th>\n",
       "      <th>pred away</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true home</th>\n",
       "      <td>320</td>\n",
       "      <td>7</td>\n",
       "      <td>411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true draw</th>\n",
       "      <td>147</td>\n",
       "      <td>17</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true away</th>\n",
       "      <td>137</td>\n",
       "      <td>14</td>\n",
       "      <td>1150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pred home  pred draw  pred away\n",
       "true home        320          7        411\n",
       "true draw        147         17        457\n",
       "true away        137         14       1150"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train\n",
    "df_conf_matrix = pd.DataFrame(confusion_matrix(y_train, train_predictions, labels=[0, 1, 2]), \n",
    "             index=['true home', 'true draw', 'true away'], columns=['pred home', 'pred draw', 'pred away'])\n",
    "print(\"Train Data\")\n",
    "df_conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred home</th>\n",
       "      <th>pred draw</th>\n",
       "      <th>pred away</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true home</th>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true draw</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true away</th>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pred home  pred draw  pred away\n",
       "true home         38          2         73\n",
       "true draw         20          1         62\n",
       "true away         22          5        157"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test\n",
    "df_conf_matrix = pd.DataFrame(confusion_matrix(y_test, test_predictions, labels=[0, 1, 2]), \n",
    "             index=['true home', 'true draw', 'true away'], columns=['pred home', 'pred draw', 'pred away'])\n",
    "print(\"Test Data\")\n",
    "df_conf_matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
