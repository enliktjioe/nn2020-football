{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from betting_utils import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "# making all pandas columns visable with display command\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EPL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Train (Season 2009/2010 until Season 2015/2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_api_id</th>\n",
       "      <th>B365H</th>\n",
       "      <th>B365D</th>\n",
       "      <th>B365A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>658575</td>\n",
       "      <td>1.67</td>\n",
       "      <td>3.60</td>\n",
       "      <td>5.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>658578</td>\n",
       "      <td>3.60</td>\n",
       "      <td>3.25</td>\n",
       "      <td>2.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>658579</td>\n",
       "      <td>2.25</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>658582</td>\n",
       "      <td>1.17</td>\n",
       "      <td>6.50</td>\n",
       "      <td>21.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>658576</td>\n",
       "      <td>3.20</td>\n",
       "      <td>3.25</td>\n",
       "      <td>2.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     match_api_id  B365H  B365D  B365A\n",
       "382        658575   1.67   3.60   5.50\n",
       "385        658578   3.60   3.25   2.10\n",
       "386        658579   2.25   3.25   3.25\n",
       "389        658582   1.17   6.50  21.00\n",
       "383        658576   3.20   3.25   2.30"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv(\"datasets/EPL_sort.csv\", index_col=0)\n",
    "df1 = df1[df1['season'] != '2008/2009']\n",
    "df1 = df1[['match_api_id','B365H', 'B365D', 'B365A']]\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_api_id</th>\n",
       "      <th>FTR</th>\n",
       "      <th>HTGS</th>\n",
       "      <th>ATGS</th>\n",
       "      <th>HTGC</th>\n",
       "      <th>ATGC</th>\n",
       "      <th>HTP</th>\n",
       "      <th>ATP</th>\n",
       "      <th>HM1</th>\n",
       "      <th>HM2</th>\n",
       "      <th>HM3</th>\n",
       "      <th>HM4</th>\n",
       "      <th>HM5</th>\n",
       "      <th>AM1</th>\n",
       "      <th>AM2</th>\n",
       "      <th>AM3</th>\n",
       "      <th>AM4</th>\n",
       "      <th>AM5</th>\n",
       "      <th>HTWinStreak3</th>\n",
       "      <th>HTWinStreak5</th>\n",
       "      <th>HTLossStreak3</th>\n",
       "      <th>HTLossStreak5</th>\n",
       "      <th>ATWinStreak3</th>\n",
       "      <th>ATWinStreak5</th>\n",
       "      <th>ATLossStreak3</th>\n",
       "      <th>ATLossStreak5</th>\n",
       "      <th>HTGD</th>\n",
       "      <th>ATGD</th>\n",
       "      <th>DiffPts</th>\n",
       "      <th>DiffFormPts</th>\n",
       "      <th>DiffLP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1987033</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1987034</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1987035</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1987036</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1987037</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   match_api_id  FTR  HTGS  ATGS  HTGC  ATGC  HTP  ATP  HM1  HM2  HM3  HM4  \\\n",
       "0       1987033    0   0.0   0.0   0.0   0.0  0.0  0.0    2    2    2    2   \n",
       "1       1987034    1   0.0   0.0   0.0   0.0  0.0  0.0    2    2    2    2   \n",
       "2       1987035    1   0.0   0.0   0.0   0.0  0.0  0.0    2    2    2    2   \n",
       "3       1987036    2   0.0   0.0   0.0   0.0  0.0  0.0    2    2    2    2   \n",
       "4       1987037    2   0.0   0.0   0.0   0.0  0.0  0.0    2    2    2    2   \n",
       "\n",
       "   HM5  AM1  AM2  AM3  AM4  AM5  HTWinStreak3  HTWinStreak5  HTLossStreak3  \\\n",
       "0    2    2    2    2    2    2             0             0              0   \n",
       "1    2    2    2    2    2    2             0             0              0   \n",
       "2    2    2    2    2    2    2             0             0              0   \n",
       "3    2    2    2    2    2    2             0             0              0   \n",
       "4    2    2    2    2    2    2             0             0              0   \n",
       "\n",
       "   HTLossStreak5  ATWinStreak3  ATWinStreak5  ATLossStreak3  ATLossStreak5  \\\n",
       "0              0             0             0              0              0   \n",
       "1              0             0             0              0              0   \n",
       "2              0             0             0              0              0   \n",
       "3              0             0             0              0              0   \n",
       "4              0             0             0              0              0   \n",
       "\n",
       "   HTGD  ATGD  DiffPts  DiffFormPts  DiffLP  \n",
       "0   0.0   0.0      0.0          0.0       3  \n",
       "1   0.0   0.0      0.0          0.0      -9  \n",
       "2   0.0   0.0      0.0          0.0     -13  \n",
       "3   0.0   0.0      0.0          0.0       4  \n",
       "4   0.0   0.0      0.0          0.0       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv(\"datasets/epl_data_train_onehot_matchid.csv\")\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B365H</th>\n",
       "      <th>B365D</th>\n",
       "      <th>B365A</th>\n",
       "      <th>FTR</th>\n",
       "      <th>HTGS</th>\n",
       "      <th>ATGS</th>\n",
       "      <th>HTGC</th>\n",
       "      <th>ATGC</th>\n",
       "      <th>HTP</th>\n",
       "      <th>ATP</th>\n",
       "      <th>HM1</th>\n",
       "      <th>HM2</th>\n",
       "      <th>HM3</th>\n",
       "      <th>HM4</th>\n",
       "      <th>HM5</th>\n",
       "      <th>AM1</th>\n",
       "      <th>AM2</th>\n",
       "      <th>AM3</th>\n",
       "      <th>AM4</th>\n",
       "      <th>AM5</th>\n",
       "      <th>HTWinStreak3</th>\n",
       "      <th>HTWinStreak5</th>\n",
       "      <th>HTLossStreak3</th>\n",
       "      <th>HTLossStreak5</th>\n",
       "      <th>ATWinStreak3</th>\n",
       "      <th>ATWinStreak5</th>\n",
       "      <th>ATLossStreak3</th>\n",
       "      <th>ATLossStreak5</th>\n",
       "      <th>HTGD</th>\n",
       "      <th>ATGD</th>\n",
       "      <th>DiffPts</th>\n",
       "      <th>DiffFormPts</th>\n",
       "      <th>DiffLP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2650</th>\n",
       "      <td>1.17</td>\n",
       "      <td>9.00</td>\n",
       "      <td>17.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>0.433735</td>\n",
       "      <td>0.911392</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.657895</td>\n",
       "      <td>-1.184211</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2651</th>\n",
       "      <td>2.30</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.697917</td>\n",
       "      <td>0.626506</td>\n",
       "      <td>0.443038</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>-0.052632</td>\n",
       "      <td>-0.157895</td>\n",
       "      <td>-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2652</th>\n",
       "      <td>1.80</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.50</td>\n",
       "      <td>2</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.406250</td>\n",
       "      <td>0.662651</td>\n",
       "      <td>0.810127</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>-0.657895</td>\n",
       "      <td>-0.078947</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2653</th>\n",
       "      <td>4.50</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.80</td>\n",
       "      <td>2</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.771084</td>\n",
       "      <td>0.379747</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.657895</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2654</th>\n",
       "      <td>1.36</td>\n",
       "      <td>5.50</td>\n",
       "      <td>9.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.395833</td>\n",
       "      <td>0.481928</td>\n",
       "      <td>0.594937</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.394737</td>\n",
       "      <td>-0.236842</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2655</th>\n",
       "      <td>3.50</td>\n",
       "      <td>3.60</td>\n",
       "      <td>2.15</td>\n",
       "      <td>2</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.650602</td>\n",
       "      <td>0.620253</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.394737</td>\n",
       "      <td>0.394737</td>\n",
       "      <td>-0.078947</td>\n",
       "      <td>-0.236842</td>\n",
       "      <td>-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2656</th>\n",
       "      <td>6.00</td>\n",
       "      <td>4.75</td>\n",
       "      <td>1.53</td>\n",
       "      <td>1</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.614458</td>\n",
       "      <td>0.506329</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.263158</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2657</th>\n",
       "      <td>2.05</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.70</td>\n",
       "      <td>1</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.479167</td>\n",
       "      <td>0.578313</td>\n",
       "      <td>0.759494</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.263158</td>\n",
       "      <td>-0.368421</td>\n",
       "      <td>-0.078947</td>\n",
       "      <td>-0.131579</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2658</th>\n",
       "      <td>2.40</td>\n",
       "      <td>3.60</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.566265</td>\n",
       "      <td>0.620253</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.368421</td>\n",
       "      <td>0.342105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.157895</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2659</th>\n",
       "      <td>1.67</td>\n",
       "      <td>4.20</td>\n",
       "      <td>5.25</td>\n",
       "      <td>2</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.409639</td>\n",
       "      <td>0.810127</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>-0.526316</td>\n",
       "      <td>-0.026316</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>-11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      B365H  B365D  B365A  FTR  HTGS      ATGS      HTGC      ATGC       HTP  \\\n",
       "2650   1.17   9.00  17.00    2  0.61  0.281250  0.433735  0.911392  0.026316   \n",
       "2651   2.30   3.75   3.10    1  0.58  0.697917  0.626506  0.443038  0.026316   \n",
       "2652   1.80   4.00   4.50    2  0.56  0.406250  0.662651  0.810127  0.000000   \n",
       "2653   4.50   4.00   1.80    2  0.39  0.708333  0.771084  0.379747  0.026316   \n",
       "2654   1.36   5.50   9.00    2  0.55  0.395833  0.481928  0.594937  0.078947   \n",
       "2655   3.50   3.60   2.15    2  0.39  0.666667  0.650602  0.620253  0.000000   \n",
       "2656   6.00   4.75   1.53    1  0.41  0.729167  0.614458  0.506329  0.078947   \n",
       "2657   2.05   3.75   3.70    1  0.38  0.479167  0.578313  0.759494  0.000000   \n",
       "2658   2.40   3.60   3.00    1  0.33  0.645833  0.566265  0.620253  0.026316   \n",
       "2659   1.67   4.20   5.25    2  0.46  0.458333  0.409639  0.810127  0.000000   \n",
       "\n",
       "           ATP  HM1  HM2  HM3  HM4  HM5  AM1  AM2  AM3  AM4  AM5  \\\n",
       "2650  0.026316    0    3    0    3    0    0    1    1    1    1   \n",
       "2651  0.078947    0    1    0    3    1    3    0    3    0    3   \n",
       "2652  0.078947    1    1    3    1    0    3    1    1    1    1   \n",
       "2653  0.000000    0    3    0    0    3    1    0    0    3    3   \n",
       "2654  0.078947    3    3    3    0    3    3    1    1    0    0   \n",
       "2655  0.078947    1    0    1    1    1    3    1    3    3    0   \n",
       "2656  0.026316    3    3    1    1    3    0    1    3    0    3   \n",
       "2657  0.078947    1    1    3    1    3    3    3    0    0    3   \n",
       "2658  0.026316    0    1    0    1    1    0    3    1    0    3   \n",
       "2659  0.026316    1    3    0    3    3    0    1    1    1    3   \n",
       "\n",
       "      HTWinStreak3  HTWinStreak5  HTLossStreak3  HTLossStreak5  ATWinStreak3  \\\n",
       "2650             0             0              0              0             0   \n",
       "2651             0             0              0              0             0   \n",
       "2652             0             0              0              0             0   \n",
       "2653             0             0              0              0             0   \n",
       "2654             0             0              0              0             0   \n",
       "2655             0             0              1              0             0   \n",
       "2656             0             0              0              0             0   \n",
       "2657             0             0              0              0             0   \n",
       "2658             0             0              0              0             0   \n",
       "2659             0             0              0              0             0   \n",
       "\n",
       "      ATWinStreak5  ATLossStreak3  ATLossStreak5      HTGD      ATGD  \\\n",
       "2650             0              1              0  0.657895 -1.184211   \n",
       "2651             0              0              0  0.157895  0.842105   \n",
       "2652             0              1              0  0.026316 -0.657895   \n",
       "2653             0              0              0 -0.657895  1.000000   \n",
       "2654             0              0              0  0.394737 -0.236842   \n",
       "2655             0              0              0 -0.394737  0.394737   \n",
       "2656             0              0              0 -0.263158  0.789474   \n",
       "2657             0              0              0 -0.263158 -0.368421   \n",
       "2658             0              0              0 -0.368421  0.342105   \n",
       "2659             0              0              0  0.315789 -0.526316   \n",
       "\n",
       "       DiffPts  DiffFormPts  DiffLP  \n",
       "2650  0.000000     0.210526     -11  \n",
       "2651 -0.052632    -0.157895     -15  \n",
       "2652 -0.078947     0.026316     -13  \n",
       "2653  0.026316     0.026316       4  \n",
       "2654  0.000000     0.210526      -3  \n",
       "2655 -0.078947    -0.236842      -4  \n",
       "2656  0.052632     0.026316      11  \n",
       "2657 -0.078947    -0.131579       4  \n",
       "2658  0.000000    -0.157895      15  \n",
       "2659 -0.026316     0.157895     -11  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df1.set_index('match_api_id').join(df2.set_index('match_api_id'))\n",
    "df_train = df_train.reset_index()\n",
    "df_train = df_train.drop(columns = ['match_api_id'])\n",
    "df_train.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Test (Season 2008/2009)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_api_id</th>\n",
       "      <th>B365H</th>\n",
       "      <th>B365D</th>\n",
       "      <th>B365A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>489043</td>\n",
       "      <td>1.20</td>\n",
       "      <td>6.5</td>\n",
       "      <td>15.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>489049</td>\n",
       "      <td>1.83</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>489047</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.3</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>489050</td>\n",
       "      <td>2.60</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>489048</td>\n",
       "      <td>3.20</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   match_api_id  B365H  B365D  B365A\n",
       "1        489043   1.20    6.5  15.00\n",
       "7        489049   1.83    3.5   4.50\n",
       "5        489047   2.00    3.3   4.00\n",
       "8        489050   2.60    3.2   2.80\n",
       "6        489048   3.20    3.4   2.25"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = pd.read_csv(\"datasets/EPL_sort.csv\", index_col=0)\n",
    "df3 = df3[df3['season'] == '2008/2009']\n",
    "df3 = df3[['match_api_id','B365H', 'B365D', 'B365A']]\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_api_id</th>\n",
       "      <th>FTR</th>\n",
       "      <th>HTGS</th>\n",
       "      <th>ATGS</th>\n",
       "      <th>HTGC</th>\n",
       "      <th>ATGC</th>\n",
       "      <th>HTP</th>\n",
       "      <th>ATP</th>\n",
       "      <th>HM1</th>\n",
       "      <th>HM2</th>\n",
       "      <th>HM3</th>\n",
       "      <th>HM4</th>\n",
       "      <th>HM5</th>\n",
       "      <th>AM1</th>\n",
       "      <th>AM2</th>\n",
       "      <th>AM3</th>\n",
       "      <th>AM4</th>\n",
       "      <th>AM5</th>\n",
       "      <th>HTWinStreak3</th>\n",
       "      <th>HTWinStreak5</th>\n",
       "      <th>HTLossStreak3</th>\n",
       "      <th>HTLossStreak5</th>\n",
       "      <th>ATWinStreak3</th>\n",
       "      <th>ATWinStreak5</th>\n",
       "      <th>ATLossStreak3</th>\n",
       "      <th>ATLossStreak5</th>\n",
       "      <th>HTGD</th>\n",
       "      <th>ATGD</th>\n",
       "      <th>DiffPts</th>\n",
       "      <th>DiffFormPts</th>\n",
       "      <th>DiffLP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>489043</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>489049</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>489047</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>489050</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>489048</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   match_api_id  FTR  HTGS  ATGS  HTGC  ATGC  HTP  ATP  HM1  HM2  HM3  HM4  \\\n",
       "0        489043    2   0.0   0.0   0.0   0.0  0.0  0.0    2    2    2    2   \n",
       "1        489049    2   0.0   0.0   0.0   0.0  0.0  0.0    2    2    2    2   \n",
       "2        489047    0   0.0   0.0   0.0   0.0  0.0  0.0    2    2    2    2   \n",
       "3        489050    2   0.0   0.0   0.0   0.0  0.0  0.0    2    2    2    2   \n",
       "4        489048    2   0.0   0.0   0.0   0.0  0.0  0.0    2    2    2    2   \n",
       "\n",
       "   HM5  AM1  AM2  AM3  AM4  AM5  HTWinStreak3  HTWinStreak5  HTLossStreak3  \\\n",
       "0    2    2    2    2    2    2             0             0              0   \n",
       "1    2    2    2    2    2    2             0             0              0   \n",
       "2    2    2    2    2    2    2             0             0              0   \n",
       "3    2    2    2    2    2    2             0             0              0   \n",
       "4    2    2    2    2    2    2             0             0              0   \n",
       "\n",
       "   HTLossStreak5  ATWinStreak3  ATWinStreak5  ATLossStreak3  ATLossStreak5  \\\n",
       "0              0             0             0              0              0   \n",
       "1              0             0             0              0              0   \n",
       "2              0             0             0              0              0   \n",
       "3              0             0             0              0              0   \n",
       "4              0             0             0              0              0   \n",
       "\n",
       "   HTGD  ATGD  DiffPts  DiffFormPts  DiffLP  \n",
       "0   0.0   0.0      0.0          0.0     -14  \n",
       "1   0.0   0.0      0.0          0.0     -11  \n",
       "2   0.0   0.0      0.0          0.0      -4  \n",
       "3   0.0   0.0      0.0          0.0       0  \n",
       "4   0.0   0.0      0.0          0.0       7  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4 = pd.read_csv(\"datasets/epl_data_test_onehot_matchid.csv\")\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B365H</th>\n",
       "      <th>B365D</th>\n",
       "      <th>B365A</th>\n",
       "      <th>FTR</th>\n",
       "      <th>HTGS</th>\n",
       "      <th>ATGS</th>\n",
       "      <th>HTGC</th>\n",
       "      <th>ATGC</th>\n",
       "      <th>HTP</th>\n",
       "      <th>ATP</th>\n",
       "      <th>HM1</th>\n",
       "      <th>HM2</th>\n",
       "      <th>HM3</th>\n",
       "      <th>HM4</th>\n",
       "      <th>HM5</th>\n",
       "      <th>AM1</th>\n",
       "      <th>AM2</th>\n",
       "      <th>AM3</th>\n",
       "      <th>AM4</th>\n",
       "      <th>AM5</th>\n",
       "      <th>HTWinStreak3</th>\n",
       "      <th>HTWinStreak5</th>\n",
       "      <th>HTLossStreak3</th>\n",
       "      <th>HTLossStreak5</th>\n",
       "      <th>ATWinStreak3</th>\n",
       "      <th>ATWinStreak5</th>\n",
       "      <th>ATLossStreak3</th>\n",
       "      <th>ATLossStreak5</th>\n",
       "      <th>HTGD</th>\n",
       "      <th>ATGD</th>\n",
       "      <th>DiffPts</th>\n",
       "      <th>DiffFormPts</th>\n",
       "      <th>DiffLP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>1.33</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.385417</td>\n",
       "      <td>0.433735</td>\n",
       "      <td>0.645570</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>-0.368421</td>\n",
       "      <td>-0.052632</td>\n",
       "      <td>-0.026316</td>\n",
       "      <td>-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>2.30</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.578313</td>\n",
       "      <td>0.734177</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.131579</td>\n",
       "      <td>-0.473684</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>1.83</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.722892</td>\n",
       "      <td>0.848101</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.526316</td>\n",
       "      <td>-0.815789</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>2.10</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.60</td>\n",
       "      <td>0</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.552083</td>\n",
       "      <td>0.385542</td>\n",
       "      <td>0.468354</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.184211</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>3.00</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.697917</td>\n",
       "      <td>0.759036</td>\n",
       "      <td>0.303797</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.631579</td>\n",
       "      <td>1.131579</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.315789</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>1.53</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.50</td>\n",
       "      <td>2</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.313253</td>\n",
       "      <td>0.531646</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.263158</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>1.73</td>\n",
       "      <td>3.6</td>\n",
       "      <td>5.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.427083</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.658228</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.184211</td>\n",
       "      <td>-0.289474</td>\n",
       "      <td>-0.026316</td>\n",
       "      <td>0.131579</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>4.00</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.91</td>\n",
       "      <td>0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.677083</td>\n",
       "      <td>0.614458</td>\n",
       "      <td>0.278481</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>1.131579</td>\n",
       "      <td>-0.078947</td>\n",
       "      <td>-0.236842</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>2.25</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.20</td>\n",
       "      <td>2</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>0.530120</td>\n",
       "      <td>0.696203</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.105263</td>\n",
       "      <td>-0.736842</td>\n",
       "      <td>-0.026316</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>2.10</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.50</td>\n",
       "      <td>2</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.395833</td>\n",
       "      <td>0.542169</td>\n",
       "      <td>0.708861</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.315789</td>\n",
       "      <td>-0.473684</td>\n",
       "      <td>-0.078947</td>\n",
       "      <td>-0.078947</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     B365H  B365D  B365A  FTR  HTGS      ATGS      HTGC      ATGC       HTP  \\\n",
       "370   1.33    5.0  10.00    2  0.64  0.385417  0.433735  0.645570  0.026316   \n",
       "371   2.30    3.4   3.10    2  0.53  0.416667  0.578313  0.734177  0.026316   \n",
       "372   1.83    3.5   4.50    1  0.40  0.375000  0.722892  0.848101  0.000000   \n",
       "373   2.10    3.3   3.60    0  0.39  0.552083  0.385542  0.468354  0.078947   \n",
       "374   3.00    3.5   2.30    0  0.39  0.697917  0.759036  0.303797  0.026316   \n",
       "375   1.53    4.0   6.50    2  0.74  0.458333  0.313253  0.531646  0.078947   \n",
       "376   1.73    3.6   5.00    2  0.57  0.427083  0.602410  0.658228  0.000000   \n",
       "377   4.00    3.6   1.91    0  0.32  0.677083  0.614458  0.278481  0.000000   \n",
       "378   2.25    3.4   3.20    2  0.40  0.281250  0.530120  0.696203  0.000000   \n",
       "379   2.10    3.4   3.50    2  0.33  0.395833  0.542169  0.708861  0.000000   \n",
       "\n",
       "          ATP  HM1  HM2  HM3  HM4  HM5  AM1  AM2  AM3  AM4  AM5  HTWinStreak3  \\\n",
       "370  0.078947    0    1    3    3    0    3    3    1    1    3             0   \n",
       "371  0.000000    0    1    3    0    0    1    3    1    0    1             0   \n",
       "372  0.000000    1    3    1    3    1    1    3    1    3    1             0   \n",
       "373  0.078947    3    3    1    3    0    3    0    3    1    0             0   \n",
       "374  0.026316    0    1    1    1    1    0    3    3    3    3             0   \n",
       "375  0.078947    3    3    3    3    0    3    0    3    1    3             0   \n",
       "376  0.026316    1    1    3    3    3    0    0    0    0    1             1   \n",
       "377  0.078947    1    0    1    1    3    3    3    3    3    0             0   \n",
       "378  0.026316    1    1    3    1    0    0    1    1    1    0             0   \n",
       "379  0.078947    1    1    1    0    1    3    1    1    0    1             0   \n",
       "\n",
       "     HTWinStreak5  HTLossStreak3  HTLossStreak5  ATWinStreak3  ATWinStreak5  \\\n",
       "370             0              0              0             0             0   \n",
       "371             0              0              0             0             0   \n",
       "372             0              0              0             0             0   \n",
       "373             0              0              0             0             0   \n",
       "374             0              1              0             1             0   \n",
       "375             0              0              0             0             0   \n",
       "376             0              0              0             0             0   \n",
       "377             0              0              0             0             0   \n",
       "378             0              0              0             0             0   \n",
       "379             0              0              0             0             0   \n",
       "\n",
       "     ATLossStreak3  ATLossStreak5      HTGD      ATGD   DiffPts  DiffFormPts  \\\n",
       "370              0              0  0.736842 -0.368421 -0.052632    -0.026316   \n",
       "371              0              0  0.131579 -0.473684  0.026316     0.052632   \n",
       "372              0              0 -0.526316 -0.815789  0.000000     0.000000   \n",
       "373              0              0  0.184211  0.421053  0.000000     0.052632   \n",
       "374              0              0 -0.631579  1.131579  0.000000    -0.315789   \n",
       "375              0              0  1.263158  0.052632  0.000000     0.078947   \n",
       "376              0              0  0.184211 -0.289474 -0.026316     0.131579   \n",
       "377              0              0 -0.500000  1.131579 -0.078947    -0.236842   \n",
       "378              0              0 -0.105263 -0.736842 -0.026316     0.052632   \n",
       "379              0              0 -0.315789 -0.473684 -0.078947    -0.078947   \n",
       "\n",
       "     DiffLP  \n",
       "370     -14  \n",
       "371      -2  \n",
       "372      -8  \n",
       "373      12  \n",
       "374      17  \n",
       "375      -2  \n",
       "376       7  \n",
       "377      16  \n",
       "378       3  \n",
       "379       9  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = df3.set_index('match_api_id').join(df4.set_index('match_api_id'))\n",
    "df_test = df_test.reset_index()\n",
    "df_test = df_test.drop(columns = ['match_api_id'])\n",
    "df_test.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2660, 32)\n",
      "(2660,)\n",
      "(380, 32)\n",
      "(380,)\n",
      "(2660, 3)\n",
      "(380, 3)\n"
     ]
    }
   ],
   "source": [
    "x_train = df_train.drop(columns = ['FTR'])\n",
    "y_train = df_train['FTR']\n",
    "x_test = df_test.drop(columns = ['FTR'])\n",
    "y_test = df_test['FTR']\n",
    "bet_train = df_train[['B365H', 'B365D', 'B365A']]\n",
    "bet_test = df_test[['B365H', 'B365D', 'B365A']]\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "print(bet_train.shape)\n",
    "print(bet_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = x_train.values.shape[1]\n",
    "columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First neural model start here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32)]              0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 41)                1353      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 75)                3150      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 228       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 4,731\n",
      "Trainable params: 4,731\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, Activation, Flatten, Dense, Dropout, LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# 41-75-3\n",
    "# We first need to define the sequence of dependencies (the computational graph)\n",
    "# x = Input(shape=(20,32))\n",
    "x = Input(shape=(columns,))\n",
    "# h = Conv2D(32, (7, 7), strides=(2, 2))(x)\n",
    "# h = Activation('relu')(x)\n",
    "h = Flatten()(x)\n",
    "h = Dense(41)(h)\n",
    "h = Dense(75)(h)\n",
    "h = Dense(3)(h)\n",
    "# for i in range(10):\n",
    "#     h = Dense(75)(h)\n",
    "h = Dropout(0.3)(h)\n",
    "p = Activation('softmax')(h)\n",
    "\n",
    "# Now that we have defined how to find p from x, we can create a \n",
    "# model simply by saying what is input and what is output\n",
    "model = Model(inputs=x, outputs=p)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(lr=0.00001), metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 4.7009 - accuracy: 0.2914 - val_loss: 3.2788 - val_accuracy: 0.3178\n",
      "Epoch 2/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.8198 - accuracy: 0.2949 - val_loss: 2.6184 - val_accuracy: 0.2991\n",
      "Epoch 3/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.0234 - accuracy: 0.2899 - val_loss: 2.0187 - val_accuracy: 0.2897\n",
      "Epoch 4/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.2318 - accuracy: 0.3071 - val_loss: 1.5492 - val_accuracy: 0.2991\n",
      "Epoch 5/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.6868 - accuracy: 0.3337 - val_loss: 1.3081 - val_accuracy: 0.3832\n",
      "Epoch 6/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.4612 - accuracy: 0.3717 - val_loss: 1.2172 - val_accuracy: 0.4206\n",
      "Epoch 7/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.3237 - accuracy: 0.3980 - val_loss: 1.1777 - val_accuracy: 0.4112\n",
      "Epoch 8/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.2508 - accuracy: 0.4034 - val_loss: 1.1593 - val_accuracy: 0.4393\n",
      "Epoch 9/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.1865 - accuracy: 0.4191 - val_loss: 1.1494 - val_accuracy: 0.4673\n",
      "Epoch 10/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.1467 - accuracy: 0.4348 - val_loss: 1.1400 - val_accuracy: 0.4579\n",
      "Epoch 11/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.1311 - accuracy: 0.4363 - val_loss: 1.1333 - val_accuracy: 0.4486\n",
      "Epoch 12/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.1141 - accuracy: 0.4410 - val_loss: 1.1296 - val_accuracy: 0.4579\n",
      "Epoch 13/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.1198 - accuracy: 0.4407 - val_loss: 1.1209 - val_accuracy: 0.4860\n",
      "Epoch 14/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0927 - accuracy: 0.4536 - val_loss: 1.1177 - val_accuracy: 0.4766\n",
      "Epoch 15/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0917 - accuracy: 0.4422 - val_loss: 1.1100 - val_accuracy: 0.4860\n",
      "Epoch 16/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0926 - accuracy: 0.4477 - val_loss: 1.1072 - val_accuracy: 0.4766\n",
      "Epoch 17/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0806 - accuracy: 0.4442 - val_loss: 1.0997 - val_accuracy: 0.4860\n",
      "Epoch 18/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0757 - accuracy: 0.4602 - val_loss: 1.0965 - val_accuracy: 0.4860\n",
      "Epoch 19/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0725 - accuracy: 0.4458 - val_loss: 1.0930 - val_accuracy: 0.4766\n",
      "Epoch 20/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0721 - accuracy: 0.4512 - val_loss: 1.0893 - val_accuracy: 0.4766\n",
      "Epoch 21/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0643 - accuracy: 0.4528 - val_loss: 1.0802 - val_accuracy: 0.4860\n",
      "Epoch 22/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0664 - accuracy: 0.4575 - val_loss: 1.0819 - val_accuracy: 0.4860\n",
      "Epoch 23/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0612 - accuracy: 0.4497 - val_loss: 1.0783 - val_accuracy: 0.4860\n",
      "Epoch 24/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0590 - accuracy: 0.4465 - val_loss: 1.0737 - val_accuracy: 0.4860\n",
      "Epoch 25/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0614 - accuracy: 0.4505 - val_loss: 1.0683 - val_accuracy: 0.4860\n",
      "Epoch 26/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0545 - accuracy: 0.4567 - val_loss: 1.0670 - val_accuracy: 0.4860\n",
      "Epoch 27/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0421 - accuracy: 0.4602 - val_loss: 1.0612 - val_accuracy: 0.4860\n",
      "Epoch 28/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 1.0471 - accuracy: 0.4599 - val_loss: 1.0605 - val_accuracy: 0.4860\n",
      "Epoch 29/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0518 - accuracy: 0.4446 - val_loss: 1.0564 - val_accuracy: 0.4860\n",
      "Epoch 30/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0418 - accuracy: 0.4540 - val_loss: 1.0531 - val_accuracy: 0.4860\n",
      "Epoch 31/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 1.0360 - accuracy: 0.4779 - val_loss: 1.0541 - val_accuracy: 0.4953\n",
      "Epoch 32/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 1.0327 - accuracy: 0.4681 - val_loss: 1.0501 - val_accuracy: 0.4953\n",
      "Epoch 33/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 1.0413 - accuracy: 0.4559 - val_loss: 1.0460 - val_accuracy: 0.4860\n",
      "Epoch 34/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0382 - accuracy: 0.4583 - val_loss: 1.0419 - val_accuracy: 0.4953\n",
      "Epoch 35/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0261 - accuracy: 0.4653 - val_loss: 1.0442 - val_accuracy: 0.4953\n",
      "Epoch 36/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0258 - accuracy: 0.4626 - val_loss: 1.0396 - val_accuracy: 0.4953\n",
      "Epoch 37/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0277 - accuracy: 0.4579 - val_loss: 1.0397 - val_accuracy: 0.4953\n",
      "Epoch 38/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 1.0314 - accuracy: 0.4657 - val_loss: 1.0365 - val_accuracy: 0.5047\n",
      "Epoch 39/200\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 1.0292 - accuracy: 0.4595 - val_loss: 1.0335 - val_accuracy: 0.5047\n",
      "Epoch 40/200\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 1.0206 - accuracy: 0.4798 - val_loss: 1.0348 - val_accuracy: 0.5140\n",
      "Epoch 41/200\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 1.0214 - accuracy: 0.4638 - val_loss: 1.0299 - val_accuracy: 0.5047\n",
      "Epoch 42/200\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 1.0267 - accuracy: 0.4767 - val_loss: 1.0256 - val_accuracy: 0.4860\n",
      "Epoch 43/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0225 - accuracy: 0.4736 - val_loss: 1.0280 - val_accuracy: 0.5047\n",
      "Epoch 44/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0174 - accuracy: 0.4622 - val_loss: 1.0257 - val_accuracy: 0.5047\n",
      "Epoch 45/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0273 - accuracy: 0.4516 - val_loss: 1.0233 - val_accuracy: 0.4860\n",
      "Epoch 46/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 1.0202 - accuracy: 0.4740 - val_loss: 1.0235 - val_accuracy: 0.4860\n",
      "Epoch 47/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0197 - accuracy: 0.4720 - val_loss: 1.0220 - val_accuracy: 0.4860\n",
      "Epoch 48/200\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 1.0097 - accuracy: 0.4743 - val_loss: 1.0212 - val_accuracy: 0.5047\n",
      "Epoch 49/200\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 1.0148 - accuracy: 0.4779 - val_loss: 1.0187 - val_accuracy: 0.5047\n",
      "Epoch 50/200\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 1.0076 - accuracy: 0.4877 - val_loss: 1.0183 - val_accuracy: 0.5140\n",
      "Epoch 51/200\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 1.0158 - accuracy: 0.4830 - val_loss: 1.0178 - val_accuracy: 0.5140\n",
      "Epoch 52/200\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 1.0080 - accuracy: 0.4857 - val_loss: 1.0173 - val_accuracy: 0.5234\n",
      "Epoch 53/200\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 1.0195 - accuracy: 0.4783 - val_loss: 1.0133 - val_accuracy: 0.5047\n",
      "Epoch 54/200\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 1.0227 - accuracy: 0.4653 - val_loss: 1.0134 - val_accuracy: 0.5234\n",
      "Epoch 55/200\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 1.0164 - accuracy: 0.4689 - val_loss: 1.0119 - val_accuracy: 0.5140\n",
      "Epoch 56/200\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 1.0121 - accuracy: 0.4689 - val_loss: 1.0117 - val_accuracy: 0.5327\n",
      "Epoch 57/200\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 1.0080 - accuracy: 0.4865 - val_loss: 1.0103 - val_accuracy: 0.5327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/200\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 1.0142 - accuracy: 0.4634 - val_loss: 1.0112 - val_accuracy: 0.5327\n",
      "Epoch 59/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0117 - accuracy: 0.4708 - val_loss: 1.0102 - val_accuracy: 0.5234\n",
      "Epoch 60/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0060 - accuracy: 0.4818 - val_loss: 1.0083 - val_accuracy: 0.5234\n",
      "Epoch 61/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0033 - accuracy: 0.4826 - val_loss: 1.0080 - val_accuracy: 0.5234\n",
      "Epoch 62/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0066 - accuracy: 0.4767 - val_loss: 1.0098 - val_accuracy: 0.5234\n",
      "Epoch 63/200\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 1.0060 - accuracy: 0.4716 - val_loss: 1.0086 - val_accuracy: 0.5234\n",
      "Epoch 64/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 1.0013 - accuracy: 0.4959 - val_loss: 1.0064 - val_accuracy: 0.5327\n",
      "Epoch 65/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 1.0123 - accuracy: 0.4732 - val_loss: 1.0032 - val_accuracy: 0.5327\n",
      "Epoch 66/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0009 - accuracy: 0.4787 - val_loss: 1.0042 - val_accuracy: 0.5327\n",
      "Epoch 67/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9994 - accuracy: 0.4779 - val_loss: 1.0048 - val_accuracy: 0.5327\n",
      "Epoch 68/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0014 - accuracy: 0.4779 - val_loss: 1.0041 - val_accuracy: 0.5234\n",
      "Epoch 69/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9974 - accuracy: 0.4873 - val_loss: 1.0009 - val_accuracy: 0.5327\n",
      "Epoch 70/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0086 - accuracy: 0.4790 - val_loss: 1.0006 - val_accuracy: 0.5327\n",
      "Epoch 71/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9996 - accuracy: 0.4802 - val_loss: 1.0005 - val_accuracy: 0.5327\n",
      "Epoch 72/200\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.9931 - accuracy: 0.4924 - val_loss: 1.0008 - val_accuracy: 0.5234\n",
      "Epoch 73/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9956 - accuracy: 0.4837 - val_loss: 1.0006 - val_accuracy: 0.5327\n",
      "Epoch 74/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0064 - accuracy: 0.4798 - val_loss: 1.0021 - val_accuracy: 0.5234\n",
      "Epoch 75/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0048 - accuracy: 0.4802 - val_loss: 1.0019 - val_accuracy: 0.5327\n",
      "Epoch 76/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 1.0027 - accuracy: 0.4865 - val_loss: 1.0020 - val_accuracy: 0.5234\n",
      "Epoch 77/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.9959 - accuracy: 0.4794 - val_loss: 0.9998 - val_accuracy: 0.5327\n",
      "Epoch 78/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0125 - accuracy: 0.4720 - val_loss: 0.9988 - val_accuracy: 0.5140\n",
      "Epoch 79/200\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.9946 - accuracy: 0.5018 - val_loss: 0.9983 - val_accuracy: 0.5234\n",
      "Epoch 80/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9925 - accuracy: 0.4904 - val_loss: 1.0015 - val_accuracy: 0.5234\n",
      "Epoch 81/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9976 - accuracy: 0.4861 - val_loss: 0.9998 - val_accuracy: 0.5234\n",
      "Epoch 82/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9985 - accuracy: 0.4916 - val_loss: 0.9984 - val_accuracy: 0.5421\n",
      "Epoch 83/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9983 - accuracy: 0.4900 - val_loss: 0.9992 - val_accuracy: 0.5234\n",
      "Epoch 84/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9967 - accuracy: 0.4971 - val_loss: 0.9977 - val_accuracy: 0.5327\n",
      "Epoch 85/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9979 - accuracy: 0.4853 - val_loss: 0.9975 - val_accuracy: 0.5327\n",
      "Epoch 86/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0021 - accuracy: 0.4865 - val_loss: 0.9995 - val_accuracy: 0.5140\n",
      "Epoch 87/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0028 - accuracy: 0.4834 - val_loss: 0.9980 - val_accuracy: 0.5140\n",
      "Epoch 88/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0012 - accuracy: 0.4845 - val_loss: 0.9971 - val_accuracy: 0.5327\n",
      "Epoch 89/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9945 - accuracy: 0.4935 - val_loss: 0.9978 - val_accuracy: 0.5234\n",
      "Epoch 90/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0027 - accuracy: 0.4837 - val_loss: 0.9950 - val_accuracy: 0.5327\n",
      "Epoch 91/200\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 1.0010 - accuracy: 0.4708 - val_loss: 0.9959 - val_accuracy: 0.5234\n",
      "Epoch 92/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0063 - accuracy: 0.4740 - val_loss: 0.9946 - val_accuracy: 0.5234\n",
      "Epoch 93/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9981 - accuracy: 0.4814 - val_loss: 0.9962 - val_accuracy: 0.5327\n",
      "Epoch 94/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.9987 - accuracy: 0.4939 - val_loss: 0.9957 - val_accuracy: 0.5140\n",
      "Epoch 95/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9997 - accuracy: 0.4861 - val_loss: 0.9966 - val_accuracy: 0.5327\n",
      "Epoch 96/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0005 - accuracy: 0.4712 - val_loss: 0.9957 - val_accuracy: 0.5140\n",
      "Epoch 97/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9921 - accuracy: 0.4990 - val_loss: 0.9945 - val_accuracy: 0.5234\n",
      "Epoch 98/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0058 - accuracy: 0.4747 - val_loss: 0.9939 - val_accuracy: 0.5421\n",
      "Epoch 99/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9906 - accuracy: 0.4951 - val_loss: 0.9940 - val_accuracy: 0.5234\n",
      "Epoch 100/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9987 - accuracy: 0.4857 - val_loss: 0.9928 - val_accuracy: 0.5140\n",
      "Epoch 101/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9922 - accuracy: 0.4939 - val_loss: 0.9962 - val_accuracy: 0.5047\n",
      "Epoch 102/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9964 - accuracy: 0.5006 - val_loss: 0.9939 - val_accuracy: 0.5327\n",
      "Epoch 103/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9927 - accuracy: 0.4857 - val_loss: 0.9926 - val_accuracy: 0.5140\n",
      "Epoch 104/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9974 - accuracy: 0.4837 - val_loss: 0.9946 - val_accuracy: 0.5327\n",
      "Epoch 105/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.9924 - accuracy: 0.4963 - val_loss: 0.9956 - val_accuracy: 0.5140\n",
      "Epoch 106/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9976 - accuracy: 0.4939 - val_loss: 0.9932 - val_accuracy: 0.5327\n",
      "Epoch 107/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9951 - accuracy: 0.4951 - val_loss: 0.9962 - val_accuracy: 0.5234\n",
      "Epoch 108/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9972 - accuracy: 0.4810 - val_loss: 0.9938 - val_accuracy: 0.5327\n",
      "Epoch 109/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9997 - accuracy: 0.4810 - val_loss: 0.9927 - val_accuracy: 0.5327\n",
      "Epoch 110/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9975 - accuracy: 0.4810 - val_loss: 0.9935 - val_accuracy: 0.5327\n",
      "Epoch 111/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.9885 - accuracy: 0.4881 - val_loss: 0.9939 - val_accuracy: 0.5140\n",
      "Epoch 112/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9929 - accuracy: 0.4881 - val_loss: 0.9931 - val_accuracy: 0.5234\n",
      "Epoch 113/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9954 - accuracy: 0.4884 - val_loss: 0.9932 - val_accuracy: 0.5234\n",
      "Epoch 114/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9978 - accuracy: 0.4978 - val_loss: 0.9917 - val_accuracy: 0.5327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9934 - accuracy: 0.4865 - val_loss: 0.9914 - val_accuracy: 0.5327\n",
      "Epoch 116/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9990 - accuracy: 0.4763 - val_loss: 0.9911 - val_accuracy: 0.5327\n",
      "Epoch 117/200\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.9991 - accuracy: 0.4892 - val_loss: 0.9943 - val_accuracy: 0.5140\n",
      "Epoch 118/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.9904 - accuracy: 0.4982 - val_loss: 0.9926 - val_accuracy: 0.5140\n",
      "Epoch 119/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.9951 - accuracy: 0.4767 - val_loss: 0.9925 - val_accuracy: 0.5140\n",
      "Epoch 120/200\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.9932 - accuracy: 0.4834 - val_loss: 0.9928 - val_accuracy: 0.5234\n",
      "Epoch 121/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.9925 - accuracy: 0.4990 - val_loss: 0.9918 - val_accuracy: 0.5234\n",
      "Epoch 122/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9936 - accuracy: 0.4834 - val_loss: 0.9933 - val_accuracy: 0.5047\n",
      "Epoch 123/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9947 - accuracy: 0.4967 - val_loss: 0.9931 - val_accuracy: 0.5140\n",
      "Epoch 124/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9938 - accuracy: 0.4935 - val_loss: 0.9905 - val_accuracy: 0.5140\n",
      "Epoch 125/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9914 - accuracy: 0.5025 - val_loss: 0.9923 - val_accuracy: 0.5047\n",
      "Epoch 126/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9928 - accuracy: 0.5029 - val_loss: 0.9903 - val_accuracy: 0.5234\n",
      "Epoch 127/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9918 - accuracy: 0.4978 - val_loss: 0.9933 - val_accuracy: 0.5140\n",
      "Epoch 128/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9975 - accuracy: 0.4865 - val_loss: 0.9923 - val_accuracy: 0.5047\n",
      "Epoch 129/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9953 - accuracy: 0.5014 - val_loss: 0.9922 - val_accuracy: 0.5140\n",
      "Epoch 130/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9866 - accuracy: 0.5025 - val_loss: 0.9896 - val_accuracy: 0.5140\n",
      "Epoch 131/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9889 - accuracy: 0.4896 - val_loss: 0.9888 - val_accuracy: 0.5234\n",
      "Epoch 132/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.9939 - accuracy: 0.4861 - val_loss: 0.9902 - val_accuracy: 0.5140\n",
      "Epoch 133/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 1.0008 - accuracy: 0.4798 - val_loss: 0.9916 - val_accuracy: 0.5047\n",
      "Epoch 134/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.9940 - accuracy: 0.4955 - val_loss: 0.9901 - val_accuracy: 0.5140\n",
      "Epoch 135/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0003 - accuracy: 0.4920 - val_loss: 0.9913 - val_accuracy: 0.5047\n",
      "Epoch 136/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9883 - accuracy: 0.4975 - val_loss: 0.9903 - val_accuracy: 0.5140\n",
      "Epoch 137/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9984 - accuracy: 0.4912 - val_loss: 0.9920 - val_accuracy: 0.4953\n",
      "Epoch 138/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0033 - accuracy: 0.4826 - val_loss: 0.9929 - val_accuracy: 0.5047\n",
      "Epoch 139/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9968 - accuracy: 0.4896 - val_loss: 0.9908 - val_accuracy: 0.5047\n",
      "Epoch 140/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9902 - accuracy: 0.4920 - val_loss: 0.9932 - val_accuracy: 0.5047\n",
      "Epoch 141/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9930 - accuracy: 0.4861 - val_loss: 0.9921 - val_accuracy: 0.5047\n",
      "Epoch 142/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9912 - accuracy: 0.4920 - val_loss: 0.9914 - val_accuracy: 0.5047\n",
      "Epoch 143/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9934 - accuracy: 0.4888 - val_loss: 0.9907 - val_accuracy: 0.5047\n",
      "Epoch 144/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9905 - accuracy: 0.4881 - val_loss: 0.9920 - val_accuracy: 0.5047\n",
      "Epoch 145/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9907 - accuracy: 0.4955 - val_loss: 0.9891 - val_accuracy: 0.5047\n",
      "Epoch 146/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9851 - accuracy: 0.4920 - val_loss: 0.9890 - val_accuracy: 0.5047\n",
      "Epoch 147/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9966 - accuracy: 0.4967 - val_loss: 0.9898 - val_accuracy: 0.5047\n",
      "Epoch 148/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9855 - accuracy: 0.4947 - val_loss: 0.9890 - val_accuracy: 0.5047\n",
      "Epoch 149/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9942 - accuracy: 0.4892 - val_loss: 0.9919 - val_accuracy: 0.5140\n",
      "Epoch 150/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9918 - accuracy: 0.4959 - val_loss: 0.9908 - val_accuracy: 0.5047\n",
      "Epoch 151/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9909 - accuracy: 0.4884 - val_loss: 0.9897 - val_accuracy: 0.5047\n",
      "Epoch 152/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9902 - accuracy: 0.4865 - val_loss: 0.9927 - val_accuracy: 0.4953\n",
      "Epoch 153/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9922 - accuracy: 0.4975 - val_loss: 0.9898 - val_accuracy: 0.5047\n",
      "Epoch 154/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9907 - accuracy: 0.4857 - val_loss: 0.9902 - val_accuracy: 0.4953\n",
      "Epoch 155/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9994 - accuracy: 0.4834 - val_loss: 0.9911 - val_accuracy: 0.5047\n",
      "Epoch 156/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9923 - accuracy: 0.4818 - val_loss: 0.9911 - val_accuracy: 0.5047\n",
      "Epoch 157/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9893 - accuracy: 0.4990 - val_loss: 0.9912 - val_accuracy: 0.5047\n",
      "Epoch 158/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9855 - accuracy: 0.5116 - val_loss: 0.9911 - val_accuracy: 0.5047\n",
      "Epoch 159/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9854 - accuracy: 0.5018 - val_loss: 0.9904 - val_accuracy: 0.5047\n",
      "Epoch 160/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9970 - accuracy: 0.4884 - val_loss: 0.9894 - val_accuracy: 0.5047\n",
      "Epoch 161/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9903 - accuracy: 0.4955 - val_loss: 0.9888 - val_accuracy: 0.4953\n",
      "Epoch 162/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9868 - accuracy: 0.4939 - val_loss: 0.9891 - val_accuracy: 0.5140\n",
      "Epoch 163/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9933 - accuracy: 0.4877 - val_loss: 0.9873 - val_accuracy: 0.5234\n",
      "Epoch 164/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9910 - accuracy: 0.4967 - val_loss: 0.9880 - val_accuracy: 0.5140\n",
      "Epoch 165/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9909 - accuracy: 0.5033 - val_loss: 0.9886 - val_accuracy: 0.5047\n",
      "Epoch 166/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9943 - accuracy: 0.4892 - val_loss: 0.9900 - val_accuracy: 0.5140\n",
      "Epoch 167/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9866 - accuracy: 0.5018 - val_loss: 0.9886 - val_accuracy: 0.5047\n",
      "Epoch 168/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9889 - accuracy: 0.4939 - val_loss: 0.9897 - val_accuracy: 0.5140\n",
      "Epoch 169/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9902 - accuracy: 0.4873 - val_loss: 0.9896 - val_accuracy: 0.5140\n",
      "Epoch 170/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9986 - accuracy: 0.4896 - val_loss: 0.9893 - val_accuracy: 0.5047\n",
      "Epoch 171/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.9855 - accuracy: 0.4994 - val_loss: 0.9883 - val_accuracy: 0.5140\n",
      "Epoch 172/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9903 - accuracy: 0.5045 - val_loss: 0.9900 - val_accuracy: 0.5047\n",
      "Epoch 173/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9872 - accuracy: 0.4904 - val_loss: 0.9889 - val_accuracy: 0.5140\n",
      "Epoch 174/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9867 - accuracy: 0.4920 - val_loss: 0.9870 - val_accuracy: 0.5140\n",
      "Epoch 175/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.9924 - accuracy: 0.4947 - val_loss: 0.9887 - val_accuracy: 0.5047\n",
      "Epoch 176/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9912 - accuracy: 0.5080 - val_loss: 0.9893 - val_accuracy: 0.5140\n",
      "Epoch 177/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9898 - accuracy: 0.4900 - val_loss: 0.9909 - val_accuracy: 0.5140\n",
      "Epoch 178/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.9928 - accuracy: 0.4869 - val_loss: 0.9905 - val_accuracy: 0.4953\n",
      "Epoch 179/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9961 - accuracy: 0.4959 - val_loss: 0.9889 - val_accuracy: 0.4953\n",
      "Epoch 180/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0006 - accuracy: 0.4763 - val_loss: 0.9891 - val_accuracy: 0.5140\n",
      "Epoch 181/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9911 - accuracy: 0.4990 - val_loss: 0.9900 - val_accuracy: 0.5140\n",
      "Epoch 182/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9948 - accuracy: 0.4865 - val_loss: 0.9887 - val_accuracy: 0.5140\n",
      "Epoch 183/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9884 - accuracy: 0.5006 - val_loss: 0.9902 - val_accuracy: 0.5140\n",
      "Epoch 184/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9921 - accuracy: 0.4975 - val_loss: 0.9884 - val_accuracy: 0.5140\n",
      "Epoch 185/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9930 - accuracy: 0.4920 - val_loss: 0.9896 - val_accuracy: 0.5140\n",
      "Epoch 186/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9844 - accuracy: 0.4994 - val_loss: 0.9881 - val_accuracy: 0.5140\n",
      "Epoch 187/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9913 - accuracy: 0.4943 - val_loss: 0.9891 - val_accuracy: 0.5140\n",
      "Epoch 188/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9944 - accuracy: 0.4967 - val_loss: 0.9890 - val_accuracy: 0.5140\n",
      "Epoch 189/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9936 - accuracy: 0.4947 - val_loss: 0.9893 - val_accuracy: 0.5047\n",
      "Epoch 190/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9901 - accuracy: 0.4904 - val_loss: 0.9903 - val_accuracy: 0.5140\n",
      "Epoch 191/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9901 - accuracy: 0.4943 - val_loss: 0.9883 - val_accuracy: 0.5140\n",
      "Epoch 192/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9845 - accuracy: 0.5104 - val_loss: 0.9892 - val_accuracy: 0.5047\n",
      "Epoch 193/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9924 - accuracy: 0.5061 - val_loss: 0.9879 - val_accuracy: 0.5140\n",
      "Epoch 194/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9915 - accuracy: 0.4920 - val_loss: 0.9889 - val_accuracy: 0.5140\n",
      "Epoch 195/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9928 - accuracy: 0.5045 - val_loss: 0.9883 - val_accuracy: 0.5140\n",
      "Epoch 196/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.9869 - accuracy: 0.5049 - val_loss: 0.9908 - val_accuracy: 0.5140\n",
      "Epoch 197/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9952 - accuracy: 0.4963 - val_loss: 0.9898 - val_accuracy: 0.5140\n",
      "Epoch 198/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9889 - accuracy: 0.4998 - val_loss: 0.9896 - val_accuracy: 0.5140\n",
      "Epoch 199/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9895 - accuracy: 0.5065 - val_loss: 0.9890 - val_accuracy: 0.5047\n",
      "Epoch 200/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9932 - accuracy: 0.4939 - val_loss: 0.9900 - val_accuracy: 0.4953\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, batch_size=16, epochs=200, validation_split=0.04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='validation')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'], label='train')\n",
    "plt.plot(history.history['val_accuracy'], label='validation')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.5131578947368421\n"
     ]
    }
   ],
   "source": [
    "predictions = np.argmax(model.predict(x_test), axis=1)\n",
    "accuracy = (predictions == y_test.values).sum() / y_test.values.shape[0]\n",
    "print(\"Test set accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Betting time..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outcome when bet on home team\n",
    "Just a sanity check. Should not see high/any yields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agency B365, \twin amount: 33.66\n",
      "Agency B365, \twin amount: 50.57\n"
     ]
    }
   ],
   "source": [
    "## Profit for Away Wins Only \n",
    "predict_always_on_one_thing_benefit(y_train, bet_train, [0]) #Data Train\n",
    "predict_always_on_one_thing_benefit(y_test, bet_test, [0]) #Data Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agency B365, \twin amount: -96.47\n",
      "Agency B365, \twin amount: -25.46\n"
     ]
    }
   ],
   "source": [
    "## Profit for Draw Only \n",
    "predict_always_on_one_thing_benefit(y_train, bet_train, [1]) #Data Train\n",
    "predict_always_on_one_thing_benefit(y_test, bet_test, [1]) #Data Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agency B365, \twin amount: 5112.06\n",
      "Agency B365, \twin amount: 685.15\n"
     ]
    }
   ],
   "source": [
    "## Profit for Home Wins Only \n",
    "predict_always_on_one_thing_benefit(y_train, bet_train, [2]) #Data Train\n",
    "predict_always_on_one_thing_benefit(y_test, bet_test, [2]) #Data Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agency B365, \twin amount: 5145.72\n",
      "Agency B365, \twin amount: 735.72\n"
     ]
    }
   ],
   "source": [
    "## Profit for Home or Away \n",
    "predict_always_on_one_thing_benefit(y_train, bet_train, [0, 2]) #Data Train\n",
    "predict_always_on_one_thing_benefit(y_test, bet_test, [0, 2]) #Data Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agency B365, \twin amount: 5049.25\n",
      "Agency B365, \twin amount: 710.26\n"
     ]
    }
   ],
   "source": [
    "## Profit for All Possibilities\n",
    "predict_always_on_one_thing_benefit(y_train, bet_train, [0, 1, 2]) #Data Train\n",
    "predict_always_on_one_thing_benefit(y_test, bet_test, [0, 1, 2]) #Data Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bet on every match\n",
    "Always bet on the predicted winner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions_3x1 = model.predict(x_train)\n",
    "test_predictions_3x1 = model.predict(x_test)\n",
    "train_predictions = np.argmax(train_predictions_3x1 , axis=1)\n",
    "test_predictions = np.argmax(test_predictions_3x1 , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_predictions\n",
    "# test_predictions\n",
    "# print(train_predictions_3x1.shape)\n",
    "# print(test_predictions_3x1.shape)\n",
    "# x_train.shape\n",
    "# x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agency B365, \twin amount: 6610.12\n",
      "Agency B365, \twin amount: 907.43\n"
     ]
    }
   ],
   "source": [
    "always_bet_predicted_winner_profit(train_predictions, y_train, bet_train)\n",
    "always_bet_predicted_winner_profit(test_predictions, y_test, bet_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bet when expected return high enough\n",
    "First calculate the expected return of the team expected to win. If yield is high enough, then bet. \n",
    "* yield = prediction probability * odds. \n",
    "* Bet if yield > threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agency B365, \twin amount: 7752.36. Didn't bet on 49.25% of matches\n",
      "Agency B365, \twin amount: 1078.06. Didn't bet on 51.32% of matches\n"
     ]
    }
   ],
   "source": [
    "bet_predicted_winner_with_threshold_profit(train_predictions_3x1, train_predictions, y_train, bet_train, threshold=1)\n",
    "bet_predicted_winner_with_threshold_profit(test_predictions_3x1, test_predictions, y_test, bet_test, threshold=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bet on highest return\n",
    "Multiplies the neural network match predictions with betting odds and from these multiplications chooses from home win, draw, away win the highest expected return value. A threshhold can be set to choose if the yield is high enough to bet.  [prediction probability * odds > threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agency B365, \twin amount: -296.00. Didn't bet on 63.20% of matches\n",
      "Agency B365, \twin amount: -37.00. Didn't bet on 64.47% of matches\n"
     ]
    }
   ],
   "source": [
    "predict_on_highest_return(train_predictions_3x1, y_train, bet_train, threshold=2.5)\n",
    "predict_on_highest_return(test_predictions_3x1, y_test, bet_test, threshold=2.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## La Liga"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Train (Season 2009/2010 until Season 2015/2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_api_id</th>\n",
       "      <th>B365H</th>\n",
       "      <th>B365D</th>\n",
       "      <th>B365A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>684585</td>\n",
       "      <td>1.25</td>\n",
       "      <td>5.5</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>684589</td>\n",
       "      <td>1.91</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>684586</td>\n",
       "      <td>2.10</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>684588</td>\n",
       "      <td>2.88</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>684594</td>\n",
       "      <td>3.40</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     match_api_id  B365H  B365D  B365A\n",
       "380        684585   1.25    5.5   13.0\n",
       "384        684589   1.91    3.4    4.2\n",
       "381        684586   2.10    3.3    3.5\n",
       "383        684588   2.88    3.2    2.5\n",
       "389        684594   3.40    3.4    2.1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv(\"datasets/LaLiga_sort.csv\", index_col=0)\n",
    "df1 = df1[df1['season'] != '2008/2009']\n",
    "df1 = df1[['match_api_id','B365H', 'B365D', 'B365A']]\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_api_id</th>\n",
       "      <th>FTR</th>\n",
       "      <th>HTGS</th>\n",
       "      <th>ATGS</th>\n",
       "      <th>HTGC</th>\n",
       "      <th>ATGC</th>\n",
       "      <th>HTP</th>\n",
       "      <th>ATP</th>\n",
       "      <th>HM1</th>\n",
       "      <th>HM2</th>\n",
       "      <th>HM3</th>\n",
       "      <th>HM4</th>\n",
       "      <th>HM5</th>\n",
       "      <th>AM1</th>\n",
       "      <th>AM2</th>\n",
       "      <th>AM3</th>\n",
       "      <th>AM4</th>\n",
       "      <th>AM5</th>\n",
       "      <th>HTWinStreak3</th>\n",
       "      <th>HTWinStreak5</th>\n",
       "      <th>HTLossStreak3</th>\n",
       "      <th>HTLossStreak5</th>\n",
       "      <th>ATWinStreak3</th>\n",
       "      <th>ATWinStreak5</th>\n",
       "      <th>ATLossStreak3</th>\n",
       "      <th>ATLossStreak5</th>\n",
       "      <th>HTGD</th>\n",
       "      <th>ATGD</th>\n",
       "      <th>DiffPts</th>\n",
       "      <th>DiffFormPts</th>\n",
       "      <th>DiffLP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2030084</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2030083</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2030090</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2030087</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2030091</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   match_api_id  FTR  HTGS  ATGS  HTGC  ATGC  HTP  ATP  HM1  HM2  HM3  HM4  \\\n",
       "0       2030084    1   0.0   0.0   0.0   0.0  0.0  0.0    2    2    2    2   \n",
       "1       2030083    2   0.0   0.0   0.0   0.0  0.0  0.0    2    2    2    2   \n",
       "2       2030090    1   0.0   0.0   0.0   0.0  0.0  0.0    2    2    2    2   \n",
       "3       2030087    2   0.0   0.0   0.0   0.0  0.0  0.0    2    2    2    2   \n",
       "4       2030091    1   0.0   0.0   0.0   0.0  0.0  0.0    2    2    2    2   \n",
       "\n",
       "   HM5  AM1  AM2  AM3  AM4  AM5  HTWinStreak3  HTWinStreak5  HTLossStreak3  \\\n",
       "0    2    2    2    2    2    2             0             0              0   \n",
       "1    2    2    2    2    2    2             0             0              0   \n",
       "2    2    2    2    2    2    2             0             0              0   \n",
       "3    2    2    2    2    2    2             0             0              0   \n",
       "4    2    2    2    2    2    2             0             0              0   \n",
       "\n",
       "   HTLossStreak5  ATWinStreak3  ATWinStreak5  ATLossStreak3  ATLossStreak5  \\\n",
       "0              0             0             0              0              0   \n",
       "1              0             0             0              0              0   \n",
       "2              0             0             0              0              0   \n",
       "3              0             0             0              0              0   \n",
       "4              0             0             0              0              0   \n",
       "\n",
       "   HTGD  ATGD  DiffPts  DiffFormPts  DiffLP  \n",
       "0   0.0   0.0      0.0          0.0       4  \n",
       "1   0.0   0.0      0.0          0.0     -15  \n",
       "2   0.0   0.0      0.0          0.0       6  \n",
       "3   0.0   0.0      0.0          0.0      -5  \n",
       "4   0.0   0.0      0.0          0.0       7  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv(\"datasets/laliga_data_train_onehot_matchid.csv\")\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B365H</th>\n",
       "      <th>B365D</th>\n",
       "      <th>B365A</th>\n",
       "      <th>FTR</th>\n",
       "      <th>HTGS</th>\n",
       "      <th>ATGS</th>\n",
       "      <th>HTGC</th>\n",
       "      <th>ATGC</th>\n",
       "      <th>HTP</th>\n",
       "      <th>ATP</th>\n",
       "      <th>HM1</th>\n",
       "      <th>HM2</th>\n",
       "      <th>HM3</th>\n",
       "      <th>HM4</th>\n",
       "      <th>HM5</th>\n",
       "      <th>AM1</th>\n",
       "      <th>AM2</th>\n",
       "      <th>AM3</th>\n",
       "      <th>AM4</th>\n",
       "      <th>AM5</th>\n",
       "      <th>HTWinStreak3</th>\n",
       "      <th>HTWinStreak5</th>\n",
       "      <th>HTLossStreak3</th>\n",
       "      <th>HTLossStreak5</th>\n",
       "      <th>ATWinStreak3</th>\n",
       "      <th>ATWinStreak5</th>\n",
       "      <th>ATLossStreak3</th>\n",
       "      <th>ATLossStreak5</th>\n",
       "      <th>HTGD</th>\n",
       "      <th>ATGD</th>\n",
       "      <th>DiffPts</th>\n",
       "      <th>DiffFormPts</th>\n",
       "      <th>DiffLP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2650</th>\n",
       "      <td>1.95</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0.393162</td>\n",
       "      <td>0.382609</td>\n",
       "      <td>0.602564</td>\n",
       "      <td>0.623377</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.026316</td>\n",
       "      <td>-0.105263</td>\n",
       "      <td>-0.078947</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>-8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2651</th>\n",
       "      <td>1.33</td>\n",
       "      <td>5.75</td>\n",
       "      <td>8.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.470085</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.564103</td>\n",
       "      <td>0.610390</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.289474</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2652</th>\n",
       "      <td>1.75</td>\n",
       "      <td>3.75</td>\n",
       "      <td>4.50</td>\n",
       "      <td>2</td>\n",
       "      <td>0.521368</td>\n",
       "      <td>0.443478</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.740260</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.131579</td>\n",
       "      <td>-0.157895</td>\n",
       "      <td>-0.078947</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2653</th>\n",
       "      <td>26.00</td>\n",
       "      <td>11.00</td>\n",
       "      <td>1.08</td>\n",
       "      <td>0</td>\n",
       "      <td>0.393162</td>\n",
       "      <td>0.947826</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.376623</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.526316</td>\n",
       "      <td>2.105263</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.078947</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2654</th>\n",
       "      <td>13.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.939130</td>\n",
       "      <td>0.756410</td>\n",
       "      <td>0.441558</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.368421</td>\n",
       "      <td>1.947368</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.263158</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2655</th>\n",
       "      <td>1.80</td>\n",
       "      <td>3.75</td>\n",
       "      <td>4.50</td>\n",
       "      <td>2</td>\n",
       "      <td>0.290598</td>\n",
       "      <td>0.382609</td>\n",
       "      <td>0.435897</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.131579</td>\n",
       "      <td>-0.026316</td>\n",
       "      <td>-0.026316</td>\n",
       "      <td>-9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2656</th>\n",
       "      <td>2.00</td>\n",
       "      <td>3.60</td>\n",
       "      <td>3.70</td>\n",
       "      <td>2</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.408696</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.740260</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.947368</td>\n",
       "      <td>-0.263158</td>\n",
       "      <td>-0.026316</td>\n",
       "      <td>-0.026316</td>\n",
       "      <td>-8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2657</th>\n",
       "      <td>1.33</td>\n",
       "      <td>5.25</td>\n",
       "      <td>9.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.418803</td>\n",
       "      <td>0.313043</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.605263</td>\n",
       "      <td>-0.815789</td>\n",
       "      <td>-0.078947</td>\n",
       "      <td>-0.078947</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2658</th>\n",
       "      <td>5.00</td>\n",
       "      <td>3.80</td>\n",
       "      <td>1.70</td>\n",
       "      <td>2</td>\n",
       "      <td>0.273504</td>\n",
       "      <td>0.313043</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.763158</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.078947</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2659</th>\n",
       "      <td>1.44</td>\n",
       "      <td>4.50</td>\n",
       "      <td>7.50</td>\n",
       "      <td>2</td>\n",
       "      <td>0.324786</td>\n",
       "      <td>0.382609</td>\n",
       "      <td>0.794872</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.631579</td>\n",
       "      <td>0.289474</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      B365H  B365D  B365A  FTR      HTGS      ATGS      HTGC      ATGC  \\\n",
       "2650   1.95   3.75   3.75    0  0.393162  0.382609  0.602564  0.623377   \n",
       "2651   1.33   5.75   8.00    2  0.470085  0.434783  0.564103  0.610390   \n",
       "2652   1.75   3.75   4.50    2  0.521368  0.443478  0.230769  0.740260   \n",
       "2653  26.00  11.00   1.08    0  0.393162  0.947826  0.846154  0.376623   \n",
       "2654  13.00   8.00   1.18    0  0.384615  0.939130  0.756410  0.441558   \n",
       "2655   1.80   3.75   4.50    2  0.290598  0.382609  0.435897  0.636364   \n",
       "2656   2.00   3.60   3.70    2  0.307692  0.408696  0.923077  0.740260   \n",
       "2657   1.33   5.25   9.00    2  0.418803  0.313043  0.923077  0.870130   \n",
       "2658   5.00   3.80   1.70    2  0.273504  0.313043  0.653846  0.844156   \n",
       "2659   1.44   4.50   7.50    2  0.324786  0.382609  0.794872  0.428571   \n",
       "\n",
       "           HTP       ATP  HM1  HM2  HM3  HM4  HM5  AM1  AM2  AM3  AM4  AM5  \\\n",
       "2650  0.000000  0.078947    1    1    0    3    3    3    1    0    1    1   \n",
       "2651  0.026316  0.000000    0    3    0    1    3    1    1    3    1    0   \n",
       "2652  0.000000  0.078947    1    3    3    3    3    3    1    3    0    0   \n",
       "2653  0.078947  0.078947    3    3    1    3    1    3    3    3    3    1   \n",
       "2654  0.078947  0.078947    3    1    0    1    0    3    3    3    3    3   \n",
       "2655  0.000000  0.026316    1    3    1    0    1    0    1    3    1    0   \n",
       "2656  0.000000  0.026316    1    3    1    0    1    0    1    0    1    3   \n",
       "2657  0.000000  0.078947    1    1    1    0    3    3    1    0    1    3   \n",
       "2658  0.026316  0.026316    0    1    1    3    0    0    3    0    3    1   \n",
       "2659  0.026316  0.000000    0    3    1    3    0    1    3    0    1    1   \n",
       "\n",
       "      HTWinStreak3  HTWinStreak5  HTLossStreak3  HTLossStreak5  ATWinStreak3  \\\n",
       "2650             0             0              0              0             0   \n",
       "2651             0             0              0              0             0   \n",
       "2652             1             0              0              0             0   \n",
       "2653             0             0              0              0             0   \n",
       "2654             0             0              0              0             1   \n",
       "2655             0             0              0              0             0   \n",
       "2656             0             0              0              0             0   \n",
       "2657             0             0              0              0             0   \n",
       "2658             0             0              0              0             0   \n",
       "2659             0             0              0              0             0   \n",
       "\n",
       "      ATWinStreak5  ATLossStreak3  ATLossStreak5      HTGD      ATGD  \\\n",
       "2650             0              0              0 -0.026316 -0.105263   \n",
       "2651             0              0              0  0.289474  0.078947   \n",
       "2652             0              0              0  1.131579 -0.157895   \n",
       "2653             0              0              0 -0.526316  2.105263   \n",
       "2654             1              0              0 -0.368421  1.947368   \n",
       "2655             0              0              0  0.000000 -0.131579   \n",
       "2656             0              0              0 -0.947368 -0.263158   \n",
       "2657             0              0              0 -0.605263 -0.815789   \n",
       "2658             0              0              0 -0.500000 -0.763158   \n",
       "2659             0              0              0 -0.631579  0.289474   \n",
       "\n",
       "       DiffPts  DiffFormPts  DiffLP  \n",
       "2650 -0.078947     0.078947      -8  \n",
       "2651  0.026316     0.105263       2  \n",
       "2652 -0.078947     0.105263      -5  \n",
       "2653  0.000000    -0.078947      16  \n",
       "2654  0.000000    -0.263158      16  \n",
       "2655 -0.026316    -0.026316      -9  \n",
       "2656 -0.026316    -0.026316      -8  \n",
       "2657 -0.078947    -0.078947      -3  \n",
       "2658  0.000000    -0.078947       3  \n",
       "2659  0.026316     0.105263      12  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df1.set_index('match_api_id').join(df2.set_index('match_api_id'))\n",
    "df_train = df_train.reset_index()\n",
    "df_train = df_train.drop(columns = ['match_api_id'])\n",
    "df_train.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Test (Season 2008/2009)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_api_id</th>\n",
       "      <th>B365H</th>\n",
       "      <th>B365D</th>\n",
       "      <th>B365A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>530090</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>530023</td>\n",
       "      <td>1.70</td>\n",
       "      <td>3.6</td>\n",
       "      <td>5.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>530091</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>530092</td>\n",
       "      <td>1.44</td>\n",
       "      <td>4.2</td>\n",
       "      <td>7.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>530084</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.3</td>\n",
       "      <td>2.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   match_api_id  B365H  B365D  B365A\n",
       "7        530090   2.00    3.3   3.80\n",
       "0        530023   1.70    3.6   5.25\n",
       "8        530091   2.00    3.3   3.80\n",
       "9        530092   1.44    4.2   7.50\n",
       "1        530084   2.80    3.3   2.50"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = pd.read_csv(\"datasets/LaLiga_sort.csv\", index_col=0)\n",
    "df3 = df3[df3['season'] == '2008/2009']\n",
    "df3 = df3[['match_api_id','B365H', 'B365D', 'B365A']]\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_api_id</th>\n",
       "      <th>FTR</th>\n",
       "      <th>HTGS</th>\n",
       "      <th>ATGS</th>\n",
       "      <th>HTGC</th>\n",
       "      <th>ATGC</th>\n",
       "      <th>HTP</th>\n",
       "      <th>ATP</th>\n",
       "      <th>HM1</th>\n",
       "      <th>HM2</th>\n",
       "      <th>HM3</th>\n",
       "      <th>HM4</th>\n",
       "      <th>HM5</th>\n",
       "      <th>AM1</th>\n",
       "      <th>AM2</th>\n",
       "      <th>AM3</th>\n",
       "      <th>AM4</th>\n",
       "      <th>AM5</th>\n",
       "      <th>HTWinStreak3</th>\n",
       "      <th>HTWinStreak5</th>\n",
       "      <th>HTLossStreak3</th>\n",
       "      <th>HTLossStreak5</th>\n",
       "      <th>ATWinStreak3</th>\n",
       "      <th>ATWinStreak5</th>\n",
       "      <th>ATLossStreak3</th>\n",
       "      <th>ATLossStreak5</th>\n",
       "      <th>HTGD</th>\n",
       "      <th>ATGD</th>\n",
       "      <th>DiffPts</th>\n",
       "      <th>DiffFormPts</th>\n",
       "      <th>DiffLP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>530090</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>530023</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>530091</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>530092</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>530084</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   match_api_id  FTR  HTGS  ATGS  HTGC  ATGC  HTP  ATP  HM1  HM2  HM3  HM4  \\\n",
       "0        530090    2   0.0   0.0   0.0   0.0  0.0  0.0    2    2    2    2   \n",
       "1        530023    2   0.0   0.0   0.0   0.0  0.0  0.0    2    2    2    2   \n",
       "2        530091    0   0.0   0.0   0.0   0.0  0.0  0.0    2    2    2    2   \n",
       "3        530092    2   0.0   0.0   0.0   0.0  0.0  0.0    2    2    2    2   \n",
       "4        530084    1   0.0   0.0   0.0   0.0  0.0  0.0    2    2    2    2   \n",
       "\n",
       "   HM5  AM1  AM2  AM3  AM4  AM5  HTWinStreak3  HTWinStreak5  HTLossStreak3  \\\n",
       "0    2    2    2    2    2    2             0             0              0   \n",
       "1    2    2    2    2    2    2             0             0              0   \n",
       "2    2    2    2    2    2    2             0             0              0   \n",
       "3    2    2    2    2    2    2             0             0              0   \n",
       "4    2    2    2    2    2    2             0             0              0   \n",
       "\n",
       "   HTLossStreak5  ATWinStreak3  ATWinStreak5  ATLossStreak3  ATLossStreak5  \\\n",
       "0              0             0             0              0              0   \n",
       "1              0             0             0              0              0   \n",
       "2              0             0             0              0              0   \n",
       "3              0             0             0              0              0   \n",
       "4              0             0             0              0              0   \n",
       "\n",
       "   HTGD  ATGD  DiffPts  DiffFormPts  DiffLP  \n",
       "0   0.0   0.0      0.0          0.0      -3  \n",
       "1   0.0   0.0      0.0          0.0       3  \n",
       "2   0.0   0.0      0.0          0.0       3  \n",
       "3   0.0   0.0      0.0          0.0     -14  \n",
       "4   0.0   0.0      0.0          0.0      15  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4 = pd.read_csv(\"datasets/laliga_data_test_onehot_matchid.csv\")\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B365H</th>\n",
       "      <th>B365D</th>\n",
       "      <th>B365A</th>\n",
       "      <th>FTR</th>\n",
       "      <th>HTGS</th>\n",
       "      <th>ATGS</th>\n",
       "      <th>HTGC</th>\n",
       "      <th>ATGC</th>\n",
       "      <th>HTP</th>\n",
       "      <th>ATP</th>\n",
       "      <th>HM1</th>\n",
       "      <th>HM2</th>\n",
       "      <th>HM3</th>\n",
       "      <th>HM4</th>\n",
       "      <th>HM5</th>\n",
       "      <th>AM1</th>\n",
       "      <th>AM2</th>\n",
       "      <th>AM3</th>\n",
       "      <th>AM4</th>\n",
       "      <th>AM5</th>\n",
       "      <th>HTWinStreak3</th>\n",
       "      <th>HTWinStreak5</th>\n",
       "      <th>HTLossStreak3</th>\n",
       "      <th>HTLossStreak5</th>\n",
       "      <th>ATWinStreak3</th>\n",
       "      <th>ATWinStreak5</th>\n",
       "      <th>ATLossStreak3</th>\n",
       "      <th>ATLossStreak5</th>\n",
       "      <th>HTGD</th>\n",
       "      <th>ATGD</th>\n",
       "      <th>DiffPts</th>\n",
       "      <th>DiffFormPts</th>\n",
       "      <th>DiffLP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>1.25</td>\n",
       "      <td>5.25</td>\n",
       "      <td>13.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.658120</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.753247</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>-0.342105</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>2.00</td>\n",
       "      <td>3.60</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1</td>\n",
       "      <td>0.401709</td>\n",
       "      <td>0.904348</td>\n",
       "      <td>0.589744</td>\n",
       "      <td>0.441558</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>1.842105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>3.40</td>\n",
       "      <td>3.30</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0</td>\n",
       "      <td>0.435897</td>\n",
       "      <td>0.504348</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.675325</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.157895</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>1.36</td>\n",
       "      <td>4.75</td>\n",
       "      <td>8.50</td>\n",
       "      <td>2</td>\n",
       "      <td>0.564103</td>\n",
       "      <td>0.408696</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>-0.342105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.078947</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>1.70</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.33</td>\n",
       "      <td>2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.713043</td>\n",
       "      <td>0.589744</td>\n",
       "      <td>0.649351</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.184211</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>4.20</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.83</td>\n",
       "      <td>0</td>\n",
       "      <td>0.324786</td>\n",
       "      <td>0.452174</td>\n",
       "      <td>0.858974</td>\n",
       "      <td>0.506494</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.763158</td>\n",
       "      <td>0.342105</td>\n",
       "      <td>-0.078947</td>\n",
       "      <td>-0.078947</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>1.91</td>\n",
       "      <td>3.60</td>\n",
       "      <td>3.80</td>\n",
       "      <td>2</td>\n",
       "      <td>0.367521</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.628205</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.157895</td>\n",
       "      <td>-0.026316</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.184211</td>\n",
       "      <td>-6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>3.30</td>\n",
       "      <td>3.30</td>\n",
       "      <td>2.15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.410256</td>\n",
       "      <td>0.426087</td>\n",
       "      <td>0.602564</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>-0.157895</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.026316</td>\n",
       "      <td>-8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>1.83</td>\n",
       "      <td>3.60</td>\n",
       "      <td>4.20</td>\n",
       "      <td>1</td>\n",
       "      <td>0.427350</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.740260</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.184211</td>\n",
       "      <td>-0.315789</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>1.33</td>\n",
       "      <td>5.00</td>\n",
       "      <td>8.50</td>\n",
       "      <td>2</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.286957</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.868421</td>\n",
       "      <td>-0.578947</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     B365H  B365D  B365A  FTR      HTGS      ATGS      HTGC      ATGC  \\\n",
       "370   1.25   5.25  13.00    2  0.658120  0.391304  0.730769  0.753247   \n",
       "371   2.00   3.60   3.40    1  0.401709  0.904348  0.589744  0.441558   \n",
       "372   3.40   3.30   2.15    0  0.435897  0.504348  0.730769  0.675325   \n",
       "373   1.36   4.75   8.50    2  0.564103  0.408696  0.692308  0.779221   \n",
       "374   1.70   4.00   4.33    2  0.333333  0.713043  0.589744  0.649351   \n",
       "375   4.20   3.60   1.83    0  0.324786  0.452174  0.858974  0.506494   \n",
       "376   1.91   3.60   3.80    2  0.367521  0.478261  0.628205  0.727273   \n",
       "377   3.30   3.30   2.15    1  0.410256  0.426087  0.602564  0.714286   \n",
       "378   1.83   3.60   4.20    1  0.427350  0.391304  0.730769  0.740260   \n",
       "379   1.33   5.00   8.50    2  0.384615  0.286957  1.000000  0.714286   \n",
       "\n",
       "          HTP       ATP  HM1  HM2  HM3  HM4  HM5  AM1  AM2  AM3  AM4  AM5  \\\n",
       "370  0.078947  0.000000    3    3    3    3    3    1    1    3    3    3   \n",
       "371  0.000000  0.000000    1    0    3    3    0    1    1    0    3    0   \n",
       "372  0.078947  0.078947    3    3    1    3    3    3    3    0    1    3   \n",
       "373  0.000000  0.000000    1    1    3    1    0    1    1    3    0    3   \n",
       "374  0.078947  0.000000    3    0    1    1    0    1    1    1    1    3   \n",
       "375  0.000000  0.078947    1    3    0    3    1    3    0    3    3    1   \n",
       "376  0.078947  0.026316    3    3    1    3    3    0    1    3    1    0   \n",
       "377  0.078947  0.078947    3    3    1    1    1    3    0    3    1    1   \n",
       "378  0.026316  0.000000    0    3    1    1    1    1    1    0    1    0   \n",
       "379  0.078947  0.000000    3    3    1    0    1    1    1    1    3    1   \n",
       "\n",
       "     HTWinStreak3  HTWinStreak5  HTLossStreak3  HTLossStreak5  ATWinStreak3  \\\n",
       "370             1             1              0              0             1   \n",
       "371             0             0              0              0             0   \n",
       "372             0             0              0              0             0   \n",
       "373             0             0              0              0             0   \n",
       "374             0             0              0              0             0   \n",
       "375             0             0              0              0             0   \n",
       "376             0             0              0              0             0   \n",
       "377             0             0              1              0             0   \n",
       "378             0             0              1              0             0   \n",
       "379             0             0              0              0             0   \n",
       "\n",
       "     ATWinStreak5  ATLossStreak3  ATLossStreak5      HTGD      ATGD   DiffPts  \\\n",
       "370             0              0              0  0.526316 -0.342105  0.078947   \n",
       "371             0              0              0  0.026316  1.842105  0.000000   \n",
       "372             0              0              0 -0.157895  0.157895  0.000000   \n",
       "373             0              0              0  0.315789 -0.342105  0.000000   \n",
       "374             0              0              0 -0.184211  0.842105  0.078947   \n",
       "375             0              0              0 -0.763158  0.342105 -0.078947   \n",
       "376             0              0              0 -0.157895 -0.026316  0.052632   \n",
       "377             0              0              0  0.026316 -0.157895  0.000000   \n",
       "378             0              0              0 -0.184211 -0.315789  0.026316   \n",
       "379             0              0              0 -0.868421 -0.578947  0.078947   \n",
       "\n",
       "     DiffFormPts  DiffLP  \n",
       "370     0.157895      -4  \n",
       "371     0.078947       6  \n",
       "372     0.052632       5  \n",
       "373    -0.078947      -1  \n",
       "374     0.052632      16  \n",
       "375    -0.078947      13  \n",
       "376     0.184211      -6  \n",
       "377    -0.026316      -8  \n",
       "378     0.052632      -2  \n",
       "379     0.105263       0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = df3.set_index('match_api_id').join(df4.set_index('match_api_id'))\n",
    "df_test = df_test.reset_index()\n",
    "df_test = df_test.drop(columns = ['match_api_id'])\n",
    "df_test.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2660, 32)\n",
      "(2660,)\n",
      "(380, 32)\n",
      "(380,)\n",
      "(2660, 3)\n",
      "(380, 3)\n"
     ]
    }
   ],
   "source": [
    "x_train = df_train.drop(columns = ['FTR'])\n",
    "y_train = df_train['FTR']\n",
    "x_test = df_test.drop(columns = ['FTR'])\n",
    "y_test = df_test['FTR']\n",
    "bet_train = df_train[['B365H', 'B365D', 'B365A']]\n",
    "bet_test = df_test[['B365H', 'B365D', 'B365A']]\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "print(bet_train.shape)\n",
    "print(bet_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = x_train.values.shape[1]\n",
    "columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First neural model start here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 32)]              0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 41)                1353      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 75)                3150      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 228       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 4,731\n",
      "Trainable params: 4,731\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, Activation, Flatten, Dense, Dropout, LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# 41-75-3\n",
    "# We first need to define the sequence of dependencies (the computational graph)\n",
    "# x = Input(shape=(20,32))\n",
    "x = Input(shape=(columns,))\n",
    "# h = Conv2D(32, (7, 7), strides=(2, 2))(x)\n",
    "# h = Activation('relu')(x)\n",
    "h = Flatten()(x)\n",
    "h = Dense(41)(h)\n",
    "h = Dense(75)(h)\n",
    "h = Dense(3)(h)\n",
    "# for i in range(10):\n",
    "#     h = Dense(75)(h)\n",
    "h = Dropout(0.3)(h)\n",
    "p = Activation('softmax')(h)\n",
    "\n",
    "# Now that we have defined how to find p from x, we can create a \n",
    "# model simply by saying what is input and what is output\n",
    "model = Model(inputs=x, outputs=p)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(lr=0.00001), metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 3.9584 - accuracy: 0.2523 - val_loss: 3.1560 - val_accuracy: 0.2523\n",
      "Epoch 2/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 3.0392 - accuracy: 0.2523 - val_loss: 2.3423 - val_accuracy: 0.2804\n",
      "Epoch 3/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 2.3009 - accuracy: 0.2844 - val_loss: 1.7277 - val_accuracy: 0.3551\n",
      "Epoch 4/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.8356 - accuracy: 0.3036 - val_loss: 1.3525 - val_accuracy: 0.4673\n",
      "Epoch 5/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.5199 - accuracy: 0.3596 - val_loss: 1.2156 - val_accuracy: 0.4860\n",
      "Epoch 6/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.3899 - accuracy: 0.3909 - val_loss: 1.1452 - val_accuracy: 0.4860\n",
      "Epoch 7/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.3151 - accuracy: 0.4128 - val_loss: 1.1172 - val_accuracy: 0.5234\n",
      "Epoch 8/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.2907 - accuracy: 0.4207 - val_loss: 1.0951 - val_accuracy: 0.5327\n",
      "Epoch 9/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.2447 - accuracy: 0.4324 - val_loss: 1.0788 - val_accuracy: 0.5327\n",
      "Epoch 10/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.2109 - accuracy: 0.4332 - val_loss: 1.0677 - val_accuracy: 0.5234\n",
      "Epoch 11/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.2050 - accuracy: 0.4219 - val_loss: 1.0578 - val_accuracy: 0.5234\n",
      "Epoch 12/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.1802 - accuracy: 0.4289 - val_loss: 1.0454 - val_accuracy: 0.5327\n",
      "Epoch 13/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.1712 - accuracy: 0.4454 - val_loss: 1.0378 - val_accuracy: 0.5607\n",
      "Epoch 14/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.1436 - accuracy: 0.4501 - val_loss: 1.0286 - val_accuracy: 0.5701\n",
      "Epoch 15/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.1510 - accuracy: 0.4414 - val_loss: 1.0227 - val_accuracy: 0.5514\n",
      "Epoch 16/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.1225 - accuracy: 0.4516 - val_loss: 1.0159 - val_accuracy: 0.5794\n",
      "Epoch 17/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.1205 - accuracy: 0.4669 - val_loss: 1.0130 - val_accuracy: 0.5888\n",
      "Epoch 18/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.1233 - accuracy: 0.4587 - val_loss: 1.0070 - val_accuracy: 0.5888\n",
      "Epoch 19/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.1157 - accuracy: 0.4559 - val_loss: 1.0036 - val_accuracy: 0.5888\n",
      "Epoch 20/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.1053 - accuracy: 0.4563 - val_loss: 0.9963 - val_accuracy: 0.5981\n",
      "Epoch 21/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0942 - accuracy: 0.4571 - val_loss: 0.9930 - val_accuracy: 0.6168\n",
      "Epoch 22/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 1.0875 - accuracy: 0.4532 - val_loss: 0.9882 - val_accuracy: 0.6075\n",
      "Epoch 23/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0905 - accuracy: 0.4606 - val_loss: 0.9844 - val_accuracy: 0.5981\n",
      "Epoch 24/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0579 - accuracy: 0.4665 - val_loss: 0.9819 - val_accuracy: 0.5888\n",
      "Epoch 25/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0710 - accuracy: 0.4677 - val_loss: 0.9750 - val_accuracy: 0.5981\n",
      "Epoch 26/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0592 - accuracy: 0.4673 - val_loss: 0.9740 - val_accuracy: 0.5794\n",
      "Epoch 27/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0464 - accuracy: 0.4818 - val_loss: 0.9723 - val_accuracy: 0.5888\n",
      "Epoch 28/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0433 - accuracy: 0.4712 - val_loss: 0.9684 - val_accuracy: 0.5794\n",
      "Epoch 29/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0526 - accuracy: 0.4685 - val_loss: 0.9646 - val_accuracy: 0.5888\n",
      "Epoch 30/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0313 - accuracy: 0.4693 - val_loss: 0.9649 - val_accuracy: 0.5794\n",
      "Epoch 31/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0414 - accuracy: 0.4677 - val_loss: 0.9636 - val_accuracy: 0.5794\n",
      "Epoch 32/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0311 - accuracy: 0.4845 - val_loss: 0.9643 - val_accuracy: 0.5794\n",
      "Epoch 33/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0266 - accuracy: 0.4865 - val_loss: 0.9615 - val_accuracy: 0.5794\n",
      "Epoch 34/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0314 - accuracy: 0.4638 - val_loss: 0.9574 - val_accuracy: 0.5794\n",
      "Epoch 35/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0296 - accuracy: 0.4677 - val_loss: 0.9580 - val_accuracy: 0.5701\n",
      "Epoch 36/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0157 - accuracy: 0.4837 - val_loss: 0.9541 - val_accuracy: 0.5794\n",
      "Epoch 37/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0180 - accuracy: 0.4743 - val_loss: 0.9549 - val_accuracy: 0.5607\n",
      "Epoch 38/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0232 - accuracy: 0.4693 - val_loss: 0.9513 - val_accuracy: 0.5701\n",
      "Epoch 39/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0143 - accuracy: 0.4861 - val_loss: 0.9494 - val_accuracy: 0.5701\n",
      "Epoch 40/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0133 - accuracy: 0.4755 - val_loss: 0.9491 - val_accuracy: 0.5794\n",
      "Epoch 41/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0067 - accuracy: 0.4790 - val_loss: 0.9525 - val_accuracy: 0.5607\n",
      "Epoch 42/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0055 - accuracy: 0.4779 - val_loss: 0.9512 - val_accuracy: 0.5607\n",
      "Epoch 43/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0094 - accuracy: 0.4763 - val_loss: 0.9503 - val_accuracy: 0.5701\n",
      "Epoch 44/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9922 - accuracy: 0.4986 - val_loss: 0.9508 - val_accuracy: 0.5701\n",
      "Epoch 45/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9934 - accuracy: 0.4837 - val_loss: 0.9475 - val_accuracy: 0.5701\n",
      "Epoch 46/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9982 - accuracy: 0.4888 - val_loss: 0.9468 - val_accuracy: 0.5607\n",
      "Epoch 47/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0011 - accuracy: 0.4841 - val_loss: 0.9472 - val_accuracy: 0.5794\n",
      "Epoch 48/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0027 - accuracy: 0.4665 - val_loss: 0.9445 - val_accuracy: 0.5701\n",
      "Epoch 49/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9992 - accuracy: 0.4708 - val_loss: 0.9450 - val_accuracy: 0.5607\n",
      "Epoch 50/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9911 - accuracy: 0.4841 - val_loss: 0.9449 - val_accuracy: 0.5514\n",
      "Epoch 51/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.0053 - accuracy: 0.4747 - val_loss: 0.9440 - val_accuracy: 0.5607\n",
      "Epoch 52/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9908 - accuracy: 0.4924 - val_loss: 0.9427 - val_accuracy: 0.5794\n",
      "Epoch 53/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9856 - accuracy: 0.4806 - val_loss: 0.9443 - val_accuracy: 0.5794\n",
      "Epoch 54/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9865 - accuracy: 0.4806 - val_loss: 0.9441 - val_accuracy: 0.5888\n",
      "Epoch 55/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.9819 - accuracy: 0.4810 - val_loss: 0.9450 - val_accuracy: 0.5794\n",
      "Epoch 56/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9839 - accuracy: 0.4959 - val_loss: 0.9447 - val_accuracy: 0.5794\n",
      "Epoch 57/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9866 - accuracy: 0.4955 - val_loss: 0.9460 - val_accuracy: 0.5794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9840 - accuracy: 0.4904 - val_loss: 0.9440 - val_accuracy: 0.5888\n",
      "Epoch 59/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9866 - accuracy: 0.4837 - val_loss: 0.9443 - val_accuracy: 0.5888\n",
      "Epoch 60/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9849 - accuracy: 0.4916 - val_loss: 0.9426 - val_accuracy: 0.5981\n",
      "Epoch 61/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9827 - accuracy: 0.5010 - val_loss: 0.9450 - val_accuracy: 0.5794\n",
      "Epoch 62/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9819 - accuracy: 0.4924 - val_loss: 0.9424 - val_accuracy: 0.5981\n",
      "Epoch 63/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9816 - accuracy: 0.5006 - val_loss: 0.9402 - val_accuracy: 0.5701\n",
      "Epoch 64/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.9834 - accuracy: 0.4951 - val_loss: 0.9401 - val_accuracy: 0.5981\n",
      "Epoch 65/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.9817 - accuracy: 0.4892 - val_loss: 0.9431 - val_accuracy: 0.5888\n",
      "Epoch 66/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.9840 - accuracy: 0.4837 - val_loss: 0.9405 - val_accuracy: 0.6075\n",
      "Epoch 67/200\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.9824 - accuracy: 0.4857 - val_loss: 0.9386 - val_accuracy: 0.5701\n",
      "Epoch 68/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9792 - accuracy: 0.4986 - val_loss: 0.9410 - val_accuracy: 0.6075\n",
      "Epoch 69/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9787 - accuracy: 0.4994 - val_loss: 0.9422 - val_accuracy: 0.5981\n",
      "Epoch 70/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9748 - accuracy: 0.4939 - val_loss: 0.9433 - val_accuracy: 0.5981\n",
      "Epoch 71/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9802 - accuracy: 0.4994 - val_loss: 0.9451 - val_accuracy: 0.5701\n",
      "Epoch 72/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9814 - accuracy: 0.4967 - val_loss: 0.9435 - val_accuracy: 0.5981\n",
      "Epoch 73/200\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.9690 - accuracy: 0.5076 - val_loss: 0.9427 - val_accuracy: 0.5981\n",
      "Epoch 74/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9791 - accuracy: 0.4931 - val_loss: 0.9420 - val_accuracy: 0.5888\n",
      "Epoch 75/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9794 - accuracy: 0.4982 - val_loss: 0.9414 - val_accuracy: 0.5888\n",
      "Epoch 76/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9709 - accuracy: 0.5006 - val_loss: 0.9448 - val_accuracy: 0.5607\n",
      "Epoch 77/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9706 - accuracy: 0.4994 - val_loss: 0.9466 - val_accuracy: 0.5607\n",
      "Epoch 78/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9686 - accuracy: 0.5033 - val_loss: 0.9450 - val_accuracy: 0.5607\n",
      "Epoch 79/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9758 - accuracy: 0.5061 - val_loss: 0.9444 - val_accuracy: 0.5794\n",
      "Epoch 80/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9745 - accuracy: 0.5022 - val_loss: 0.9436 - val_accuracy: 0.5701\n",
      "Epoch 81/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9780 - accuracy: 0.4865 - val_loss: 0.9438 - val_accuracy: 0.5701\n",
      "Epoch 82/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9766 - accuracy: 0.4790 - val_loss: 0.9452 - val_accuracy: 0.5514\n",
      "Epoch 83/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9714 - accuracy: 0.4912 - val_loss: 0.9414 - val_accuracy: 0.5888\n",
      "Epoch 84/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9618 - accuracy: 0.5096 - val_loss: 0.9395 - val_accuracy: 0.5888\n",
      "Epoch 85/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9731 - accuracy: 0.4955 - val_loss: 0.9405 - val_accuracy: 0.5888\n",
      "Epoch 86/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9690 - accuracy: 0.5033 - val_loss: 0.9419 - val_accuracy: 0.5794\n",
      "Epoch 87/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9620 - accuracy: 0.5178 - val_loss: 0.9412 - val_accuracy: 0.5794\n",
      "Epoch 88/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9629 - accuracy: 0.5119 - val_loss: 0.9412 - val_accuracy: 0.5888\n",
      "Epoch 89/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9655 - accuracy: 0.5147 - val_loss: 0.9421 - val_accuracy: 0.5607\n",
      "Epoch 90/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9689 - accuracy: 0.5088 - val_loss: 0.9408 - val_accuracy: 0.5888\n",
      "Epoch 91/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9782 - accuracy: 0.5049 - val_loss: 0.9441 - val_accuracy: 0.5514\n",
      "Epoch 92/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9717 - accuracy: 0.5080 - val_loss: 0.9407 - val_accuracy: 0.5888\n",
      "Epoch 93/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9672 - accuracy: 0.5108 - val_loss: 0.9411 - val_accuracy: 0.5701\n",
      "Epoch 94/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9623 - accuracy: 0.5166 - val_loss: 0.9407 - val_accuracy: 0.5888\n",
      "Epoch 95/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9595 - accuracy: 0.5108 - val_loss: 0.9391 - val_accuracy: 0.5888\n",
      "Epoch 96/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9638 - accuracy: 0.5116 - val_loss: 0.9408 - val_accuracy: 0.5794\n",
      "Epoch 97/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.9625 - accuracy: 0.5096 - val_loss: 0.9397 - val_accuracy: 0.5888\n",
      "Epoch 98/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.9677 - accuracy: 0.5186 - val_loss: 0.9411 - val_accuracy: 0.5888\n",
      "Epoch 99/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9673 - accuracy: 0.5119 - val_loss: 0.9420 - val_accuracy: 0.5701\n",
      "Epoch 100/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9701 - accuracy: 0.5100 - val_loss: 0.9417 - val_accuracy: 0.5794\n",
      "Epoch 101/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9624 - accuracy: 0.4990 - val_loss: 0.9428 - val_accuracy: 0.5794\n",
      "Epoch 102/200\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.9639 - accuracy: 0.5178 - val_loss: 0.9407 - val_accuracy: 0.5888\n",
      "Epoch 103/200\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.9670 - accuracy: 0.5112 - val_loss: 0.9430 - val_accuracy: 0.5701\n",
      "Epoch 104/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9690 - accuracy: 0.5131 - val_loss: 0.9383 - val_accuracy: 0.5888\n",
      "Epoch 105/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.9656 - accuracy: 0.5202 - val_loss: 0.9375 - val_accuracy: 0.5888\n",
      "Epoch 106/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9677 - accuracy: 0.5033 - val_loss: 0.9380 - val_accuracy: 0.5888\n",
      "Epoch 107/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9627 - accuracy: 0.5076 - val_loss: 0.9407 - val_accuracy: 0.5701\n",
      "Epoch 108/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9625 - accuracy: 0.5119 - val_loss: 0.9422 - val_accuracy: 0.5794\n",
      "Epoch 109/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.9716 - accuracy: 0.5057 - val_loss: 0.9423 - val_accuracy: 0.5794\n",
      "Epoch 110/200\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.9575 - accuracy: 0.5065 - val_loss: 0.9426 - val_accuracy: 0.5701\n",
      "Epoch 111/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9679 - accuracy: 0.5006 - val_loss: 0.9401 - val_accuracy: 0.5794\n",
      "Epoch 112/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9650 - accuracy: 0.5084 - val_loss: 0.9431 - val_accuracy: 0.5607\n",
      "Epoch 113/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.9661 - accuracy: 0.5033 - val_loss: 0.9415 - val_accuracy: 0.5888\n",
      "Epoch 114/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9618 - accuracy: 0.5100 - val_loss: 0.9417 - val_accuracy: 0.5888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9565 - accuracy: 0.5202 - val_loss: 0.9417 - val_accuracy: 0.5701\n",
      "Epoch 116/200\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.9679 - accuracy: 0.5182 - val_loss: 0.9413 - val_accuracy: 0.5888\n",
      "Epoch 117/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9657 - accuracy: 0.5049 - val_loss: 0.9434 - val_accuracy: 0.5794\n",
      "Epoch 118/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9535 - accuracy: 0.5280 - val_loss: 0.9402 - val_accuracy: 0.5888\n",
      "Epoch 119/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9687 - accuracy: 0.5112 - val_loss: 0.9408 - val_accuracy: 0.5888\n",
      "Epoch 120/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9654 - accuracy: 0.5022 - val_loss: 0.9417 - val_accuracy: 0.5794\n",
      "Epoch 121/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9587 - accuracy: 0.5147 - val_loss: 0.9432 - val_accuracy: 0.5794\n",
      "Epoch 122/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.9649 - accuracy: 0.5069 - val_loss: 0.9423 - val_accuracy: 0.5794\n",
      "Epoch 123/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9677 - accuracy: 0.5069 - val_loss: 0.9447 - val_accuracy: 0.5701\n",
      "Epoch 124/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9609 - accuracy: 0.5119 - val_loss: 0.9451 - val_accuracy: 0.5701\n",
      "Epoch 125/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9582 - accuracy: 0.5233 - val_loss: 0.9437 - val_accuracy: 0.5888\n",
      "Epoch 126/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9639 - accuracy: 0.5080 - val_loss: 0.9424 - val_accuracy: 0.5794\n",
      "Epoch 127/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9579 - accuracy: 0.5096 - val_loss: 0.9430 - val_accuracy: 0.5888\n",
      "Epoch 128/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9557 - accuracy: 0.5135 - val_loss: 0.9453 - val_accuracy: 0.5794\n",
      "Epoch 129/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9631 - accuracy: 0.5131 - val_loss: 0.9455 - val_accuracy: 0.5701\n",
      "Epoch 130/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.9606 - accuracy: 0.5119 - val_loss: 0.9453 - val_accuracy: 0.5794\n",
      "Epoch 131/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9660 - accuracy: 0.5053 - val_loss: 0.9478 - val_accuracy: 0.5607\n",
      "Epoch 132/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9566 - accuracy: 0.5147 - val_loss: 0.9466 - val_accuracy: 0.5794\n",
      "Epoch 133/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9631 - accuracy: 0.5096 - val_loss: 0.9442 - val_accuracy: 0.5888\n",
      "Epoch 134/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9631 - accuracy: 0.5147 - val_loss: 0.9449 - val_accuracy: 0.5794\n",
      "Epoch 135/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9554 - accuracy: 0.5210 - val_loss: 0.9442 - val_accuracy: 0.5794\n",
      "Epoch 136/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9640 - accuracy: 0.5127 - val_loss: 0.9459 - val_accuracy: 0.5607\n",
      "Epoch 137/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9571 - accuracy: 0.5112 - val_loss: 0.9440 - val_accuracy: 0.5888\n",
      "Epoch 138/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9646 - accuracy: 0.5022 - val_loss: 0.9454 - val_accuracy: 0.5794\n",
      "Epoch 139/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9536 - accuracy: 0.5304 - val_loss: 0.9445 - val_accuracy: 0.5888\n",
      "Epoch 140/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9636 - accuracy: 0.5135 - val_loss: 0.9441 - val_accuracy: 0.5701\n",
      "Epoch 141/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9637 - accuracy: 0.5053 - val_loss: 0.9456 - val_accuracy: 0.5701\n",
      "Epoch 142/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.9545 - accuracy: 0.5143 - val_loss: 0.9453 - val_accuracy: 0.5794\n",
      "Epoch 143/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9666 - accuracy: 0.5065 - val_loss: 0.9417 - val_accuracy: 0.5794\n",
      "Epoch 144/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.9508 - accuracy: 0.5213 - val_loss: 0.9420 - val_accuracy: 0.5888\n",
      "Epoch 145/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9586 - accuracy: 0.5174 - val_loss: 0.9479 - val_accuracy: 0.5701\n",
      "Epoch 146/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9628 - accuracy: 0.5163 - val_loss: 0.9487 - val_accuracy: 0.5514\n",
      "Epoch 147/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9576 - accuracy: 0.5155 - val_loss: 0.9453 - val_accuracy: 0.5701\n",
      "Epoch 148/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9597 - accuracy: 0.5178 - val_loss: 0.9470 - val_accuracy: 0.5794\n",
      "Epoch 149/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9647 - accuracy: 0.5135 - val_loss: 0.9457 - val_accuracy: 0.5888\n",
      "Epoch 150/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9662 - accuracy: 0.5253 - val_loss: 0.9457 - val_accuracy: 0.5794\n",
      "Epoch 151/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9594 - accuracy: 0.5076 - val_loss: 0.9450 - val_accuracy: 0.5701\n",
      "Epoch 152/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9554 - accuracy: 0.5127 - val_loss: 0.9495 - val_accuracy: 0.5607\n",
      "Epoch 153/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9617 - accuracy: 0.5045 - val_loss: 0.9454 - val_accuracy: 0.5888\n",
      "Epoch 154/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9637 - accuracy: 0.5202 - val_loss: 0.9454 - val_accuracy: 0.5794\n",
      "Epoch 155/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9636 - accuracy: 0.5041 - val_loss: 0.9465 - val_accuracy: 0.5888\n",
      "Epoch 156/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9612 - accuracy: 0.5139 - val_loss: 0.9456 - val_accuracy: 0.5888\n",
      "Epoch 157/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9626 - accuracy: 0.5104 - val_loss: 0.9478 - val_accuracy: 0.5701\n",
      "Epoch 158/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9685 - accuracy: 0.5100 - val_loss: 0.9462 - val_accuracy: 0.5888\n",
      "Epoch 159/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9594 - accuracy: 0.5049 - val_loss: 0.9463 - val_accuracy: 0.5794\n",
      "Epoch 160/200\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.9639 - accuracy: 0.5135 - val_loss: 0.9448 - val_accuracy: 0.5888\n",
      "Epoch 161/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9625 - accuracy: 0.5080 - val_loss: 0.9442 - val_accuracy: 0.5888\n",
      "Epoch 162/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9475 - accuracy: 0.5284 - val_loss: 0.9432 - val_accuracy: 0.5888\n",
      "Epoch 163/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9578 - accuracy: 0.5112 - val_loss: 0.9445 - val_accuracy: 0.5888\n",
      "Epoch 164/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9600 - accuracy: 0.5178 - val_loss: 0.9466 - val_accuracy: 0.5794\n",
      "Epoch 165/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9613 - accuracy: 0.5065 - val_loss: 0.9446 - val_accuracy: 0.5981\n",
      "Epoch 166/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9610 - accuracy: 0.5127 - val_loss: 0.9445 - val_accuracy: 0.5888\n",
      "Epoch 167/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9596 - accuracy: 0.5080 - val_loss: 0.9478 - val_accuracy: 0.5701\n",
      "Epoch 168/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9515 - accuracy: 0.5284 - val_loss: 0.9444 - val_accuracy: 0.5888\n",
      "Epoch 169/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9630 - accuracy: 0.5147 - val_loss: 0.9490 - val_accuracy: 0.5701\n",
      "Epoch 170/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9603 - accuracy: 0.5135 - val_loss: 0.9469 - val_accuracy: 0.5794\n",
      "Epoch 171/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9609 - accuracy: 0.5127 - val_loss: 0.9488 - val_accuracy: 0.5794\n",
      "Epoch 172/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9539 - accuracy: 0.5186 - val_loss: 0.9482 - val_accuracy: 0.5888\n",
      "Epoch 173/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9573 - accuracy: 0.5127 - val_loss: 0.9465 - val_accuracy: 0.5794\n",
      "Epoch 174/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9633 - accuracy: 0.5182 - val_loss: 0.9448 - val_accuracy: 0.5981\n",
      "Epoch 175/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9567 - accuracy: 0.5202 - val_loss: 0.9458 - val_accuracy: 0.5794\n",
      "Epoch 176/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9673 - accuracy: 0.5108 - val_loss: 0.9457 - val_accuracy: 0.5888\n",
      "Epoch 177/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9621 - accuracy: 0.5096 - val_loss: 0.9454 - val_accuracy: 0.5794\n",
      "Epoch 178/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9554 - accuracy: 0.5221 - val_loss: 0.9478 - val_accuracy: 0.5794\n",
      "Epoch 179/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9582 - accuracy: 0.5147 - val_loss: 0.9466 - val_accuracy: 0.5794\n",
      "Epoch 180/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9555 - accuracy: 0.5166 - val_loss: 0.9482 - val_accuracy: 0.5794\n",
      "Epoch 181/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9652 - accuracy: 0.5174 - val_loss: 0.9432 - val_accuracy: 0.5888\n",
      "Epoch 182/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9567 - accuracy: 0.5210 - val_loss: 0.9439 - val_accuracy: 0.5981\n",
      "Epoch 183/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9629 - accuracy: 0.5076 - val_loss: 0.9459 - val_accuracy: 0.5888\n",
      "Epoch 184/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9619 - accuracy: 0.5080 - val_loss: 0.9476 - val_accuracy: 0.5794\n",
      "Epoch 185/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9533 - accuracy: 0.5139 - val_loss: 0.9489 - val_accuracy: 0.5701\n",
      "Epoch 186/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9577 - accuracy: 0.5166 - val_loss: 0.9494 - val_accuracy: 0.5701\n",
      "Epoch 187/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9609 - accuracy: 0.5190 - val_loss: 0.9481 - val_accuracy: 0.5794\n",
      "Epoch 188/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9660 - accuracy: 0.5186 - val_loss: 0.9473 - val_accuracy: 0.5794\n",
      "Epoch 189/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9535 - accuracy: 0.5229 - val_loss: 0.9464 - val_accuracy: 0.5888\n",
      "Epoch 190/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9671 - accuracy: 0.5049 - val_loss: 0.9448 - val_accuracy: 0.5981\n",
      "Epoch 191/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9564 - accuracy: 0.5194 - val_loss: 0.9444 - val_accuracy: 0.5981\n",
      "Epoch 192/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.9615 - accuracy: 0.5147 - val_loss: 0.9451 - val_accuracy: 0.5888\n",
      "Epoch 193/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9606 - accuracy: 0.5182 - val_loss: 0.9482 - val_accuracy: 0.5888\n",
      "Epoch 194/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9582 - accuracy: 0.5139 - val_loss: 0.9461 - val_accuracy: 0.5981\n",
      "Epoch 195/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9534 - accuracy: 0.5272 - val_loss: 0.9462 - val_accuracy: 0.5888\n",
      "Epoch 196/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9573 - accuracy: 0.5221 - val_loss: 0.9457 - val_accuracy: 0.5888\n",
      "Epoch 197/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9654 - accuracy: 0.5131 - val_loss: 0.9478 - val_accuracy: 0.5888\n",
      "Epoch 198/200\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.9548 - accuracy: 0.5288 - val_loss: 0.9463 - val_accuracy: 0.5888\n",
      "Epoch 199/200\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.9557 - accuracy: 0.5135 - val_loss: 0.9475 - val_accuracy: 0.5981\n",
      "Epoch 200/200\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.9557 - accuracy: 0.5186 - val_loss: 0.9492 - val_accuracy: 0.5888\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, batch_size=16, epochs=200, validation_split=0.04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='validation')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'], label='train')\n",
    "plt.plot(history.history['val_accuracy'], label='validation')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.55\n"
     ]
    }
   ],
   "source": [
    "predictions = np.argmax(model.predict(x_test), axis=1)\n",
    "accuracy = (predictions == y_test.values).sum() / y_test.values.shape[0]\n",
    "print(\"Test set accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Betting Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agencies = ['B365', 'BW', 'IW', 'LB', 'WH', 'SJ', 'VC', 'GB', 'BS']\n",
    "agencies = ['B365']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set size (380,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Test set size\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x = [1,2,np.nan]\n",
    "# np.nansum(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agency B365, \twin amount: 475.51\n",
      "Agency B365, \twin amount: -37.26\n"
     ]
    }
   ],
   "source": [
    "## Profit for Away Wins Only \n",
    "predict_always_on_one_thing_benefit(y_train, bet_train, [0]) #Data Train\n",
    "predict_always_on_one_thing_benefit(y_test, bet_test, [0]) #Data Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agency B365, \twin amount: -345.36\n",
      "Agency B365, \twin amount: -92.20\n"
     ]
    }
   ],
   "source": [
    "## Profit for Draw Only \n",
    "predict_always_on_one_thing_benefit(y_train, bet_train, [1]) #Data Train\n",
    "predict_always_on_one_thing_benefit(y_test, bet_test, [1]) #Data Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agency B365, \twin amount: 6797.98\n",
      "Agency B365, \twin amount: 582.66\n"
     ]
    }
   ],
   "source": [
    "## Profit for Home Wins Only \n",
    "predict_always_on_one_thing_benefit(y_train, bet_train, [2]) #Data Train\n",
    "predict_always_on_one_thing_benefit(y_test, bet_test, [2]) #Data Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agency B365, \twin amount: 7273.49\n",
      "Agency B365, \twin amount: 545.40\n"
     ]
    }
   ],
   "source": [
    "## Profit for Home or Away \n",
    "predict_always_on_one_thing_benefit(y_train, bet_train, [0, 2]) #Data Train\n",
    "predict_always_on_one_thing_benefit(y_test, bet_test, [0, 2]) #Data Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agency B365, \twin amount: 6928.13\n",
      "Agency B365, \twin amount: 453.20\n"
     ]
    }
   ],
   "source": [
    "## Profit for All Possibilities\n",
    "predict_always_on_one_thing_benefit(y_train, bet_train, [0, 1, 2]) #Data Train\n",
    "predict_always_on_one_thing_benefit(y_test, bet_test, [0, 1, 2]) #Data Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions_3x1 = model.predict(x_train)\n",
    "test_predictions_3x1 = model.predict(x_test)\n",
    "train_predictions = np.argmax(train_predictions_3x1 , axis=1)\n",
    "test_predictions = np.argmax(test_predictions_3x1 , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2660, 3)\n",
      "(380, 3)\n"
     ]
    }
   ],
   "source": [
    "# train_predictions\n",
    "# test_predictions\n",
    "print(train_predictions_3x1.shape)\n",
    "print(test_predictions_3x1.shape)\n",
    "# x_train.shape\n",
    "# x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agency B365, \twin amount: 8829.68\n",
      "Agency B365, \twin amount: 733.60\n"
     ]
    }
   ],
   "source": [
    "always_bet_predicted_winner_profit(train_predictions, y_train, bet_train)\n",
    "always_bet_predicted_winner_profit(test_predictions, y_test, bet_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agency B365, \twin amount: 9913.08. Didn't bet on 45.41% of matches\n",
      "Agency B365, \twin amount: 894.86. Didn't bet on 46.58% of matches\n"
     ]
    }
   ],
   "source": [
    "bet_predicted_winner_with_threshold_profit(train_predictions_3x1, train_predictions, y_train, bet_train, threshold=1)\n",
    "bet_predicted_winner_with_threshold_profit(test_predictions_3x1, test_predictions, y_test, bet_test, threshold=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agency B365, \twin amount: -283.00. Didn't bet on 60.38% of matches\n",
      "Agency B365, \twin amount: -32.00. Didn't bet on 70.53% of matches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in greater\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "predict_on_highest_return(train_predictions_3x1, y_train, bet_train, threshold=2.5)\n",
    "predict_on_highest_return(test_predictions_3x1, y_test, bet_test, threshold=2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
